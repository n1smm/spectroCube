// modules are defined as an array
// [ module function, map of requires ]
//
// map of requires is short require name -> numeric require
//
// anything defined in a previous bundle is accessed via the
// orig method which is the require for previous bundles

(function (modules, entry, mainEntry, parcelRequireName, globalName) {
  /* eslint-disable no-undef */
  var globalObject =
    typeof globalThis !== 'undefined'
      ? globalThis
      : typeof self !== 'undefined'
      ? self
      : typeof window !== 'undefined'
      ? window
      : typeof global !== 'undefined'
      ? global
      : {};
  /* eslint-enable no-undef */

  // Save the require from previous bundle to this closure if any
  var previousRequire =
    typeof globalObject[parcelRequireName] === 'function' &&
    globalObject[parcelRequireName];

  var cache = previousRequire.cache || {};
  // Do not use `require` to prevent Webpack from trying to bundle this call
  var nodeRequire =
    typeof module !== 'undefined' &&
    typeof module.require === 'function' &&
    module.require.bind(module);

  function newRequire(name, jumped) {
    if (!cache[name]) {
      if (!modules[name]) {
        // if we cannot find the module within our internal map or
        // cache jump to the current global require ie. the last bundle
        // that was added to the page.
        var currentRequire =
          typeof globalObject[parcelRequireName] === 'function' &&
          globalObject[parcelRequireName];
        if (!jumped && currentRequire) {
          return currentRequire(name, true);
        }

        // If there are other bundles on this page the require from the
        // previous one is saved to 'previousRequire'. Repeat this as
        // many times as there are bundles until the module is found or
        // we exhaust the require chain.
        if (previousRequire) {
          return previousRequire(name, true);
        }

        // Try the node require function if it exists.
        if (nodeRequire && typeof name === 'string') {
          return nodeRequire(name);
        }

        var err = new Error("Cannot find module '" + name + "'");
        err.code = 'MODULE_NOT_FOUND';
        throw err;
      }

      localRequire.resolve = resolve;
      localRequire.cache = {};

      var module = (cache[name] = new newRequire.Module(name));

      modules[name][0].call(
        module.exports,
        localRequire,
        module,
        module.exports,
        this
      );
    }

    return cache[name].exports;

    function localRequire(x) {
      var res = localRequire.resolve(x);
      return res === false ? {} : newRequire(res);
    }

    function resolve(x) {
      var id = modules[name][1][x];
      return id != null ? id : x;
    }
  }

  function Module(moduleName) {
    this.id = moduleName;
    this.bundle = newRequire;
    this.exports = {};
  }

  newRequire.isParcelRequire = true;
  newRequire.Module = Module;
  newRequire.modules = modules;
  newRequire.cache = cache;
  newRequire.parent = previousRequire;
  newRequire.register = function (id, exports) {
    modules[id] = [
      function (require, module) {
        module.exports = exports;
      },
      {},
    ];
  };

  Object.defineProperty(newRequire, 'root', {
    get: function () {
      return globalObject[parcelRequireName];
    },
  });

  globalObject[parcelRequireName] = newRequire;

  for (var i = 0; i < entry.length; i++) {
    newRequire(entry[i]);
  }

  if (mainEntry) {
    // Expose entry point to Node, AMD or browser globals
    // Based on https://github.com/ForbesLindesay/umd/blob/master/template.js
    var mainExports = newRequire(mainEntry);

    // CommonJS
    if (typeof exports === 'object' && typeof module !== 'undefined') {
      module.exports = mainExports;

      // RequireJS
    } else if (typeof define === 'function' && define.amd) {
      define(function () {
        return mainExports;
      });

      // <script>
    } else if (globalName) {
      this[globalName] = mainExports;
    }
  }
})({"aP7aF":[function(require,module,exports) {
var global = arguments[3];
var HMR_HOST = null;
var HMR_PORT = null;
var HMR_SECURE = false;
var HMR_ENV_HASH = "d6ea1d42532a7575";
var HMR_USE_SSE = false;
module.bundle.HMR_BUNDLE_ID = "d7fe96c059a40e7a";
"use strict";
/* global HMR_HOST, HMR_PORT, HMR_ENV_HASH, HMR_SECURE, HMR_USE_SSE, chrome, browser, __parcel__import__, __parcel__importScripts__, ServiceWorkerGlobalScope */ /*::
import type {
  HMRAsset,
  HMRMessage,
} from '@parcel/reporter-dev-server/src/HMRServer.js';
interface ParcelRequire {
  (string): mixed;
  cache: {|[string]: ParcelModule|};
  hotData: {|[string]: mixed|};
  Module: any;
  parent: ?ParcelRequire;
  isParcelRequire: true;
  modules: {|[string]: [Function, {|[string]: string|}]|};
  HMR_BUNDLE_ID: string;
  root: ParcelRequire;
}
interface ParcelModule {
  hot: {|
    data: mixed,
    accept(cb: (Function) => void): void,
    dispose(cb: (mixed) => void): void,
    // accept(deps: Array<string> | string, cb: (Function) => void): void,
    // decline(): void,
    _acceptCallbacks: Array<(Function) => void>,
    _disposeCallbacks: Array<(mixed) => void>,
  |};
}
interface ExtensionContext {
  runtime: {|
    reload(): void,
    getURL(url: string): string;
    getManifest(): {manifest_version: number, ...};
  |};
}
declare var module: {bundle: ParcelRequire, ...};
declare var HMR_HOST: string;
declare var HMR_PORT: string;
declare var HMR_ENV_HASH: string;
declare var HMR_SECURE: boolean;
declare var HMR_USE_SSE: boolean;
declare var chrome: ExtensionContext;
declare var browser: ExtensionContext;
declare var __parcel__import__: (string) => Promise<void>;
declare var __parcel__importScripts__: (string) => Promise<void>;
declare var globalThis: typeof self;
declare var ServiceWorkerGlobalScope: Object;
*/ var OVERLAY_ID = "__parcel__error__overlay__";
var OldModule = module.bundle.Module;
function Module(moduleName) {
    OldModule.call(this, moduleName);
    this.hot = {
        data: module.bundle.hotData[moduleName],
        _acceptCallbacks: [],
        _disposeCallbacks: [],
        accept: function(fn) {
            this._acceptCallbacks.push(fn || function() {});
        },
        dispose: function(fn) {
            this._disposeCallbacks.push(fn);
        }
    };
    module.bundle.hotData[moduleName] = undefined;
}
module.bundle.Module = Module;
module.bundle.hotData = {};
var checkedAssets /*: {|[string]: boolean|} */ , assetsToDispose /*: Array<[ParcelRequire, string]> */ , assetsToAccept /*: Array<[ParcelRequire, string]> */ ;
function getHostname() {
    return HMR_HOST || (location.protocol.indexOf("http") === 0 ? location.hostname : "localhost");
}
function getPort() {
    return HMR_PORT || location.port;
}
// eslint-disable-next-line no-redeclare
var parent = module.bundle.parent;
if ((!parent || !parent.isParcelRequire) && typeof WebSocket !== "undefined") {
    var hostname = getHostname();
    var port = getPort();
    var protocol = HMR_SECURE || location.protocol == "https:" && ![
        "localhost",
        "127.0.0.1",
        "0.0.0.0"
    ].includes(hostname) ? "wss" : "ws";
    var ws;
    if (HMR_USE_SSE) ws = new EventSource("/__parcel_hmr");
    else try {
        ws = new WebSocket(protocol + "://" + hostname + (port ? ":" + port : "") + "/");
    } catch (err) {
        if (err.message) console.error(err.message);
        ws = {};
    }
    // Web extension context
    var extCtx = typeof browser === "undefined" ? typeof chrome === "undefined" ? null : chrome : browser;
    // Safari doesn't support sourceURL in error stacks.
    // eval may also be disabled via CSP, so do a quick check.
    var supportsSourceURL = false;
    try {
        (0, eval)('throw new Error("test"); //# sourceURL=test.js');
    } catch (err) {
        supportsSourceURL = err.stack.includes("test.js");
    }
    // $FlowFixMe
    ws.onmessage = async function(event /*: {data: string, ...} */ ) {
        checkedAssets = {} /*: {|[string]: boolean|} */ ;
        assetsToAccept = [];
        assetsToDispose = [];
        var data /*: HMRMessage */  = JSON.parse(event.data);
        if (data.type === "update") {
            // Remove error overlay if there is one
            if (typeof document !== "undefined") removeErrorOverlay();
            let assets = data.assets.filter((asset)=>asset.envHash === HMR_ENV_HASH);
            // Handle HMR Update
            let handled = assets.every((asset)=>{
                return asset.type === "css" || asset.type === "js" && hmrAcceptCheck(module.bundle.root, asset.id, asset.depsByBundle);
            });
            if (handled) {
                console.clear();
                // Dispatch custom event so other runtimes (e.g React Refresh) are aware.
                if (typeof window !== "undefined" && typeof CustomEvent !== "undefined") window.dispatchEvent(new CustomEvent("parcelhmraccept"));
                await hmrApplyUpdates(assets);
                // Dispose all old assets.
                let processedAssets = {} /*: {|[string]: boolean|} */ ;
                for(let i = 0; i < assetsToDispose.length; i++){
                    let id = assetsToDispose[i][1];
                    if (!processedAssets[id]) {
                        hmrDispose(assetsToDispose[i][0], id);
                        processedAssets[id] = true;
                    }
                }
                // Run accept callbacks. This will also re-execute other disposed assets in topological order.
                processedAssets = {};
                for(let i = 0; i < assetsToAccept.length; i++){
                    let id = assetsToAccept[i][1];
                    if (!processedAssets[id]) {
                        hmrAccept(assetsToAccept[i][0], id);
                        processedAssets[id] = true;
                    }
                }
            } else fullReload();
        }
        if (data.type === "error") {
            // Log parcel errors to console
            for (let ansiDiagnostic of data.diagnostics.ansi){
                let stack = ansiDiagnostic.codeframe ? ansiDiagnostic.codeframe : ansiDiagnostic.stack;
                console.error("\uD83D\uDEA8 [parcel]: " + ansiDiagnostic.message + "\n" + stack + "\n\n" + ansiDiagnostic.hints.join("\n"));
            }
            if (typeof document !== "undefined") {
                // Render the fancy html overlay
                removeErrorOverlay();
                var overlay = createErrorOverlay(data.diagnostics.html);
                // $FlowFixMe
                document.body.appendChild(overlay);
            }
        }
    };
    if (ws instanceof WebSocket) {
        ws.onerror = function(e) {
            if (e.message) console.error(e.message);
        };
        ws.onclose = function() {
            console.warn("[parcel] \uD83D\uDEA8 Connection to the HMR server was lost");
        };
    }
}
function removeErrorOverlay() {
    var overlay = document.getElementById(OVERLAY_ID);
    if (overlay) {
        overlay.remove();
        console.log("[parcel] \u2728 Error resolved");
    }
}
function createErrorOverlay(diagnostics) {
    var overlay = document.createElement("div");
    overlay.id = OVERLAY_ID;
    let errorHTML = '<div style="background: black; opacity: 0.85; font-size: 16px; color: white; position: fixed; height: 100%; width: 100%; top: 0px; left: 0px; padding: 30px; font-family: Menlo, Consolas, monospace; z-index: 9999;">';
    for (let diagnostic of diagnostics){
        let stack = diagnostic.frames.length ? diagnostic.frames.reduce((p, frame)=>{
            return `${p}
<a href="/__parcel_launch_editor?file=${encodeURIComponent(frame.location)}" style="text-decoration: underline; color: #888" onclick="fetch(this.href); return false">${frame.location}</a>
${frame.code}`;
        }, "") : diagnostic.stack;
        errorHTML += `
      <div>
        <div style="font-size: 18px; font-weight: bold; margin-top: 20px;">
          \u{1F6A8} ${diagnostic.message}
        </div>
        <pre>${stack}</pre>
        <div>
          ${diagnostic.hints.map((hint)=>"<div>\uD83D\uDCA1 " + hint + "</div>").join("")}
        </div>
        ${diagnostic.documentation ? `<div>\u{1F4DD} <a style="color: violet" href="${diagnostic.documentation}" target="_blank">Learn more</a></div>` : ""}
      </div>
    `;
    }
    errorHTML += "</div>";
    overlay.innerHTML = errorHTML;
    return overlay;
}
function fullReload() {
    if ("reload" in location) location.reload();
    else if (extCtx && extCtx.runtime && extCtx.runtime.reload) extCtx.runtime.reload();
}
function getParents(bundle, id) /*: Array<[ParcelRequire, string]> */ {
    var modules = bundle.modules;
    if (!modules) return [];
    var parents = [];
    var k, d, dep;
    for(k in modules)for(d in modules[k][1]){
        dep = modules[k][1][d];
        if (dep === id || Array.isArray(dep) && dep[dep.length - 1] === id) parents.push([
            bundle,
            k
        ]);
    }
    if (bundle.parent) parents = parents.concat(getParents(bundle.parent, id));
    return parents;
}
function updateLink(link) {
    var href = link.getAttribute("href");
    if (!href) return;
    var newLink = link.cloneNode();
    newLink.onload = function() {
        if (link.parentNode !== null) // $FlowFixMe
        link.parentNode.removeChild(link);
    };
    newLink.setAttribute("href", // $FlowFixMe
    href.split("?")[0] + "?" + Date.now());
    // $FlowFixMe
    link.parentNode.insertBefore(newLink, link.nextSibling);
}
var cssTimeout = null;
function reloadCSS() {
    if (cssTimeout) return;
    cssTimeout = setTimeout(function() {
        var links = document.querySelectorAll('link[rel="stylesheet"]');
        for(var i = 0; i < links.length; i++){
            // $FlowFixMe[incompatible-type]
            var href /*: string */  = links[i].getAttribute("href");
            var hostname = getHostname();
            var servedFromHMRServer = hostname === "localhost" ? new RegExp("^(https?:\\/\\/(0.0.0.0|127.0.0.1)|localhost):" + getPort()).test(href) : href.indexOf(hostname + ":" + getPort());
            var absolute = /^https?:\/\//i.test(href) && href.indexOf(location.origin) !== 0 && !servedFromHMRServer;
            if (!absolute) updateLink(links[i]);
        }
        cssTimeout = null;
    }, 50);
}
function hmrDownload(asset) {
    if (asset.type === "js") {
        if (typeof document !== "undefined") {
            let script = document.createElement("script");
            script.src = asset.url + "?t=" + Date.now();
            if (asset.outputFormat === "esmodule") script.type = "module";
            return new Promise((resolve, reject)=>{
                var _document$head;
                script.onload = ()=>resolve(script);
                script.onerror = reject;
                (_document$head = document.head) === null || _document$head === void 0 || _document$head.appendChild(script);
            });
        } else if (typeof importScripts === "function") {
            // Worker scripts
            if (asset.outputFormat === "esmodule") return import(asset.url + "?t=" + Date.now());
            else return new Promise((resolve, reject)=>{
                try {
                    importScripts(asset.url + "?t=" + Date.now());
                    resolve();
                } catch (err) {
                    reject(err);
                }
            });
        }
    }
}
async function hmrApplyUpdates(assets) {
    global.parcelHotUpdate = Object.create(null);
    let scriptsToRemove;
    try {
        // If sourceURL comments aren't supported in eval, we need to load
        // the update from the dev server over HTTP so that stack traces
        // are correct in errors/logs. This is much slower than eval, so
        // we only do it if needed (currently just Safari).
        // https://bugs.webkit.org/show_bug.cgi?id=137297
        // This path is also taken if a CSP disallows eval.
        if (!supportsSourceURL) {
            let promises = assets.map((asset)=>{
                var _hmrDownload;
                return (_hmrDownload = hmrDownload(asset)) === null || _hmrDownload === void 0 ? void 0 : _hmrDownload.catch((err)=>{
                    // Web extension fix
                    if (extCtx && extCtx.runtime && extCtx.runtime.getManifest().manifest_version == 3 && typeof ServiceWorkerGlobalScope != "undefined" && global instanceof ServiceWorkerGlobalScope) {
                        extCtx.runtime.reload();
                        return;
                    }
                    throw err;
                });
            });
            scriptsToRemove = await Promise.all(promises);
        }
        assets.forEach(function(asset) {
            hmrApply(module.bundle.root, asset);
        });
    } finally{
        delete global.parcelHotUpdate;
        if (scriptsToRemove) scriptsToRemove.forEach((script)=>{
            if (script) {
                var _document$head2;
                (_document$head2 = document.head) === null || _document$head2 === void 0 || _document$head2.removeChild(script);
            }
        });
    }
}
function hmrApply(bundle /*: ParcelRequire */ , asset /*:  HMRAsset */ ) {
    var modules = bundle.modules;
    if (!modules) return;
    if (asset.type === "css") reloadCSS();
    else if (asset.type === "js") {
        let deps = asset.depsByBundle[bundle.HMR_BUNDLE_ID];
        if (deps) {
            if (modules[asset.id]) {
                // Remove dependencies that are removed and will become orphaned.
                // This is necessary so that if the asset is added back again, the cache is gone, and we prevent a full page reload.
                let oldDeps = modules[asset.id][1];
                for(let dep in oldDeps)if (!deps[dep] || deps[dep] !== oldDeps[dep]) {
                    let id = oldDeps[dep];
                    let parents = getParents(module.bundle.root, id);
                    if (parents.length === 1) hmrDelete(module.bundle.root, id);
                }
            }
            if (supportsSourceURL) // Global eval. We would use `new Function` here but browser
            // support for source maps is better with eval.
            (0, eval)(asset.output);
            // $FlowFixMe
            let fn = global.parcelHotUpdate[asset.id];
            modules[asset.id] = [
                fn,
                deps
            ];
        } else if (bundle.parent) hmrApply(bundle.parent, asset);
    }
}
function hmrDelete(bundle, id) {
    let modules = bundle.modules;
    if (!modules) return;
    if (modules[id]) {
        // Collect dependencies that will become orphaned when this module is deleted.
        let deps = modules[id][1];
        let orphans = [];
        for(let dep in deps){
            let parents = getParents(module.bundle.root, deps[dep]);
            if (parents.length === 1) orphans.push(deps[dep]);
        }
        // Delete the module. This must be done before deleting dependencies in case of circular dependencies.
        delete modules[id];
        delete bundle.cache[id];
        // Now delete the orphans.
        orphans.forEach((id)=>{
            hmrDelete(module.bundle.root, id);
        });
    } else if (bundle.parent) hmrDelete(bundle.parent, id);
}
function hmrAcceptCheck(bundle /*: ParcelRequire */ , id /*: string */ , depsByBundle /*: ?{ [string]: { [string]: string } }*/ ) {
    if (hmrAcceptCheckOne(bundle, id, depsByBundle)) return true;
    // Traverse parents breadth first. All possible ancestries must accept the HMR update, or we'll reload.
    let parents = getParents(module.bundle.root, id);
    let accepted = false;
    while(parents.length > 0){
        let v = parents.shift();
        let a = hmrAcceptCheckOne(v[0], v[1], null);
        if (a) // If this parent accepts, stop traversing upward, but still consider siblings.
        accepted = true;
        else {
            // Otherwise, queue the parents in the next level upward.
            let p = getParents(module.bundle.root, v[1]);
            if (p.length === 0) {
                // If there are no parents, then we've reached an entry without accepting. Reload.
                accepted = false;
                break;
            }
            parents.push(...p);
        }
    }
    return accepted;
}
function hmrAcceptCheckOne(bundle /*: ParcelRequire */ , id /*: string */ , depsByBundle /*: ?{ [string]: { [string]: string } }*/ ) {
    var modules = bundle.modules;
    if (!modules) return;
    if (depsByBundle && !depsByBundle[bundle.HMR_BUNDLE_ID]) {
        // If we reached the root bundle without finding where the asset should go,
        // there's nothing to do. Mark as "accepted" so we don't reload the page.
        if (!bundle.parent) return true;
        return hmrAcceptCheck(bundle.parent, id, depsByBundle);
    }
    if (checkedAssets[id]) return true;
    checkedAssets[id] = true;
    var cached = bundle.cache[id];
    assetsToDispose.push([
        bundle,
        id
    ]);
    if (!cached || cached.hot && cached.hot._acceptCallbacks.length) {
        assetsToAccept.push([
            bundle,
            id
        ]);
        return true;
    }
}
function hmrDispose(bundle /*: ParcelRequire */ , id /*: string */ ) {
    var cached = bundle.cache[id];
    bundle.hotData[id] = {};
    if (cached && cached.hot) cached.hot.data = bundle.hotData[id];
    if (cached && cached.hot && cached.hot._disposeCallbacks.length) cached.hot._disposeCallbacks.forEach(function(cb) {
        cb(bundle.hotData[id]);
    });
    delete bundle.cache[id];
}
function hmrAccept(bundle /*: ParcelRequire */ , id /*: string */ ) {
    // Execute the module.
    bundle(id);
    // Run the accept callbacks in the new version of the module.
    var cached = bundle.cache[id];
    if (cached && cached.hot && cached.hot._acceptCallbacks.length) cached.hot._acceptCallbacks.forEach(function(cb) {
        var assetsToAlsoAccept = cb(function() {
            return getParents(module.bundle.root, id);
        });
        if (assetsToAlsoAccept && assetsToAccept.length) {
            assetsToAlsoAccept.forEach(function(a) {
                hmrDispose(a[0], a[1]);
            });
            // $FlowFixMe[method-unbinding]
            assetsToAccept.push.apply(assetsToAccept, assetsToAlsoAccept);
        }
    });
}

},{}],"8lRBv":[function(require,module,exports) {
var _three = require("three");
var _tone = require("tone");
var _orbitControlsJs = require("three/examples/jsm/controls/OrbitControls.js");
let noise = new _tone.Noise("pink");
let autoFilter = new _tone.AutoFilter({
    "frequency": "16n",
    "min": 800,
    "max": 15000
});
// noise.toDestination();
let analyze = new _tone.Analyser("waveform", 1024);
// let fft = new Tone.FFT(512);
// noise.connect(fft);
noise.connect(autoFilter);
autoFilter.connect(analyze);
analyze.toDestination();
const renderer = new _three.WebGLRenderer();
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild(renderer.domElement);
const scene = new _three.Scene();
//camera
const camera = new _three.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.set(0, 10, 30);
camera.lookAt(scene.position);
const orbit = new (0, _orbitControlsJs.OrbitControls)(camera, renderer.domElement);
//axis helper
const axesHelper = new _three.AxesHelper(3);
scene.add(axesHelper);
// box definition
const boxVertices = 6;
const boxGeometry = new _three.BoxGeometry(6, 6, 6, boxVertices, boxVertices, boxVertices);
const boxMaterial = new _three.MeshBasicMaterial({
    color: 0xff0088,
    wireframe: true
});
const box = new _three.Mesh(boxGeometry, boxMaterial);
scene.add(box);
// box 2
const box2Geometry = new _three.BoxGeometry(5, 5, 5, boxVertices, boxVertices, boxVertices);
const box2Material = new _three.MeshBasicMaterial({
    color: 0xff00cc,
    wireframe: true
});
const box2 = new _three.Mesh(box2Geometry, box2Material);
scene.add(box2);
const originalPositions = boxGeometry.attributes.position.array.slice();
function updateVertices() {
    const waveform = analyze.getValue();
    const vertPerSide = (boxVertices + 1) * (boxVertices + 1);
    const valuesPerSide = vertPerSide * 3;
    for(let i = 0; i < waveform.length; i++){
        let value = waveform[i];
        boxGeometry.attributes.position.array[i] += value;
    }
    boxGeometry.attributes.position.needsUpdate = true;
}
function originalVertices() {
    for(let i = 0; i < originalPositions.length; i++)boxGeometry.attributes.position.array[i] = originalPositions[i];
    boxGeometry.attributes.position.needsUpdate = true;
}
// Render loop
let originalToggle = false;
let frameCounter = 0;
function animate() {
    // if (cube_restart === false) {
    // 	if (originalToggle)
    // 		updateVertices();
    // 	else 
    // 		originalVertices();
    // 	originalToggle = !originalToggle;
    // }
    if (frameCounter % 5 === 0) originalVertices();
    else updateVertices();
    frameCounter++;
    if (frameCounter === 50) frameCounter = 0;
    box.rotation.x += 0.01;
    box.rotation.y += 0.01;
    box2.rotation.x += 0.01;
    box2.rotation.y += 0.01;
    renderer.render(scene, camera);
}
//start noise sound
let cube_restart = true;
document.addEventListener("click", function() {
    if (noise.state === "started") {
        noise.stop();
        cube_restart = true;
    } else {
        cube_restart = false;
        _tone.start();
        noise.start();
        setTimeout(()=>{
            for(let i = 0; i < 10000; i++)console.log(analyze.getValue());
        }, 1);
    }
});
function touchStarted() {
    if (getAudioContext().state !== "running") {
        console.log("audio context is not running");
        getAudioContext().resume();
    }
    console.log("audio context");
}
// renderer.render(scene, camera);
renderer.setAnimationLoop(animate);

},{"three":"ktPTu","tone":"2tCfN","three/examples/jsm/controls/OrbitControls.js":"7mqRv"}],"ktPTu":[function(require,module,exports) {
/**
 * @license
 * Copyright 2010-2024 Three.js Authors
 * SPDX-License-Identifier: MIT
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ACESFilmicToneMapping", ()=>ACESFilmicToneMapping);
parcelHelpers.export(exports, "AddEquation", ()=>AddEquation);
parcelHelpers.export(exports, "AddOperation", ()=>AddOperation);
parcelHelpers.export(exports, "AdditiveAnimationBlendMode", ()=>AdditiveAnimationBlendMode);
parcelHelpers.export(exports, "AdditiveBlending", ()=>AdditiveBlending);
parcelHelpers.export(exports, "AgXToneMapping", ()=>AgXToneMapping);
parcelHelpers.export(exports, "AlphaFormat", ()=>AlphaFormat);
parcelHelpers.export(exports, "AlwaysCompare", ()=>AlwaysCompare);
parcelHelpers.export(exports, "AlwaysDepth", ()=>AlwaysDepth);
parcelHelpers.export(exports, "AlwaysStencilFunc", ()=>AlwaysStencilFunc);
parcelHelpers.export(exports, "AmbientLight", ()=>AmbientLight);
parcelHelpers.export(exports, "AnimationAction", ()=>AnimationAction);
parcelHelpers.export(exports, "AnimationClip", ()=>AnimationClip);
parcelHelpers.export(exports, "AnimationLoader", ()=>AnimationLoader);
parcelHelpers.export(exports, "AnimationMixer", ()=>AnimationMixer);
parcelHelpers.export(exports, "AnimationObjectGroup", ()=>AnimationObjectGroup);
parcelHelpers.export(exports, "AnimationUtils", ()=>AnimationUtils);
parcelHelpers.export(exports, "ArcCurve", ()=>ArcCurve);
parcelHelpers.export(exports, "ArrayCamera", ()=>ArrayCamera);
parcelHelpers.export(exports, "ArrowHelper", ()=>ArrowHelper);
parcelHelpers.export(exports, "AttachedBindMode", ()=>AttachedBindMode);
parcelHelpers.export(exports, "Audio", ()=>Audio);
parcelHelpers.export(exports, "AudioAnalyser", ()=>AudioAnalyser);
parcelHelpers.export(exports, "AudioContext", ()=>AudioContext);
parcelHelpers.export(exports, "AudioListener", ()=>AudioListener);
parcelHelpers.export(exports, "AudioLoader", ()=>AudioLoader);
parcelHelpers.export(exports, "AxesHelper", ()=>AxesHelper);
parcelHelpers.export(exports, "BackSide", ()=>BackSide);
parcelHelpers.export(exports, "BasicDepthPacking", ()=>BasicDepthPacking);
parcelHelpers.export(exports, "BasicShadowMap", ()=>BasicShadowMap);
parcelHelpers.export(exports, "BatchedMesh", ()=>BatchedMesh);
parcelHelpers.export(exports, "Bone", ()=>Bone);
parcelHelpers.export(exports, "BooleanKeyframeTrack", ()=>BooleanKeyframeTrack);
parcelHelpers.export(exports, "Box2", ()=>Box2);
parcelHelpers.export(exports, "Box3", ()=>Box3);
parcelHelpers.export(exports, "Box3Helper", ()=>Box3Helper);
parcelHelpers.export(exports, "BoxGeometry", ()=>BoxGeometry);
parcelHelpers.export(exports, "BoxHelper", ()=>BoxHelper);
parcelHelpers.export(exports, "BufferAttribute", ()=>BufferAttribute);
parcelHelpers.export(exports, "BufferGeometry", ()=>BufferGeometry);
parcelHelpers.export(exports, "BufferGeometryLoader", ()=>BufferGeometryLoader);
parcelHelpers.export(exports, "ByteType", ()=>ByteType);
parcelHelpers.export(exports, "Cache", ()=>Cache);
parcelHelpers.export(exports, "Camera", ()=>Camera);
parcelHelpers.export(exports, "CameraHelper", ()=>CameraHelper);
parcelHelpers.export(exports, "CanvasTexture", ()=>CanvasTexture);
parcelHelpers.export(exports, "CapsuleGeometry", ()=>CapsuleGeometry);
parcelHelpers.export(exports, "CatmullRomCurve3", ()=>CatmullRomCurve3);
parcelHelpers.export(exports, "CineonToneMapping", ()=>CineonToneMapping);
parcelHelpers.export(exports, "CircleGeometry", ()=>CircleGeometry);
parcelHelpers.export(exports, "ClampToEdgeWrapping", ()=>ClampToEdgeWrapping);
parcelHelpers.export(exports, "Clock", ()=>Clock);
parcelHelpers.export(exports, "Color", ()=>Color);
parcelHelpers.export(exports, "ColorKeyframeTrack", ()=>ColorKeyframeTrack);
parcelHelpers.export(exports, "ColorManagement", ()=>ColorManagement);
parcelHelpers.export(exports, "CompressedArrayTexture", ()=>CompressedArrayTexture);
parcelHelpers.export(exports, "CompressedCubeTexture", ()=>CompressedCubeTexture);
parcelHelpers.export(exports, "CompressedTexture", ()=>CompressedTexture);
parcelHelpers.export(exports, "CompressedTextureLoader", ()=>CompressedTextureLoader);
parcelHelpers.export(exports, "ConeGeometry", ()=>ConeGeometry);
parcelHelpers.export(exports, "ConstantAlphaFactor", ()=>ConstantAlphaFactor);
parcelHelpers.export(exports, "ConstantColorFactor", ()=>ConstantColorFactor);
parcelHelpers.export(exports, "CubeCamera", ()=>CubeCamera);
parcelHelpers.export(exports, "CubeReflectionMapping", ()=>CubeReflectionMapping);
parcelHelpers.export(exports, "CubeRefractionMapping", ()=>CubeRefractionMapping);
parcelHelpers.export(exports, "CubeTexture", ()=>CubeTexture);
parcelHelpers.export(exports, "CubeTextureLoader", ()=>CubeTextureLoader);
parcelHelpers.export(exports, "CubeUVReflectionMapping", ()=>CubeUVReflectionMapping);
parcelHelpers.export(exports, "CubicBezierCurve", ()=>CubicBezierCurve);
parcelHelpers.export(exports, "CubicBezierCurve3", ()=>CubicBezierCurve3);
parcelHelpers.export(exports, "CubicInterpolant", ()=>CubicInterpolant);
parcelHelpers.export(exports, "CullFaceBack", ()=>CullFaceBack);
parcelHelpers.export(exports, "CullFaceFront", ()=>CullFaceFront);
parcelHelpers.export(exports, "CullFaceFrontBack", ()=>CullFaceFrontBack);
parcelHelpers.export(exports, "CullFaceNone", ()=>CullFaceNone);
parcelHelpers.export(exports, "Curve", ()=>Curve);
parcelHelpers.export(exports, "CurvePath", ()=>CurvePath);
parcelHelpers.export(exports, "CustomBlending", ()=>CustomBlending);
parcelHelpers.export(exports, "CustomToneMapping", ()=>CustomToneMapping);
parcelHelpers.export(exports, "CylinderGeometry", ()=>CylinderGeometry);
parcelHelpers.export(exports, "Cylindrical", ()=>Cylindrical);
parcelHelpers.export(exports, "Data3DTexture", ()=>Data3DTexture);
parcelHelpers.export(exports, "DataArrayTexture", ()=>DataArrayTexture);
parcelHelpers.export(exports, "DataTexture", ()=>DataTexture);
parcelHelpers.export(exports, "DataTextureLoader", ()=>DataTextureLoader);
parcelHelpers.export(exports, "DataUtils", ()=>DataUtils);
parcelHelpers.export(exports, "DecrementStencilOp", ()=>DecrementStencilOp);
parcelHelpers.export(exports, "DecrementWrapStencilOp", ()=>DecrementWrapStencilOp);
parcelHelpers.export(exports, "DefaultLoadingManager", ()=>DefaultLoadingManager);
parcelHelpers.export(exports, "DepthFormat", ()=>DepthFormat);
parcelHelpers.export(exports, "DepthStencilFormat", ()=>DepthStencilFormat);
parcelHelpers.export(exports, "DepthTexture", ()=>DepthTexture);
parcelHelpers.export(exports, "DetachedBindMode", ()=>DetachedBindMode);
parcelHelpers.export(exports, "DirectionalLight", ()=>DirectionalLight);
parcelHelpers.export(exports, "DirectionalLightHelper", ()=>DirectionalLightHelper);
parcelHelpers.export(exports, "DiscreteInterpolant", ()=>DiscreteInterpolant);
parcelHelpers.export(exports, "DisplayP3ColorSpace", ()=>DisplayP3ColorSpace);
parcelHelpers.export(exports, "DodecahedronGeometry", ()=>DodecahedronGeometry);
parcelHelpers.export(exports, "DoubleSide", ()=>DoubleSide);
parcelHelpers.export(exports, "DstAlphaFactor", ()=>DstAlphaFactor);
parcelHelpers.export(exports, "DstColorFactor", ()=>DstColorFactor);
parcelHelpers.export(exports, "DynamicCopyUsage", ()=>DynamicCopyUsage);
parcelHelpers.export(exports, "DynamicDrawUsage", ()=>DynamicDrawUsage);
parcelHelpers.export(exports, "DynamicReadUsage", ()=>DynamicReadUsage);
parcelHelpers.export(exports, "EdgesGeometry", ()=>EdgesGeometry);
parcelHelpers.export(exports, "EllipseCurve", ()=>EllipseCurve);
parcelHelpers.export(exports, "EqualCompare", ()=>EqualCompare);
parcelHelpers.export(exports, "EqualDepth", ()=>EqualDepth);
parcelHelpers.export(exports, "EqualStencilFunc", ()=>EqualStencilFunc);
parcelHelpers.export(exports, "EquirectangularReflectionMapping", ()=>EquirectangularReflectionMapping);
parcelHelpers.export(exports, "EquirectangularRefractionMapping", ()=>EquirectangularRefractionMapping);
parcelHelpers.export(exports, "Euler", ()=>Euler);
parcelHelpers.export(exports, "EventDispatcher", ()=>EventDispatcher);
parcelHelpers.export(exports, "ExtrudeGeometry", ()=>ExtrudeGeometry);
parcelHelpers.export(exports, "FileLoader", ()=>FileLoader);
parcelHelpers.export(exports, "Float16BufferAttribute", ()=>Float16BufferAttribute);
parcelHelpers.export(exports, "Float32BufferAttribute", ()=>Float32BufferAttribute);
parcelHelpers.export(exports, "FloatType", ()=>FloatType);
parcelHelpers.export(exports, "Fog", ()=>Fog);
parcelHelpers.export(exports, "FogExp2", ()=>FogExp2);
parcelHelpers.export(exports, "FramebufferTexture", ()=>FramebufferTexture);
parcelHelpers.export(exports, "FrontSide", ()=>FrontSide);
parcelHelpers.export(exports, "Frustum", ()=>Frustum);
parcelHelpers.export(exports, "GLBufferAttribute", ()=>GLBufferAttribute);
parcelHelpers.export(exports, "GLSL1", ()=>GLSL1);
parcelHelpers.export(exports, "GLSL3", ()=>GLSL3);
parcelHelpers.export(exports, "GreaterCompare", ()=>GreaterCompare);
parcelHelpers.export(exports, "GreaterDepth", ()=>GreaterDepth);
parcelHelpers.export(exports, "GreaterEqualCompare", ()=>GreaterEqualCompare);
parcelHelpers.export(exports, "GreaterEqualDepth", ()=>GreaterEqualDepth);
parcelHelpers.export(exports, "GreaterEqualStencilFunc", ()=>GreaterEqualStencilFunc);
parcelHelpers.export(exports, "GreaterStencilFunc", ()=>GreaterStencilFunc);
parcelHelpers.export(exports, "GridHelper", ()=>GridHelper);
parcelHelpers.export(exports, "Group", ()=>Group);
parcelHelpers.export(exports, "HalfFloatType", ()=>HalfFloatType);
parcelHelpers.export(exports, "HemisphereLight", ()=>HemisphereLight);
parcelHelpers.export(exports, "HemisphereLightHelper", ()=>HemisphereLightHelper);
parcelHelpers.export(exports, "IcosahedronGeometry", ()=>IcosahedronGeometry);
parcelHelpers.export(exports, "ImageBitmapLoader", ()=>ImageBitmapLoader);
parcelHelpers.export(exports, "ImageLoader", ()=>ImageLoader);
parcelHelpers.export(exports, "ImageUtils", ()=>ImageUtils);
parcelHelpers.export(exports, "IncrementStencilOp", ()=>IncrementStencilOp);
parcelHelpers.export(exports, "IncrementWrapStencilOp", ()=>IncrementWrapStencilOp);
parcelHelpers.export(exports, "InstancedBufferAttribute", ()=>InstancedBufferAttribute);
parcelHelpers.export(exports, "InstancedBufferGeometry", ()=>InstancedBufferGeometry);
parcelHelpers.export(exports, "InstancedInterleavedBuffer", ()=>InstancedInterleavedBuffer);
parcelHelpers.export(exports, "InstancedMesh", ()=>InstancedMesh);
parcelHelpers.export(exports, "Int16BufferAttribute", ()=>Int16BufferAttribute);
parcelHelpers.export(exports, "Int32BufferAttribute", ()=>Int32BufferAttribute);
parcelHelpers.export(exports, "Int8BufferAttribute", ()=>Int8BufferAttribute);
parcelHelpers.export(exports, "IntType", ()=>IntType);
parcelHelpers.export(exports, "InterleavedBuffer", ()=>InterleavedBuffer);
parcelHelpers.export(exports, "InterleavedBufferAttribute", ()=>InterleavedBufferAttribute);
parcelHelpers.export(exports, "Interpolant", ()=>Interpolant);
parcelHelpers.export(exports, "InterpolateDiscrete", ()=>InterpolateDiscrete);
parcelHelpers.export(exports, "InterpolateLinear", ()=>InterpolateLinear);
parcelHelpers.export(exports, "InterpolateSmooth", ()=>InterpolateSmooth);
parcelHelpers.export(exports, "InvertStencilOp", ()=>InvertStencilOp);
parcelHelpers.export(exports, "KeepStencilOp", ()=>KeepStencilOp);
parcelHelpers.export(exports, "KeyframeTrack", ()=>KeyframeTrack);
parcelHelpers.export(exports, "LOD", ()=>LOD);
parcelHelpers.export(exports, "LatheGeometry", ()=>LatheGeometry);
parcelHelpers.export(exports, "Layers", ()=>Layers);
parcelHelpers.export(exports, "LessCompare", ()=>LessCompare);
parcelHelpers.export(exports, "LessDepth", ()=>LessDepth);
parcelHelpers.export(exports, "LessEqualCompare", ()=>LessEqualCompare);
parcelHelpers.export(exports, "LessEqualDepth", ()=>LessEqualDepth);
parcelHelpers.export(exports, "LessEqualStencilFunc", ()=>LessEqualStencilFunc);
parcelHelpers.export(exports, "LessStencilFunc", ()=>LessStencilFunc);
parcelHelpers.export(exports, "Light", ()=>Light);
parcelHelpers.export(exports, "LightProbe", ()=>LightProbe);
parcelHelpers.export(exports, "Line", ()=>Line);
parcelHelpers.export(exports, "Line3", ()=>Line3);
parcelHelpers.export(exports, "LineBasicMaterial", ()=>LineBasicMaterial);
parcelHelpers.export(exports, "LineCurve", ()=>LineCurve);
parcelHelpers.export(exports, "LineCurve3", ()=>LineCurve3);
parcelHelpers.export(exports, "LineDashedMaterial", ()=>LineDashedMaterial);
parcelHelpers.export(exports, "LineLoop", ()=>LineLoop);
parcelHelpers.export(exports, "LineSegments", ()=>LineSegments);
parcelHelpers.export(exports, "LinearDisplayP3ColorSpace", ()=>LinearDisplayP3ColorSpace);
parcelHelpers.export(exports, "LinearFilter", ()=>LinearFilter);
parcelHelpers.export(exports, "LinearInterpolant", ()=>LinearInterpolant);
parcelHelpers.export(exports, "LinearMipMapLinearFilter", ()=>LinearMipMapLinearFilter);
parcelHelpers.export(exports, "LinearMipMapNearestFilter", ()=>LinearMipMapNearestFilter);
parcelHelpers.export(exports, "LinearMipmapLinearFilter", ()=>LinearMipmapLinearFilter);
parcelHelpers.export(exports, "LinearMipmapNearestFilter", ()=>LinearMipmapNearestFilter);
parcelHelpers.export(exports, "LinearSRGBColorSpace", ()=>LinearSRGBColorSpace);
parcelHelpers.export(exports, "LinearToneMapping", ()=>LinearToneMapping);
parcelHelpers.export(exports, "LinearTransfer", ()=>LinearTransfer);
parcelHelpers.export(exports, "Loader", ()=>Loader);
parcelHelpers.export(exports, "LoaderUtils", ()=>LoaderUtils);
parcelHelpers.export(exports, "LoadingManager", ()=>LoadingManager);
parcelHelpers.export(exports, "LoopOnce", ()=>LoopOnce);
parcelHelpers.export(exports, "LoopPingPong", ()=>LoopPingPong);
parcelHelpers.export(exports, "LoopRepeat", ()=>LoopRepeat);
parcelHelpers.export(exports, "LuminanceAlphaFormat", ()=>LuminanceAlphaFormat);
parcelHelpers.export(exports, "LuminanceFormat", ()=>LuminanceFormat);
parcelHelpers.export(exports, "MOUSE", ()=>MOUSE);
parcelHelpers.export(exports, "Material", ()=>Material);
parcelHelpers.export(exports, "MaterialLoader", ()=>MaterialLoader);
parcelHelpers.export(exports, "MathUtils", ()=>MathUtils);
parcelHelpers.export(exports, "Matrix3", ()=>Matrix3);
parcelHelpers.export(exports, "Matrix4", ()=>Matrix4);
parcelHelpers.export(exports, "MaxEquation", ()=>MaxEquation);
parcelHelpers.export(exports, "Mesh", ()=>Mesh);
parcelHelpers.export(exports, "MeshBasicMaterial", ()=>MeshBasicMaterial);
parcelHelpers.export(exports, "MeshDepthMaterial", ()=>MeshDepthMaterial);
parcelHelpers.export(exports, "MeshDistanceMaterial", ()=>MeshDistanceMaterial);
parcelHelpers.export(exports, "MeshLambertMaterial", ()=>MeshLambertMaterial);
parcelHelpers.export(exports, "MeshMatcapMaterial", ()=>MeshMatcapMaterial);
parcelHelpers.export(exports, "MeshNormalMaterial", ()=>MeshNormalMaterial);
parcelHelpers.export(exports, "MeshPhongMaterial", ()=>MeshPhongMaterial);
parcelHelpers.export(exports, "MeshPhysicalMaterial", ()=>MeshPhysicalMaterial);
parcelHelpers.export(exports, "MeshStandardMaterial", ()=>MeshStandardMaterial);
parcelHelpers.export(exports, "MeshToonMaterial", ()=>MeshToonMaterial);
parcelHelpers.export(exports, "MinEquation", ()=>MinEquation);
parcelHelpers.export(exports, "MirroredRepeatWrapping", ()=>MirroredRepeatWrapping);
parcelHelpers.export(exports, "MixOperation", ()=>MixOperation);
parcelHelpers.export(exports, "MultiplyBlending", ()=>MultiplyBlending);
parcelHelpers.export(exports, "MultiplyOperation", ()=>MultiplyOperation);
parcelHelpers.export(exports, "NearestFilter", ()=>NearestFilter);
parcelHelpers.export(exports, "NearestMipMapLinearFilter", ()=>NearestMipMapLinearFilter);
parcelHelpers.export(exports, "NearestMipMapNearestFilter", ()=>NearestMipMapNearestFilter);
parcelHelpers.export(exports, "NearestMipmapLinearFilter", ()=>NearestMipmapLinearFilter);
parcelHelpers.export(exports, "NearestMipmapNearestFilter", ()=>NearestMipmapNearestFilter);
parcelHelpers.export(exports, "NeutralToneMapping", ()=>NeutralToneMapping);
parcelHelpers.export(exports, "NeverCompare", ()=>NeverCompare);
parcelHelpers.export(exports, "NeverDepth", ()=>NeverDepth);
parcelHelpers.export(exports, "NeverStencilFunc", ()=>NeverStencilFunc);
parcelHelpers.export(exports, "NoBlending", ()=>NoBlending);
parcelHelpers.export(exports, "NoColorSpace", ()=>NoColorSpace);
parcelHelpers.export(exports, "NoToneMapping", ()=>NoToneMapping);
parcelHelpers.export(exports, "NormalAnimationBlendMode", ()=>NormalAnimationBlendMode);
parcelHelpers.export(exports, "NormalBlending", ()=>NormalBlending);
parcelHelpers.export(exports, "NotEqualCompare", ()=>NotEqualCompare);
parcelHelpers.export(exports, "NotEqualDepth", ()=>NotEqualDepth);
parcelHelpers.export(exports, "NotEqualStencilFunc", ()=>NotEqualStencilFunc);
parcelHelpers.export(exports, "NumberKeyframeTrack", ()=>NumberKeyframeTrack);
parcelHelpers.export(exports, "Object3D", ()=>Object3D);
parcelHelpers.export(exports, "ObjectLoader", ()=>ObjectLoader);
parcelHelpers.export(exports, "ObjectSpaceNormalMap", ()=>ObjectSpaceNormalMap);
parcelHelpers.export(exports, "OctahedronGeometry", ()=>OctahedronGeometry);
parcelHelpers.export(exports, "OneFactor", ()=>OneFactor);
parcelHelpers.export(exports, "OneMinusConstantAlphaFactor", ()=>OneMinusConstantAlphaFactor);
parcelHelpers.export(exports, "OneMinusConstantColorFactor", ()=>OneMinusConstantColorFactor);
parcelHelpers.export(exports, "OneMinusDstAlphaFactor", ()=>OneMinusDstAlphaFactor);
parcelHelpers.export(exports, "OneMinusDstColorFactor", ()=>OneMinusDstColorFactor);
parcelHelpers.export(exports, "OneMinusSrcAlphaFactor", ()=>OneMinusSrcAlphaFactor);
parcelHelpers.export(exports, "OneMinusSrcColorFactor", ()=>OneMinusSrcColorFactor);
parcelHelpers.export(exports, "OrthographicCamera", ()=>OrthographicCamera);
parcelHelpers.export(exports, "P3Primaries", ()=>P3Primaries);
parcelHelpers.export(exports, "PCFShadowMap", ()=>PCFShadowMap);
parcelHelpers.export(exports, "PCFSoftShadowMap", ()=>PCFSoftShadowMap);
parcelHelpers.export(exports, "PMREMGenerator", ()=>PMREMGenerator);
parcelHelpers.export(exports, "Path", ()=>Path);
parcelHelpers.export(exports, "PerspectiveCamera", ()=>PerspectiveCamera);
parcelHelpers.export(exports, "Plane", ()=>Plane);
parcelHelpers.export(exports, "PlaneGeometry", ()=>PlaneGeometry);
parcelHelpers.export(exports, "PlaneHelper", ()=>PlaneHelper);
parcelHelpers.export(exports, "PointLight", ()=>PointLight);
parcelHelpers.export(exports, "PointLightHelper", ()=>PointLightHelper);
parcelHelpers.export(exports, "Points", ()=>Points);
parcelHelpers.export(exports, "PointsMaterial", ()=>PointsMaterial);
parcelHelpers.export(exports, "PolarGridHelper", ()=>PolarGridHelper);
parcelHelpers.export(exports, "PolyhedronGeometry", ()=>PolyhedronGeometry);
parcelHelpers.export(exports, "PositionalAudio", ()=>PositionalAudio);
parcelHelpers.export(exports, "PropertyBinding", ()=>PropertyBinding);
parcelHelpers.export(exports, "PropertyMixer", ()=>PropertyMixer);
parcelHelpers.export(exports, "QuadraticBezierCurve", ()=>QuadraticBezierCurve);
parcelHelpers.export(exports, "QuadraticBezierCurve3", ()=>QuadraticBezierCurve3);
parcelHelpers.export(exports, "Quaternion", ()=>Quaternion);
parcelHelpers.export(exports, "QuaternionKeyframeTrack", ()=>QuaternionKeyframeTrack);
parcelHelpers.export(exports, "QuaternionLinearInterpolant", ()=>QuaternionLinearInterpolant);
parcelHelpers.export(exports, "RED_GREEN_RGTC2_Format", ()=>RED_GREEN_RGTC2_Format);
parcelHelpers.export(exports, "RED_RGTC1_Format", ()=>RED_RGTC1_Format);
parcelHelpers.export(exports, "REVISION", ()=>REVISION);
parcelHelpers.export(exports, "RGBADepthPacking", ()=>RGBADepthPacking);
parcelHelpers.export(exports, "RGBAFormat", ()=>RGBAFormat);
parcelHelpers.export(exports, "RGBAIntegerFormat", ()=>RGBAIntegerFormat);
parcelHelpers.export(exports, "RGBA_ASTC_10x10_Format", ()=>RGBA_ASTC_10x10_Format);
parcelHelpers.export(exports, "RGBA_ASTC_10x5_Format", ()=>RGBA_ASTC_10x5_Format);
parcelHelpers.export(exports, "RGBA_ASTC_10x6_Format", ()=>RGBA_ASTC_10x6_Format);
parcelHelpers.export(exports, "RGBA_ASTC_10x8_Format", ()=>RGBA_ASTC_10x8_Format);
parcelHelpers.export(exports, "RGBA_ASTC_12x10_Format", ()=>RGBA_ASTC_12x10_Format);
parcelHelpers.export(exports, "RGBA_ASTC_12x12_Format", ()=>RGBA_ASTC_12x12_Format);
parcelHelpers.export(exports, "RGBA_ASTC_4x4_Format", ()=>RGBA_ASTC_4x4_Format);
parcelHelpers.export(exports, "RGBA_ASTC_5x4_Format", ()=>RGBA_ASTC_5x4_Format);
parcelHelpers.export(exports, "RGBA_ASTC_5x5_Format", ()=>RGBA_ASTC_5x5_Format);
parcelHelpers.export(exports, "RGBA_ASTC_6x5_Format", ()=>RGBA_ASTC_6x5_Format);
parcelHelpers.export(exports, "RGBA_ASTC_6x6_Format", ()=>RGBA_ASTC_6x6_Format);
parcelHelpers.export(exports, "RGBA_ASTC_8x5_Format", ()=>RGBA_ASTC_8x5_Format);
parcelHelpers.export(exports, "RGBA_ASTC_8x6_Format", ()=>RGBA_ASTC_8x6_Format);
parcelHelpers.export(exports, "RGBA_ASTC_8x8_Format", ()=>RGBA_ASTC_8x8_Format);
parcelHelpers.export(exports, "RGBA_BPTC_Format", ()=>RGBA_BPTC_Format);
parcelHelpers.export(exports, "RGBA_ETC2_EAC_Format", ()=>RGBA_ETC2_EAC_Format);
parcelHelpers.export(exports, "RGBA_PVRTC_2BPPV1_Format", ()=>RGBA_PVRTC_2BPPV1_Format);
parcelHelpers.export(exports, "RGBA_PVRTC_4BPPV1_Format", ()=>RGBA_PVRTC_4BPPV1_Format);
parcelHelpers.export(exports, "RGBA_S3TC_DXT1_Format", ()=>RGBA_S3TC_DXT1_Format);
parcelHelpers.export(exports, "RGBA_S3TC_DXT3_Format", ()=>RGBA_S3TC_DXT3_Format);
parcelHelpers.export(exports, "RGBA_S3TC_DXT5_Format", ()=>RGBA_S3TC_DXT5_Format);
parcelHelpers.export(exports, "RGBFormat", ()=>RGBFormat);
parcelHelpers.export(exports, "RGBIntegerFormat", ()=>RGBIntegerFormat);
parcelHelpers.export(exports, "RGB_BPTC_SIGNED_Format", ()=>RGB_BPTC_SIGNED_Format);
parcelHelpers.export(exports, "RGB_BPTC_UNSIGNED_Format", ()=>RGB_BPTC_UNSIGNED_Format);
parcelHelpers.export(exports, "RGB_ETC1_Format", ()=>RGB_ETC1_Format);
parcelHelpers.export(exports, "RGB_ETC2_Format", ()=>RGB_ETC2_Format);
parcelHelpers.export(exports, "RGB_PVRTC_2BPPV1_Format", ()=>RGB_PVRTC_2BPPV1_Format);
parcelHelpers.export(exports, "RGB_PVRTC_4BPPV1_Format", ()=>RGB_PVRTC_4BPPV1_Format);
parcelHelpers.export(exports, "RGB_S3TC_DXT1_Format", ()=>RGB_S3TC_DXT1_Format);
parcelHelpers.export(exports, "RGFormat", ()=>RGFormat);
parcelHelpers.export(exports, "RGIntegerFormat", ()=>RGIntegerFormat);
parcelHelpers.export(exports, "RawShaderMaterial", ()=>RawShaderMaterial);
parcelHelpers.export(exports, "Ray", ()=>Ray);
parcelHelpers.export(exports, "Raycaster", ()=>Raycaster);
parcelHelpers.export(exports, "Rec709Primaries", ()=>Rec709Primaries);
parcelHelpers.export(exports, "RectAreaLight", ()=>RectAreaLight);
parcelHelpers.export(exports, "RedFormat", ()=>RedFormat);
parcelHelpers.export(exports, "RedIntegerFormat", ()=>RedIntegerFormat);
parcelHelpers.export(exports, "ReinhardToneMapping", ()=>ReinhardToneMapping);
parcelHelpers.export(exports, "RenderTarget", ()=>RenderTarget);
parcelHelpers.export(exports, "RepeatWrapping", ()=>RepeatWrapping);
parcelHelpers.export(exports, "ReplaceStencilOp", ()=>ReplaceStencilOp);
parcelHelpers.export(exports, "ReverseSubtractEquation", ()=>ReverseSubtractEquation);
parcelHelpers.export(exports, "RingGeometry", ()=>RingGeometry);
parcelHelpers.export(exports, "SIGNED_RED_GREEN_RGTC2_Format", ()=>SIGNED_RED_GREEN_RGTC2_Format);
parcelHelpers.export(exports, "SIGNED_RED_RGTC1_Format", ()=>SIGNED_RED_RGTC1_Format);
parcelHelpers.export(exports, "SRGBColorSpace", ()=>SRGBColorSpace);
parcelHelpers.export(exports, "SRGBTransfer", ()=>SRGBTransfer);
parcelHelpers.export(exports, "Scene", ()=>Scene);
parcelHelpers.export(exports, "ShaderChunk", ()=>ShaderChunk);
parcelHelpers.export(exports, "ShaderLib", ()=>ShaderLib);
parcelHelpers.export(exports, "ShaderMaterial", ()=>ShaderMaterial);
parcelHelpers.export(exports, "ShadowMaterial", ()=>ShadowMaterial);
parcelHelpers.export(exports, "Shape", ()=>Shape);
parcelHelpers.export(exports, "ShapeGeometry", ()=>ShapeGeometry);
parcelHelpers.export(exports, "ShapePath", ()=>ShapePath);
parcelHelpers.export(exports, "ShapeUtils", ()=>ShapeUtils);
parcelHelpers.export(exports, "ShortType", ()=>ShortType);
parcelHelpers.export(exports, "Skeleton", ()=>Skeleton);
parcelHelpers.export(exports, "SkeletonHelper", ()=>SkeletonHelper);
parcelHelpers.export(exports, "SkinnedMesh", ()=>SkinnedMesh);
parcelHelpers.export(exports, "Source", ()=>Source);
parcelHelpers.export(exports, "Sphere", ()=>Sphere);
parcelHelpers.export(exports, "SphereGeometry", ()=>SphereGeometry);
parcelHelpers.export(exports, "Spherical", ()=>Spherical);
parcelHelpers.export(exports, "SphericalHarmonics3", ()=>SphericalHarmonics3);
parcelHelpers.export(exports, "SplineCurve", ()=>SplineCurve);
parcelHelpers.export(exports, "SpotLight", ()=>SpotLight);
parcelHelpers.export(exports, "SpotLightHelper", ()=>SpotLightHelper);
parcelHelpers.export(exports, "Sprite", ()=>Sprite);
parcelHelpers.export(exports, "SpriteMaterial", ()=>SpriteMaterial);
parcelHelpers.export(exports, "SrcAlphaFactor", ()=>SrcAlphaFactor);
parcelHelpers.export(exports, "SrcAlphaSaturateFactor", ()=>SrcAlphaSaturateFactor);
parcelHelpers.export(exports, "SrcColorFactor", ()=>SrcColorFactor);
parcelHelpers.export(exports, "StaticCopyUsage", ()=>StaticCopyUsage);
parcelHelpers.export(exports, "StaticDrawUsage", ()=>StaticDrawUsage);
parcelHelpers.export(exports, "StaticReadUsage", ()=>StaticReadUsage);
parcelHelpers.export(exports, "StereoCamera", ()=>StereoCamera);
parcelHelpers.export(exports, "StreamCopyUsage", ()=>StreamCopyUsage);
parcelHelpers.export(exports, "StreamDrawUsage", ()=>StreamDrawUsage);
parcelHelpers.export(exports, "StreamReadUsage", ()=>StreamReadUsage);
parcelHelpers.export(exports, "StringKeyframeTrack", ()=>StringKeyframeTrack);
parcelHelpers.export(exports, "SubtractEquation", ()=>SubtractEquation);
parcelHelpers.export(exports, "SubtractiveBlending", ()=>SubtractiveBlending);
parcelHelpers.export(exports, "TOUCH", ()=>TOUCH);
parcelHelpers.export(exports, "TangentSpaceNormalMap", ()=>TangentSpaceNormalMap);
parcelHelpers.export(exports, "TetrahedronGeometry", ()=>TetrahedronGeometry);
parcelHelpers.export(exports, "Texture", ()=>Texture);
parcelHelpers.export(exports, "TextureLoader", ()=>TextureLoader);
parcelHelpers.export(exports, "TextureUtils", ()=>TextureUtils);
parcelHelpers.export(exports, "TorusGeometry", ()=>TorusGeometry);
parcelHelpers.export(exports, "TorusKnotGeometry", ()=>TorusKnotGeometry);
parcelHelpers.export(exports, "Triangle", ()=>Triangle);
parcelHelpers.export(exports, "TriangleFanDrawMode", ()=>TriangleFanDrawMode);
parcelHelpers.export(exports, "TriangleStripDrawMode", ()=>TriangleStripDrawMode);
parcelHelpers.export(exports, "TrianglesDrawMode", ()=>TrianglesDrawMode);
parcelHelpers.export(exports, "TubeGeometry", ()=>TubeGeometry);
parcelHelpers.export(exports, "UVMapping", ()=>UVMapping);
parcelHelpers.export(exports, "Uint16BufferAttribute", ()=>Uint16BufferAttribute);
parcelHelpers.export(exports, "Uint32BufferAttribute", ()=>Uint32BufferAttribute);
parcelHelpers.export(exports, "Uint8BufferAttribute", ()=>Uint8BufferAttribute);
parcelHelpers.export(exports, "Uint8ClampedBufferAttribute", ()=>Uint8ClampedBufferAttribute);
parcelHelpers.export(exports, "Uniform", ()=>Uniform);
parcelHelpers.export(exports, "UniformsGroup", ()=>UniformsGroup);
parcelHelpers.export(exports, "UniformsLib", ()=>UniformsLib);
parcelHelpers.export(exports, "UniformsUtils", ()=>UniformsUtils);
parcelHelpers.export(exports, "UnsignedByteType", ()=>UnsignedByteType);
parcelHelpers.export(exports, "UnsignedInt248Type", ()=>UnsignedInt248Type);
parcelHelpers.export(exports, "UnsignedInt5999Type", ()=>UnsignedInt5999Type);
parcelHelpers.export(exports, "UnsignedIntType", ()=>UnsignedIntType);
parcelHelpers.export(exports, "UnsignedShort4444Type", ()=>UnsignedShort4444Type);
parcelHelpers.export(exports, "UnsignedShort5551Type", ()=>UnsignedShort5551Type);
parcelHelpers.export(exports, "UnsignedShortType", ()=>UnsignedShortType);
parcelHelpers.export(exports, "VSMShadowMap", ()=>VSMShadowMap);
parcelHelpers.export(exports, "Vector2", ()=>Vector2);
parcelHelpers.export(exports, "Vector3", ()=>Vector3);
parcelHelpers.export(exports, "Vector4", ()=>Vector4);
parcelHelpers.export(exports, "VectorKeyframeTrack", ()=>VectorKeyframeTrack);
parcelHelpers.export(exports, "VideoTexture", ()=>VideoTexture);
parcelHelpers.export(exports, "WebGL3DRenderTarget", ()=>WebGL3DRenderTarget);
parcelHelpers.export(exports, "WebGLArrayRenderTarget", ()=>WebGLArrayRenderTarget);
parcelHelpers.export(exports, "WebGLCoordinateSystem", ()=>WebGLCoordinateSystem);
parcelHelpers.export(exports, "WebGLCubeRenderTarget", ()=>WebGLCubeRenderTarget);
parcelHelpers.export(exports, "WebGLMultipleRenderTargets", ()=>WebGLMultipleRenderTargets);
parcelHelpers.export(exports, "WebGLRenderTarget", ()=>WebGLRenderTarget);
parcelHelpers.export(exports, "WebGLRenderer", ()=>WebGLRenderer);
parcelHelpers.export(exports, "WebGLUtils", ()=>WebGLUtils);
parcelHelpers.export(exports, "WebGPUCoordinateSystem", ()=>WebGPUCoordinateSystem);
parcelHelpers.export(exports, "WireframeGeometry", ()=>WireframeGeometry);
parcelHelpers.export(exports, "WrapAroundEnding", ()=>WrapAroundEnding);
parcelHelpers.export(exports, "ZeroCurvatureEnding", ()=>ZeroCurvatureEnding);
parcelHelpers.export(exports, "ZeroFactor", ()=>ZeroFactor);
parcelHelpers.export(exports, "ZeroSlopeEnding", ()=>ZeroSlopeEnding);
parcelHelpers.export(exports, "ZeroStencilOp", ()=>ZeroStencilOp);
parcelHelpers.export(exports, "createCanvasElement", ()=>createCanvasElement);
const REVISION = "166";
const MOUSE = {
    LEFT: 0,
    MIDDLE: 1,
    RIGHT: 2,
    ROTATE: 0,
    DOLLY: 1,
    PAN: 2
};
const TOUCH = {
    ROTATE: 0,
    PAN: 1,
    DOLLY_PAN: 2,
    DOLLY_ROTATE: 3
};
const CullFaceNone = 0;
const CullFaceBack = 1;
const CullFaceFront = 2;
const CullFaceFrontBack = 3;
const BasicShadowMap = 0;
const PCFShadowMap = 1;
const PCFSoftShadowMap = 2;
const VSMShadowMap = 3;
const FrontSide = 0;
const BackSide = 1;
const DoubleSide = 2;
const NoBlending = 0;
const NormalBlending = 1;
const AdditiveBlending = 2;
const SubtractiveBlending = 3;
const MultiplyBlending = 4;
const CustomBlending = 5;
const AddEquation = 100;
const SubtractEquation = 101;
const ReverseSubtractEquation = 102;
const MinEquation = 103;
const MaxEquation = 104;
const ZeroFactor = 200;
const OneFactor = 201;
const SrcColorFactor = 202;
const OneMinusSrcColorFactor = 203;
const SrcAlphaFactor = 204;
const OneMinusSrcAlphaFactor = 205;
const DstAlphaFactor = 206;
const OneMinusDstAlphaFactor = 207;
const DstColorFactor = 208;
const OneMinusDstColorFactor = 209;
const SrcAlphaSaturateFactor = 210;
const ConstantColorFactor = 211;
const OneMinusConstantColorFactor = 212;
const ConstantAlphaFactor = 213;
const OneMinusConstantAlphaFactor = 214;
const NeverDepth = 0;
const AlwaysDepth = 1;
const LessDepth = 2;
const LessEqualDepth = 3;
const EqualDepth = 4;
const GreaterEqualDepth = 5;
const GreaterDepth = 6;
const NotEqualDepth = 7;
const MultiplyOperation = 0;
const MixOperation = 1;
const AddOperation = 2;
const NoToneMapping = 0;
const LinearToneMapping = 1;
const ReinhardToneMapping = 2;
const CineonToneMapping = 3;
const ACESFilmicToneMapping = 4;
const CustomToneMapping = 5;
const AgXToneMapping = 6;
const NeutralToneMapping = 7;
const AttachedBindMode = "attached";
const DetachedBindMode = "detached";
const UVMapping = 300;
const CubeReflectionMapping = 301;
const CubeRefractionMapping = 302;
const EquirectangularReflectionMapping = 303;
const EquirectangularRefractionMapping = 304;
const CubeUVReflectionMapping = 306;
const RepeatWrapping = 1000;
const ClampToEdgeWrapping = 1001;
const MirroredRepeatWrapping = 1002;
const NearestFilter = 1003;
const NearestMipmapNearestFilter = 1004;
const NearestMipMapNearestFilter = 1004;
const NearestMipmapLinearFilter = 1005;
const NearestMipMapLinearFilter = 1005;
const LinearFilter = 1006;
const LinearMipmapNearestFilter = 1007;
const LinearMipMapNearestFilter = 1007;
const LinearMipmapLinearFilter = 1008;
const LinearMipMapLinearFilter = 1008;
const UnsignedByteType = 1009;
const ByteType = 1010;
const ShortType = 1011;
const UnsignedShortType = 1012;
const IntType = 1013;
const UnsignedIntType = 1014;
const FloatType = 1015;
const HalfFloatType = 1016;
const UnsignedShort4444Type = 1017;
const UnsignedShort5551Type = 1018;
const UnsignedInt248Type = 1020;
const UnsignedInt5999Type = 35902;
const AlphaFormat = 1021;
const RGBFormat = 1022;
const RGBAFormat = 1023;
const LuminanceFormat = 1024;
const LuminanceAlphaFormat = 1025;
const DepthFormat = 1026;
const DepthStencilFormat = 1027;
const RedFormat = 1028;
const RedIntegerFormat = 1029;
const RGFormat = 1030;
const RGIntegerFormat = 1031;
const RGBIntegerFormat = 1032;
const RGBAIntegerFormat = 1033;
const RGB_S3TC_DXT1_Format = 33776;
const RGBA_S3TC_DXT1_Format = 33777;
const RGBA_S3TC_DXT3_Format = 33778;
const RGBA_S3TC_DXT5_Format = 33779;
const RGB_PVRTC_4BPPV1_Format = 35840;
const RGB_PVRTC_2BPPV1_Format = 35841;
const RGBA_PVRTC_4BPPV1_Format = 35842;
const RGBA_PVRTC_2BPPV1_Format = 35843;
const RGB_ETC1_Format = 36196;
const RGB_ETC2_Format = 37492;
const RGBA_ETC2_EAC_Format = 37496;
const RGBA_ASTC_4x4_Format = 37808;
const RGBA_ASTC_5x4_Format = 37809;
const RGBA_ASTC_5x5_Format = 37810;
const RGBA_ASTC_6x5_Format = 37811;
const RGBA_ASTC_6x6_Format = 37812;
const RGBA_ASTC_8x5_Format = 37813;
const RGBA_ASTC_8x6_Format = 37814;
const RGBA_ASTC_8x8_Format = 37815;
const RGBA_ASTC_10x5_Format = 37816;
const RGBA_ASTC_10x6_Format = 37817;
const RGBA_ASTC_10x8_Format = 37818;
const RGBA_ASTC_10x10_Format = 37819;
const RGBA_ASTC_12x10_Format = 37820;
const RGBA_ASTC_12x12_Format = 37821;
const RGBA_BPTC_Format = 36492;
const RGB_BPTC_SIGNED_Format = 36494;
const RGB_BPTC_UNSIGNED_Format = 36495;
const RED_RGTC1_Format = 36283;
const SIGNED_RED_RGTC1_Format = 36284;
const RED_GREEN_RGTC2_Format = 36285;
const SIGNED_RED_GREEN_RGTC2_Format = 36286;
const LoopOnce = 2200;
const LoopRepeat = 2201;
const LoopPingPong = 2202;
const InterpolateDiscrete = 2300;
const InterpolateLinear = 2301;
const InterpolateSmooth = 2302;
const ZeroCurvatureEnding = 2400;
const ZeroSlopeEnding = 2401;
const WrapAroundEnding = 2402;
const NormalAnimationBlendMode = 2500;
const AdditiveAnimationBlendMode = 2501;
const TrianglesDrawMode = 0;
const TriangleStripDrawMode = 1;
const TriangleFanDrawMode = 2;
const BasicDepthPacking = 3200;
const RGBADepthPacking = 3201;
const TangentSpaceNormalMap = 0;
const ObjectSpaceNormalMap = 1;
// Color space string identifiers, matching CSS Color Module Level 4 and WebGPU names where available.
const NoColorSpace = "";
const SRGBColorSpace = "srgb";
const LinearSRGBColorSpace = "srgb-linear";
const DisplayP3ColorSpace = "display-p3";
const LinearDisplayP3ColorSpace = "display-p3-linear";
const LinearTransfer = "linear";
const SRGBTransfer = "srgb";
const Rec709Primaries = "rec709";
const P3Primaries = "p3";
const ZeroStencilOp = 0;
const KeepStencilOp = 7680;
const ReplaceStencilOp = 7681;
const IncrementStencilOp = 7682;
const DecrementStencilOp = 7683;
const IncrementWrapStencilOp = 34055;
const DecrementWrapStencilOp = 34056;
const InvertStencilOp = 5386;
const NeverStencilFunc = 512;
const LessStencilFunc = 513;
const EqualStencilFunc = 514;
const LessEqualStencilFunc = 515;
const GreaterStencilFunc = 516;
const NotEqualStencilFunc = 517;
const GreaterEqualStencilFunc = 518;
const AlwaysStencilFunc = 519;
const NeverCompare = 512;
const LessCompare = 513;
const EqualCompare = 514;
const LessEqualCompare = 515;
const GreaterCompare = 516;
const NotEqualCompare = 517;
const GreaterEqualCompare = 518;
const AlwaysCompare = 519;
const StaticDrawUsage = 35044;
const DynamicDrawUsage = 35048;
const StreamDrawUsage = 35040;
const StaticReadUsage = 35045;
const DynamicReadUsage = 35049;
const StreamReadUsage = 35041;
const StaticCopyUsage = 35046;
const DynamicCopyUsage = 35050;
const StreamCopyUsage = 35042;
const GLSL1 = "100";
const GLSL3 = "300 es";
const WebGLCoordinateSystem = 2000;
const WebGPUCoordinateSystem = 2001;
/**
 * https://github.com/mrdoob/eventdispatcher.js/
 */ class EventDispatcher {
    addEventListener(type, listener) {
        if (this._listeners === undefined) this._listeners = {};
        const listeners = this._listeners;
        if (listeners[type] === undefined) listeners[type] = [];
        if (listeners[type].indexOf(listener) === -1) listeners[type].push(listener);
    }
    hasEventListener(type, listener) {
        if (this._listeners === undefined) return false;
        const listeners = this._listeners;
        return listeners[type] !== undefined && listeners[type].indexOf(listener) !== -1;
    }
    removeEventListener(type, listener) {
        if (this._listeners === undefined) return;
        const listeners = this._listeners;
        const listenerArray = listeners[type];
        if (listenerArray !== undefined) {
            const index = listenerArray.indexOf(listener);
            if (index !== -1) listenerArray.splice(index, 1);
        }
    }
    dispatchEvent(event) {
        if (this._listeners === undefined) return;
        const listeners = this._listeners;
        const listenerArray = listeners[event.type];
        if (listenerArray !== undefined) {
            event.target = this;
            // Make a copy, in case listeners are removed while iterating.
            const array = listenerArray.slice(0);
            for(let i = 0, l = array.length; i < l; i++)array[i].call(this, event);
            event.target = null;
        }
    }
}
const _lut = [
    "00",
    "01",
    "02",
    "03",
    "04",
    "05",
    "06",
    "07",
    "08",
    "09",
    "0a",
    "0b",
    "0c",
    "0d",
    "0e",
    "0f",
    "10",
    "11",
    "12",
    "13",
    "14",
    "15",
    "16",
    "17",
    "18",
    "19",
    "1a",
    "1b",
    "1c",
    "1d",
    "1e",
    "1f",
    "20",
    "21",
    "22",
    "23",
    "24",
    "25",
    "26",
    "27",
    "28",
    "29",
    "2a",
    "2b",
    "2c",
    "2d",
    "2e",
    "2f",
    "30",
    "31",
    "32",
    "33",
    "34",
    "35",
    "36",
    "37",
    "38",
    "39",
    "3a",
    "3b",
    "3c",
    "3d",
    "3e",
    "3f",
    "40",
    "41",
    "42",
    "43",
    "44",
    "45",
    "46",
    "47",
    "48",
    "49",
    "4a",
    "4b",
    "4c",
    "4d",
    "4e",
    "4f",
    "50",
    "51",
    "52",
    "53",
    "54",
    "55",
    "56",
    "57",
    "58",
    "59",
    "5a",
    "5b",
    "5c",
    "5d",
    "5e",
    "5f",
    "60",
    "61",
    "62",
    "63",
    "64",
    "65",
    "66",
    "67",
    "68",
    "69",
    "6a",
    "6b",
    "6c",
    "6d",
    "6e",
    "6f",
    "70",
    "71",
    "72",
    "73",
    "74",
    "75",
    "76",
    "77",
    "78",
    "79",
    "7a",
    "7b",
    "7c",
    "7d",
    "7e",
    "7f",
    "80",
    "81",
    "82",
    "83",
    "84",
    "85",
    "86",
    "87",
    "88",
    "89",
    "8a",
    "8b",
    "8c",
    "8d",
    "8e",
    "8f",
    "90",
    "91",
    "92",
    "93",
    "94",
    "95",
    "96",
    "97",
    "98",
    "99",
    "9a",
    "9b",
    "9c",
    "9d",
    "9e",
    "9f",
    "a0",
    "a1",
    "a2",
    "a3",
    "a4",
    "a5",
    "a6",
    "a7",
    "a8",
    "a9",
    "aa",
    "ab",
    "ac",
    "ad",
    "ae",
    "af",
    "b0",
    "b1",
    "b2",
    "b3",
    "b4",
    "b5",
    "b6",
    "b7",
    "b8",
    "b9",
    "ba",
    "bb",
    "bc",
    "bd",
    "be",
    "bf",
    "c0",
    "c1",
    "c2",
    "c3",
    "c4",
    "c5",
    "c6",
    "c7",
    "c8",
    "c9",
    "ca",
    "cb",
    "cc",
    "cd",
    "ce",
    "cf",
    "d0",
    "d1",
    "d2",
    "d3",
    "d4",
    "d5",
    "d6",
    "d7",
    "d8",
    "d9",
    "da",
    "db",
    "dc",
    "dd",
    "de",
    "df",
    "e0",
    "e1",
    "e2",
    "e3",
    "e4",
    "e5",
    "e6",
    "e7",
    "e8",
    "e9",
    "ea",
    "eb",
    "ec",
    "ed",
    "ee",
    "ef",
    "f0",
    "f1",
    "f2",
    "f3",
    "f4",
    "f5",
    "f6",
    "f7",
    "f8",
    "f9",
    "fa",
    "fb",
    "fc",
    "fd",
    "fe",
    "ff"
];
let _seed = 1234567;
const DEG2RAD = Math.PI / 180;
const RAD2DEG = 180 / Math.PI;
// http://stackoverflow.com/questions/105034/how-to-create-a-guid-uuid-in-javascript/21963136#21963136
function generateUUID() {
    const d0 = Math.random() * 0xffffffff | 0;
    const d1 = Math.random() * 0xffffffff | 0;
    const d2 = Math.random() * 0xffffffff | 0;
    const d3 = Math.random() * 0xffffffff | 0;
    const uuid = _lut[d0 & 0xff] + _lut[d0 >> 8 & 0xff] + _lut[d0 >> 16 & 0xff] + _lut[d0 >> 24 & 0xff] + "-" + _lut[d1 & 0xff] + _lut[d1 >> 8 & 0xff] + "-" + _lut[d1 >> 16 & 0x0f | 0x40] + _lut[d1 >> 24 & 0xff] + "-" + _lut[d2 & 0x3f | 0x80] + _lut[d2 >> 8 & 0xff] + "-" + _lut[d2 >> 16 & 0xff] + _lut[d2 >> 24 & 0xff] + _lut[d3 & 0xff] + _lut[d3 >> 8 & 0xff] + _lut[d3 >> 16 & 0xff] + _lut[d3 >> 24 & 0xff];
    // .toLowerCase() here flattens concatenated strings to save heap memory space.
    return uuid.toLowerCase();
}
function clamp(value, min, max) {
    return Math.max(min, Math.min(max, value));
}
// compute euclidean modulo of m % n
// https://en.wikipedia.org/wiki/Modulo_operation
function euclideanModulo(n, m) {
    return (n % m + m) % m;
}
// Linear mapping from range <a1, a2> to range <b1, b2>
function mapLinear(x, a1, a2, b1, b2) {
    return b1 + (x - a1) * (b2 - b1) / (a2 - a1);
}
// https://www.gamedev.net/tutorials/programming/general-and-gameplay-programming/inverse-lerp-a-super-useful-yet-often-overlooked-function-r5230/
function inverseLerp(x, y, value) {
    if (x !== y) return (value - x) / (y - x);
    else return 0;
}
// https://en.wikipedia.org/wiki/Linear_interpolation
function lerp(x, y, t) {
    return (1 - t) * x + t * y;
}
// http://www.rorydriscoll.com/2016/03/07/frame-rate-independent-damping-using-lerp/
function damp(x, y, lambda, dt) {
    return lerp(x, y, 1 - Math.exp(-lambda * dt));
}
// https://www.desmos.com/calculator/vcsjnyz7x4
function pingpong(x, length = 1) {
    return length - Math.abs(euclideanModulo(x, length * 2) - length);
}
// http://en.wikipedia.org/wiki/Smoothstep
function smoothstep(x, min, max) {
    if (x <= min) return 0;
    if (x >= max) return 1;
    x = (x - min) / (max - min);
    return x * x * (3 - 2 * x);
}
function smootherstep(x, min, max) {
    if (x <= min) return 0;
    if (x >= max) return 1;
    x = (x - min) / (max - min);
    return x * x * x * (x * (x * 6 - 15) + 10);
}
// Random integer from <low, high> interval
function randInt(low, high) {
    return low + Math.floor(Math.random() * (high - low + 1));
}
// Random float from <low, high> interval
function randFloat(low, high) {
    return low + Math.random() * (high - low);
}
// Random float from <-range/2, range/2> interval
function randFloatSpread(range) {
    return range * (0.5 - Math.random());
}
// Deterministic pseudo-random float in the interval [ 0, 1 ]
function seededRandom(s) {
    if (s !== undefined) _seed = s;
    // Mulberry32 generator
    let t = _seed += 0x6D2B79F5;
    t = Math.imul(t ^ t >>> 15, t | 1);
    t ^= t + Math.imul(t ^ t >>> 7, t | 61);
    return ((t ^ t >>> 14) >>> 0) / 4294967296;
}
function degToRad(degrees) {
    return degrees * DEG2RAD;
}
function radToDeg(radians) {
    return radians * RAD2DEG;
}
function isPowerOfTwo(value) {
    return (value & value - 1) === 0 && value !== 0;
}
function ceilPowerOfTwo(value) {
    return Math.pow(2, Math.ceil(Math.log(value) / Math.LN2));
}
function floorPowerOfTwo(value) {
    return Math.pow(2, Math.floor(Math.log(value) / Math.LN2));
}
function setQuaternionFromProperEuler(q, a, b, c, order) {
    // Intrinsic Proper Euler Angles - see https://en.wikipedia.org/wiki/Euler_angles
    // rotations are applied to the axes in the order specified by 'order'
    // rotation by angle 'a' is applied first, then by angle 'b', then by angle 'c'
    // angles are in radians
    const cos = Math.cos;
    const sin = Math.sin;
    const c2 = cos(b / 2);
    const s2 = sin(b / 2);
    const c13 = cos((a + c) / 2);
    const s13 = sin((a + c) / 2);
    const c1_3 = cos((a - c) / 2);
    const s1_3 = sin((a - c) / 2);
    const c3_1 = cos((c - a) / 2);
    const s3_1 = sin((c - a) / 2);
    switch(order){
        case "XYX":
            q.set(c2 * s13, s2 * c1_3, s2 * s1_3, c2 * c13);
            break;
        case "YZY":
            q.set(s2 * s1_3, c2 * s13, s2 * c1_3, c2 * c13);
            break;
        case "ZXZ":
            q.set(s2 * c1_3, s2 * s1_3, c2 * s13, c2 * c13);
            break;
        case "XZX":
            q.set(c2 * s13, s2 * s3_1, s2 * c3_1, c2 * c13);
            break;
        case "YXY":
            q.set(s2 * c3_1, c2 * s13, s2 * s3_1, c2 * c13);
            break;
        case "ZYZ":
            q.set(s2 * s3_1, s2 * c3_1, c2 * s13, c2 * c13);
            break;
        default:
            console.warn("THREE.MathUtils: .setQuaternionFromProperEuler() encountered an unknown order: " + order);
    }
}
function denormalize(value, array) {
    switch(array.constructor){
        case Float32Array:
            return value;
        case Uint32Array:
            return value / 4294967295.0;
        case Uint16Array:
            return value / 65535.0;
        case Uint8Array:
            return value / 255.0;
        case Int32Array:
            return Math.max(value / 2147483647.0, -1);
        case Int16Array:
            return Math.max(value / 32767.0, -1);
        case Int8Array:
            return Math.max(value / 127.0, -1);
        default:
            throw new Error("Invalid component type.");
    }
}
function normalize(value, array) {
    switch(array.constructor){
        case Float32Array:
            return value;
        case Uint32Array:
            return Math.round(value * 4294967295.0);
        case Uint16Array:
            return Math.round(value * 65535.0);
        case Uint8Array:
            return Math.round(value * 255.0);
        case Int32Array:
            return Math.round(value * 2147483647.0);
        case Int16Array:
            return Math.round(value * 32767.0);
        case Int8Array:
            return Math.round(value * 127.0);
        default:
            throw new Error("Invalid component type.");
    }
}
const MathUtils = {
    DEG2RAD: DEG2RAD,
    RAD2DEG: RAD2DEG,
    generateUUID: generateUUID,
    clamp: clamp,
    euclideanModulo: euclideanModulo,
    mapLinear: mapLinear,
    inverseLerp: inverseLerp,
    lerp: lerp,
    damp: damp,
    pingpong: pingpong,
    smoothstep: smoothstep,
    smootherstep: smootherstep,
    randInt: randInt,
    randFloat: randFloat,
    randFloatSpread: randFloatSpread,
    seededRandom: seededRandom,
    degToRad: degToRad,
    radToDeg: radToDeg,
    isPowerOfTwo: isPowerOfTwo,
    ceilPowerOfTwo: ceilPowerOfTwo,
    floorPowerOfTwo: floorPowerOfTwo,
    setQuaternionFromProperEuler: setQuaternionFromProperEuler,
    normalize: normalize,
    denormalize: denormalize
};
class Vector2 {
    constructor(x = 0, y = 0){
        Vector2.prototype.isVector2 = true;
        this.x = x;
        this.y = y;
    }
    get width() {
        return this.x;
    }
    set width(value) {
        this.x = value;
    }
    get height() {
        return this.y;
    }
    set height(value) {
        this.y = value;
    }
    set(x, y) {
        this.x = x;
        this.y = y;
        return this;
    }
    setScalar(scalar) {
        this.x = scalar;
        this.y = scalar;
        return this;
    }
    setX(x) {
        this.x = x;
        return this;
    }
    setY(y) {
        this.y = y;
        return this;
    }
    setComponent(index, value) {
        switch(index){
            case 0:
                this.x = value;
                break;
            case 1:
                this.y = value;
                break;
            default:
                throw new Error("index is out of range: " + index);
        }
        return this;
    }
    getComponent(index) {
        switch(index){
            case 0:
                return this.x;
            case 1:
                return this.y;
            default:
                throw new Error("index is out of range: " + index);
        }
    }
    clone() {
        return new this.constructor(this.x, this.y);
    }
    copy(v) {
        this.x = v.x;
        this.y = v.y;
        return this;
    }
    add(v) {
        this.x += v.x;
        this.y += v.y;
        return this;
    }
    addScalar(s) {
        this.x += s;
        this.y += s;
        return this;
    }
    addVectors(a, b) {
        this.x = a.x + b.x;
        this.y = a.y + b.y;
        return this;
    }
    addScaledVector(v, s) {
        this.x += v.x * s;
        this.y += v.y * s;
        return this;
    }
    sub(v) {
        this.x -= v.x;
        this.y -= v.y;
        return this;
    }
    subScalar(s) {
        this.x -= s;
        this.y -= s;
        return this;
    }
    subVectors(a, b) {
        this.x = a.x - b.x;
        this.y = a.y - b.y;
        return this;
    }
    multiply(v) {
        this.x *= v.x;
        this.y *= v.y;
        return this;
    }
    multiplyScalar(scalar) {
        this.x *= scalar;
        this.y *= scalar;
        return this;
    }
    divide(v) {
        this.x /= v.x;
        this.y /= v.y;
        return this;
    }
    divideScalar(scalar) {
        return this.multiplyScalar(1 / scalar);
    }
    applyMatrix3(m) {
        const x = this.x, y = this.y;
        const e = m.elements;
        this.x = e[0] * x + e[3] * y + e[6];
        this.y = e[1] * x + e[4] * y + e[7];
        return this;
    }
    min(v) {
        this.x = Math.min(this.x, v.x);
        this.y = Math.min(this.y, v.y);
        return this;
    }
    max(v) {
        this.x = Math.max(this.x, v.x);
        this.y = Math.max(this.y, v.y);
        return this;
    }
    clamp(min, max) {
        // assumes min < max, componentwise
        this.x = Math.max(min.x, Math.min(max.x, this.x));
        this.y = Math.max(min.y, Math.min(max.y, this.y));
        return this;
    }
    clampScalar(minVal, maxVal) {
        this.x = Math.max(minVal, Math.min(maxVal, this.x));
        this.y = Math.max(minVal, Math.min(maxVal, this.y));
        return this;
    }
    clampLength(min, max) {
        const length = this.length();
        return this.divideScalar(length || 1).multiplyScalar(Math.max(min, Math.min(max, length)));
    }
    floor() {
        this.x = Math.floor(this.x);
        this.y = Math.floor(this.y);
        return this;
    }
    ceil() {
        this.x = Math.ceil(this.x);
        this.y = Math.ceil(this.y);
        return this;
    }
    round() {
        this.x = Math.round(this.x);
        this.y = Math.round(this.y);
        return this;
    }
    roundToZero() {
        this.x = Math.trunc(this.x);
        this.y = Math.trunc(this.y);
        return this;
    }
    negate() {
        this.x = -this.x;
        this.y = -this.y;
        return this;
    }
    dot(v) {
        return this.x * v.x + this.y * v.y;
    }
    cross(v) {
        return this.x * v.y - this.y * v.x;
    }
    lengthSq() {
        return this.x * this.x + this.y * this.y;
    }
    length() {
        return Math.sqrt(this.x * this.x + this.y * this.y);
    }
    manhattanLength() {
        return Math.abs(this.x) + Math.abs(this.y);
    }
    normalize() {
        return this.divideScalar(this.length() || 1);
    }
    angle() {
        // computes the angle in radians with respect to the positive x-axis
        const angle = Math.atan2(-this.y, -this.x) + Math.PI;
        return angle;
    }
    angleTo(v) {
        const denominator = Math.sqrt(this.lengthSq() * v.lengthSq());
        if (denominator === 0) return Math.PI / 2;
        const theta = this.dot(v) / denominator;
        // clamp, to handle numerical problems
        return Math.acos(clamp(theta, -1, 1));
    }
    distanceTo(v) {
        return Math.sqrt(this.distanceToSquared(v));
    }
    distanceToSquared(v) {
        const dx = this.x - v.x, dy = this.y - v.y;
        return dx * dx + dy * dy;
    }
    manhattanDistanceTo(v) {
        return Math.abs(this.x - v.x) + Math.abs(this.y - v.y);
    }
    setLength(length) {
        return this.normalize().multiplyScalar(length);
    }
    lerp(v, alpha) {
        this.x += (v.x - this.x) * alpha;
        this.y += (v.y - this.y) * alpha;
        return this;
    }
    lerpVectors(v1, v2, alpha) {
        this.x = v1.x + (v2.x - v1.x) * alpha;
        this.y = v1.y + (v2.y - v1.y) * alpha;
        return this;
    }
    equals(v) {
        return v.x === this.x && v.y === this.y;
    }
    fromArray(array, offset = 0) {
        this.x = array[offset];
        this.y = array[offset + 1];
        return this;
    }
    toArray(array = [], offset = 0) {
        array[offset] = this.x;
        array[offset + 1] = this.y;
        return array;
    }
    fromBufferAttribute(attribute, index) {
        this.x = attribute.getX(index);
        this.y = attribute.getY(index);
        return this;
    }
    rotateAround(center, angle) {
        const c = Math.cos(angle), s = Math.sin(angle);
        const x = this.x - center.x;
        const y = this.y - center.y;
        this.x = x * c - y * s + center.x;
        this.y = x * s + y * c + center.y;
        return this;
    }
    random() {
        this.x = Math.random();
        this.y = Math.random();
        return this;
    }
    *[Symbol.iterator]() {
        yield this.x;
        yield this.y;
    }
}
class Matrix3 {
    constructor(n11, n12, n13, n21, n22, n23, n31, n32, n33){
        Matrix3.prototype.isMatrix3 = true;
        this.elements = [
            1,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            1
        ];
        if (n11 !== undefined) this.set(n11, n12, n13, n21, n22, n23, n31, n32, n33);
    }
    set(n11, n12, n13, n21, n22, n23, n31, n32, n33) {
        const te = this.elements;
        te[0] = n11;
        te[1] = n21;
        te[2] = n31;
        te[3] = n12;
        te[4] = n22;
        te[5] = n32;
        te[6] = n13;
        te[7] = n23;
        te[8] = n33;
        return this;
    }
    identity() {
        this.set(1, 0, 0, 0, 1, 0, 0, 0, 1);
        return this;
    }
    copy(m) {
        const te = this.elements;
        const me = m.elements;
        te[0] = me[0];
        te[1] = me[1];
        te[2] = me[2];
        te[3] = me[3];
        te[4] = me[4];
        te[5] = me[5];
        te[6] = me[6];
        te[7] = me[7];
        te[8] = me[8];
        return this;
    }
    extractBasis(xAxis, yAxis, zAxis) {
        xAxis.setFromMatrix3Column(this, 0);
        yAxis.setFromMatrix3Column(this, 1);
        zAxis.setFromMatrix3Column(this, 2);
        return this;
    }
    setFromMatrix4(m) {
        const me = m.elements;
        this.set(me[0], me[4], me[8], me[1], me[5], me[9], me[2], me[6], me[10]);
        return this;
    }
    multiply(m) {
        return this.multiplyMatrices(this, m);
    }
    premultiply(m) {
        return this.multiplyMatrices(m, this);
    }
    multiplyMatrices(a, b) {
        const ae = a.elements;
        const be = b.elements;
        const te = this.elements;
        const a11 = ae[0], a12 = ae[3], a13 = ae[6];
        const a21 = ae[1], a22 = ae[4], a23 = ae[7];
        const a31 = ae[2], a32 = ae[5], a33 = ae[8];
        const b11 = be[0], b12 = be[3], b13 = be[6];
        const b21 = be[1], b22 = be[4], b23 = be[7];
        const b31 = be[2], b32 = be[5], b33 = be[8];
        te[0] = a11 * b11 + a12 * b21 + a13 * b31;
        te[3] = a11 * b12 + a12 * b22 + a13 * b32;
        te[6] = a11 * b13 + a12 * b23 + a13 * b33;
        te[1] = a21 * b11 + a22 * b21 + a23 * b31;
        te[4] = a21 * b12 + a22 * b22 + a23 * b32;
        te[7] = a21 * b13 + a22 * b23 + a23 * b33;
        te[2] = a31 * b11 + a32 * b21 + a33 * b31;
        te[5] = a31 * b12 + a32 * b22 + a33 * b32;
        te[8] = a31 * b13 + a32 * b23 + a33 * b33;
        return this;
    }
    multiplyScalar(s) {
        const te = this.elements;
        te[0] *= s;
        te[3] *= s;
        te[6] *= s;
        te[1] *= s;
        te[4] *= s;
        te[7] *= s;
        te[2] *= s;
        te[5] *= s;
        te[8] *= s;
        return this;
    }
    determinant() {
        const te = this.elements;
        const a = te[0], b = te[1], c = te[2], d = te[3], e = te[4], f = te[5], g = te[6], h = te[7], i = te[8];
        return a * e * i - a * f * h - b * d * i + b * f * g + c * d * h - c * e * g;
    }
    invert() {
        const te = this.elements, n11 = te[0], n21 = te[1], n31 = te[2], n12 = te[3], n22 = te[4], n32 = te[5], n13 = te[6], n23 = te[7], n33 = te[8], t11 = n33 * n22 - n32 * n23, t12 = n32 * n13 - n33 * n12, t13 = n23 * n12 - n22 * n13, det = n11 * t11 + n21 * t12 + n31 * t13;
        if (det === 0) return this.set(0, 0, 0, 0, 0, 0, 0, 0, 0);
        const detInv = 1 / det;
        te[0] = t11 * detInv;
        te[1] = (n31 * n23 - n33 * n21) * detInv;
        te[2] = (n32 * n21 - n31 * n22) * detInv;
        te[3] = t12 * detInv;
        te[4] = (n33 * n11 - n31 * n13) * detInv;
        te[5] = (n31 * n12 - n32 * n11) * detInv;
        te[6] = t13 * detInv;
        te[7] = (n21 * n13 - n23 * n11) * detInv;
        te[8] = (n22 * n11 - n21 * n12) * detInv;
        return this;
    }
    transpose() {
        let tmp;
        const m = this.elements;
        tmp = m[1];
        m[1] = m[3];
        m[3] = tmp;
        tmp = m[2];
        m[2] = m[6];
        m[6] = tmp;
        tmp = m[5];
        m[5] = m[7];
        m[7] = tmp;
        return this;
    }
    getNormalMatrix(matrix4) {
        return this.setFromMatrix4(matrix4).invert().transpose();
    }
    transposeIntoArray(r) {
        const m = this.elements;
        r[0] = m[0];
        r[1] = m[3];
        r[2] = m[6];
        r[3] = m[1];
        r[4] = m[4];
        r[5] = m[7];
        r[6] = m[2];
        r[7] = m[5];
        r[8] = m[8];
        return this;
    }
    setUvTransform(tx, ty, sx, sy, rotation, cx, cy) {
        const c = Math.cos(rotation);
        const s = Math.sin(rotation);
        this.set(sx * c, sx * s, -sx * (c * cx + s * cy) + cx + tx, -sy * s, sy * c, -sy * (-s * cx + c * cy) + cy + ty, 0, 0, 1);
        return this;
    }
    //
    scale(sx, sy) {
        this.premultiply(_m3.makeScale(sx, sy));
        return this;
    }
    rotate(theta) {
        this.premultiply(_m3.makeRotation(-theta));
        return this;
    }
    translate(tx, ty) {
        this.premultiply(_m3.makeTranslation(tx, ty));
        return this;
    }
    // for 2D Transforms
    makeTranslation(x, y) {
        if (x.isVector2) this.set(1, 0, x.x, 0, 1, x.y, 0, 0, 1);
        else this.set(1, 0, x, 0, 1, y, 0, 0, 1);
        return this;
    }
    makeRotation(theta) {
        // counterclockwise
        const c = Math.cos(theta);
        const s = Math.sin(theta);
        this.set(c, -s, 0, s, c, 0, 0, 0, 1);
        return this;
    }
    makeScale(x, y) {
        this.set(x, 0, 0, 0, y, 0, 0, 0, 1);
        return this;
    }
    //
    equals(matrix) {
        const te = this.elements;
        const me = matrix.elements;
        for(let i = 0; i < 9; i++){
            if (te[i] !== me[i]) return false;
        }
        return true;
    }
    fromArray(array, offset = 0) {
        for(let i = 0; i < 9; i++)this.elements[i] = array[i + offset];
        return this;
    }
    toArray(array = [], offset = 0) {
        const te = this.elements;
        array[offset] = te[0];
        array[offset + 1] = te[1];
        array[offset + 2] = te[2];
        array[offset + 3] = te[3];
        array[offset + 4] = te[4];
        array[offset + 5] = te[5];
        array[offset + 6] = te[6];
        array[offset + 7] = te[7];
        array[offset + 8] = te[8];
        return array;
    }
    clone() {
        return new this.constructor().fromArray(this.elements);
    }
}
const _m3 = /*@__PURE__*/ new Matrix3();
function arrayNeedsUint32(array) {
    // assumes larger values usually on last
    for(let i = array.length - 1; i >= 0; --i){
        if (array[i] >= 65535) return true; // account for PRIMITIVE_RESTART_FIXED_INDEX, #24565
    }
    return false;
}
const TYPED_ARRAYS = {
    Int8Array: Int8Array,
    Uint8Array: Uint8Array,
    Uint8ClampedArray: Uint8ClampedArray,
    Int16Array: Int16Array,
    Uint16Array: Uint16Array,
    Int32Array: Int32Array,
    Uint32Array: Uint32Array,
    Float32Array: Float32Array,
    Float64Array: Float64Array
};
function getTypedArray(type, buffer) {
    return new TYPED_ARRAYS[type](buffer);
}
function createElementNS(name) {
    return document.createElementNS("http://www.w3.org/1999/xhtml", name);
}
function createCanvasElement() {
    const canvas = createElementNS("canvas");
    canvas.style.display = "block";
    return canvas;
}
const _cache = {};
function warnOnce(message) {
    if (message in _cache) return;
    _cache[message] = true;
    console.warn(message);
}
function probeAsync(gl, sync, interval) {
    return new Promise(function(resolve, reject) {
        function probe() {
            switch(gl.clientWaitSync(sync, gl.SYNC_FLUSH_COMMANDS_BIT, 0)){
                case gl.WAIT_FAILED:
                    reject();
                    break;
                case gl.TIMEOUT_EXPIRED:
                    setTimeout(probe, interval);
                    break;
                default:
                    resolve();
            }
        }
        setTimeout(probe, interval);
    });
}
/**
 * Matrices converting P3 <-> Rec. 709 primaries, without gamut mapping
 * or clipping. Based on W3C specifications for sRGB and Display P3,
 * and ICC specifications for the D50 connection space. Values in/out
 * are _linear_ sRGB and _linear_ Display P3.
 *
 * Note that both sRGB and Display P3 use the sRGB transfer functions.
 *
 * Reference:
 * - http://www.russellcottrell.com/photo/matrixCalculator.htm
 */ const LINEAR_SRGB_TO_LINEAR_DISPLAY_P3 = /*@__PURE__*/ new Matrix3().set(0.8224621, 0.177538, 0.0, 0.0331941, 0.9668058, 0.0, 0.0170827, 0.0723974, 0.9105199);
const LINEAR_DISPLAY_P3_TO_LINEAR_SRGB = /*@__PURE__*/ new Matrix3().set(1.2249401, -0.2249404, 0.0, -0.0420569, 1.0420571, 0.0, -0.0196376, -0.0786361, 1.0982735);
/**
 * Defines supported color spaces by transfer function and primaries,
 * and provides conversions to/from the Linear-sRGB reference space.
 */ const COLOR_SPACES = {
    [LinearSRGBColorSpace]: {
        transfer: LinearTransfer,
        primaries: Rec709Primaries,
        toReference: (color)=>color,
        fromReference: (color)=>color
    },
    [SRGBColorSpace]: {
        transfer: SRGBTransfer,
        primaries: Rec709Primaries,
        toReference: (color)=>color.convertSRGBToLinear(),
        fromReference: (color)=>color.convertLinearToSRGB()
    },
    [LinearDisplayP3ColorSpace]: {
        transfer: LinearTransfer,
        primaries: P3Primaries,
        toReference: (color)=>color.applyMatrix3(LINEAR_DISPLAY_P3_TO_LINEAR_SRGB),
        fromReference: (color)=>color.applyMatrix3(LINEAR_SRGB_TO_LINEAR_DISPLAY_P3)
    },
    [DisplayP3ColorSpace]: {
        transfer: SRGBTransfer,
        primaries: P3Primaries,
        toReference: (color)=>color.convertSRGBToLinear().applyMatrix3(LINEAR_DISPLAY_P3_TO_LINEAR_SRGB),
        fromReference: (color)=>color.applyMatrix3(LINEAR_SRGB_TO_LINEAR_DISPLAY_P3).convertLinearToSRGB()
    }
};
const SUPPORTED_WORKING_COLOR_SPACES = new Set([
    LinearSRGBColorSpace,
    LinearDisplayP3ColorSpace
]);
const ColorManagement = {
    enabled: true,
    _workingColorSpace: LinearSRGBColorSpace,
    get workingColorSpace () {
        return this._workingColorSpace;
    },
    set workingColorSpace (colorSpace){
        if (!SUPPORTED_WORKING_COLOR_SPACES.has(colorSpace)) throw new Error(`Unsupported working color space, "${colorSpace}".`);
        this._workingColorSpace = colorSpace;
    },
    convert: function(color, sourceColorSpace, targetColorSpace) {
        if (this.enabled === false || sourceColorSpace === targetColorSpace || !sourceColorSpace || !targetColorSpace) return color;
        const sourceToReference = COLOR_SPACES[sourceColorSpace].toReference;
        const targetFromReference = COLOR_SPACES[targetColorSpace].fromReference;
        return targetFromReference(sourceToReference(color));
    },
    fromWorkingColorSpace: function(color, targetColorSpace) {
        return this.convert(color, this._workingColorSpace, targetColorSpace);
    },
    toWorkingColorSpace: function(color, sourceColorSpace) {
        return this.convert(color, sourceColorSpace, this._workingColorSpace);
    },
    getPrimaries: function(colorSpace1) {
        return COLOR_SPACES[colorSpace1].primaries;
    },
    getTransfer: function(colorSpace1) {
        if (colorSpace1 === NoColorSpace) return LinearTransfer;
        return COLOR_SPACES[colorSpace1].transfer;
    }
};
function SRGBToLinear(c) {
    return c < 0.04045 ? c * 0.0773993808 : Math.pow(c * 0.9478672986 + 0.0521327014, 2.4);
}
function LinearToSRGB(c) {
    return c < 0.0031308 ? c * 12.92 : 1.055 * Math.pow(c, 0.41666) - 0.055;
}
let _canvas;
class ImageUtils {
    static getDataURL(image) {
        if (/^data:/i.test(image.src)) return image.src;
        if (typeof HTMLCanvasElement === "undefined") return image.src;
        let canvas;
        if (image instanceof HTMLCanvasElement) canvas = image;
        else {
            if (_canvas === undefined) _canvas = createElementNS("canvas");
            _canvas.width = image.width;
            _canvas.height = image.height;
            const context = _canvas.getContext("2d");
            if (image instanceof ImageData) context.putImageData(image, 0, 0);
            else context.drawImage(image, 0, 0, image.width, image.height);
            canvas = _canvas;
        }
        if (canvas.width > 2048 || canvas.height > 2048) {
            console.warn("THREE.ImageUtils.getDataURL: Image converted to jpg for performance reasons", image);
            return canvas.toDataURL("image/jpeg", 0.6);
        } else return canvas.toDataURL("image/png");
    }
    static sRGBToLinear(image) {
        if (typeof HTMLImageElement !== "undefined" && image instanceof HTMLImageElement || typeof HTMLCanvasElement !== "undefined" && image instanceof HTMLCanvasElement || typeof ImageBitmap !== "undefined" && image instanceof ImageBitmap) {
            const canvas = createElementNS("canvas");
            canvas.width = image.width;
            canvas.height = image.height;
            const context = canvas.getContext("2d");
            context.drawImage(image, 0, 0, image.width, image.height);
            const imageData = context.getImageData(0, 0, image.width, image.height);
            const data = imageData.data;
            for(let i = 0; i < data.length; i++)data[i] = SRGBToLinear(data[i] / 255) * 255;
            context.putImageData(imageData, 0, 0);
            return canvas;
        } else if (image.data) {
            const data = image.data.slice(0);
            for(let i = 0; i < data.length; i++)if (data instanceof Uint8Array || data instanceof Uint8ClampedArray) data[i] = Math.floor(SRGBToLinear(data[i] / 255) * 255);
            else // assuming float
            data[i] = SRGBToLinear(data[i]);
            return {
                data: data,
                width: image.width,
                height: image.height
            };
        } else {
            console.warn("THREE.ImageUtils.sRGBToLinear(): Unsupported image type. No color space conversion applied.");
            return image;
        }
    }
}
let _sourceId = 0;
class Source {
    constructor(data = null){
        this.isSource = true;
        Object.defineProperty(this, "id", {
            value: _sourceId++
        });
        this.uuid = generateUUID();
        this.data = data;
        this.dataReady = true;
        this.version = 0;
    }
    set needsUpdate(value) {
        if (value === true) this.version++;
    }
    toJSON(meta) {
        const isRootObject = meta === undefined || typeof meta === "string";
        if (!isRootObject && meta.images[this.uuid] !== undefined) return meta.images[this.uuid];
        const output = {
            uuid: this.uuid,
            url: ""
        };
        const data = this.data;
        if (data !== null) {
            let url;
            if (Array.isArray(data)) {
                // cube texture
                url = [];
                for(let i = 0, l = data.length; i < l; i++)if (data[i].isDataTexture) url.push(serializeImage(data[i].image));
                else url.push(serializeImage(data[i]));
            } else // texture
            url = serializeImage(data);
            output.url = url;
        }
        if (!isRootObject) meta.images[this.uuid] = output;
        return output;
    }
}
function serializeImage(image) {
    if (typeof HTMLImageElement !== "undefined" && image instanceof HTMLImageElement || typeof HTMLCanvasElement !== "undefined" && image instanceof HTMLCanvasElement || typeof ImageBitmap !== "undefined" && image instanceof ImageBitmap) // default images
    return ImageUtils.getDataURL(image);
    else {
        if (image.data) // images of DataTexture
        return {
            data: Array.from(image.data),
            width: image.width,
            height: image.height,
            type: image.data.constructor.name
        };
        else {
            console.warn("THREE.Texture: Unable to serialize Texture.");
            return {};
        }
    }
}
let _textureId = 0;
class Texture extends EventDispatcher {
    constructor(image = Texture.DEFAULT_IMAGE, mapping = Texture.DEFAULT_MAPPING, wrapS = ClampToEdgeWrapping, wrapT = ClampToEdgeWrapping, magFilter = LinearFilter, minFilter = LinearMipmapLinearFilter, format = RGBAFormat, type = UnsignedByteType, anisotropy = Texture.DEFAULT_ANISOTROPY, colorSpace1 = NoColorSpace){
        super();
        this.isTexture = true;
        Object.defineProperty(this, "id", {
            value: _textureId++
        });
        this.uuid = generateUUID();
        this.name = "";
        this.source = new Source(image);
        this.mipmaps = [];
        this.mapping = mapping;
        this.channel = 0;
        this.wrapS = wrapS;
        this.wrapT = wrapT;
        this.magFilter = magFilter;
        this.minFilter = minFilter;
        this.anisotropy = anisotropy;
        this.format = format;
        this.internalFormat = null;
        this.type = type;
        this.offset = new Vector2(0, 0);
        this.repeat = new Vector2(1, 1);
        this.center = new Vector2(0, 0);
        this.rotation = 0;
        this.matrixAutoUpdate = true;
        this.matrix = new Matrix3();
        this.generateMipmaps = true;
        this.premultiplyAlpha = false;
        this.flipY = true;
        this.unpackAlignment = 4; // valid values: 1, 2, 4, 8 (see http://www.khronos.org/opengles/sdk/docs/man/xhtml/glPixelStorei.xml)
        this.colorSpace = colorSpace1;
        this.userData = {};
        this.version = 0;
        this.onUpdate = null;
        this.isRenderTargetTexture = false; // indicates whether a texture belongs to a render target or not
        this.pmremVersion = 0; // indicates whether this texture should be processed by PMREMGenerator or not (only relevant for render target textures)
    }
    get image() {
        return this.source.data;
    }
    set image(value = null) {
        this.source.data = value;
    }
    updateMatrix() {
        this.matrix.setUvTransform(this.offset.x, this.offset.y, this.repeat.x, this.repeat.y, this.rotation, this.center.x, this.center.y);
    }
    clone() {
        return new this.constructor().copy(this);
    }
    copy(source) {
        this.name = source.name;
        this.source = source.source;
        this.mipmaps = source.mipmaps.slice(0);
        this.mapping = source.mapping;
        this.channel = source.channel;
        this.wrapS = source.wrapS;
        this.wrapT = source.wrapT;
        this.magFilter = source.magFilter;
        this.minFilter = source.minFilter;
        this.anisotropy = source.anisotropy;
        this.format = source.format;
        this.internalFormat = source.internalFormat;
        this.type = source.type;
        this.offset.copy(source.offset);
        this.repeat.copy(source.repeat);
        this.center.copy(source.center);
        this.rotation = source.rotation;
        this.matrixAutoUpdate = source.matrixAutoUpdate;
        this.matrix.copy(source.matrix);
        this.generateMipmaps = source.generateMipmaps;
        this.premultiplyAlpha = source.premultiplyAlpha;
        this.flipY = source.flipY;
        this.unpackAlignment = source.unpackAlignment;
        this.colorSpace = source.colorSpace;
        this.userData = JSON.parse(JSON.stringify(source.userData));
        this.needsUpdate = true;
        return this;
    }
    toJSON(meta) {
        const isRootObject = meta === undefined || typeof meta === "string";
        if (!isRootObject && meta.textures[this.uuid] !== undefined) return meta.textures[this.uuid];
        const output = {
            metadata: {
                version: 4.6,
                type: "Texture",
                generator: "Texture.toJSON"
            },
            uuid: this.uuid,
            name: this.name,
            image: this.source.toJSON(meta).uuid,
            mapping: this.mapping,
            channel: this.channel,
            repeat: [
                this.repeat.x,
                this.repeat.y
            ],
            offset: [
                this.offset.x,
                this.offset.y
            ],
            center: [
                this.center.x,
                this.center.y
            ],
            rotation: this.rotation,
            wrap: [
                this.wrapS,
                this.wrapT
            ],
            format: this.format,
            internalFormat: this.internalFormat,
            type: this.type,
            colorSpace: this.colorSpace,
            minFilter: this.minFilter,
            magFilter: this.magFilter,
            anisotropy: this.anisotropy,
            flipY: this.flipY,
            generateMipmaps: this.generateMipmaps,
            premultiplyAlpha: this.premultiplyAlpha,
            unpackAlignment: this.unpackAlignment
        };
        if (Object.keys(this.userData).length > 0) output.userData = this.userData;
        if (!isRootObject) meta.textures[this.uuid] = output;
        return output;
    }
    dispose() {
        this.dispatchEvent({
            type: "dispose"
        });
    }
    transformUv(uv) {
        if (this.mapping !== UVMapping) return uv;
        uv.applyMatrix3(this.matrix);
        if (uv.x < 0 || uv.x > 1) switch(this.wrapS){
            case RepeatWrapping:
                uv.x = uv.x - Math.floor(uv.x);
                break;
            case ClampToEdgeWrapping:
                uv.x = uv.x < 0 ? 0 : 1;
                break;
            case MirroredRepeatWrapping:
                if (Math.abs(Math.floor(uv.x) % 2) === 1) uv.x = Math.ceil(uv.x) - uv.x;
                else uv.x = uv.x - Math.floor(uv.x);
                break;
        }
        if (uv.y < 0 || uv.y > 1) switch(this.wrapT){
            case RepeatWrapping:
                uv.y = uv.y - Math.floor(uv.y);
                break;
            case ClampToEdgeWrapping:
                uv.y = uv.y < 0 ? 0 : 1;
                break;
            case MirroredRepeatWrapping:
                if (Math.abs(Math.floor(uv.y) % 2) === 1) uv.y = Math.ceil(uv.y) - uv.y;
                else uv.y = uv.y - Math.floor(uv.y);
                break;
        }
        if (this.flipY) uv.y = 1 - uv.y;
        return uv;
    }
    set needsUpdate(value) {
        if (value === true) {
            this.version++;
            this.source.needsUpdate = true;
        }
    }
    set needsPMREMUpdate(value) {
        if (value === true) this.pmremVersion++;
    }
}
Texture.DEFAULT_IMAGE = null;
Texture.DEFAULT_MAPPING = UVMapping;
Texture.DEFAULT_ANISOTROPY = 1;
class Vector4 {
    constructor(x = 0, y = 0, z = 0, w = 1){
        Vector4.prototype.isVector4 = true;
        this.x = x;
        this.y = y;
        this.z = z;
        this.w = w;
    }
    get width() {
        return this.z;
    }
    set width(value) {
        this.z = value;
    }
    get height() {
        return this.w;
    }
    set height(value) {
        this.w = value;
    }
    set(x, y, z, w) {
        this.x = x;
        this.y = y;
        this.z = z;
        this.w = w;
        return this;
    }
    setScalar(scalar) {
        this.x = scalar;
        this.y = scalar;
        this.z = scalar;
        this.w = scalar;
        return this;
    }
    setX(x) {
        this.x = x;
        return this;
    }
    setY(y) {
        this.y = y;
        return this;
    }
    setZ(z) {
        this.z = z;
        return this;
    }
    setW(w) {
        this.w = w;
        return this;
    }
    setComponent(index, value) {
        switch(index){
            case 0:
                this.x = value;
                break;
            case 1:
                this.y = value;
                break;
            case 2:
                this.z = value;
                break;
            case 3:
                this.w = value;
                break;
            default:
                throw new Error("index is out of range: " + index);
        }
        return this;
    }
    getComponent(index) {
        switch(index){
            case 0:
                return this.x;
            case 1:
                return this.y;
            case 2:
                return this.z;
            case 3:
                return this.w;
            default:
                throw new Error("index is out of range: " + index);
        }
    }
    clone() {
        return new this.constructor(this.x, this.y, this.z, this.w);
    }
    copy(v) {
        this.x = v.x;
        this.y = v.y;
        this.z = v.z;
        this.w = v.w !== undefined ? v.w : 1;
        return this;
    }
    add(v) {
        this.x += v.x;
        this.y += v.y;
        this.z += v.z;
        this.w += v.w;
        return this;
    }
    addScalar(s) {
        this.x += s;
        this.y += s;
        this.z += s;
        this.w += s;
        return this;
    }
    addVectors(a, b) {
        this.x = a.x + b.x;
        this.y = a.y + b.y;
        this.z = a.z + b.z;
        this.w = a.w + b.w;
        return this;
    }
    addScaledVector(v, s) {
        this.x += v.x * s;
        this.y += v.y * s;
        this.z += v.z * s;
        this.w += v.w * s;
        return this;
    }
    sub(v) {
        this.x -= v.x;
        this.y -= v.y;
        this.z -= v.z;
        this.w -= v.w;
        return this;
    }
    subScalar(s) {
        this.x -= s;
        this.y -= s;
        this.z -= s;
        this.w -= s;
        return this;
    }
    subVectors(a, b) {
        this.x = a.x - b.x;
        this.y = a.y - b.y;
        this.z = a.z - b.z;
        this.w = a.w - b.w;
        return this;
    }
    multiply(v) {
        this.x *= v.x;
        this.y *= v.y;
        this.z *= v.z;
        this.w *= v.w;
        return this;
    }
    multiplyScalar(scalar) {
        this.x *= scalar;
        this.y *= scalar;
        this.z *= scalar;
        this.w *= scalar;
        return this;
    }
    applyMatrix4(m) {
        const x = this.x, y = this.y, z = this.z, w = this.w;
        const e = m.elements;
        this.x = e[0] * x + e[4] * y + e[8] * z + e[12] * w;
        this.y = e[1] * x + e[5] * y + e[9] * z + e[13] * w;
        this.z = e[2] * x + e[6] * y + e[10] * z + e[14] * w;
        this.w = e[3] * x + e[7] * y + e[11] * z + e[15] * w;
        return this;
    }
    divideScalar(scalar) {
        return this.multiplyScalar(1 / scalar);
    }
    setAxisAngleFromQuaternion(q) {
        // http://www.euclideanspace.com/maths/geometry/rotations/conversions/quaternionToAngle/index.htm
        // q is assumed to be normalized
        this.w = 2 * Math.acos(q.w);
        const s = Math.sqrt(1 - q.w * q.w);
        if (s < 0.0001) {
            this.x = 1;
            this.y = 0;
            this.z = 0;
        } else {
            this.x = q.x / s;
            this.y = q.y / s;
            this.z = q.z / s;
        }
        return this;
    }
    setAxisAngleFromRotationMatrix(m) {
        // http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToAngle/index.htm
        // assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)
        let angle, x, y, z; // variables for result
        const epsilon = 0.01, epsilon2 = 0.1, te = m.elements, m11 = te[0], m12 = te[4], m13 = te[8], m21 = te[1], m22 = te[5], m23 = te[9], m31 = te[2], m32 = te[6], m33 = te[10];
        if (Math.abs(m12 - m21) < epsilon && Math.abs(m13 - m31) < epsilon && Math.abs(m23 - m32) < epsilon) {
            // singularity found
            // first check for identity matrix which must have +1 for all terms
            // in leading diagonal and zero in other terms
            if (Math.abs(m12 + m21) < epsilon2 && Math.abs(m13 + m31) < epsilon2 && Math.abs(m23 + m32) < epsilon2 && Math.abs(m11 + m22 + m33 - 3) < epsilon2) {
                // this singularity is identity matrix so angle = 0
                this.set(1, 0, 0, 0);
                return this; // zero angle, arbitrary axis
            }
            // otherwise this singularity is angle = 180
            angle = Math.PI;
            const xx = (m11 + 1) / 2;
            const yy = (m22 + 1) / 2;
            const zz = (m33 + 1) / 2;
            const xy = (m12 + m21) / 4;
            const xz = (m13 + m31) / 4;
            const yz = (m23 + m32) / 4;
            if (xx > yy && xx > zz) {
                // m11 is the largest diagonal term
                if (xx < epsilon) {
                    x = 0;
                    y = 0.707106781;
                    z = 0.707106781;
                } else {
                    x = Math.sqrt(xx);
                    y = xy / x;
                    z = xz / x;
                }
            } else if (yy > zz) {
                // m22 is the largest diagonal term
                if (yy < epsilon) {
                    x = 0.707106781;
                    y = 0;
                    z = 0.707106781;
                } else {
                    y = Math.sqrt(yy);
                    x = xy / y;
                    z = yz / y;
                }
            } else // m33 is the largest diagonal term so base result on this
            if (zz < epsilon) {
                x = 0.707106781;
                y = 0.707106781;
                z = 0;
            } else {
                z = Math.sqrt(zz);
                x = xz / z;
                y = yz / z;
            }
            this.set(x, y, z, angle);
            return this; // return 180 deg rotation
        }
        // as we have reached here there are no singularities so we can handle normally
        let s = Math.sqrt((m32 - m23) * (m32 - m23) + (m13 - m31) * (m13 - m31) + (m21 - m12) * (m21 - m12)); // used to normalize
        if (Math.abs(s) < 0.001) s = 1;
        // prevent divide by zero, should not happen if matrix is orthogonal and should be
        // caught by singularity test above, but I've left it in just in case
        this.x = (m32 - m23) / s;
        this.y = (m13 - m31) / s;
        this.z = (m21 - m12) / s;
        this.w = Math.acos((m11 + m22 + m33 - 1) / 2);
        return this;
    }
    setFromMatrixPosition(m) {
        const e = m.elements;
        this.x = e[12];
        this.y = e[13];
        this.z = e[14];
        this.w = e[15];
        return this;
    }
    min(v) {
        this.x = Math.min(this.x, v.x);
        this.y = Math.min(this.y, v.y);
        this.z = Math.min(this.z, v.z);
        this.w = Math.min(this.w, v.w);
        return this;
    }
    max(v) {
        this.x = Math.max(this.x, v.x);
        this.y = Math.max(this.y, v.y);
        this.z = Math.max(this.z, v.z);
        this.w = Math.max(this.w, v.w);
        return this;
    }
    clamp(min, max) {
        // assumes min < max, componentwise
        this.x = Math.max(min.x, Math.min(max.x, this.x));
        this.y = Math.max(min.y, Math.min(max.y, this.y));
        this.z = Math.max(min.z, Math.min(max.z, this.z));
        this.w = Math.max(min.w, Math.min(max.w, this.w));
        return this;
    }
    clampScalar(minVal, maxVal) {
        this.x = Math.max(minVal, Math.min(maxVal, this.x));
        this.y = Math.max(minVal, Math.min(maxVal, this.y));
        this.z = Math.max(minVal, Math.min(maxVal, this.z));
        this.w = Math.max(minVal, Math.min(maxVal, this.w));
        return this;
    }
    clampLength(min, max) {
        const length = this.length();
        return this.divideScalar(length || 1).multiplyScalar(Math.max(min, Math.min(max, length)));
    }
    floor() {
        this.x = Math.floor(this.x);
        this.y = Math.floor(this.y);
        this.z = Math.floor(this.z);
        this.w = Math.floor(this.w);
        return this;
    }
    ceil() {
        this.x = Math.ceil(this.x);
        this.y = Math.ceil(this.y);
        this.z = Math.ceil(this.z);
        this.w = Math.ceil(this.w);
        return this;
    }
    round() {
        this.x = Math.round(this.x);
        this.y = Math.round(this.y);
        this.z = Math.round(this.z);
        this.w = Math.round(this.w);
        return this;
    }
    roundToZero() {
        this.x = Math.trunc(this.x);
        this.y = Math.trunc(this.y);
        this.z = Math.trunc(this.z);
        this.w = Math.trunc(this.w);
        return this;
    }
    negate() {
        this.x = -this.x;
        this.y = -this.y;
        this.z = -this.z;
        this.w = -this.w;
        return this;
    }
    dot(v) {
        return this.x * v.x + this.y * v.y + this.z * v.z + this.w * v.w;
    }
    lengthSq() {
        return this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w;
    }
    length() {
        return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w);
    }
    manhattanLength() {
        return Math.abs(this.x) + Math.abs(this.y) + Math.abs(this.z) + Math.abs(this.w);
    }
    normalize() {
        return this.divideScalar(this.length() || 1);
    }
    setLength(length) {
        return this.normalize().multiplyScalar(length);
    }
    lerp(v, alpha) {
        this.x += (v.x - this.x) * alpha;
        this.y += (v.y - this.y) * alpha;
        this.z += (v.z - this.z) * alpha;
        this.w += (v.w - this.w) * alpha;
        return this;
    }
    lerpVectors(v1, v2, alpha) {
        this.x = v1.x + (v2.x - v1.x) * alpha;
        this.y = v1.y + (v2.y - v1.y) * alpha;
        this.z = v1.z + (v2.z - v1.z) * alpha;
        this.w = v1.w + (v2.w - v1.w) * alpha;
        return this;
    }
    equals(v) {
        return v.x === this.x && v.y === this.y && v.z === this.z && v.w === this.w;
    }
    fromArray(array, offset = 0) {
        this.x = array[offset];
        this.y = array[offset + 1];
        this.z = array[offset + 2];
        this.w = array[offset + 3];
        return this;
    }
    toArray(array = [], offset = 0) {
        array[offset] = this.x;
        array[offset + 1] = this.y;
        array[offset + 2] = this.z;
        array[offset + 3] = this.w;
        return array;
    }
    fromBufferAttribute(attribute, index) {
        this.x = attribute.getX(index);
        this.y = attribute.getY(index);
        this.z = attribute.getZ(index);
        this.w = attribute.getW(index);
        return this;
    }
    random() {
        this.x = Math.random();
        this.y = Math.random();
        this.z = Math.random();
        this.w = Math.random();
        return this;
    }
    *[Symbol.iterator]() {
        yield this.x;
        yield this.y;
        yield this.z;
        yield this.w;
    }
}
/*
 In options, we can specify:
 * Texture parameters for an auto-generated target texture
 * depthBuffer/stencilBuffer: Booleans to indicate if we should generate these buffers
*/ class RenderTarget extends EventDispatcher {
    constructor(width = 1, height = 1, options = {}){
        super();
        this.isRenderTarget = true;
        this.width = width;
        this.height = height;
        this.depth = 1;
        this.scissor = new Vector4(0, 0, width, height);
        this.scissorTest = false;
        this.viewport = new Vector4(0, 0, width, height);
        const image = {
            width: width,
            height: height,
            depth: 1
        };
        options = Object.assign({
            generateMipmaps: false,
            internalFormat: null,
            minFilter: LinearFilter,
            depthBuffer: true,
            stencilBuffer: false,
            resolveDepthBuffer: true,
            resolveStencilBuffer: true,
            depthTexture: null,
            samples: 0,
            count: 1
        }, options);
        const texture = new Texture(image, options.mapping, options.wrapS, options.wrapT, options.magFilter, options.minFilter, options.format, options.type, options.anisotropy, options.colorSpace);
        texture.flipY = false;
        texture.generateMipmaps = options.generateMipmaps;
        texture.internalFormat = options.internalFormat;
        this.textures = [];
        const count = options.count;
        for(let i = 0; i < count; i++){
            this.textures[i] = texture.clone();
            this.textures[i].isRenderTargetTexture = true;
        }
        this.depthBuffer = options.depthBuffer;
        this.stencilBuffer = options.stencilBuffer;
        this.resolveDepthBuffer = options.resolveDepthBuffer;
        this.resolveStencilBuffer = options.resolveStencilBuffer;
        this.depthTexture = options.depthTexture;
        this.samples = options.samples;
    }
    get texture() {
        return this.textures[0];
    }
    set texture(value) {
        this.textures[0] = value;
    }
    setSize(width, height, depth = 1) {
        if (this.width !== width || this.height !== height || this.depth !== depth) {
            this.width = width;
            this.height = height;
            this.depth = depth;
            for(let i = 0, il = this.textures.length; i < il; i++){
                this.textures[i].image.width = width;
                this.textures[i].image.height = height;
                this.textures[i].image.depth = depth;
            }
            this.dispose();
        }
        this.viewport.set(0, 0, width, height);
        this.scissor.set(0, 0, width, height);
    }
    clone() {
        return new this.constructor().copy(this);
    }
    copy(source) {
        this.width = source.width;
        this.height = source.height;
        this.depth = source.depth;
        this.scissor.copy(source.scissor);
        this.scissorTest = source.scissorTest;
        this.viewport.copy(source.viewport);
        this.textures.length = 0;
        for(let i = 0, il = source.textures.length; i < il; i++){
            this.textures[i] = source.textures[i].clone();
            this.textures[i].isRenderTargetTexture = true;
        }
        // ensure image object is not shared, see #20328
        const image = Object.assign({}, source.texture.image);
        this.texture.source = new Source(image);
        this.depthBuffer = source.depthBuffer;
        this.stencilBuffer = source.stencilBuffer;
        this.resolveDepthBuffer = source.resolveDepthBuffer;
        this.resolveStencilBuffer = source.resolveStencilBuffer;
        if (source.depthTexture !== null) this.depthTexture = source.depthTexture.clone();
        this.samples = source.samples;
        return this;
    }
    dispose() {
        this.dispatchEvent({
            type: "dispose"
        });
    }
}
class WebGLRenderTarget extends RenderTarget {
    constructor(width = 1, height = 1, options = {}){
        super(width, height, options);
        this.isWebGLRenderTarget = true;
    }
}
class DataArrayTexture extends Texture {
    constructor(data = null, width = 1, height = 1, depth = 1){
        super(null);
        this.isDataArrayTexture = true;
        this.image = {
            data,
            width,
            height,
            depth
        };
        this.magFilter = NearestFilter;
        this.minFilter = NearestFilter;
        this.wrapR = ClampToEdgeWrapping;
        this.generateMipmaps = false;
        this.flipY = false;
        this.unpackAlignment = 1;
        this.layerUpdates = new Set();
    }
    addLayerUpdate(layerIndex) {
        this.layerUpdates.add(layerIndex);
    }
    clearLayerUpdates() {
        this.layerUpdates.clear();
    }
}
class WebGLArrayRenderTarget extends WebGLRenderTarget {
    constructor(width = 1, height = 1, depth = 1, options = {}){
        super(width, height, options);
        this.isWebGLArrayRenderTarget = true;
        this.depth = depth;
        this.texture = new DataArrayTexture(null, width, height, depth);
        this.texture.isRenderTargetTexture = true;
    }
}
class Data3DTexture extends Texture {
    constructor(data = null, width = 1, height = 1, depth = 1){
        // We're going to add .setXXX() methods for setting properties later.
        // Users can still set in DataTexture3D directly.
        //
        //	const texture = new THREE.DataTexture3D( data, width, height, depth );
        // 	texture.anisotropy = 16;
        //
        // See #14839
        super(null);
        this.isData3DTexture = true;
        this.image = {
            data,
            width,
            height,
            depth
        };
        this.magFilter = NearestFilter;
        this.minFilter = NearestFilter;
        this.wrapR = ClampToEdgeWrapping;
        this.generateMipmaps = false;
        this.flipY = false;
        this.unpackAlignment = 1;
    }
}
class WebGL3DRenderTarget extends WebGLRenderTarget {
    constructor(width = 1, height = 1, depth = 1, options = {}){
        super(width, height, options);
        this.isWebGL3DRenderTarget = true;
        this.depth = depth;
        this.texture = new Data3DTexture(null, width, height, depth);
        this.texture.isRenderTargetTexture = true;
    }
}
class Quaternion {
    constructor(x = 0, y = 0, z = 0, w = 1){
        this.isQuaternion = true;
        this._x = x;
        this._y = y;
        this._z = z;
        this._w = w;
    }
    static slerpFlat(dst, dstOffset, src0, srcOffset0, src1, srcOffset1, t) {
        // fuzz-free, array-based Quaternion SLERP operation
        let x0 = src0[srcOffset0 + 0], y0 = src0[srcOffset0 + 1], z0 = src0[srcOffset0 + 2], w0 = src0[srcOffset0 + 3];
        const x1 = src1[srcOffset1 + 0], y1 = src1[srcOffset1 + 1], z1 = src1[srcOffset1 + 2], w1 = src1[srcOffset1 + 3];
        if (t === 0) {
            dst[dstOffset + 0] = x0;
            dst[dstOffset + 1] = y0;
            dst[dstOffset + 2] = z0;
            dst[dstOffset + 3] = w0;
            return;
        }
        if (t === 1) {
            dst[dstOffset + 0] = x1;
            dst[dstOffset + 1] = y1;
            dst[dstOffset + 2] = z1;
            dst[dstOffset + 3] = w1;
            return;
        }
        if (w0 !== w1 || x0 !== x1 || y0 !== y1 || z0 !== z1) {
            let s = 1 - t;
            const cos = x0 * x1 + y0 * y1 + z0 * z1 + w0 * w1, dir = cos >= 0 ? 1 : -1, sqrSin = 1 - cos * cos;
            // Skip the Slerp for tiny steps to avoid numeric problems:
            if (sqrSin > Number.EPSILON) {
                const sin = Math.sqrt(sqrSin), len = Math.atan2(sin, cos * dir);
                s = Math.sin(s * len) / sin;
                t = Math.sin(t * len) / sin;
            }
            const tDir = t * dir;
            x0 = x0 * s + x1 * tDir;
            y0 = y0 * s + y1 * tDir;
            z0 = z0 * s + z1 * tDir;
            w0 = w0 * s + w1 * tDir;
            // Normalize in case we just did a lerp:
            if (s === 1 - t) {
                const f = 1 / Math.sqrt(x0 * x0 + y0 * y0 + z0 * z0 + w0 * w0);
                x0 *= f;
                y0 *= f;
                z0 *= f;
                w0 *= f;
            }
        }
        dst[dstOffset] = x0;
        dst[dstOffset + 1] = y0;
        dst[dstOffset + 2] = z0;
        dst[dstOffset + 3] = w0;
    }
    static multiplyQuaternionsFlat(dst, dstOffset, src0, srcOffset0, src1, srcOffset1) {
        const x0 = src0[srcOffset0];
        const y0 = src0[srcOffset0 + 1];
        const z0 = src0[srcOffset0 + 2];
        const w0 = src0[srcOffset0 + 3];
        const x1 = src1[srcOffset1];
        const y1 = src1[srcOffset1 + 1];
        const z1 = src1[srcOffset1 + 2];
        const w1 = src1[srcOffset1 + 3];
        dst[dstOffset] = x0 * w1 + w0 * x1 + y0 * z1 - z0 * y1;
        dst[dstOffset + 1] = y0 * w1 + w0 * y1 + z0 * x1 - x0 * z1;
        dst[dstOffset + 2] = z0 * w1 + w0 * z1 + x0 * y1 - y0 * x1;
        dst[dstOffset + 3] = w0 * w1 - x0 * x1 - y0 * y1 - z0 * z1;
        return dst;
    }
    get x() {
        return this._x;
    }
    set x(value) {
        this._x = value;
        this._onChangeCallback();
    }
    get y() {
        return this._y;
    }
    set y(value) {
        this._y = value;
        this._onChangeCallback();
    }
    get z() {
        return this._z;
    }
    set z(value) {
        this._z = value;
        this._onChangeCallback();
    }
    get w() {
        return this._w;
    }
    set w(value) {
        this._w = value;
        this._onChangeCallback();
    }
    set(x, y, z, w) {
        this._x = x;
        this._y = y;
        this._z = z;
        this._w = w;
        this._onChangeCallback();
        return this;
    }
    clone() {
        return new this.constructor(this._x, this._y, this._z, this._w);
    }
    copy(quaternion) {
        this._x = quaternion.x;
        this._y = quaternion.y;
        this._z = quaternion.z;
        this._w = quaternion.w;
        this._onChangeCallback();
        return this;
    }
    setFromEuler(euler, update = true) {
        const x = euler._x, y = euler._y, z = euler._z, order = euler._order;
        // http://www.mathworks.com/matlabcentral/fileexchange/
        // 	20696-function-to-convert-between-dcm-euler-angles-quaternions-and-euler-vectors/
        //	content/SpinCalc.m
        const cos = Math.cos;
        const sin = Math.sin;
        const c1 = cos(x / 2);
        const c2 = cos(y / 2);
        const c3 = cos(z / 2);
        const s1 = sin(x / 2);
        const s2 = sin(y / 2);
        const s3 = sin(z / 2);
        switch(order){
            case "XYZ":
                this._x = s1 * c2 * c3 + c1 * s2 * s3;
                this._y = c1 * s2 * c3 - s1 * c2 * s3;
                this._z = c1 * c2 * s3 + s1 * s2 * c3;
                this._w = c1 * c2 * c3 - s1 * s2 * s3;
                break;
            case "YXZ":
                this._x = s1 * c2 * c3 + c1 * s2 * s3;
                this._y = c1 * s2 * c3 - s1 * c2 * s3;
                this._z = c1 * c2 * s3 - s1 * s2 * c3;
                this._w = c1 * c2 * c3 + s1 * s2 * s3;
                break;
            case "ZXY":
                this._x = s1 * c2 * c3 - c1 * s2 * s3;
                this._y = c1 * s2 * c3 + s1 * c2 * s3;
                this._z = c1 * c2 * s3 + s1 * s2 * c3;
                this._w = c1 * c2 * c3 - s1 * s2 * s3;
                break;
            case "ZYX":
                this._x = s1 * c2 * c3 - c1 * s2 * s3;
                this._y = c1 * s2 * c3 + s1 * c2 * s3;
                this._z = c1 * c2 * s3 - s1 * s2 * c3;
                this._w = c1 * c2 * c3 + s1 * s2 * s3;
                break;
            case "YZX":
                this._x = s1 * c2 * c3 + c1 * s2 * s3;
                this._y = c1 * s2 * c3 + s1 * c2 * s3;
                this._z = c1 * c2 * s3 - s1 * s2 * c3;
                this._w = c1 * c2 * c3 - s1 * s2 * s3;
                break;
            case "XZY":
                this._x = s1 * c2 * c3 - c1 * s2 * s3;
                this._y = c1 * s2 * c3 - s1 * c2 * s3;
                this._z = c1 * c2 * s3 + s1 * s2 * c3;
                this._w = c1 * c2 * c3 + s1 * s2 * s3;
                break;
            default:
                console.warn("THREE.Quaternion: .setFromEuler() encountered an unknown order: " + order);
        }
        if (update === true) this._onChangeCallback();
        return this;
    }
    setFromAxisAngle(axis, angle) {
        // http://www.euclideanspace.com/maths/geometry/rotations/conversions/angleToQuaternion/index.htm
        // assumes axis is normalized
        const halfAngle = angle / 2, s = Math.sin(halfAngle);
        this._x = axis.x * s;
        this._y = axis.y * s;
        this._z = axis.z * s;
        this._w = Math.cos(halfAngle);
        this._onChangeCallback();
        return this;
    }
    setFromRotationMatrix(m) {
        // http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToQuaternion/index.htm
        // assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)
        const te = m.elements, m11 = te[0], m12 = te[4], m13 = te[8], m21 = te[1], m22 = te[5], m23 = te[9], m31 = te[2], m32 = te[6], m33 = te[10], trace = m11 + m22 + m33;
        if (trace > 0) {
            const s = 0.5 / Math.sqrt(trace + 1.0);
            this._w = 0.25 / s;
            this._x = (m32 - m23) * s;
            this._y = (m13 - m31) * s;
            this._z = (m21 - m12) * s;
        } else if (m11 > m22 && m11 > m33) {
            const s = 2.0 * Math.sqrt(1.0 + m11 - m22 - m33);
            this._w = (m32 - m23) / s;
            this._x = 0.25 * s;
            this._y = (m12 + m21) / s;
            this._z = (m13 + m31) / s;
        } else if (m22 > m33) {
            const s = 2.0 * Math.sqrt(1.0 + m22 - m11 - m33);
            this._w = (m13 - m31) / s;
            this._x = (m12 + m21) / s;
            this._y = 0.25 * s;
            this._z = (m23 + m32) / s;
        } else {
            const s = 2.0 * Math.sqrt(1.0 + m33 - m11 - m22);
            this._w = (m21 - m12) / s;
            this._x = (m13 + m31) / s;
            this._y = (m23 + m32) / s;
            this._z = 0.25 * s;
        }
        this._onChangeCallback();
        return this;
    }
    setFromUnitVectors(vFrom, vTo) {
        // assumes direction vectors vFrom and vTo are normalized
        let r = vFrom.dot(vTo) + 1;
        if (r < Number.EPSILON) {
            // vFrom and vTo point in opposite directions
            r = 0;
            if (Math.abs(vFrom.x) > Math.abs(vFrom.z)) {
                this._x = -vFrom.y;
                this._y = vFrom.x;
                this._z = 0;
                this._w = r;
            } else {
                this._x = 0;
                this._y = -vFrom.z;
                this._z = vFrom.y;
                this._w = r;
            }
        } else {
            // crossVectors( vFrom, vTo ); // inlined to avoid cyclic dependency on Vector3
            this._x = vFrom.y * vTo.z - vFrom.z * vTo.y;
            this._y = vFrom.z * vTo.x - vFrom.x * vTo.z;
            this._z = vFrom.x * vTo.y - vFrom.y * vTo.x;
            this._w = r;
        }
        return this.normalize();
    }
    angleTo(q) {
        return 2 * Math.acos(Math.abs(clamp(this.dot(q), -1, 1)));
    }
    rotateTowards(q, step) {
        const angle = this.angleTo(q);
        if (angle === 0) return this;
        const t = Math.min(1, step / angle);
        this.slerp(q, t);
        return this;
    }
    identity() {
        return this.set(0, 0, 0, 1);
    }
    invert() {
        // quaternion is assumed to have unit length
        return this.conjugate();
    }
    conjugate() {
        this._x *= -1;
        this._y *= -1;
        this._z *= -1;
        this._onChangeCallback();
        return this;
    }
    dot(v) {
        return this._x * v._x + this._y * v._y + this._z * v._z + this._w * v._w;
    }
    lengthSq() {
        return this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w;
    }
    length() {
        return Math.sqrt(this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w);
    }
    normalize() {
        let l = this.length();
        if (l === 0) {
            this._x = 0;
            this._y = 0;
            this._z = 0;
            this._w = 1;
        } else {
            l = 1 / l;
            this._x = this._x * l;
            this._y = this._y * l;
            this._z = this._z * l;
            this._w = this._w * l;
        }
        this._onChangeCallback();
        return this;
    }
    multiply(q) {
        return this.multiplyQuaternions(this, q);
    }
    premultiply(q) {
        return this.multiplyQuaternions(q, this);
    }
    multiplyQuaternions(a, b) {
        // from http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/code/index.htm
        const qax = a._x, qay = a._y, qaz = a._z, qaw = a._w;
        const qbx = b._x, qby = b._y, qbz = b._z, qbw = b._w;
        this._x = qax * qbw + qaw * qbx + qay * qbz - qaz * qby;
        this._y = qay * qbw + qaw * qby + qaz * qbx - qax * qbz;
        this._z = qaz * qbw + qaw * qbz + qax * qby - qay * qbx;
        this._w = qaw * qbw - qax * qbx - qay * qby - qaz * qbz;
        this._onChangeCallback();
        return this;
    }
    slerp(qb, t) {
        if (t === 0) return this;
        if (t === 1) return this.copy(qb);
        const x = this._x, y = this._y, z = this._z, w = this._w;
        // http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/slerp/
        let cosHalfTheta = w * qb._w + x * qb._x + y * qb._y + z * qb._z;
        if (cosHalfTheta < 0) {
            this._w = -qb._w;
            this._x = -qb._x;
            this._y = -qb._y;
            this._z = -qb._z;
            cosHalfTheta = -cosHalfTheta;
        } else this.copy(qb);
        if (cosHalfTheta >= 1.0) {
            this._w = w;
            this._x = x;
            this._y = y;
            this._z = z;
            return this;
        }
        const sqrSinHalfTheta = 1.0 - cosHalfTheta * cosHalfTheta;
        if (sqrSinHalfTheta <= Number.EPSILON) {
            const s = 1 - t;
            this._w = s * w + t * this._w;
            this._x = s * x + t * this._x;
            this._y = s * y + t * this._y;
            this._z = s * z + t * this._z;
            this.normalize(); // normalize calls _onChangeCallback()
            return this;
        }
        const sinHalfTheta = Math.sqrt(sqrSinHalfTheta);
        const halfTheta = Math.atan2(sinHalfTheta, cosHalfTheta);
        const ratioA = Math.sin((1 - t) * halfTheta) / sinHalfTheta, ratioB = Math.sin(t * halfTheta) / sinHalfTheta;
        this._w = w * ratioA + this._w * ratioB;
        this._x = x * ratioA + this._x * ratioB;
        this._y = y * ratioA + this._y * ratioB;
        this._z = z * ratioA + this._z * ratioB;
        this._onChangeCallback();
        return this;
    }
    slerpQuaternions(qa, qb, t) {
        return this.copy(qa).slerp(qb, t);
    }
    random() {
        // sets this quaternion to a uniform random unit quaternnion
        // Ken Shoemake
        // Uniform random rotations
        // D. Kirk, editor, Graphics Gems III, pages 124-132. Academic Press, New York, 1992.
        const theta1 = 2 * Math.PI * Math.random();
        const theta2 = 2 * Math.PI * Math.random();
        const x0 = Math.random();
        const r1 = Math.sqrt(1 - x0);
        const r2 = Math.sqrt(x0);
        return this.set(r1 * Math.sin(theta1), r1 * Math.cos(theta1), r2 * Math.sin(theta2), r2 * Math.cos(theta2));
    }
    equals(quaternion) {
        return quaternion._x === this._x && quaternion._y === this._y && quaternion._z === this._z && quaternion._w === this._w;
    }
    fromArray(array, offset = 0) {
        this._x = array[offset];
        this._y = array[offset + 1];
        this._z = array[offset + 2];
        this._w = array[offset + 3];
        this._onChangeCallback();
        return this;
    }
    toArray(array = [], offset = 0) {
        array[offset] = this._x;
        array[offset + 1] = this._y;
        array[offset + 2] = this._z;
        array[offset + 3] = this._w;
        return array;
    }
    fromBufferAttribute(attribute, index) {
        this._x = attribute.getX(index);
        this._y = attribute.getY(index);
        this._z = attribute.getZ(index);
        this._w = attribute.getW(index);
        this._onChangeCallback();
        return this;
    }
    toJSON() {
        return this.toArray();
    }
    _onChange(callback) {
        this._onChangeCallback = callback;
        return this;
    }
    _onChangeCallback() {}
    *[Symbol.iterator]() {
        yield this._x;
        yield this._y;
        yield this._z;
        yield this._w;
    }
}
class Vector3 {
    constructor(x = 0, y = 0, z = 0){
        Vector3.prototype.isVector3 = true;
        this.x = x;
        this.y = y;
        this.z = z;
    }
    set(x, y, z) {
        if (z === undefined) z = this.z; // sprite.scale.set(x,y)
        this.x = x;
        this.y = y;
        this.z = z;
        return this;
    }
    setScalar(scalar) {
        this.x = scalar;
        this.y = scalar;
        this.z = scalar;
        return this;
    }
    setX(x) {
        this.x = x;
        return this;
    }
    setY(y) {
        this.y = y;
        return this;
    }
    setZ(z) {
        this.z = z;
        return this;
    }
    setComponent(index, value) {
        switch(index){
            case 0:
                this.x = value;
                break;
            case 1:
                this.y = value;
                break;
            case 2:
                this.z = value;
                break;
            default:
                throw new Error("index is out of range: " + index);
        }
        return this;
    }
    getComponent(index) {
        switch(index){
            case 0:
                return this.x;
            case 1:
                return this.y;
            case 2:
                return this.z;
            default:
                throw new Error("index is out of range: " + index);
        }
    }
    clone() {
        return new this.constructor(this.x, this.y, this.z);
    }
    copy(v) {
        this.x = v.x;
        this.y = v.y;
        this.z = v.z;
        return this;
    }
    add(v) {
        this.x += v.x;
        this.y += v.y;
        this.z += v.z;
        return this;
    }
    addScalar(s) {
        this.x += s;
        this.y += s;
        this.z += s;
        return this;
    }
    addVectors(a, b) {
        this.x = a.x + b.x;
        this.y = a.y + b.y;
        this.z = a.z + b.z;
        return this;
    }
    addScaledVector(v, s) {
        this.x += v.x * s;
        this.y += v.y * s;
        this.z += v.z * s;
        return this;
    }
    sub(v) {
        this.x -= v.x;
        this.y -= v.y;
        this.z -= v.z;
        return this;
    }
    subScalar(s) {
        this.x -= s;
        this.y -= s;
        this.z -= s;
        return this;
    }
    subVectors(a, b) {
        this.x = a.x - b.x;
        this.y = a.y - b.y;
        this.z = a.z - b.z;
        return this;
    }
    multiply(v) {
        this.x *= v.x;
        this.y *= v.y;
        this.z *= v.z;
        return this;
    }
    multiplyScalar(scalar) {
        this.x *= scalar;
        this.y *= scalar;
        this.z *= scalar;
        return this;
    }
    multiplyVectors(a, b) {
        this.x = a.x * b.x;
        this.y = a.y * b.y;
        this.z = a.z * b.z;
        return this;
    }
    applyEuler(euler) {
        return this.applyQuaternion(_quaternion$4.setFromEuler(euler));
    }
    applyAxisAngle(axis, angle) {
        return this.applyQuaternion(_quaternion$4.setFromAxisAngle(axis, angle));
    }
    applyMatrix3(m) {
        const x = this.x, y = this.y, z = this.z;
        const e = m.elements;
        this.x = e[0] * x + e[3] * y + e[6] * z;
        this.y = e[1] * x + e[4] * y + e[7] * z;
        this.z = e[2] * x + e[5] * y + e[8] * z;
        return this;
    }
    applyNormalMatrix(m) {
        return this.applyMatrix3(m).normalize();
    }
    applyMatrix4(m) {
        const x = this.x, y = this.y, z = this.z;
        const e = m.elements;
        const w = 1 / (e[3] * x + e[7] * y + e[11] * z + e[15]);
        this.x = (e[0] * x + e[4] * y + e[8] * z + e[12]) * w;
        this.y = (e[1] * x + e[5] * y + e[9] * z + e[13]) * w;
        this.z = (e[2] * x + e[6] * y + e[10] * z + e[14]) * w;
        return this;
    }
    applyQuaternion(q) {
        // quaternion q is assumed to have unit length
        const vx = this.x, vy = this.y, vz = this.z;
        const qx = q.x, qy = q.y, qz = q.z, qw = q.w;
        // t = 2 * cross( q.xyz, v );
        const tx = 2 * (qy * vz - qz * vy);
        const ty = 2 * (qz * vx - qx * vz);
        const tz = 2 * (qx * vy - qy * vx);
        // v + q.w * t + cross( q.xyz, t );
        this.x = vx + qw * tx + qy * tz - qz * ty;
        this.y = vy + qw * ty + qz * tx - qx * tz;
        this.z = vz + qw * tz + qx * ty - qy * tx;
        return this;
    }
    project(camera) {
        return this.applyMatrix4(camera.matrixWorldInverse).applyMatrix4(camera.projectionMatrix);
    }
    unproject(camera) {
        return this.applyMatrix4(camera.projectionMatrixInverse).applyMatrix4(camera.matrixWorld);
    }
    transformDirection(m) {
        // input: THREE.Matrix4 affine matrix
        // vector interpreted as a direction
        const x = this.x, y = this.y, z = this.z;
        const e = m.elements;
        this.x = e[0] * x + e[4] * y + e[8] * z;
        this.y = e[1] * x + e[5] * y + e[9] * z;
        this.z = e[2] * x + e[6] * y + e[10] * z;
        return this.normalize();
    }
    divide(v) {
        this.x /= v.x;
        this.y /= v.y;
        this.z /= v.z;
        return this;
    }
    divideScalar(scalar) {
        return this.multiplyScalar(1 / scalar);
    }
    min(v) {
        this.x = Math.min(this.x, v.x);
        this.y = Math.min(this.y, v.y);
        this.z = Math.min(this.z, v.z);
        return this;
    }
    max(v) {
        this.x = Math.max(this.x, v.x);
        this.y = Math.max(this.y, v.y);
        this.z = Math.max(this.z, v.z);
        return this;
    }
    clamp(min, max) {
        // assumes min < max, componentwise
        this.x = Math.max(min.x, Math.min(max.x, this.x));
        this.y = Math.max(min.y, Math.min(max.y, this.y));
        this.z = Math.max(min.z, Math.min(max.z, this.z));
        return this;
    }
    clampScalar(minVal, maxVal) {
        this.x = Math.max(minVal, Math.min(maxVal, this.x));
        this.y = Math.max(minVal, Math.min(maxVal, this.y));
        this.z = Math.max(minVal, Math.min(maxVal, this.z));
        return this;
    }
    clampLength(min, max) {
        const length = this.length();
        return this.divideScalar(length || 1).multiplyScalar(Math.max(min, Math.min(max, length)));
    }
    floor() {
        this.x = Math.floor(this.x);
        this.y = Math.floor(this.y);
        this.z = Math.floor(this.z);
        return this;
    }
    ceil() {
        this.x = Math.ceil(this.x);
        this.y = Math.ceil(this.y);
        this.z = Math.ceil(this.z);
        return this;
    }
    round() {
        this.x = Math.round(this.x);
        this.y = Math.round(this.y);
        this.z = Math.round(this.z);
        return this;
    }
    roundToZero() {
        this.x = Math.trunc(this.x);
        this.y = Math.trunc(this.y);
        this.z = Math.trunc(this.z);
        return this;
    }
    negate() {
        this.x = -this.x;
        this.y = -this.y;
        this.z = -this.z;
        return this;
    }
    dot(v) {
        return this.x * v.x + this.y * v.y + this.z * v.z;
    }
    // TODO lengthSquared?
    lengthSq() {
        return this.x * this.x + this.y * this.y + this.z * this.z;
    }
    length() {
        return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z);
    }
    manhattanLength() {
        return Math.abs(this.x) + Math.abs(this.y) + Math.abs(this.z);
    }
    normalize() {
        return this.divideScalar(this.length() || 1);
    }
    setLength(length) {
        return this.normalize().multiplyScalar(length);
    }
    lerp(v, alpha) {
        this.x += (v.x - this.x) * alpha;
        this.y += (v.y - this.y) * alpha;
        this.z += (v.z - this.z) * alpha;
        return this;
    }
    lerpVectors(v1, v2, alpha) {
        this.x = v1.x + (v2.x - v1.x) * alpha;
        this.y = v1.y + (v2.y - v1.y) * alpha;
        this.z = v1.z + (v2.z - v1.z) * alpha;
        return this;
    }
    cross(v) {
        return this.crossVectors(this, v);
    }
    crossVectors(a, b) {
        const ax = a.x, ay = a.y, az = a.z;
        const bx = b.x, by = b.y, bz = b.z;
        this.x = ay * bz - az * by;
        this.y = az * bx - ax * bz;
        this.z = ax * by - ay * bx;
        return this;
    }
    projectOnVector(v) {
        const denominator = v.lengthSq();
        if (denominator === 0) return this.set(0, 0, 0);
        const scalar = v.dot(this) / denominator;
        return this.copy(v).multiplyScalar(scalar);
    }
    projectOnPlane(planeNormal) {
        _vector$c.copy(this).projectOnVector(planeNormal);
        return this.sub(_vector$c);
    }
    reflect(normal) {
        // reflect incident vector off plane orthogonal to normal
        // normal is assumed to have unit length
        return this.sub(_vector$c.copy(normal).multiplyScalar(2 * this.dot(normal)));
    }
    angleTo(v) {
        const denominator = Math.sqrt(this.lengthSq() * v.lengthSq());
        if (denominator === 0) return Math.PI / 2;
        const theta = this.dot(v) / denominator;
        // clamp, to handle numerical problems
        return Math.acos(clamp(theta, -1, 1));
    }
    distanceTo(v) {
        return Math.sqrt(this.distanceToSquared(v));
    }
    distanceToSquared(v) {
        const dx = this.x - v.x, dy = this.y - v.y, dz = this.z - v.z;
        return dx * dx + dy * dy + dz * dz;
    }
    manhattanDistanceTo(v) {
        return Math.abs(this.x - v.x) + Math.abs(this.y - v.y) + Math.abs(this.z - v.z);
    }
    setFromSpherical(s) {
        return this.setFromSphericalCoords(s.radius, s.phi, s.theta);
    }
    setFromSphericalCoords(radius, phi, theta) {
        const sinPhiRadius = Math.sin(phi) * radius;
        this.x = sinPhiRadius * Math.sin(theta);
        this.y = Math.cos(phi) * radius;
        this.z = sinPhiRadius * Math.cos(theta);
        return this;
    }
    setFromCylindrical(c) {
        return this.setFromCylindricalCoords(c.radius, c.theta, c.y);
    }
    setFromCylindricalCoords(radius, theta, y) {
        this.x = radius * Math.sin(theta);
        this.y = y;
        this.z = radius * Math.cos(theta);
        return this;
    }
    setFromMatrixPosition(m) {
        const e = m.elements;
        this.x = e[12];
        this.y = e[13];
        this.z = e[14];
        return this;
    }
    setFromMatrixScale(m) {
        const sx = this.setFromMatrixColumn(m, 0).length();
        const sy = this.setFromMatrixColumn(m, 1).length();
        const sz = this.setFromMatrixColumn(m, 2).length();
        this.x = sx;
        this.y = sy;
        this.z = sz;
        return this;
    }
    setFromMatrixColumn(m, index) {
        return this.fromArray(m.elements, index * 4);
    }
    setFromMatrix3Column(m, index) {
        return this.fromArray(m.elements, index * 3);
    }
    setFromEuler(e) {
        this.x = e._x;
        this.y = e._y;
        this.z = e._z;
        return this;
    }
    setFromColor(c) {
        this.x = c.r;
        this.y = c.g;
        this.z = c.b;
        return this;
    }
    equals(v) {
        return v.x === this.x && v.y === this.y && v.z === this.z;
    }
    fromArray(array, offset = 0) {
        this.x = array[offset];
        this.y = array[offset + 1];
        this.z = array[offset + 2];
        return this;
    }
    toArray(array = [], offset = 0) {
        array[offset] = this.x;
        array[offset + 1] = this.y;
        array[offset + 2] = this.z;
        return array;
    }
    fromBufferAttribute(attribute, index) {
        this.x = attribute.getX(index);
        this.y = attribute.getY(index);
        this.z = attribute.getZ(index);
        return this;
    }
    random() {
        this.x = Math.random();
        this.y = Math.random();
        this.z = Math.random();
        return this;
    }
    randomDirection() {
        // https://mathworld.wolfram.com/SpherePointPicking.html
        const theta = Math.random() * Math.PI * 2;
        const u = Math.random() * 2 - 1;
        const c = Math.sqrt(1 - u * u);
        this.x = c * Math.cos(theta);
        this.y = u;
        this.z = c * Math.sin(theta);
        return this;
    }
    *[Symbol.iterator]() {
        yield this.x;
        yield this.y;
        yield this.z;
    }
}
const _vector$c = /*@__PURE__*/ new Vector3();
const _quaternion$4 = /*@__PURE__*/ new Quaternion();
class Box3 {
    constructor(min = new Vector3(Infinity, Infinity, Infinity), max = new Vector3(-Infinity, -Infinity, -Infinity)){
        this.isBox3 = true;
        this.min = min;
        this.max = max;
    }
    set(min, max) {
        this.min.copy(min);
        this.max.copy(max);
        return this;
    }
    setFromArray(array) {
        this.makeEmpty();
        for(let i = 0, il = array.length; i < il; i += 3)this.expandByPoint(_vector$b.fromArray(array, i));
        return this;
    }
    setFromBufferAttribute(attribute) {
        this.makeEmpty();
        for(let i = 0, il = attribute.count; i < il; i++)this.expandByPoint(_vector$b.fromBufferAttribute(attribute, i));
        return this;
    }
    setFromPoints(points) {
        this.makeEmpty();
        for(let i = 0, il = points.length; i < il; i++)this.expandByPoint(points[i]);
        return this;
    }
    setFromCenterAndSize(center, size) {
        const halfSize = _vector$b.copy(size).multiplyScalar(0.5);
        this.min.copy(center).sub(halfSize);
        this.max.copy(center).add(halfSize);
        return this;
    }
    setFromObject(object, precise = false) {
        this.makeEmpty();
        return this.expandByObject(object, precise);
    }
    clone() {
        return new this.constructor().copy(this);
    }
    copy(box) {
        this.min.copy(box.min);
        this.max.copy(box.max);
        return this;
    }
    makeEmpty() {
        this.min.x = this.min.y = this.min.z = Infinity;
        this.max.x = this.max.y = this.max.z = -Infinity;
        return this;
    }
    isEmpty() {
        // this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes
        return this.max.x < this.min.x || this.max.y < this.min.y || this.max.z < this.min.z;
    }
    getCenter(target) {
        return this.isEmpty() ? target.set(0, 0, 0) : target.addVectors(this.min, this.max).multiplyScalar(0.5);
    }
    getSize(target) {
        return this.isEmpty() ? target.set(0, 0, 0) : target.subVectors(this.max, this.min);
    }
    expandByPoint(point) {
        this.min.min(point);
        this.max.max(point);
        return this;
    }
    expandByVector(vector) {
        this.min.sub(vector);
        this.max.add(vector);
        return this;
    }
    expandByScalar(scalar) {
        this.min.addScalar(-scalar);
        this.max.addScalar(scalar);
        return this;
    }
    expandByObject(object, precise = false) {
        // Computes the world-axis-aligned bounding box of an object (including its children),
        // accounting for both the object's, and children's, world transforms
        object.updateWorldMatrix(false, false);
        const geometry = object.geometry;
        if (geometry !== undefined) {
            const positionAttribute = geometry.getAttribute("position");
            // precise AABB computation based on vertex data requires at least a position attribute.
            // instancing isn't supported so far and uses the normal (conservative) code path.
            if (precise === true && positionAttribute !== undefined && object.isInstancedMesh !== true) for(let i = 0, l = positionAttribute.count; i < l; i++){
                if (object.isMesh === true) object.getVertexPosition(i, _vector$b);
                else _vector$b.fromBufferAttribute(positionAttribute, i);
                _vector$b.applyMatrix4(object.matrixWorld);
                this.expandByPoint(_vector$b);
            }
            else {
                if (object.boundingBox !== undefined) {
                    // object-level bounding box
                    if (object.boundingBox === null) object.computeBoundingBox();
                    _box$4.copy(object.boundingBox);
                } else {
                    // geometry-level bounding box
                    if (geometry.boundingBox === null) geometry.computeBoundingBox();
                    _box$4.copy(geometry.boundingBox);
                }
                _box$4.applyMatrix4(object.matrixWorld);
                this.union(_box$4);
            }
        }
        const children = object.children;
        for(let i = 0, l = children.length; i < l; i++)this.expandByObject(children[i], precise);
        return this;
    }
    containsPoint(point) {
        return point.x < this.min.x || point.x > this.max.x || point.y < this.min.y || point.y > this.max.y || point.z < this.min.z || point.z > this.max.z ? false : true;
    }
    containsBox(box) {
        return this.min.x <= box.min.x && box.max.x <= this.max.x && this.min.y <= box.min.y && box.max.y <= this.max.y && this.min.z <= box.min.z && box.max.z <= this.max.z;
    }
    getParameter(point, target) {
        // This can potentially have a divide by zero if the box
        // has a size dimension of 0.
        return target.set((point.x - this.min.x) / (this.max.x - this.min.x), (point.y - this.min.y) / (this.max.y - this.min.y), (point.z - this.min.z) / (this.max.z - this.min.z));
    }
    intersectsBox(box) {
        // using 6 splitting planes to rule out intersections.
        return box.max.x < this.min.x || box.min.x > this.max.x || box.max.y < this.min.y || box.min.y > this.max.y || box.max.z < this.min.z || box.min.z > this.max.z ? false : true;
    }
    intersectsSphere(sphere) {
        // Find the point on the AABB closest to the sphere center.
        this.clampPoint(sphere.center, _vector$b);
        // If that point is inside the sphere, the AABB and sphere intersect.
        return _vector$b.distanceToSquared(sphere.center) <= sphere.radius * sphere.radius;
    }
    intersectsPlane(plane) {
        // We compute the minimum and maximum dot product values. If those values
        // are on the same side (back or front) of the plane, then there is no intersection.
        let min, max;
        if (plane.normal.x > 0) {
            min = plane.normal.x * this.min.x;
            max = plane.normal.x * this.max.x;
        } else {
            min = plane.normal.x * this.max.x;
            max = plane.normal.x * this.min.x;
        }
        if (plane.normal.y > 0) {
            min += plane.normal.y * this.min.y;
            max += plane.normal.y * this.max.y;
        } else {
            min += plane.normal.y * this.max.y;
            max += plane.normal.y * this.min.y;
        }
        if (plane.normal.z > 0) {
            min += plane.normal.z * this.min.z;
            max += plane.normal.z * this.max.z;
        } else {
            min += plane.normal.z * this.max.z;
            max += plane.normal.z * this.min.z;
        }
        return min <= -plane.constant && max >= -plane.constant;
    }
    intersectsTriangle(triangle) {
        if (this.isEmpty()) return false;
        // compute box center and extents
        this.getCenter(_center);
        _extents.subVectors(this.max, _center);
        // translate triangle to aabb origin
        _v0$2.subVectors(triangle.a, _center);
        _v1$7.subVectors(triangle.b, _center);
        _v2$4.subVectors(triangle.c, _center);
        // compute edge vectors for triangle
        _f0.subVectors(_v1$7, _v0$2);
        _f1.subVectors(_v2$4, _v1$7);
        _f2.subVectors(_v0$2, _v2$4);
        // test against axes that are given by cross product combinations of the edges of the triangle and the edges of the aabb
        // make an axis testing of each of the 3 sides of the aabb against each of the 3 sides of the triangle = 9 axis of separation
        // axis_ij = u_i x f_j (u0, u1, u2 = face normals of aabb = x,y,z axes vectors since aabb is axis aligned)
        let axes = [
            0,
            -_f0.z,
            _f0.y,
            0,
            -_f1.z,
            _f1.y,
            0,
            -_f2.z,
            _f2.y,
            _f0.z,
            0,
            -_f0.x,
            _f1.z,
            0,
            -_f1.x,
            _f2.z,
            0,
            -_f2.x,
            -_f0.y,
            _f0.x,
            0,
            -_f1.y,
            _f1.x,
            0,
            -_f2.y,
            _f2.x,
            0
        ];
        if (!satForAxes(axes, _v0$2, _v1$7, _v2$4, _extents)) return false;
        // test 3 face normals from the aabb
        axes = [
            1,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            1
        ];
        if (!satForAxes(axes, _v0$2, _v1$7, _v2$4, _extents)) return false;
        // finally testing the face normal of the triangle
        // use already existing triangle edge vectors here
        _triangleNormal.crossVectors(_f0, _f1);
        axes = [
            _triangleNormal.x,
            _triangleNormal.y,
            _triangleNormal.z
        ];
        return satForAxes(axes, _v0$2, _v1$7, _v2$4, _extents);
    }
    clampPoint(point, target) {
        return target.copy(point).clamp(this.min, this.max);
    }
    distanceToPoint(point) {
        return this.clampPoint(point, _vector$b).distanceTo(point);
    }
    getBoundingSphere(target) {
        if (this.isEmpty()) target.makeEmpty();
        else {
            this.getCenter(target.center);
            target.radius = this.getSize(_vector$b).length() * 0.5;
        }
        return target;
    }
    intersect(box) {
        this.min.max(box.min);
        this.max.min(box.max);
        // ensure that if there is no overlap, the result is fully empty, not slightly empty with non-inf/+inf values that will cause subsequence intersects to erroneously return valid values.
        if (this.isEmpty()) this.makeEmpty();
        return this;
    }
    union(box) {
        this.min.min(box.min);
        this.max.max(box.max);
        return this;
    }
    applyMatrix4(matrix) {
        // transform of empty box is an empty box.
        if (this.isEmpty()) return this;
        // NOTE: I am using a binary pattern to specify all 2^3 combinations below
        _points[0].set(this.min.x, this.min.y, this.min.z).applyMatrix4(matrix); // 000
        _points[1].set(this.min.x, this.min.y, this.max.z).applyMatrix4(matrix); // 001
        _points[2].set(this.min.x, this.max.y, this.min.z).applyMatrix4(matrix); // 010
        _points[3].set(this.min.x, this.max.y, this.max.z).applyMatrix4(matrix); // 011
        _points[4].set(this.max.x, this.min.y, this.min.z).applyMatrix4(matrix); // 100
        _points[5].set(this.max.x, this.min.y, this.max.z).applyMatrix4(matrix); // 101
        _points[6].set(this.max.x, this.max.y, this.min.z).applyMatrix4(matrix); // 110
        _points[7].set(this.max.x, this.max.y, this.max.z).applyMatrix4(matrix); // 111
        this.setFromPoints(_points);
        return this;
    }
    translate(offset) {
        this.min.add(offset);
        this.max.add(offset);
        return this;
    }
    equals(box) {
        return box.min.equals(this.min) && box.max.equals(this.max);
    }
}
const _points = [
    /*@__PURE__*/ new Vector3(),
    /*@__PURE__*/ new Vector3(),
    /*@__PURE__*/ new Vector3(),
    /*@__PURE__*/ new Vector3(),
    /*@__PURE__*/ new Vector3(),
    /*@__PURE__*/ new Vector3(),
    /*@__PURE__*/ new Vector3(),
    /*@__PURE__*/ new Vector3()
];
const _vector$b = /*@__PURE__*/ new Vector3();
const _box$4 = /*@__PURE__*/ new Box3();
// triangle centered vertices
const _v0$2 = /*@__PURE__*/ new Vector3();
const _v1$7 = /*@__PURE__*/ new Vector3();
const _v2$4 = /*@__PURE__*/ new Vector3();
// triangle edge vectors
const _f0 = /*@__PURE__*/ new Vector3();
const _f1 = /*@__PURE__*/ new Vector3();
const _f2 = /*@__PURE__*/ new Vector3();
const _center = /*@__PURE__*/ new Vector3();
const _extents = /*@__PURE__*/ new Vector3();
const _triangleNormal = /*@__PURE__*/ new Vector3();
const _testAxis = /*@__PURE__*/ new Vector3();
function satForAxes(axes, v0, v1, v2, extents) {
    for(let i = 0, j = axes.length - 3; i <= j; i += 3){
        _testAxis.fromArray(axes, i);
        // project the aabb onto the separating axis
        const r = extents.x * Math.abs(_testAxis.x) + extents.y * Math.abs(_testAxis.y) + extents.z * Math.abs(_testAxis.z);
        // project all 3 vertices of the triangle onto the separating axis
        const p0 = v0.dot(_testAxis);
        const p1 = v1.dot(_testAxis);
        const p2 = v2.dot(_testAxis);
        // actual test, basically see if either of the most extreme of the triangle points intersects r
        if (Math.max(-Math.max(p0, p1, p2), Math.min(p0, p1, p2)) > r) // points of the projected triangle are outside the projected half-length of the aabb
        // the axis is separating and we can exit
        return false;
    }
    return true;
}
const _box$3 = /*@__PURE__*/ new Box3();
const _v1$6 = /*@__PURE__*/ new Vector3();
const _v2$3 = /*@__PURE__*/ new Vector3();
class Sphere {
    constructor(center = new Vector3(), radius = -1){
        this.isSphere = true;
        this.center = center;
        this.radius = radius;
    }
    set(center, radius) {
        this.center.copy(center);
        this.radius = radius;
        return this;
    }
    setFromPoints(points, optionalCenter) {
        const center = this.center;
        if (optionalCenter !== undefined) center.copy(optionalCenter);
        else _box$3.setFromPoints(points).getCenter(center);
        let maxRadiusSq = 0;
        for(let i = 0, il = points.length; i < il; i++)maxRadiusSq = Math.max(maxRadiusSq, center.distanceToSquared(points[i]));
        this.radius = Math.sqrt(maxRadiusSq);
        return this;
    }
    copy(sphere) {
        this.center.copy(sphere.center);
        this.radius = sphere.radius;
        return this;
    }
    isEmpty() {
        return this.radius < 0;
    }
    makeEmpty() {
        this.center.set(0, 0, 0);
        this.radius = -1;
        return this;
    }
    containsPoint(point) {
        return point.distanceToSquared(this.center) <= this.radius * this.radius;
    }
    distanceToPoint(point) {
        return point.distanceTo(this.center) - this.radius;
    }
    intersectsSphere(sphere) {
        const radiusSum = this.radius + sphere.radius;
        return sphere.center.distanceToSquared(this.center) <= radiusSum * radiusSum;
    }
    intersectsBox(box) {
        return box.intersectsSphere(this);
    }
    intersectsPlane(plane) {
        return Math.abs(plane.distanceToPoint(this.center)) <= this.radius;
    }
    clampPoint(point, target) {
        const deltaLengthSq = this.center.distanceToSquared(point);
        target.copy(point);
        if (deltaLengthSq > this.radius * this.radius) {
            target.sub(this.center).normalize();
            target.multiplyScalar(this.radius).add(this.center);
        }
        return target;
    }
    getBoundingBox(target) {
        if (this.isEmpty()) {
            // Empty sphere produces empty bounding box
            target.makeEmpty();
            return target;
        }
        target.set(this.center, this.center);
        target.expandByScalar(this.radius);
        return target;
    }
    applyMatrix4(matrix) {
        this.center.applyMatrix4(matrix);
        this.radius = this.radius * matrix.getMaxScaleOnAxis();
        return this;
    }
    translate(offset) {
        this.center.add(offset);
        return this;
    }
    expandByPoint(point) {
        if (this.isEmpty()) {
            this.center.copy(point);
            this.radius = 0;
            return this;
        }
        _v1$6.subVectors(point, this.center);
        const lengthSq = _v1$6.lengthSq();
        if (lengthSq > this.radius * this.radius) {
            // calculate the minimal sphere
            const length = Math.sqrt(lengthSq);
            const delta = (length - this.radius) * 0.5;
            this.center.addScaledVector(_v1$6, delta / length);
            this.radius += delta;
        }
        return this;
    }
    union(sphere) {
        if (sphere.isEmpty()) return this;
        if (this.isEmpty()) {
            this.copy(sphere);
            return this;
        }
        if (this.center.equals(sphere.center) === true) this.radius = Math.max(this.radius, sphere.radius);
        else {
            _v2$3.subVectors(sphere.center, this.center).setLength(sphere.radius);
            this.expandByPoint(_v1$6.copy(sphere.center).add(_v2$3));
            this.expandByPoint(_v1$6.copy(sphere.center).sub(_v2$3));
        }
        return this;
    }
    equals(sphere) {
        return sphere.center.equals(this.center) && sphere.radius === this.radius;
    }
    clone() {
        return new this.constructor().copy(this);
    }
}
const _vector$a = /*@__PURE__*/ new Vector3();
const _segCenter = /*@__PURE__*/ new Vector3();
const _segDir = /*@__PURE__*/ new Vector3();
const _diff = /*@__PURE__*/ new Vector3();
const _edge1 = /*@__PURE__*/ new Vector3();
const _edge2 = /*@__PURE__*/ new Vector3();
const _normal$1 = /*@__PURE__*/ new Vector3();
class Ray {
    constructor(origin = new Vector3(), direction = new Vector3(0, 0, -1)){
        this.origin = origin;
        this.direction = direction;
    }
    set(origin, direction) {
        this.origin.copy(origin);
        this.direction.copy(direction);
        return this;
    }
    copy(ray) {
        this.origin.copy(ray.origin);
        this.direction.copy(ray.direction);
        return this;
    }
    at(t, target) {
        return target.copy(this.origin).addScaledVector(this.direction, t);
    }
    lookAt(v) {
        this.direction.copy(v).sub(this.origin).normalize();
        return this;
    }
    recast(t) {
        this.origin.copy(this.at(t, _vector$a));
        return this;
    }
    closestPointToPoint(point, target) {
        target.subVectors(point, this.origin);
        const directionDistance = target.dot(this.direction);
        if (directionDistance < 0) return target.copy(this.origin);
        return target.copy(this.origin).addScaledVector(this.direction, directionDistance);
    }
    distanceToPoint(point) {
        return Math.sqrt(this.distanceSqToPoint(point));
    }
    distanceSqToPoint(point) {
        const directionDistance = _vector$a.subVectors(point, this.origin).dot(this.direction);
        // point behind the ray
        if (directionDistance < 0) return this.origin.distanceToSquared(point);
        _vector$a.copy(this.origin).addScaledVector(this.direction, directionDistance);
        return _vector$a.distanceToSquared(point);
    }
    distanceSqToSegment(v0, v1, optionalPointOnRay, optionalPointOnSegment) {
        // from https://github.com/pmjoniak/GeometricTools/blob/master/GTEngine/Include/Mathematics/GteDistRaySegment.h
        // It returns the min distance between the ray and the segment
        // defined by v0 and v1
        // It can also set two optional targets :
        // - The closest point on the ray
        // - The closest point on the segment
        _segCenter.copy(v0).add(v1).multiplyScalar(0.5);
        _segDir.copy(v1).sub(v0).normalize();
        _diff.copy(this.origin).sub(_segCenter);
        const segExtent = v0.distanceTo(v1) * 0.5;
        const a01 = -this.direction.dot(_segDir);
        const b0 = _diff.dot(this.direction);
        const b1 = -_diff.dot(_segDir);
        const c = _diff.lengthSq();
        const det = Math.abs(1 - a01 * a01);
        let s0, s1, sqrDist, extDet;
        if (det > 0) {
            // The ray and segment are not parallel.
            s0 = a01 * b1 - b0;
            s1 = a01 * b0 - b1;
            extDet = segExtent * det;
            if (s0 >= 0) {
                if (s1 >= -extDet) {
                    if (s1 <= extDet) {
                        // region 0
                        // Minimum at interior points of ray and segment.
                        const invDet = 1 / det;
                        s0 *= invDet;
                        s1 *= invDet;
                        sqrDist = s0 * (s0 + a01 * s1 + 2 * b0) + s1 * (a01 * s0 + s1 + 2 * b1) + c;
                    } else {
                        // region 1
                        s1 = segExtent;
                        s0 = Math.max(0, -(a01 * s1 + b0));
                        sqrDist = -s0 * s0 + s1 * (s1 + 2 * b1) + c;
                    }
                } else {
                    // region 5
                    s1 = -segExtent;
                    s0 = Math.max(0, -(a01 * s1 + b0));
                    sqrDist = -s0 * s0 + s1 * (s1 + 2 * b1) + c;
                }
            } else {
                if (s1 <= -extDet) {
                    // region 4
                    s0 = Math.max(0, -(-a01 * segExtent + b0));
                    s1 = s0 > 0 ? -segExtent : Math.min(Math.max(-segExtent, -b1), segExtent);
                    sqrDist = -s0 * s0 + s1 * (s1 + 2 * b1) + c;
                } else if (s1 <= extDet) {
                    // region 3
                    s0 = 0;
                    s1 = Math.min(Math.max(-segExtent, -b1), segExtent);
                    sqrDist = s1 * (s1 + 2 * b1) + c;
                } else {
                    // region 2
                    s0 = Math.max(0, -(a01 * segExtent + b0));
                    s1 = s0 > 0 ? segExtent : Math.min(Math.max(-segExtent, -b1), segExtent);
                    sqrDist = -s0 * s0 + s1 * (s1 + 2 * b1) + c;
                }
            }
        } else {
            // Ray and segment are parallel.
            s1 = a01 > 0 ? -segExtent : segExtent;
            s0 = Math.max(0, -(a01 * s1 + b0));
            sqrDist = -s0 * s0 + s1 * (s1 + 2 * b1) + c;
        }
        if (optionalPointOnRay) optionalPointOnRay.copy(this.origin).addScaledVector(this.direction, s0);
        if (optionalPointOnSegment) optionalPointOnSegment.copy(_segCenter).addScaledVector(_segDir, s1);
        return sqrDist;
    }
    intersectSphere(sphere, target) {
        _vector$a.subVectors(sphere.center, this.origin);
        const tca = _vector$a.dot(this.direction);
        const d2 = _vector$a.dot(_vector$a) - tca * tca;
        const radius2 = sphere.radius * sphere.radius;
        if (d2 > radius2) return null;
        const thc = Math.sqrt(radius2 - d2);
        // t0 = first intersect point - entrance on front of sphere
        const t0 = tca - thc;
        // t1 = second intersect point - exit point on back of sphere
        const t1 = tca + thc;
        // test to see if t1 is behind the ray - if so, return null
        if (t1 < 0) return null;
        // test to see if t0 is behind the ray:
        // if it is, the ray is inside the sphere, so return the second exit point scaled by t1,
        // in order to always return an intersect point that is in front of the ray.
        if (t0 < 0) return this.at(t1, target);
        // else t0 is in front of the ray, so return the first collision point scaled by t0
        return this.at(t0, target);
    }
    intersectsSphere(sphere) {
        return this.distanceSqToPoint(sphere.center) <= sphere.radius * sphere.radius;
    }
    distanceToPlane(plane) {
        const denominator = plane.normal.dot(this.direction);
        if (denominator === 0) {
            // line is coplanar, return origin
            if (plane.distanceToPoint(this.origin) === 0) return 0;
            // Null is preferable to undefined since undefined means.... it is undefined
            return null;
        }
        const t = -(this.origin.dot(plane.normal) + plane.constant) / denominator;
        // Return if the ray never intersects the plane
        return t >= 0 ? t : null;
    }
    intersectPlane(plane, target) {
        const t = this.distanceToPlane(plane);
        if (t === null) return null;
        return this.at(t, target);
    }
    intersectsPlane(plane) {
        // check if the ray lies on the plane first
        const distToPoint = plane.distanceToPoint(this.origin);
        if (distToPoint === 0) return true;
        const denominator = plane.normal.dot(this.direction);
        if (denominator * distToPoint < 0) return true;
        // ray origin is behind the plane (and is pointing behind it)
        return false;
    }
    intersectBox(box, target) {
        let tmin, tmax, tymin, tymax, tzmin, tzmax;
        const invdirx = 1 / this.direction.x, invdiry = 1 / this.direction.y, invdirz = 1 / this.direction.z;
        const origin = this.origin;
        if (invdirx >= 0) {
            tmin = (box.min.x - origin.x) * invdirx;
            tmax = (box.max.x - origin.x) * invdirx;
        } else {
            tmin = (box.max.x - origin.x) * invdirx;
            tmax = (box.min.x - origin.x) * invdirx;
        }
        if (invdiry >= 0) {
            tymin = (box.min.y - origin.y) * invdiry;
            tymax = (box.max.y - origin.y) * invdiry;
        } else {
            tymin = (box.max.y - origin.y) * invdiry;
            tymax = (box.min.y - origin.y) * invdiry;
        }
        if (tmin > tymax || tymin > tmax) return null;
        if (tymin > tmin || isNaN(tmin)) tmin = tymin;
        if (tymax < tmax || isNaN(tmax)) tmax = tymax;
        if (invdirz >= 0) {
            tzmin = (box.min.z - origin.z) * invdirz;
            tzmax = (box.max.z - origin.z) * invdirz;
        } else {
            tzmin = (box.max.z - origin.z) * invdirz;
            tzmax = (box.min.z - origin.z) * invdirz;
        }
        if (tmin > tzmax || tzmin > tmax) return null;
        if (tzmin > tmin || tmin !== tmin) tmin = tzmin;
        if (tzmax < tmax || tmax !== tmax) tmax = tzmax;
        //return point closest to the ray (positive side)
        if (tmax < 0) return null;
        return this.at(tmin >= 0 ? tmin : tmax, target);
    }
    intersectsBox(box) {
        return this.intersectBox(box, _vector$a) !== null;
    }
    intersectTriangle(a, b, c, backfaceCulling, target) {
        // Compute the offset origin, edges, and normal.
        // from https://github.com/pmjoniak/GeometricTools/blob/master/GTEngine/Include/Mathematics/GteIntrRay3Triangle3.h
        _edge1.subVectors(b, a);
        _edge2.subVectors(c, a);
        _normal$1.crossVectors(_edge1, _edge2);
        // Solve Q + t*D = b1*E1 + b2*E2 (Q = kDiff, D = ray direction,
        // E1 = kEdge1, E2 = kEdge2, N = Cross(E1,E2)) by
        //   |Dot(D,N)|*b1 = sign(Dot(D,N))*Dot(D,Cross(Q,E2))
        //   |Dot(D,N)|*b2 = sign(Dot(D,N))*Dot(D,Cross(E1,Q))
        //   |Dot(D,N)|*t = -sign(Dot(D,N))*Dot(Q,N)
        let DdN = this.direction.dot(_normal$1);
        let sign;
        if (DdN > 0) {
            if (backfaceCulling) return null;
            sign = 1;
        } else if (DdN < 0) {
            sign = -1;
            DdN = -DdN;
        } else return null;
        _diff.subVectors(this.origin, a);
        const DdQxE2 = sign * this.direction.dot(_edge2.crossVectors(_diff, _edge2));
        // b1 < 0, no intersection
        if (DdQxE2 < 0) return null;
        const DdE1xQ = sign * this.direction.dot(_edge1.cross(_diff));
        // b2 < 0, no intersection
        if (DdE1xQ < 0) return null;
        // b1+b2 > 1, no intersection
        if (DdQxE2 + DdE1xQ > DdN) return null;
        // Line intersects triangle, check if ray does.
        const QdN = -sign * _diff.dot(_normal$1);
        // t < 0, no intersection
        if (QdN < 0) return null;
        // Ray intersects triangle.
        return this.at(QdN / DdN, target);
    }
    applyMatrix4(matrix4) {
        this.origin.applyMatrix4(matrix4);
        this.direction.transformDirection(matrix4);
        return this;
    }
    equals(ray) {
        return ray.origin.equals(this.origin) && ray.direction.equals(this.direction);
    }
    clone() {
        return new this.constructor().copy(this);
    }
}
class Matrix4 {
    constructor(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44){
        Matrix4.prototype.isMatrix4 = true;
        this.elements = [
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1
        ];
        if (n11 !== undefined) this.set(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44);
    }
    set(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44) {
        const te = this.elements;
        te[0] = n11;
        te[4] = n12;
        te[8] = n13;
        te[12] = n14;
        te[1] = n21;
        te[5] = n22;
        te[9] = n23;
        te[13] = n24;
        te[2] = n31;
        te[6] = n32;
        te[10] = n33;
        te[14] = n34;
        te[3] = n41;
        te[7] = n42;
        te[11] = n43;
        te[15] = n44;
        return this;
    }
    identity() {
        this.set(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);
        return this;
    }
    clone() {
        return new Matrix4().fromArray(this.elements);
    }
    copy(m) {
        const te = this.elements;
        const me = m.elements;
        te[0] = me[0];
        te[1] = me[1];
        te[2] = me[2];
        te[3] = me[3];
        te[4] = me[4];
        te[5] = me[5];
        te[6] = me[6];
        te[7] = me[7];
        te[8] = me[8];
        te[9] = me[9];
        te[10] = me[10];
        te[11] = me[11];
        te[12] = me[12];
        te[13] = me[13];
        te[14] = me[14];
        te[15] = me[15];
        return this;
    }
    copyPosition(m) {
        const te = this.elements, me = m.elements;
        te[12] = me[12];
        te[13] = me[13];
        te[14] = me[14];
        return this;
    }
    setFromMatrix3(m) {
        const me = m.elements;
        this.set(me[0], me[3], me[6], 0, me[1], me[4], me[7], 0, me[2], me[5], me[8], 0, 0, 0, 0, 1);
        return this;
    }
    extractBasis(xAxis, yAxis, zAxis) {
        xAxis.setFromMatrixColumn(this, 0);
        yAxis.setFromMatrixColumn(this, 1);
        zAxis.setFromMatrixColumn(this, 2);
        return this;
    }
    makeBasis(xAxis, yAxis, zAxis) {
        this.set(xAxis.x, yAxis.x, zAxis.x, 0, xAxis.y, yAxis.y, zAxis.y, 0, xAxis.z, yAxis.z, zAxis.z, 0, 0, 0, 0, 1);
        return this;
    }
    extractRotation(m) {
        // this method does not support reflection matrices
        const te = this.elements;
        const me = m.elements;
        const scaleX = 1 / _v1$5.setFromMatrixColumn(m, 0).length();
        const scaleY = 1 / _v1$5.setFromMatrixColumn(m, 1).length();
        const scaleZ = 1 / _v1$5.setFromMatrixColumn(m, 2).length();
        te[0] = me[0] * scaleX;
        te[1] = me[1] * scaleX;
        te[2] = me[2] * scaleX;
        te[3] = 0;
        te[4] = me[4] * scaleY;
        te[5] = me[5] * scaleY;
        te[6] = me[6] * scaleY;
        te[7] = 0;
        te[8] = me[8] * scaleZ;
        te[9] = me[9] * scaleZ;
        te[10] = me[10] * scaleZ;
        te[11] = 0;
        te[12] = 0;
        te[13] = 0;
        te[14] = 0;
        te[15] = 1;
        return this;
    }
    makeRotationFromEuler(euler) {
        const te = this.elements;
        const x = euler.x, y = euler.y, z = euler.z;
        const a = Math.cos(x), b = Math.sin(x);
        const c = Math.cos(y), d = Math.sin(y);
        const e = Math.cos(z), f = Math.sin(z);
        if (euler.order === "XYZ") {
            const ae = a * e, af = a * f, be = b * e, bf = b * f;
            te[0] = c * e;
            te[4] = -c * f;
            te[8] = d;
            te[1] = af + be * d;
            te[5] = ae - bf * d;
            te[9] = -b * c;
            te[2] = bf - ae * d;
            te[6] = be + af * d;
            te[10] = a * c;
        } else if (euler.order === "YXZ") {
            const ce = c * e, cf = c * f, de = d * e, df = d * f;
            te[0] = ce + df * b;
            te[4] = de * b - cf;
            te[8] = a * d;
            te[1] = a * f;
            te[5] = a * e;
            te[9] = -b;
            te[2] = cf * b - de;
            te[6] = df + ce * b;
            te[10] = a * c;
        } else if (euler.order === "ZXY") {
            const ce = c * e, cf = c * f, de = d * e, df = d * f;
            te[0] = ce - df * b;
            te[4] = -a * f;
            te[8] = de + cf * b;
            te[1] = cf + de * b;
            te[5] = a * e;
            te[9] = df - ce * b;
            te[2] = -a * d;
            te[6] = b;
            te[10] = a * c;
        } else if (euler.order === "ZYX") {
            const ae = a * e, af = a * f, be = b * e, bf = b * f;
            te[0] = c * e;
            te[4] = be * d - af;
            te[8] = ae * d + bf;
            te[1] = c * f;
            te[5] = bf * d + ae;
            te[9] = af * d - be;
            te[2] = -d;
            te[6] = b * c;
            te[10] = a * c;
        } else if (euler.order === "YZX") {
            const ac = a * c, ad = a * d, bc = b * c, bd = b * d;
            te[0] = c * e;
            te[4] = bd - ac * f;
            te[8] = bc * f + ad;
            te[1] = f;
            te[5] = a * e;
            te[9] = -b * e;
            te[2] = -d * e;
            te[6] = ad * f + bc;
            te[10] = ac - bd * f;
        } else if (euler.order === "XZY") {
            const ac = a * c, ad = a * d, bc = b * c, bd = b * d;
            te[0] = c * e;
            te[4] = -f;
            te[8] = d * e;
            te[1] = ac * f + bd;
            te[5] = a * e;
            te[9] = ad * f - bc;
            te[2] = bc * f - ad;
            te[6] = b * e;
            te[10] = bd * f + ac;
        }
        // bottom row
        te[3] = 0;
        te[7] = 0;
        te[11] = 0;
        // last column
        te[12] = 0;
        te[13] = 0;
        te[14] = 0;
        te[15] = 1;
        return this;
    }
    makeRotationFromQuaternion(q) {
        return this.compose(_zero, q, _one);
    }
    lookAt(eye, target, up) {
        const te = this.elements;
        _z.subVectors(eye, target);
        if (_z.lengthSq() === 0) // eye and target are in the same position
        _z.z = 1;
        _z.normalize();
        _x.crossVectors(up, _z);
        if (_x.lengthSq() === 0) {
            // up and z are parallel
            if (Math.abs(up.z) === 1) _z.x += 0.0001;
            else _z.z += 0.0001;
            _z.normalize();
            _x.crossVectors(up, _z);
        }
        _x.normalize();
        _y.crossVectors(_z, _x);
        te[0] = _x.x;
        te[4] = _y.x;
        te[8] = _z.x;
        te[1] = _x.y;
        te[5] = _y.y;
        te[9] = _z.y;
        te[2] = _x.z;
        te[6] = _y.z;
        te[10] = _z.z;
        return this;
    }
    multiply(m) {
        return this.multiplyMatrices(this, m);
    }
    premultiply(m) {
        return this.multiplyMatrices(m, this);
    }
    multiplyMatrices(a, b) {
        const ae = a.elements;
        const be = b.elements;
        const te = this.elements;
        const a11 = ae[0], a12 = ae[4], a13 = ae[8], a14 = ae[12];
        const a21 = ae[1], a22 = ae[5], a23 = ae[9], a24 = ae[13];
        const a31 = ae[2], a32 = ae[6], a33 = ae[10], a34 = ae[14];
        const a41 = ae[3], a42 = ae[7], a43 = ae[11], a44 = ae[15];
        const b11 = be[0], b12 = be[4], b13 = be[8], b14 = be[12];
        const b21 = be[1], b22 = be[5], b23 = be[9], b24 = be[13];
        const b31 = be[2], b32 = be[6], b33 = be[10], b34 = be[14];
        const b41 = be[3], b42 = be[7], b43 = be[11], b44 = be[15];
        te[0] = a11 * b11 + a12 * b21 + a13 * b31 + a14 * b41;
        te[4] = a11 * b12 + a12 * b22 + a13 * b32 + a14 * b42;
        te[8] = a11 * b13 + a12 * b23 + a13 * b33 + a14 * b43;
        te[12] = a11 * b14 + a12 * b24 + a13 * b34 + a14 * b44;
        te[1] = a21 * b11 + a22 * b21 + a23 * b31 + a24 * b41;
        te[5] = a21 * b12 + a22 * b22 + a23 * b32 + a24 * b42;
        te[9] = a21 * b13 + a22 * b23 + a23 * b33 + a24 * b43;
        te[13] = a21 * b14 + a22 * b24 + a23 * b34 + a24 * b44;
        te[2] = a31 * b11 + a32 * b21 + a33 * b31 + a34 * b41;
        te[6] = a31 * b12 + a32 * b22 + a33 * b32 + a34 * b42;
        te[10] = a31 * b13 + a32 * b23 + a33 * b33 + a34 * b43;
        te[14] = a31 * b14 + a32 * b24 + a33 * b34 + a34 * b44;
        te[3] = a41 * b11 + a42 * b21 + a43 * b31 + a44 * b41;
        te[7] = a41 * b12 + a42 * b22 + a43 * b32 + a44 * b42;
        te[11] = a41 * b13 + a42 * b23 + a43 * b33 + a44 * b43;
        te[15] = a41 * b14 + a42 * b24 + a43 * b34 + a44 * b44;
        return this;
    }
    multiplyScalar(s) {
        const te = this.elements;
        te[0] *= s;
        te[4] *= s;
        te[8] *= s;
        te[12] *= s;
        te[1] *= s;
        te[5] *= s;
        te[9] *= s;
        te[13] *= s;
        te[2] *= s;
        te[6] *= s;
        te[10] *= s;
        te[14] *= s;
        te[3] *= s;
        te[7] *= s;
        te[11] *= s;
        te[15] *= s;
        return this;
    }
    determinant() {
        const te = this.elements;
        const n11 = te[0], n12 = te[4], n13 = te[8], n14 = te[12];
        const n21 = te[1], n22 = te[5], n23 = te[9], n24 = te[13];
        const n31 = te[2], n32 = te[6], n33 = te[10], n34 = te[14];
        const n41 = te[3], n42 = te[7], n43 = te[11], n44 = te[15];
        //TODO: make this more efficient
        //( based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm )
        return n41 * (+n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34) + n42 * (+n11 * n23 * n34 - n11 * n24 * n33 + n14 * n21 * n33 - n13 * n21 * n34 + n13 * n24 * n31 - n14 * n23 * n31) + n43 * (+n11 * n24 * n32 - n11 * n22 * n34 - n14 * n21 * n32 + n12 * n21 * n34 + n14 * n22 * n31 - n12 * n24 * n31) + n44 * (-n13 * n22 * n31 - n11 * n23 * n32 + n11 * n22 * n33 + n13 * n21 * n32 - n12 * n21 * n33 + n12 * n23 * n31);
    }
    transpose() {
        const te = this.elements;
        let tmp;
        tmp = te[1];
        te[1] = te[4];
        te[4] = tmp;
        tmp = te[2];
        te[2] = te[8];
        te[8] = tmp;
        tmp = te[6];
        te[6] = te[9];
        te[9] = tmp;
        tmp = te[3];
        te[3] = te[12];
        te[12] = tmp;
        tmp = te[7];
        te[7] = te[13];
        te[13] = tmp;
        tmp = te[11];
        te[11] = te[14];
        te[14] = tmp;
        return this;
    }
    setPosition(x, y, z) {
        const te = this.elements;
        if (x.isVector3) {
            te[12] = x.x;
            te[13] = x.y;
            te[14] = x.z;
        } else {
            te[12] = x;
            te[13] = y;
            te[14] = z;
        }
        return this;
    }
    invert() {
        // based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm
        const te = this.elements, n11 = te[0], n21 = te[1], n31 = te[2], n41 = te[3], n12 = te[4], n22 = te[5], n32 = te[6], n42 = te[7], n13 = te[8], n23 = te[9], n33 = te[10], n43 = te[11], n14 = te[12], n24 = te[13], n34 = te[14], n44 = te[15], t11 = n23 * n34 * n42 - n24 * n33 * n42 + n24 * n32 * n43 - n22 * n34 * n43 - n23 * n32 * n44 + n22 * n33 * n44, t12 = n14 * n33 * n42 - n13 * n34 * n42 - n14 * n32 * n43 + n12 * n34 * n43 + n13 * n32 * n44 - n12 * n33 * n44, t13 = n13 * n24 * n42 - n14 * n23 * n42 + n14 * n22 * n43 - n12 * n24 * n43 - n13 * n22 * n44 + n12 * n23 * n44, t14 = n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34;
        const det = n11 * t11 + n21 * t12 + n31 * t13 + n41 * t14;
        if (det === 0) return this.set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);
        const detInv = 1 / det;
        te[0] = t11 * detInv;
        te[1] = (n24 * n33 * n41 - n23 * n34 * n41 - n24 * n31 * n43 + n21 * n34 * n43 + n23 * n31 * n44 - n21 * n33 * n44) * detInv;
        te[2] = (n22 * n34 * n41 - n24 * n32 * n41 + n24 * n31 * n42 - n21 * n34 * n42 - n22 * n31 * n44 + n21 * n32 * n44) * detInv;
        te[3] = (n23 * n32 * n41 - n22 * n33 * n41 - n23 * n31 * n42 + n21 * n33 * n42 + n22 * n31 * n43 - n21 * n32 * n43) * detInv;
        te[4] = t12 * detInv;
        te[5] = (n13 * n34 * n41 - n14 * n33 * n41 + n14 * n31 * n43 - n11 * n34 * n43 - n13 * n31 * n44 + n11 * n33 * n44) * detInv;
        te[6] = (n14 * n32 * n41 - n12 * n34 * n41 - n14 * n31 * n42 + n11 * n34 * n42 + n12 * n31 * n44 - n11 * n32 * n44) * detInv;
        te[7] = (n12 * n33 * n41 - n13 * n32 * n41 + n13 * n31 * n42 - n11 * n33 * n42 - n12 * n31 * n43 + n11 * n32 * n43) * detInv;
        te[8] = t13 * detInv;
        te[9] = (n14 * n23 * n41 - n13 * n24 * n41 - n14 * n21 * n43 + n11 * n24 * n43 + n13 * n21 * n44 - n11 * n23 * n44) * detInv;
        te[10] = (n12 * n24 * n41 - n14 * n22 * n41 + n14 * n21 * n42 - n11 * n24 * n42 - n12 * n21 * n44 + n11 * n22 * n44) * detInv;
        te[11] = (n13 * n22 * n41 - n12 * n23 * n41 - n13 * n21 * n42 + n11 * n23 * n42 + n12 * n21 * n43 - n11 * n22 * n43) * detInv;
        te[12] = t14 * detInv;
        te[13] = (n13 * n24 * n31 - n14 * n23 * n31 + n14 * n21 * n33 - n11 * n24 * n33 - n13 * n21 * n34 + n11 * n23 * n34) * detInv;
        te[14] = (n14 * n22 * n31 - n12 * n24 * n31 - n14 * n21 * n32 + n11 * n24 * n32 + n12 * n21 * n34 - n11 * n22 * n34) * detInv;
        te[15] = (n12 * n23 * n31 - n13 * n22 * n31 + n13 * n21 * n32 - n11 * n23 * n32 - n12 * n21 * n33 + n11 * n22 * n33) * detInv;
        return this;
    }
    scale(v) {
        const te = this.elements;
        const x = v.x, y = v.y, z = v.z;
        te[0] *= x;
        te[4] *= y;
        te[8] *= z;
        te[1] *= x;
        te[5] *= y;
        te[9] *= z;
        te[2] *= x;
        te[6] *= y;
        te[10] *= z;
        te[3] *= x;
        te[7] *= y;
        te[11] *= z;
        return this;
    }
    getMaxScaleOnAxis() {
        const te = this.elements;
        const scaleXSq = te[0] * te[0] + te[1] * te[1] + te[2] * te[2];
        const scaleYSq = te[4] * te[4] + te[5] * te[5] + te[6] * te[6];
        const scaleZSq = te[8] * te[8] + te[9] * te[9] + te[10] * te[10];
        return Math.sqrt(Math.max(scaleXSq, scaleYSq, scaleZSq));
    }
    makeTranslation(x, y, z) {
        if (x.isVector3) this.set(1, 0, 0, x.x, 0, 1, 0, x.y, 0, 0, 1, x.z, 0, 0, 0, 1);
        else this.set(1, 0, 0, x, 0, 1, 0, y, 0, 0, 1, z, 0, 0, 0, 1);
        return this;
    }
    makeRotationX(theta) {
        const c = Math.cos(theta), s = Math.sin(theta);
        this.set(1, 0, 0, 0, 0, c, -s, 0, 0, s, c, 0, 0, 0, 0, 1);
        return this;
    }
    makeRotationY(theta) {
        const c = Math.cos(theta), s = Math.sin(theta);
        this.set(c, 0, s, 0, 0, 1, 0, 0, -s, 0, c, 0, 0, 0, 0, 1);
        return this;
    }
    makeRotationZ(theta) {
        const c = Math.cos(theta), s = Math.sin(theta);
        this.set(c, -s, 0, 0, s, c, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);
        return this;
    }
    makeRotationAxis(axis, angle) {
        // Based on http://www.gamedev.net/reference/articles/article1199.asp
        const c = Math.cos(angle);
        const s = Math.sin(angle);
        const t = 1 - c;
        const x = axis.x, y = axis.y, z = axis.z;
        const tx = t * x, ty = t * y;
        this.set(tx * x + c, tx * y - s * z, tx * z + s * y, 0, tx * y + s * z, ty * y + c, ty * z - s * x, 0, tx * z - s * y, ty * z + s * x, t * z * z + c, 0, 0, 0, 0, 1);
        return this;
    }
    makeScale(x, y, z) {
        this.set(x, 0, 0, 0, 0, y, 0, 0, 0, 0, z, 0, 0, 0, 0, 1);
        return this;
    }
    makeShear(xy, xz, yx, yz, zx, zy) {
        this.set(1, yx, zx, 0, xy, 1, zy, 0, xz, yz, 1, 0, 0, 0, 0, 1);
        return this;
    }
    compose(position, quaternion, scale) {
        const te = this.elements;
        const x = quaternion._x, y = quaternion._y, z = quaternion._z, w = quaternion._w;
        const x2 = x + x, y2 = y + y, z2 = z + z;
        const xx = x * x2, xy = x * y2, xz = x * z2;
        const yy = y * y2, yz = y * z2, zz = z * z2;
        const wx = w * x2, wy = w * y2, wz = w * z2;
        const sx = scale.x, sy = scale.y, sz = scale.z;
        te[0] = (1 - (yy + zz)) * sx;
        te[1] = (xy + wz) * sx;
        te[2] = (xz - wy) * sx;
        te[3] = 0;
        te[4] = (xy - wz) * sy;
        te[5] = (1 - (xx + zz)) * sy;
        te[6] = (yz + wx) * sy;
        te[7] = 0;
        te[8] = (xz + wy) * sz;
        te[9] = (yz - wx) * sz;
        te[10] = (1 - (xx + yy)) * sz;
        te[11] = 0;
        te[12] = position.x;
        te[13] = position.y;
        te[14] = position.z;
        te[15] = 1;
        return this;
    }
    decompose(position, quaternion, scale) {
        const te = this.elements;
        let sx = _v1$5.set(te[0], te[1], te[2]).length();
        const sy = _v1$5.set(te[4], te[5], te[6]).length();
        const sz = _v1$5.set(te[8], te[9], te[10]).length();
        // if determine is negative, we need to invert one scale
        const det = this.determinant();
        if (det < 0) sx = -sx;
        position.x = te[12];
        position.y = te[13];
        position.z = te[14];
        // scale the rotation part
        _m1$4.copy(this);
        const invSX = 1 / sx;
        const invSY = 1 / sy;
        const invSZ = 1 / sz;
        _m1$4.elements[0] *= invSX;
        _m1$4.elements[1] *= invSX;
        _m1$4.elements[2] *= invSX;
        _m1$4.elements[4] *= invSY;
        _m1$4.elements[5] *= invSY;
        _m1$4.elements[6] *= invSY;
        _m1$4.elements[8] *= invSZ;
        _m1$4.elements[9] *= invSZ;
        _m1$4.elements[10] *= invSZ;
        quaternion.setFromRotationMatrix(_m1$4);
        scale.x = sx;
        scale.y = sy;
        scale.z = sz;
        return this;
    }
    makePerspective(left, right, top, bottom, near, far, coordinateSystem = WebGLCoordinateSystem) {
        const te = this.elements;
        const x = 2 * near / (right - left);
        const y = 2 * near / (top - bottom);
        const a = (right + left) / (right - left);
        const b = (top + bottom) / (top - bottom);
        let c, d;
        if (coordinateSystem === WebGLCoordinateSystem) {
            c = -(far + near) / (far - near);
            d = -2 * far * near / (far - near);
        } else if (coordinateSystem === WebGPUCoordinateSystem) {
            c = -far / (far - near);
            d = -far * near / (far - near);
        } else throw new Error("THREE.Matrix4.makePerspective(): Invalid coordinate system: " + coordinateSystem);
        te[0] = x;
        te[4] = 0;
        te[8] = a;
        te[12] = 0;
        te[1] = 0;
        te[5] = y;
        te[9] = b;
        te[13] = 0;
        te[2] = 0;
        te[6] = 0;
        te[10] = c;
        te[14] = d;
        te[3] = 0;
        te[7] = 0;
        te[11] = -1;
        te[15] = 0;
        return this;
    }
    makeOrthographic(left, right, top, bottom, near, far, coordinateSystem = WebGLCoordinateSystem) {
        const te = this.elements;
        const w = 1.0 / (right - left);
        const h = 1.0 / (top - bottom);
        const p = 1.0 / (far - near);
        const x = (right + left) * w;
        const y = (top + bottom) * h;
        let z, zInv;
        if (coordinateSystem === WebGLCoordinateSystem) {
            z = (far + near) * p;
            zInv = -2 * p;
        } else if (coordinateSystem === WebGPUCoordinateSystem) {
            z = near * p;
            zInv = -1 * p;
        } else throw new Error("THREE.Matrix4.makeOrthographic(): Invalid coordinate system: " + coordinateSystem);
        te[0] = 2 * w;
        te[4] = 0;
        te[8] = 0;
        te[12] = -x;
        te[1] = 0;
        te[5] = 2 * h;
        te[9] = 0;
        te[13] = -y;
        te[2] = 0;
        te[6] = 0;
        te[10] = zInv;
        te[14] = -z;
        te[3] = 0;
        te[7] = 0;
        te[11] = 0;
        te[15] = 1;
        return this;
    }
    equals(matrix) {
        const te = this.elements;
        const me = matrix.elements;
        for(let i = 0; i < 16; i++){
            if (te[i] !== me[i]) return false;
        }
        return true;
    }
    fromArray(array, offset = 0) {
        for(let i = 0; i < 16; i++)this.elements[i] = array[i + offset];
        return this;
    }
    toArray(array = [], offset = 0) {
        const te = this.elements;
        array[offset] = te[0];
        array[offset + 1] = te[1];
        array[offset + 2] = te[2];
        array[offset + 3] = te[3];
        array[offset + 4] = te[4];
        array[offset + 5] = te[5];
        array[offset + 6] = te[6];
        array[offset + 7] = te[7];
        array[offset + 8] = te[8];
        array[offset + 9] = te[9];
        array[offset + 10] = te[10];
        array[offset + 11] = te[11];
        array[offset + 12] = te[12];
        array[offset + 13] = te[13];
        array[offset + 14] = te[14];
        array[offset + 15] = te[15];
        return array;
    }
}
const _v1$5 = /*@__PURE__*/ new Vector3();
const _m1$4 = /*@__PURE__*/ new Matrix4();
const _zero = /*@__PURE__*/ new Vector3(0, 0, 0);
const _one = /*@__PURE__*/ new Vector3(1, 1, 1);
const _x = /*@__PURE__*/ new Vector3();
const _y = /*@__PURE__*/ new Vector3();
const _z = /*@__PURE__*/ new Vector3();
const _matrix$2 = /*@__PURE__*/ new Matrix4();
const _quaternion$3 = /*@__PURE__*/ new Quaternion();
class Euler {
    constructor(x = 0, y = 0, z = 0, order = Euler.DEFAULT_ORDER){
        this.isEuler = true;
        this._x = x;
        this._y = y;
        this._z = z;
        this._order = order;
    }
    get x() {
        return this._x;
    }
    set x(value) {
        this._x = value;
        this._onChangeCallback();
    }
    get y() {
        return this._y;
    }
    set y(value) {
        this._y = value;
        this._onChangeCallback();
    }
    get z() {
        return this._z;
    }
    set z(value) {
        this._z = value;
        this._onChangeCallback();
    }
    get order() {
        return this._order;
    }
    set order(value) {
        this._order = value;
        this._onChangeCallback();
    }
    set(x, y, z, order = this._order) {
        this._x = x;
        this._y = y;
        this._z = z;
        this._order = order;
        this._onChangeCallback();
        return this;
    }
    clone() {
        return new this.constructor(this._x, this._y, this._z, this._order);
    }
    copy(euler) {
        this._x = euler._x;
        this._y = euler._y;
        this._z = euler._z;
        this._order = euler._order;
        this._onChangeCallback();
        return this;
    }
    setFromRotationMatrix(m, order = this._order, update = true) {
        // assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)
        const te = m.elements;
        const m11 = te[0], m12 = te[4], m13 = te[8];
        const m21 = te[1], m22 = te[5], m23 = te[9];
        const m31 = te[2], m32 = te[6], m33 = te[10];
        switch(order){
            case "XYZ":
                this._y = Math.asin(clamp(m13, -1, 1));
                if (Math.abs(m13) < 0.9999999) {
                    this._x = Math.atan2(-m23, m33);
                    this._z = Math.atan2(-m12, m11);
                } else {
                    this._x = Math.atan2(m32, m22);
                    this._z = 0;
                }
                break;
            case "YXZ":
                this._x = Math.asin(-clamp(m23, -1, 1));
                if (Math.abs(m23) < 0.9999999) {
                    this._y = Math.atan2(m13, m33);
                    this._z = Math.atan2(m21, m22);
                } else {
                    this._y = Math.atan2(-m31, m11);
                    this._z = 0;
                }
                break;
            case "ZXY":
                this._x = Math.asin(clamp(m32, -1, 1));
                if (Math.abs(m32) < 0.9999999) {
                    this._y = Math.atan2(-m31, m33);
                    this._z = Math.atan2(-m12, m22);
                } else {
                    this._y = 0;
                    this._z = Math.atan2(m21, m11);
                }
                break;
            case "ZYX":
                this._y = Math.asin(-clamp(m31, -1, 1));
                if (Math.abs(m31) < 0.9999999) {
                    this._x = Math.atan2(m32, m33);
                    this._z = Math.atan2(m21, m11);
                } else {
                    this._x = 0;
                    this._z = Math.atan2(-m12, m22);
                }
                break;
            case "YZX":
                this._z = Math.asin(clamp(m21, -1, 1));
                if (Math.abs(m21) < 0.9999999) {
                    this._x = Math.atan2(-m23, m22);
                    this._y = Math.atan2(-m31, m11);
                } else {
                    this._x = 0;
                    this._y = Math.atan2(m13, m33);
                }
                break;
            case "XZY":
                this._z = Math.asin(-clamp(m12, -1, 1));
                if (Math.abs(m12) < 0.9999999) {
                    this._x = Math.atan2(m32, m22);
                    this._y = Math.atan2(m13, m11);
                } else {
                    this._x = Math.atan2(-m23, m33);
                    this._y = 0;
                }
                break;
            default:
                console.warn("THREE.Euler: .setFromRotationMatrix() encountered an unknown order: " + order);
        }
        this._order = order;
        if (update === true) this._onChangeCallback();
        return this;
    }
    setFromQuaternion(q, order, update) {
        _matrix$2.makeRotationFromQuaternion(q);
        return this.setFromRotationMatrix(_matrix$2, order, update);
    }
    setFromVector3(v, order = this._order) {
        return this.set(v.x, v.y, v.z, order);
    }
    reorder(newOrder) {
        // WARNING: this discards revolution information -bhouston
        _quaternion$3.setFromEuler(this);
        return this.setFromQuaternion(_quaternion$3, newOrder);
    }
    equals(euler) {
        return euler._x === this._x && euler._y === this._y && euler._z === this._z && euler._order === this._order;
    }
    fromArray(array) {
        this._x = array[0];
        this._y = array[1];
        this._z = array[2];
        if (array[3] !== undefined) this._order = array[3];
        this._onChangeCallback();
        return this;
    }
    toArray(array = [], offset = 0) {
        array[offset] = this._x;
        array[offset + 1] = this._y;
        array[offset + 2] = this._z;
        array[offset + 3] = this._order;
        return array;
    }
    _onChange(callback) {
        this._onChangeCallback = callback;
        return this;
    }
    _onChangeCallback() {}
    *[Symbol.iterator]() {
        yield this._x;
        yield this._y;
        yield this._z;
        yield this._order;
    }
}
Euler.DEFAULT_ORDER = "XYZ";
class Layers {
    constructor(){
        this.mask = 1;
    }
    set(channel) {
        this.mask = (1 << channel | 0) >>> 0;
    }
    enable(channel) {
        this.mask |= 1 << channel | 0;
    }
    enableAll() {
        this.mask = -1;
    }
    toggle(channel) {
        this.mask ^= 1 << channel | 0;
    }
    disable(channel) {
        this.mask &= ~(1 << channel | 0);
    }
    disableAll() {
        this.mask = 0;
    }
    test(layers) {
        return (this.mask & layers.mask) !== 0;
    }
    isEnabled(channel) {
        return (this.mask & (1 << channel | 0)) !== 0;
    }
}
let _object3DId = 0;
const _v1$4 = /*@__PURE__*/ new Vector3();
const _q1 = /*@__PURE__*/ new Quaternion();
const _m1$3 = /*@__PURE__*/ new Matrix4();
const _target = /*@__PURE__*/ new Vector3();
const _position$3 = /*@__PURE__*/ new Vector3();
const _scale$2 = /*@__PURE__*/ new Vector3();
const _quaternion$2 = /*@__PURE__*/ new Quaternion();
const _xAxis = /*@__PURE__*/ new Vector3(1, 0, 0);
const _yAxis = /*@__PURE__*/ new Vector3(0, 1, 0);
const _zAxis = /*@__PURE__*/ new Vector3(0, 0, 1);
const _addedEvent = {
    type: "added"
};
const _removedEvent = {
    type: "removed"
};
const _childaddedEvent = {
    type: "childadded",
    child: null
};
const _childremovedEvent = {
    type: "childremoved",
    child: null
};
class Object3D extends EventDispatcher {
    constructor(){
        super();
        this.isObject3D = true;
        Object.defineProperty(this, "id", {
            value: _object3DId++
        });
        this.uuid = generateUUID();
        this.name = "";
        this.type = "Object3D";
        this.parent = null;
        this.children = [];
        this.up = Object3D.DEFAULT_UP.clone();
        const position = new Vector3();
        const rotation = new Euler();
        const quaternion = new Quaternion();
        const scale = new Vector3(1, 1, 1);
        function onRotationChange() {
            quaternion.setFromEuler(rotation, false);
        }
        function onQuaternionChange() {
            rotation.setFromQuaternion(quaternion, undefined, false);
        }
        rotation._onChange(onRotationChange);
        quaternion._onChange(onQuaternionChange);
        Object.defineProperties(this, {
            position: {
                configurable: true,
                enumerable: true,
                value: position
            },
            rotation: {
                configurable: true,
                enumerable: true,
                value: rotation
            },
            quaternion: {
                configurable: true,
                enumerable: true,
                value: quaternion
            },
            scale: {
                configurable: true,
                enumerable: true,
                value: scale
            },
            modelViewMatrix: {
                value: new Matrix4()
            },
            normalMatrix: {
                value: new Matrix3()
            }
        });
        this.matrix = new Matrix4();
        this.matrixWorld = new Matrix4();
        this.matrixAutoUpdate = Object3D.DEFAULT_MATRIX_AUTO_UPDATE;
        this.matrixWorldAutoUpdate = Object3D.DEFAULT_MATRIX_WORLD_AUTO_UPDATE; // checked by the renderer
        this.matrixWorldNeedsUpdate = false;
        this.layers = new Layers();
        this.visible = true;
        this.castShadow = false;
        this.receiveShadow = false;
        this.frustumCulled = true;
        this.renderOrder = 0;
        this.animations = [];
        this.userData = {};
    }
    onBeforeShadow() {}
    onAfterShadow() {}
    onBeforeRender() {}
    onAfterRender() {}
    applyMatrix4(matrix) {
        if (this.matrixAutoUpdate) this.updateMatrix();
        this.matrix.premultiply(matrix);
        this.matrix.decompose(this.position, this.quaternion, this.scale);
    }
    applyQuaternion(q) {
        this.quaternion.premultiply(q);
        return this;
    }
    setRotationFromAxisAngle(axis, angle) {
        // assumes axis is normalized
        this.quaternion.setFromAxisAngle(axis, angle);
    }
    setRotationFromEuler(euler) {
        this.quaternion.setFromEuler(euler, true);
    }
    setRotationFromMatrix(m) {
        // assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)
        this.quaternion.setFromRotationMatrix(m);
    }
    setRotationFromQuaternion(q) {
        // assumes q is normalized
        this.quaternion.copy(q);
    }
    rotateOnAxis(axis, angle) {
        // rotate object on axis in object space
        // axis is assumed to be normalized
        _q1.setFromAxisAngle(axis, angle);
        this.quaternion.multiply(_q1);
        return this;
    }
    rotateOnWorldAxis(axis, angle) {
        // rotate object on axis in world space
        // axis is assumed to be normalized
        // method assumes no rotated parent
        _q1.setFromAxisAngle(axis, angle);
        this.quaternion.premultiply(_q1);
        return this;
    }
    rotateX(angle) {
        return this.rotateOnAxis(_xAxis, angle);
    }
    rotateY(angle) {
        return this.rotateOnAxis(_yAxis, angle);
    }
    rotateZ(angle) {
        return this.rotateOnAxis(_zAxis, angle);
    }
    translateOnAxis(axis, distance) {
        // translate object by distance along axis in object space
        // axis is assumed to be normalized
        _v1$4.copy(axis).applyQuaternion(this.quaternion);
        this.position.add(_v1$4.multiplyScalar(distance));
        return this;
    }
    translateX(distance) {
        return this.translateOnAxis(_xAxis, distance);
    }
    translateY(distance) {
        return this.translateOnAxis(_yAxis, distance);
    }
    translateZ(distance) {
        return this.translateOnAxis(_zAxis, distance);
    }
    localToWorld(vector) {
        this.updateWorldMatrix(true, false);
        return vector.applyMatrix4(this.matrixWorld);
    }
    worldToLocal(vector) {
        this.updateWorldMatrix(true, false);
        return vector.applyMatrix4(_m1$3.copy(this.matrixWorld).invert());
    }
    lookAt(x, y, z) {
        // This method does not support objects having non-uniformly-scaled parent(s)
        if (x.isVector3) _target.copy(x);
        else _target.set(x, y, z);
        const parent = this.parent;
        this.updateWorldMatrix(true, false);
        _position$3.setFromMatrixPosition(this.matrixWorld);
        if (this.isCamera || this.isLight) _m1$3.lookAt(_position$3, _target, this.up);
        else _m1$3.lookAt(_target, _position$3, this.up);
        this.quaternion.setFromRotationMatrix(_m1$3);
        if (parent) {
            _m1$3.extractRotation(parent.matrixWorld);
            _q1.setFromRotationMatrix(_m1$3);
            this.quaternion.premultiply(_q1.invert());
        }
    }
    add(object) {
        if (arguments.length > 1) {
            for(let i = 0; i < arguments.length; i++)this.add(arguments[i]);
            return this;
        }
        if (object === this) {
            console.error("THREE.Object3D.add: object can't be added as a child of itself.", object);
            return this;
        }
        if (object && object.isObject3D) {
            object.removeFromParent();
            object.parent = this;
            this.children.push(object);
            object.dispatchEvent(_addedEvent);
            _childaddedEvent.child = object;
            this.dispatchEvent(_childaddedEvent);
            _childaddedEvent.child = null;
        } else console.error("THREE.Object3D.add: object not an instance of THREE.Object3D.", object);
        return this;
    }
    remove(object) {
        if (arguments.length > 1) {
            for(let i = 0; i < arguments.length; i++)this.remove(arguments[i]);
            return this;
        }
        const index = this.children.indexOf(object);
        if (index !== -1) {
            object.parent = null;
            this.children.splice(index, 1);
            object.dispatchEvent(_removedEvent);
            _childremovedEvent.child = object;
            this.dispatchEvent(_childremovedEvent);
            _childremovedEvent.child = null;
        }
        return this;
    }
    removeFromParent() {
        const parent = this.parent;
        if (parent !== null) parent.remove(this);
        return this;
    }
    clear() {
        return this.remove(...this.children);
    }
    attach(object) {
        // adds object as a child of this, while maintaining the object's world transform
        // Note: This method does not support scene graphs having non-uniformly-scaled nodes(s)
        this.updateWorldMatrix(true, false);
        _m1$3.copy(this.matrixWorld).invert();
        if (object.parent !== null) {
            object.parent.updateWorldMatrix(true, false);
            _m1$3.multiply(object.parent.matrixWorld);
        }
        object.applyMatrix4(_m1$3);
        object.removeFromParent();
        object.parent = this;
        this.children.push(object);
        object.updateWorldMatrix(false, true);
        object.dispatchEvent(_addedEvent);
        _childaddedEvent.child = object;
        this.dispatchEvent(_childaddedEvent);
        _childaddedEvent.child = null;
        return this;
    }
    getObjectById(id) {
        return this.getObjectByProperty("id", id);
    }
    getObjectByName(name) {
        return this.getObjectByProperty("name", name);
    }
    getObjectByProperty(name, value) {
        if (this[name] === value) return this;
        for(let i = 0, l = this.children.length; i < l; i++){
            const child = this.children[i];
            const object = child.getObjectByProperty(name, value);
            if (object !== undefined) return object;
        }
        return undefined;
    }
    getObjectsByProperty(name, value, result = []) {
        if (this[name] === value) result.push(this);
        const children = this.children;
        for(let i = 0, l = children.length; i < l; i++)children[i].getObjectsByProperty(name, value, result);
        return result;
    }
    getWorldPosition(target) {
        this.updateWorldMatrix(true, false);
        return target.setFromMatrixPosition(this.matrixWorld);
    }
    getWorldQuaternion(target) {
        this.updateWorldMatrix(true, false);
        this.matrixWorld.decompose(_position$3, target, _scale$2);
        return target;
    }
    getWorldScale(target) {
        this.updateWorldMatrix(true, false);
        this.matrixWorld.decompose(_position$3, _quaternion$2, target);
        return target;
    }
    getWorldDirection(target) {
        this.updateWorldMatrix(true, false);
        const e = this.matrixWorld.elements;
        return target.set(e[8], e[9], e[10]).normalize();
    }
    raycast() {}
    traverse(callback) {
        callback(this);
        const children = this.children;
        for(let i = 0, l = children.length; i < l; i++)children[i].traverse(callback);
    }
    traverseVisible(callback) {
        if (this.visible === false) return;
        callback(this);
        const children = this.children;
        for(let i = 0, l = children.length; i < l; i++)children[i].traverseVisible(callback);
    }
    traverseAncestors(callback) {
        const parent = this.parent;
        if (parent !== null) {
            callback(parent);
            parent.traverseAncestors(callback);
        }
    }
    updateMatrix() {
        this.matrix.compose(this.position, this.quaternion, this.scale);
        this.matrixWorldNeedsUpdate = true;
    }
    updateMatrixWorld(force) {
        if (this.matrixAutoUpdate) this.updateMatrix();
        if (this.matrixWorldNeedsUpdate || force) {
            if (this.matrixWorldAutoUpdate === true) {
                if (this.parent === null) this.matrixWorld.copy(this.matrix);
                else this.matrixWorld.multiplyMatrices(this.parent.matrixWorld, this.matrix);
            }
            this.matrixWorldNeedsUpdate = false;
            force = true;
        }
        // make sure descendants are updated if required
        const children = this.children;
        for(let i = 0, l = children.length; i < l; i++){
            const child = children[i];
            child.updateMatrixWorld(force);
        }
    }
    updateWorldMatrix(updateParents, updateChildren) {
        const parent = this.parent;
        if (updateParents === true && parent !== null) parent.updateWorldMatrix(true, false);
        if (this.matrixAutoUpdate) this.updateMatrix();
        if (this.matrixWorldAutoUpdate === true) {
            if (this.parent === null) this.matrixWorld.copy(this.matrix);
            else this.matrixWorld.multiplyMatrices(this.parent.matrixWorld, this.matrix);
        }
        // make sure descendants are updated
        if (updateChildren === true) {
            const children = this.children;
            for(let i = 0, l = children.length; i < l; i++){
                const child = children[i];
                child.updateWorldMatrix(false, true);
            }
        }
    }
    toJSON(meta) {
        // meta is a string when called from JSON.stringify
        const isRootObject = meta === undefined || typeof meta === "string";
        const output = {};
        // meta is a hash used to collect geometries, materials.
        // not providing it implies that this is the root object
        // being serialized.
        if (isRootObject) {
            // initialize meta obj
            meta = {
                geometries: {},
                materials: {},
                textures: {},
                images: {},
                shapes: {},
                skeletons: {},
                animations: {},
                nodes: {}
            };
            output.metadata = {
                version: 4.6,
                type: "Object",
                generator: "Object3D.toJSON"
            };
        }
        // standard Object3D serialization
        const object = {};
        object.uuid = this.uuid;
        object.type = this.type;
        if (this.name !== "") object.name = this.name;
        if (this.castShadow === true) object.castShadow = true;
        if (this.receiveShadow === true) object.receiveShadow = true;
        if (this.visible === false) object.visible = false;
        if (this.frustumCulled === false) object.frustumCulled = false;
        if (this.renderOrder !== 0) object.renderOrder = this.renderOrder;
        if (Object.keys(this.userData).length > 0) object.userData = this.userData;
        object.layers = this.layers.mask;
        object.matrix = this.matrix.toArray();
        object.up = this.up.toArray();
        if (this.matrixAutoUpdate === false) object.matrixAutoUpdate = false;
        // object specific properties
        if (this.isInstancedMesh) {
            object.type = "InstancedMesh";
            object.count = this.count;
            object.instanceMatrix = this.instanceMatrix.toJSON();
            if (this.instanceColor !== null) object.instanceColor = this.instanceColor.toJSON();
        }
        if (this.isBatchedMesh) {
            object.type = "BatchedMesh";
            object.perObjectFrustumCulled = this.perObjectFrustumCulled;
            object.sortObjects = this.sortObjects;
            object.drawRanges = this._drawRanges;
            object.reservedRanges = this._reservedRanges;
            object.visibility = this._visibility;
            object.active = this._active;
            object.bounds = this._bounds.map((bound)=>({
                    boxInitialized: bound.boxInitialized,
                    boxMin: bound.box.min.toArray(),
                    boxMax: bound.box.max.toArray(),
                    sphereInitialized: bound.sphereInitialized,
                    sphereRadius: bound.sphere.radius,
                    sphereCenter: bound.sphere.center.toArray()
                }));
            object.maxInstanceCount = this._maxInstanceCount;
            object.maxVertexCount = this._maxVertexCount;
            object.maxIndexCount = this._maxIndexCount;
            object.geometryInitialized = this._geometryInitialized;
            object.geometryCount = this._geometryCount;
            object.matricesTexture = this._matricesTexture.toJSON(meta);
            if (this._colorsTexture !== null) object.colorsTexture = this._colorsTexture.toJSON(meta);
            if (this.boundingSphere !== null) object.boundingSphere = {
                center: object.boundingSphere.center.toArray(),
                radius: object.boundingSphere.radius
            };
            if (this.boundingBox !== null) object.boundingBox = {
                min: object.boundingBox.min.toArray(),
                max: object.boundingBox.max.toArray()
            };
        }
        //
        function serialize(library, element) {
            if (library[element.uuid] === undefined) library[element.uuid] = element.toJSON(meta);
            return element.uuid;
        }
        if (this.isScene) {
            if (this.background) {
                if (this.background.isColor) object.background = this.background.toJSON();
                else if (this.background.isTexture) object.background = this.background.toJSON(meta).uuid;
            }
            if (this.environment && this.environment.isTexture && this.environment.isRenderTargetTexture !== true) object.environment = this.environment.toJSON(meta).uuid;
        } else if (this.isMesh || this.isLine || this.isPoints) {
            object.geometry = serialize(meta.geometries, this.geometry);
            const parameters = this.geometry.parameters;
            if (parameters !== undefined && parameters.shapes !== undefined) {
                const shapes = parameters.shapes;
                if (Array.isArray(shapes)) for(let i = 0, l = shapes.length; i < l; i++){
                    const shape = shapes[i];
                    serialize(meta.shapes, shape);
                }
                else serialize(meta.shapes, shapes);
            }
        }
        if (this.isSkinnedMesh) {
            object.bindMode = this.bindMode;
            object.bindMatrix = this.bindMatrix.toArray();
            if (this.skeleton !== undefined) {
                serialize(meta.skeletons, this.skeleton);
                object.skeleton = this.skeleton.uuid;
            }
        }
        if (this.material !== undefined) {
            if (Array.isArray(this.material)) {
                const uuids = [];
                for(let i = 0, l = this.material.length; i < l; i++)uuids.push(serialize(meta.materials, this.material[i]));
                object.material = uuids;
            } else object.material = serialize(meta.materials, this.material);
        }
        //
        if (this.children.length > 0) {
            object.children = [];
            for(let i = 0; i < this.children.length; i++)object.children.push(this.children[i].toJSON(meta).object);
        }
        //
        if (this.animations.length > 0) {
            object.animations = [];
            for(let i = 0; i < this.animations.length; i++){
                const animation = this.animations[i];
                object.animations.push(serialize(meta.animations, animation));
            }
        }
        if (isRootObject) {
            const geometries = extractFromCache(meta.geometries);
            const materials = extractFromCache(meta.materials);
            const textures = extractFromCache(meta.textures);
            const images = extractFromCache(meta.images);
            const shapes = extractFromCache(meta.shapes);
            const skeletons = extractFromCache(meta.skeletons);
            const animations = extractFromCache(meta.animations);
            const nodes = extractFromCache(meta.nodes);
            if (geometries.length > 0) output.geometries = geometries;
            if (materials.length > 0) output.materials = materials;
            if (textures.length > 0) output.textures = textures;
            if (images.length > 0) output.images = images;
            if (shapes.length > 0) output.shapes = shapes;
            if (skeletons.length > 0) output.skeletons = skeletons;
            if (animations.length > 0) output.animations = animations;
            if (nodes.length > 0) output.nodes = nodes;
        }
        output.object = object;
        return output;
        // extract data from the cache hash
        // remove metadata on each item
        // and return as array
        function extractFromCache(cache) {
            const values = [];
            for(const key in cache){
                const data = cache[key];
                delete data.metadata;
                values.push(data);
            }
            return values;
        }
    }
    clone(recursive) {
        return new this.constructor().copy(this, recursive);
    }
    copy(source, recursive = true) {
        this.name = source.name;
        this.up.copy(source.up);
        this.position.copy(source.position);
        this.rotation.order = source.rotation.order;
        this.quaternion.copy(source.quaternion);
        this.scale.copy(source.scale);
        this.matrix.copy(source.matrix);
        this.matrixWorld.copy(source.matrixWorld);
        this.matrixAutoUpdate = source.matrixAutoUpdate;
        this.matrixWorldAutoUpdate = source.matrixWorldAutoUpdate;
        this.matrixWorldNeedsUpdate = source.matrixWorldNeedsUpdate;
        this.layers.mask = source.layers.mask;
        this.visible = source.visible;
        this.castShadow = source.castShadow;
        this.receiveShadow = source.receiveShadow;
        this.frustumCulled = source.frustumCulled;
        this.renderOrder = source.renderOrder;
        this.animations = source.animations.slice();
        this.userData = JSON.parse(JSON.stringify(source.userData));
        if (recursive === true) for(let i = 0; i < source.children.length; i++){
            const child = source.children[i];
            this.add(child.clone());
        }
        return this;
    }
}
Object3D.DEFAULT_UP = /*@__PURE__*/ new Vector3(0, 1, 0);
Object3D.DEFAULT_MATRIX_AUTO_UPDATE = true;
Object3D.DEFAULT_MATRIX_WORLD_AUTO_UPDATE = true;
const _v0$1 = /*@__PURE__*/ new Vector3();
const _v1$3 = /*@__PURE__*/ new Vector3();
const _v2$2 = /*@__PURE__*/ new Vector3();
const _v3$2 = /*@__PURE__*/ new Vector3();
const _vab = /*@__PURE__*/ new Vector3();
const _vac = /*@__PURE__*/ new Vector3();
const _vbc = /*@__PURE__*/ new Vector3();
const _vap = /*@__PURE__*/ new Vector3();
const _vbp = /*@__PURE__*/ new Vector3();
const _vcp = /*@__PURE__*/ new Vector3();
class Triangle {
    constructor(a = new Vector3(), b = new Vector3(), c = new Vector3()){
        this.a = a;
        this.b = b;
        this.c = c;
    }
    static getNormal(a, b, c, target) {
        target.subVectors(c, b);
        _v0$1.subVectors(a, b);
        target.cross(_v0$1);
        const targetLengthSq = target.lengthSq();
        if (targetLengthSq > 0) return target.multiplyScalar(1 / Math.sqrt(targetLengthSq));
        return target.set(0, 0, 0);
    }
    // static/instance method to calculate barycentric coordinates
    // based on: http://www.blackpawn.com/texts/pointinpoly/default.html
    static getBarycoord(point, a, b, c, target) {
        _v0$1.subVectors(c, a);
        _v1$3.subVectors(b, a);
        _v2$2.subVectors(point, a);
        const dot00 = _v0$1.dot(_v0$1);
        const dot01 = _v0$1.dot(_v1$3);
        const dot02 = _v0$1.dot(_v2$2);
        const dot11 = _v1$3.dot(_v1$3);
        const dot12 = _v1$3.dot(_v2$2);
        const denom = dot00 * dot11 - dot01 * dot01;
        // collinear or singular triangle
        if (denom === 0) {
            target.set(0, 0, 0);
            return null;
        }
        const invDenom = 1 / denom;
        const u = (dot11 * dot02 - dot01 * dot12) * invDenom;
        const v = (dot00 * dot12 - dot01 * dot02) * invDenom;
        // barycentric coordinates must always sum to 1
        return target.set(1 - u - v, v, u);
    }
    static containsPoint(point, a, b, c) {
        // if the triangle is degenerate then we can't contain a point
        if (this.getBarycoord(point, a, b, c, _v3$2) === null) return false;
        return _v3$2.x >= 0 && _v3$2.y >= 0 && _v3$2.x + _v3$2.y <= 1;
    }
    static getInterpolation(point, p1, p2, p3, v1, v2, v3, target) {
        if (this.getBarycoord(point, p1, p2, p3, _v3$2) === null) {
            target.x = 0;
            target.y = 0;
            if ("z" in target) target.z = 0;
            if ("w" in target) target.w = 0;
            return null;
        }
        target.setScalar(0);
        target.addScaledVector(v1, _v3$2.x);
        target.addScaledVector(v2, _v3$2.y);
        target.addScaledVector(v3, _v3$2.z);
        return target;
    }
    static isFrontFacing(a, b, c, direction) {
        _v0$1.subVectors(c, b);
        _v1$3.subVectors(a, b);
        // strictly front facing
        return _v0$1.cross(_v1$3).dot(direction) < 0 ? true : false;
    }
    set(a, b, c) {
        this.a.copy(a);
        this.b.copy(b);
        this.c.copy(c);
        return this;
    }
    setFromPointsAndIndices(points, i0, i1, i2) {
        this.a.copy(points[i0]);
        this.b.copy(points[i1]);
        this.c.copy(points[i2]);
        return this;
    }
    setFromAttributeAndIndices(attribute, i0, i1, i2) {
        this.a.fromBufferAttribute(attribute, i0);
        this.b.fromBufferAttribute(attribute, i1);
        this.c.fromBufferAttribute(attribute, i2);
        return this;
    }
    clone() {
        return new this.constructor().copy(this);
    }
    copy(triangle) {
        this.a.copy(triangle.a);
        this.b.copy(triangle.b);
        this.c.copy(triangle.c);
        return this;
    }
    getArea() {
        _v0$1.subVectors(this.c, this.b);
        _v1$3.subVectors(this.a, this.b);
        return _v0$1.cross(_v1$3).length() * 0.5;
    }
    getMidpoint(target) {
        return target.addVectors(this.a, this.b).add(this.c).multiplyScalar(1 / 3);
    }
    getNormal(target) {
        return Triangle.getNormal(this.a, this.b, this.c, target);
    }
    getPlane(target) {
        return target.setFromCoplanarPoints(this.a, this.b, this.c);
    }
    getBarycoord(point, target) {
        return Triangle.getBarycoord(point, this.a, this.b, this.c, target);
    }
    getInterpolation(point, v1, v2, v3, target) {
        return Triangle.getInterpolation(point, this.a, this.b, this.c, v1, v2, v3, target);
    }
    containsPoint(point) {
        return Triangle.containsPoint(point, this.a, this.b, this.c);
    }
    isFrontFacing(direction) {
        return Triangle.isFrontFacing(this.a, this.b, this.c, direction);
    }
    intersectsBox(box) {
        return box.intersectsTriangle(this);
    }
    closestPointToPoint(p, target) {
        const a = this.a, b = this.b, c = this.c;
        let v, w;
        // algorithm thanks to Real-Time Collision Detection by Christer Ericson,
        // published by Morgan Kaufmann Publishers, (c) 2005 Elsevier Inc.,
        // under the accompanying license; see chapter 5.1.5 for detailed explanation.
        // basically, we're distinguishing which of the voronoi regions of the triangle
        // the point lies in with the minimum amount of redundant computation.
        _vab.subVectors(b, a);
        _vac.subVectors(c, a);
        _vap.subVectors(p, a);
        const d1 = _vab.dot(_vap);
        const d2 = _vac.dot(_vap);
        if (d1 <= 0 && d2 <= 0) // vertex region of A; barycentric coords (1, 0, 0)
        return target.copy(a);
        _vbp.subVectors(p, b);
        const d3 = _vab.dot(_vbp);
        const d4 = _vac.dot(_vbp);
        if (d3 >= 0 && d4 <= d3) // vertex region of B; barycentric coords (0, 1, 0)
        return target.copy(b);
        const vc = d1 * d4 - d3 * d2;
        if (vc <= 0 && d1 >= 0 && d3 <= 0) {
            v = d1 / (d1 - d3);
            // edge region of AB; barycentric coords (1-v, v, 0)
            return target.copy(a).addScaledVector(_vab, v);
        }
        _vcp.subVectors(p, c);
        const d5 = _vab.dot(_vcp);
        const d6 = _vac.dot(_vcp);
        if (d6 >= 0 && d5 <= d6) // vertex region of C; barycentric coords (0, 0, 1)
        return target.copy(c);
        const vb = d5 * d2 - d1 * d6;
        if (vb <= 0 && d2 >= 0 && d6 <= 0) {
            w = d2 / (d2 - d6);
            // edge region of AC; barycentric coords (1-w, 0, w)
            return target.copy(a).addScaledVector(_vac, w);
        }
        const va = d3 * d6 - d5 * d4;
        if (va <= 0 && d4 - d3 >= 0 && d5 - d6 >= 0) {
            _vbc.subVectors(c, b);
            w = (d4 - d3) / (d4 - d3 + (d5 - d6));
            // edge region of BC; barycentric coords (0, 1-w, w)
            return target.copy(b).addScaledVector(_vbc, w); // edge region of BC
        }
        // face region
        const denom = 1 / (va + vb + vc);
        // u = va * denom
        v = vb * denom;
        w = vc * denom;
        return target.copy(a).addScaledVector(_vab, v).addScaledVector(_vac, w);
    }
    equals(triangle) {
        return triangle.a.equals(this.a) && triangle.b.equals(this.b) && triangle.c.equals(this.c);
    }
}
const _colorKeywords = {
    "aliceblue": 0xF0F8FF,
    "antiquewhite": 0xFAEBD7,
    "aqua": 0x00FFFF,
    "aquamarine": 0x7FFFD4,
    "azure": 0xF0FFFF,
    "beige": 0xF5F5DC,
    "bisque": 0xFFE4C4,
    "black": 0x000000,
    "blanchedalmond": 0xFFEBCD,
    "blue": 0x0000FF,
    "blueviolet": 0x8A2BE2,
    "brown": 0xA52A2A,
    "burlywood": 0xDEB887,
    "cadetblue": 0x5F9EA0,
    "chartreuse": 0x7FFF00,
    "chocolate": 0xD2691E,
    "coral": 0xFF7F50,
    "cornflowerblue": 0x6495ED,
    "cornsilk": 0xFFF8DC,
    "crimson": 0xDC143C,
    "cyan": 0x00FFFF,
    "darkblue": 0x00008B,
    "darkcyan": 0x008B8B,
    "darkgoldenrod": 0xB8860B,
    "darkgray": 0xA9A9A9,
    "darkgreen": 0x006400,
    "darkgrey": 0xA9A9A9,
    "darkkhaki": 0xBDB76B,
    "darkmagenta": 0x8B008B,
    "darkolivegreen": 0x556B2F,
    "darkorange": 0xFF8C00,
    "darkorchid": 0x9932CC,
    "darkred": 0x8B0000,
    "darksalmon": 0xE9967A,
    "darkseagreen": 0x8FBC8F,
    "darkslateblue": 0x483D8B,
    "darkslategray": 0x2F4F4F,
    "darkslategrey": 0x2F4F4F,
    "darkturquoise": 0x00CED1,
    "darkviolet": 0x9400D3,
    "deeppink": 0xFF1493,
    "deepskyblue": 0x00BFFF,
    "dimgray": 0x696969,
    "dimgrey": 0x696969,
    "dodgerblue": 0x1E90FF,
    "firebrick": 0xB22222,
    "floralwhite": 0xFFFAF0,
    "forestgreen": 0x228B22,
    "fuchsia": 0xFF00FF,
    "gainsboro": 0xDCDCDC,
    "ghostwhite": 0xF8F8FF,
    "gold": 0xFFD700,
    "goldenrod": 0xDAA520,
    "gray": 0x808080,
    "green": 0x008000,
    "greenyellow": 0xADFF2F,
    "grey": 0x808080,
    "honeydew": 0xF0FFF0,
    "hotpink": 0xFF69B4,
    "indianred": 0xCD5C5C,
    "indigo": 0x4B0082,
    "ivory": 0xFFFFF0,
    "khaki": 0xF0E68C,
    "lavender": 0xE6E6FA,
    "lavenderblush": 0xFFF0F5,
    "lawngreen": 0x7CFC00,
    "lemonchiffon": 0xFFFACD,
    "lightblue": 0xADD8E6,
    "lightcoral": 0xF08080,
    "lightcyan": 0xE0FFFF,
    "lightgoldenrodyellow": 0xFAFAD2,
    "lightgray": 0xD3D3D3,
    "lightgreen": 0x90EE90,
    "lightgrey": 0xD3D3D3,
    "lightpink": 0xFFB6C1,
    "lightsalmon": 0xFFA07A,
    "lightseagreen": 0x20B2AA,
    "lightskyblue": 0x87CEFA,
    "lightslategray": 0x778899,
    "lightslategrey": 0x778899,
    "lightsteelblue": 0xB0C4DE,
    "lightyellow": 0xFFFFE0,
    "lime": 0x00FF00,
    "limegreen": 0x32CD32,
    "linen": 0xFAF0E6,
    "magenta": 0xFF00FF,
    "maroon": 0x800000,
    "mediumaquamarine": 0x66CDAA,
    "mediumblue": 0x0000CD,
    "mediumorchid": 0xBA55D3,
    "mediumpurple": 0x9370DB,
    "mediumseagreen": 0x3CB371,
    "mediumslateblue": 0x7B68EE,
    "mediumspringgreen": 0x00FA9A,
    "mediumturquoise": 0x48D1CC,
    "mediumvioletred": 0xC71585,
    "midnightblue": 0x191970,
    "mintcream": 0xF5FFFA,
    "mistyrose": 0xFFE4E1,
    "moccasin": 0xFFE4B5,
    "navajowhite": 0xFFDEAD,
    "navy": 0x000080,
    "oldlace": 0xFDF5E6,
    "olive": 0x808000,
    "olivedrab": 0x6B8E23,
    "orange": 0xFFA500,
    "orangered": 0xFF4500,
    "orchid": 0xDA70D6,
    "palegoldenrod": 0xEEE8AA,
    "palegreen": 0x98FB98,
    "paleturquoise": 0xAFEEEE,
    "palevioletred": 0xDB7093,
    "papayawhip": 0xFFEFD5,
    "peachpuff": 0xFFDAB9,
    "peru": 0xCD853F,
    "pink": 0xFFC0CB,
    "plum": 0xDDA0DD,
    "powderblue": 0xB0E0E6,
    "purple": 0x800080,
    "rebeccapurple": 0x663399,
    "red": 0xFF0000,
    "rosybrown": 0xBC8F8F,
    "royalblue": 0x4169E1,
    "saddlebrown": 0x8B4513,
    "salmon": 0xFA8072,
    "sandybrown": 0xF4A460,
    "seagreen": 0x2E8B57,
    "seashell": 0xFFF5EE,
    "sienna": 0xA0522D,
    "silver": 0xC0C0C0,
    "skyblue": 0x87CEEB,
    "slateblue": 0x6A5ACD,
    "slategray": 0x708090,
    "slategrey": 0x708090,
    "snow": 0xFFFAFA,
    "springgreen": 0x00FF7F,
    "steelblue": 0x4682B4,
    "tan": 0xD2B48C,
    "teal": 0x008080,
    "thistle": 0xD8BFD8,
    "tomato": 0xFF6347,
    "turquoise": 0x40E0D0,
    "violet": 0xEE82EE,
    "wheat": 0xF5DEB3,
    "white": 0xFFFFFF,
    "whitesmoke": 0xF5F5F5,
    "yellow": 0xFFFF00,
    "yellowgreen": 0x9ACD32
};
const _hslA = {
    h: 0,
    s: 0,
    l: 0
};
const _hslB = {
    h: 0,
    s: 0,
    l: 0
};
function hue2rgb(p, q, t) {
    if (t < 0) t += 1;
    if (t > 1) t -= 1;
    if (t < 1 / 6) return p + (q - p) * 6 * t;
    if (t < 0.5) return q;
    if (t < 2 / 3) return p + (q - p) * 6 * (2 / 3 - t);
    return p;
}
class Color {
    constructor(r, g, b){
        this.isColor = true;
        this.r = 1;
        this.g = 1;
        this.b = 1;
        return this.set(r, g, b);
    }
    set(r, g, b) {
        if (g === undefined && b === undefined) {
            // r is THREE.Color, hex or string
            const value = r;
            if (value && value.isColor) this.copy(value);
            else if (typeof value === "number") this.setHex(value);
            else if (typeof value === "string") this.setStyle(value);
        } else this.setRGB(r, g, b);
        return this;
    }
    setScalar(scalar) {
        this.r = scalar;
        this.g = scalar;
        this.b = scalar;
        return this;
    }
    setHex(hex, colorSpace1 = SRGBColorSpace) {
        hex = Math.floor(hex);
        this.r = (hex >> 16 & 255) / 255;
        this.g = (hex >> 8 & 255) / 255;
        this.b = (hex & 255) / 255;
        ColorManagement.toWorkingColorSpace(this, colorSpace1);
        return this;
    }
    setRGB(r, g, b, colorSpace1 = ColorManagement.workingColorSpace) {
        this.r = r;
        this.g = g;
        this.b = b;
        ColorManagement.toWorkingColorSpace(this, colorSpace1);
        return this;
    }
    setHSL(h, s, l, colorSpace1 = ColorManagement.workingColorSpace) {
        // h,s,l ranges are in 0.0 - 1.0
        h = euclideanModulo(h, 1);
        s = clamp(s, 0, 1);
        l = clamp(l, 0, 1);
        if (s === 0) this.r = this.g = this.b = l;
        else {
            const p = l <= 0.5 ? l * (1 + s) : l + s - l * s;
            const q = 2 * l - p;
            this.r = hue2rgb(q, p, h + 1 / 3);
            this.g = hue2rgb(q, p, h);
            this.b = hue2rgb(q, p, h - 1 / 3);
        }
        ColorManagement.toWorkingColorSpace(this, colorSpace1);
        return this;
    }
    setStyle(style, colorSpace1 = SRGBColorSpace) {
        function handleAlpha(string) {
            if (string === undefined) return;
            if (parseFloat(string) < 1) console.warn("THREE.Color: Alpha component of " + style + " will be ignored.");
        }
        let m;
        if (m = /^(\w+)\(([^\)]*)\)/.exec(style)) {
            // rgb / hsl
            let color;
            const name = m[1];
            const components = m[2];
            switch(name){
                case "rgb":
                case "rgba":
                    if (color = /^\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*(?:,\s*(\d*\.?\d+)\s*)?$/.exec(components)) {
                        // rgb(255,0,0) rgba(255,0,0,0.5)
                        handleAlpha(color[4]);
                        return this.setRGB(Math.min(255, parseInt(color[1], 10)) / 255, Math.min(255, parseInt(color[2], 10)) / 255, Math.min(255, parseInt(color[3], 10)) / 255, colorSpace1);
                    }
                    if (color = /^\s*(\d+)\%\s*,\s*(\d+)\%\s*,\s*(\d+)\%\s*(?:,\s*(\d*\.?\d+)\s*)?$/.exec(components)) {
                        // rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)
                        handleAlpha(color[4]);
                        return this.setRGB(Math.min(100, parseInt(color[1], 10)) / 100, Math.min(100, parseInt(color[2], 10)) / 100, Math.min(100, parseInt(color[3], 10)) / 100, colorSpace1);
                    }
                    break;
                case "hsl":
                case "hsla":
                    if (color = /^\s*(\d*\.?\d+)\s*,\s*(\d*\.?\d+)\%\s*,\s*(\d*\.?\d+)\%\s*(?:,\s*(\d*\.?\d+)\s*)?$/.exec(components)) {
                        // hsl(120,50%,50%) hsla(120,50%,50%,0.5)
                        handleAlpha(color[4]);
                        return this.setHSL(parseFloat(color[1]) / 360, parseFloat(color[2]) / 100, parseFloat(color[3]) / 100, colorSpace1);
                    }
                    break;
                default:
                    console.warn("THREE.Color: Unknown color model " + style);
            }
        } else if (m = /^\#([A-Fa-f\d]+)$/.exec(style)) {
            // hex color
            const hex = m[1];
            const size = hex.length;
            if (size === 3) // #ff0
            return this.setRGB(parseInt(hex.charAt(0), 16) / 15, parseInt(hex.charAt(1), 16) / 15, parseInt(hex.charAt(2), 16) / 15, colorSpace1);
            else if (size === 6) // #ff0000
            return this.setHex(parseInt(hex, 16), colorSpace1);
            else console.warn("THREE.Color: Invalid hex color " + style);
        } else if (style && style.length > 0) return this.setColorName(style, colorSpace1);
        return this;
    }
    setColorName(style, colorSpace1 = SRGBColorSpace) {
        // color keywords
        const hex = _colorKeywords[style.toLowerCase()];
        if (hex !== undefined) // red
        this.setHex(hex, colorSpace1);
        else // unknown color
        console.warn("THREE.Color: Unknown color " + style);
        return this;
    }
    clone() {
        return new this.constructor(this.r, this.g, this.b);
    }
    copy(color) {
        this.r = color.r;
        this.g = color.g;
        this.b = color.b;
        return this;
    }
    copySRGBToLinear(color) {
        this.r = SRGBToLinear(color.r);
        this.g = SRGBToLinear(color.g);
        this.b = SRGBToLinear(color.b);
        return this;
    }
    copyLinearToSRGB(color) {
        this.r = LinearToSRGB(color.r);
        this.g = LinearToSRGB(color.g);
        this.b = LinearToSRGB(color.b);
        return this;
    }
    convertSRGBToLinear() {
        this.copySRGBToLinear(this);
        return this;
    }
    convertLinearToSRGB() {
        this.copyLinearToSRGB(this);
        return this;
    }
    getHex(colorSpace1 = SRGBColorSpace) {
        ColorManagement.fromWorkingColorSpace(_color.copy(this), colorSpace1);
        return Math.round(clamp(_color.r * 255, 0, 255)) * 65536 + Math.round(clamp(_color.g * 255, 0, 255)) * 256 + Math.round(clamp(_color.b * 255, 0, 255));
    }
    getHexString(colorSpace1 = SRGBColorSpace) {
        return ("000000" + this.getHex(colorSpace1).toString(16)).slice(-6);
    }
    getHSL(target, colorSpace1 = ColorManagement.workingColorSpace) {
        // h,s,l ranges are in 0.0 - 1.0
        ColorManagement.fromWorkingColorSpace(_color.copy(this), colorSpace1);
        const r = _color.r, g = _color.g, b = _color.b;
        const max = Math.max(r, g, b);
        const min = Math.min(r, g, b);
        let hue, saturation;
        const lightness = (min + max) / 2.0;
        if (min === max) {
            hue = 0;
            saturation = 0;
        } else {
            const delta = max - min;
            saturation = lightness <= 0.5 ? delta / (max + min) : delta / (2 - max - min);
            switch(max){
                case r:
                    hue = (g - b) / delta + (g < b ? 6 : 0);
                    break;
                case g:
                    hue = (b - r) / delta + 2;
                    break;
                case b:
                    hue = (r - g) / delta + 4;
                    break;
            }
            hue /= 6;
        }
        target.h = hue;
        target.s = saturation;
        target.l = lightness;
        return target;
    }
    getRGB(target, colorSpace1 = ColorManagement.workingColorSpace) {
        ColorManagement.fromWorkingColorSpace(_color.copy(this), colorSpace1);
        target.r = _color.r;
        target.g = _color.g;
        target.b = _color.b;
        return target;
    }
    getStyle(colorSpace1 = SRGBColorSpace) {
        ColorManagement.fromWorkingColorSpace(_color.copy(this), colorSpace1);
        const r = _color.r, g = _color.g, b = _color.b;
        if (colorSpace1 !== SRGBColorSpace) // Requires CSS Color Module Level 4 (https://www.w3.org/TR/css-color-4/).
        return `color(${colorSpace1} ${r.toFixed(3)} ${g.toFixed(3)} ${b.toFixed(3)})`;
        return `rgb(${Math.round(r * 255)},${Math.round(g * 255)},${Math.round(b * 255)})`;
    }
    offsetHSL(h, s, l) {
        this.getHSL(_hslA);
        return this.setHSL(_hslA.h + h, _hslA.s + s, _hslA.l + l);
    }
    add(color) {
        this.r += color.r;
        this.g += color.g;
        this.b += color.b;
        return this;
    }
    addColors(color1, color2) {
        this.r = color1.r + color2.r;
        this.g = color1.g + color2.g;
        this.b = color1.b + color2.b;
        return this;
    }
    addScalar(s) {
        this.r += s;
        this.g += s;
        this.b += s;
        return this;
    }
    sub(color) {
        this.r = Math.max(0, this.r - color.r);
        this.g = Math.max(0, this.g - color.g);
        this.b = Math.max(0, this.b - color.b);
        return this;
    }
    multiply(color) {
        this.r *= color.r;
        this.g *= color.g;
        this.b *= color.b;
        return this;
    }
    multiplyScalar(s) {
        this.r *= s;
        this.g *= s;
        this.b *= s;
        return this;
    }
    lerp(color, alpha) {
        this.r += (color.r - this.r) * alpha;
        this.g += (color.g - this.g) * alpha;
        this.b += (color.b - this.b) * alpha;
        return this;
    }
    lerpColors(color1, color2, alpha) {
        this.r = color1.r + (color2.r - color1.r) * alpha;
        this.g = color1.g + (color2.g - color1.g) * alpha;
        this.b = color1.b + (color2.b - color1.b) * alpha;
        return this;
    }
    lerpHSL(color, alpha) {
        this.getHSL(_hslA);
        color.getHSL(_hslB);
        const h = lerp(_hslA.h, _hslB.h, alpha);
        const s = lerp(_hslA.s, _hslB.s, alpha);
        const l = lerp(_hslA.l, _hslB.l, alpha);
        this.setHSL(h, s, l);
        return this;
    }
    setFromVector3(v) {
        this.r = v.x;
        this.g = v.y;
        this.b = v.z;
        return this;
    }
    applyMatrix3(m) {
        const r = this.r, g = this.g, b = this.b;
        const e = m.elements;
        this.r = e[0] * r + e[3] * g + e[6] * b;
        this.g = e[1] * r + e[4] * g + e[7] * b;
        this.b = e[2] * r + e[5] * g + e[8] * b;
        return this;
    }
    equals(c) {
        return c.r === this.r && c.g === this.g && c.b === this.b;
    }
    fromArray(array, offset = 0) {
        this.r = array[offset];
        this.g = array[offset + 1];
        this.b = array[offset + 2];
        return this;
    }
    toArray(array = [], offset = 0) {
        array[offset] = this.r;
        array[offset + 1] = this.g;
        array[offset + 2] = this.b;
        return array;
    }
    fromBufferAttribute(attribute, index) {
        this.r = attribute.getX(index);
        this.g = attribute.getY(index);
        this.b = attribute.getZ(index);
        return this;
    }
    toJSON() {
        return this.getHex();
    }
    *[Symbol.iterator]() {
        yield this.r;
        yield this.g;
        yield this.b;
    }
}
const _color = /*@__PURE__*/ new Color();
Color.NAMES = _colorKeywords;
let _materialId = 0;
class Material extends EventDispatcher {
    constructor(){
        super();
        this.isMaterial = true;
        Object.defineProperty(this, "id", {
            value: _materialId++
        });
        this.uuid = generateUUID();
        this.name = "";
        this.type = "Material";
        this.blending = NormalBlending;
        this.side = FrontSide;
        this.vertexColors = false;
        this.opacity = 1;
        this.transparent = false;
        this.alphaHash = false;
        this.blendSrc = SrcAlphaFactor;
        this.blendDst = OneMinusSrcAlphaFactor;
        this.blendEquation = AddEquation;
        this.blendSrcAlpha = null;
        this.blendDstAlpha = null;
        this.blendEquationAlpha = null;
        this.blendColor = new Color(0, 0, 0);
        this.blendAlpha = 0;
        this.depthFunc = LessEqualDepth;
        this.depthTest = true;
        this.depthWrite = true;
        this.stencilWriteMask = 0xff;
        this.stencilFunc = AlwaysStencilFunc;
        this.stencilRef = 0;
        this.stencilFuncMask = 0xff;
        this.stencilFail = KeepStencilOp;
        this.stencilZFail = KeepStencilOp;
        this.stencilZPass = KeepStencilOp;
        this.stencilWrite = false;
        this.clippingPlanes = null;
        this.clipIntersection = false;
        this.clipShadows = false;
        this.shadowSide = null;
        this.colorWrite = true;
        this.precision = null; // override the renderer's default precision for this material
        this.polygonOffset = false;
        this.polygonOffsetFactor = 0;
        this.polygonOffsetUnits = 0;
        this.dithering = false;
        this.alphaToCoverage = false;
        this.premultipliedAlpha = false;
        this.forceSinglePass = false;
        this.visible = true;
        this.toneMapped = true;
        this.userData = {};
        this.version = 0;
        this._alphaTest = 0;
    }
    get alphaTest() {
        return this._alphaTest;
    }
    set alphaTest(value) {
        if (this._alphaTest > 0 !== value > 0) this.version++;
        this._alphaTest = value;
    }
    onBeforeCompile() {}
    customProgramCacheKey() {
        return this.onBeforeCompile.toString();
    }
    setValues(values) {
        if (values === undefined) return;
        for(const key in values){
            const newValue = values[key];
            if (newValue === undefined) {
                console.warn(`THREE.Material: parameter '${key}' has value of undefined.`);
                continue;
            }
            const currentValue = this[key];
            if (currentValue === undefined) {
                console.warn(`THREE.Material: '${key}' is not a property of THREE.${this.type}.`);
                continue;
            }
            if (currentValue && currentValue.isColor) currentValue.set(newValue);
            else if (currentValue && currentValue.isVector3 && newValue && newValue.isVector3) currentValue.copy(newValue);
            else this[key] = newValue;
        }
    }
    toJSON(meta) {
        const isRootObject = meta === undefined || typeof meta === "string";
        if (isRootObject) meta = {
            textures: {},
            images: {}
        };
        const data = {
            metadata: {
                version: 4.6,
                type: "Material",
                generator: "Material.toJSON"
            }
        };
        // standard Material serialization
        data.uuid = this.uuid;
        data.type = this.type;
        if (this.name !== "") data.name = this.name;
        if (this.color && this.color.isColor) data.color = this.color.getHex();
        if (this.roughness !== undefined) data.roughness = this.roughness;
        if (this.metalness !== undefined) data.metalness = this.metalness;
        if (this.sheen !== undefined) data.sheen = this.sheen;
        if (this.sheenColor && this.sheenColor.isColor) data.sheenColor = this.sheenColor.getHex();
        if (this.sheenRoughness !== undefined) data.sheenRoughness = this.sheenRoughness;
        if (this.emissive && this.emissive.isColor) data.emissive = this.emissive.getHex();
        if (this.emissiveIntensity !== undefined && this.emissiveIntensity !== 1) data.emissiveIntensity = this.emissiveIntensity;
        if (this.specular && this.specular.isColor) data.specular = this.specular.getHex();
        if (this.specularIntensity !== undefined) data.specularIntensity = this.specularIntensity;
        if (this.specularColor && this.specularColor.isColor) data.specularColor = this.specularColor.getHex();
        if (this.shininess !== undefined) data.shininess = this.shininess;
        if (this.clearcoat !== undefined) data.clearcoat = this.clearcoat;
        if (this.clearcoatRoughness !== undefined) data.clearcoatRoughness = this.clearcoatRoughness;
        if (this.clearcoatMap && this.clearcoatMap.isTexture) data.clearcoatMap = this.clearcoatMap.toJSON(meta).uuid;
        if (this.clearcoatRoughnessMap && this.clearcoatRoughnessMap.isTexture) data.clearcoatRoughnessMap = this.clearcoatRoughnessMap.toJSON(meta).uuid;
        if (this.clearcoatNormalMap && this.clearcoatNormalMap.isTexture) {
            data.clearcoatNormalMap = this.clearcoatNormalMap.toJSON(meta).uuid;
            data.clearcoatNormalScale = this.clearcoatNormalScale.toArray();
        }
        if (this.dispersion !== undefined) data.dispersion = this.dispersion;
        if (this.iridescence !== undefined) data.iridescence = this.iridescence;
        if (this.iridescenceIOR !== undefined) data.iridescenceIOR = this.iridescenceIOR;
        if (this.iridescenceThicknessRange !== undefined) data.iridescenceThicknessRange = this.iridescenceThicknessRange;
        if (this.iridescenceMap && this.iridescenceMap.isTexture) data.iridescenceMap = this.iridescenceMap.toJSON(meta).uuid;
        if (this.iridescenceThicknessMap && this.iridescenceThicknessMap.isTexture) data.iridescenceThicknessMap = this.iridescenceThicknessMap.toJSON(meta).uuid;
        if (this.anisotropy !== undefined) data.anisotropy = this.anisotropy;
        if (this.anisotropyRotation !== undefined) data.anisotropyRotation = this.anisotropyRotation;
        if (this.anisotropyMap && this.anisotropyMap.isTexture) data.anisotropyMap = this.anisotropyMap.toJSON(meta).uuid;
        if (this.map && this.map.isTexture) data.map = this.map.toJSON(meta).uuid;
        if (this.matcap && this.matcap.isTexture) data.matcap = this.matcap.toJSON(meta).uuid;
        if (this.alphaMap && this.alphaMap.isTexture) data.alphaMap = this.alphaMap.toJSON(meta).uuid;
        if (this.lightMap && this.lightMap.isTexture) {
            data.lightMap = this.lightMap.toJSON(meta).uuid;
            data.lightMapIntensity = this.lightMapIntensity;
        }
        if (this.aoMap && this.aoMap.isTexture) {
            data.aoMap = this.aoMap.toJSON(meta).uuid;
            data.aoMapIntensity = this.aoMapIntensity;
        }
        if (this.bumpMap && this.bumpMap.isTexture) {
            data.bumpMap = this.bumpMap.toJSON(meta).uuid;
            data.bumpScale = this.bumpScale;
        }
        if (this.normalMap && this.normalMap.isTexture) {
            data.normalMap = this.normalMap.toJSON(meta).uuid;
            data.normalMapType = this.normalMapType;
            data.normalScale = this.normalScale.toArray();
        }
        if (this.displacementMap && this.displacementMap.isTexture) {
            data.displacementMap = this.displacementMap.toJSON(meta).uuid;
            data.displacementScale = this.displacementScale;
            data.displacementBias = this.displacementBias;
        }
        if (this.roughnessMap && this.roughnessMap.isTexture) data.roughnessMap = this.roughnessMap.toJSON(meta).uuid;
        if (this.metalnessMap && this.metalnessMap.isTexture) data.metalnessMap = this.metalnessMap.toJSON(meta).uuid;
        if (this.emissiveMap && this.emissiveMap.isTexture) data.emissiveMap = this.emissiveMap.toJSON(meta).uuid;
        if (this.specularMap && this.specularMap.isTexture) data.specularMap = this.specularMap.toJSON(meta).uuid;
        if (this.specularIntensityMap && this.specularIntensityMap.isTexture) data.specularIntensityMap = this.specularIntensityMap.toJSON(meta).uuid;
        if (this.specularColorMap && this.specularColorMap.isTexture) data.specularColorMap = this.specularColorMap.toJSON(meta).uuid;
        if (this.envMap && this.envMap.isTexture) {
            data.envMap = this.envMap.toJSON(meta).uuid;
            if (this.combine !== undefined) data.combine = this.combine;
        }
        if (this.envMapRotation !== undefined) data.envMapRotation = this.envMapRotation.toArray();
        if (this.envMapIntensity !== undefined) data.envMapIntensity = this.envMapIntensity;
        if (this.reflectivity !== undefined) data.reflectivity = this.reflectivity;
        if (this.refractionRatio !== undefined) data.refractionRatio = this.refractionRatio;
        if (this.gradientMap && this.gradientMap.isTexture) data.gradientMap = this.gradientMap.toJSON(meta).uuid;
        if (this.transmission !== undefined) data.transmission = this.transmission;
        if (this.transmissionMap && this.transmissionMap.isTexture) data.transmissionMap = this.transmissionMap.toJSON(meta).uuid;
        if (this.thickness !== undefined) data.thickness = this.thickness;
        if (this.thicknessMap && this.thicknessMap.isTexture) data.thicknessMap = this.thicknessMap.toJSON(meta).uuid;
        if (this.attenuationDistance !== undefined && this.attenuationDistance !== Infinity) data.attenuationDistance = this.attenuationDistance;
        if (this.attenuationColor !== undefined) data.attenuationColor = this.attenuationColor.getHex();
        if (this.size !== undefined) data.size = this.size;
        if (this.shadowSide !== null) data.shadowSide = this.shadowSide;
        if (this.sizeAttenuation !== undefined) data.sizeAttenuation = this.sizeAttenuation;
        if (this.blending !== NormalBlending) data.blending = this.blending;
        if (this.side !== FrontSide) data.side = this.side;
        if (this.vertexColors === true) data.vertexColors = true;
        if (this.opacity < 1) data.opacity = this.opacity;
        if (this.transparent === true) data.transparent = true;
        if (this.blendSrc !== SrcAlphaFactor) data.blendSrc = this.blendSrc;
        if (this.blendDst !== OneMinusSrcAlphaFactor) data.blendDst = this.blendDst;
        if (this.blendEquation !== AddEquation) data.blendEquation = this.blendEquation;
        if (this.blendSrcAlpha !== null) data.blendSrcAlpha = this.blendSrcAlpha;
        if (this.blendDstAlpha !== null) data.blendDstAlpha = this.blendDstAlpha;
        if (this.blendEquationAlpha !== null) data.blendEquationAlpha = this.blendEquationAlpha;
        if (this.blendColor && this.blendColor.isColor) data.blendColor = this.blendColor.getHex();
        if (this.blendAlpha !== 0) data.blendAlpha = this.blendAlpha;
        if (this.depthFunc !== LessEqualDepth) data.depthFunc = this.depthFunc;
        if (this.depthTest === false) data.depthTest = this.depthTest;
        if (this.depthWrite === false) data.depthWrite = this.depthWrite;
        if (this.colorWrite === false) data.colorWrite = this.colorWrite;
        if (this.stencilWriteMask !== 0xff) data.stencilWriteMask = this.stencilWriteMask;
        if (this.stencilFunc !== AlwaysStencilFunc) data.stencilFunc = this.stencilFunc;
        if (this.stencilRef !== 0) data.stencilRef = this.stencilRef;
        if (this.stencilFuncMask !== 0xff) data.stencilFuncMask = this.stencilFuncMask;
        if (this.stencilFail !== KeepStencilOp) data.stencilFail = this.stencilFail;
        if (this.stencilZFail !== KeepStencilOp) data.stencilZFail = this.stencilZFail;
        if (this.stencilZPass !== KeepStencilOp) data.stencilZPass = this.stencilZPass;
        if (this.stencilWrite === true) data.stencilWrite = this.stencilWrite;
        // rotation (SpriteMaterial)
        if (this.rotation !== undefined && this.rotation !== 0) data.rotation = this.rotation;
        if (this.polygonOffset === true) data.polygonOffset = true;
        if (this.polygonOffsetFactor !== 0) data.polygonOffsetFactor = this.polygonOffsetFactor;
        if (this.polygonOffsetUnits !== 0) data.polygonOffsetUnits = this.polygonOffsetUnits;
        if (this.linewidth !== undefined && this.linewidth !== 1) data.linewidth = this.linewidth;
        if (this.dashSize !== undefined) data.dashSize = this.dashSize;
        if (this.gapSize !== undefined) data.gapSize = this.gapSize;
        if (this.scale !== undefined) data.scale = this.scale;
        if (this.dithering === true) data.dithering = true;
        if (this.alphaTest > 0) data.alphaTest = this.alphaTest;
        if (this.alphaHash === true) data.alphaHash = true;
        if (this.alphaToCoverage === true) data.alphaToCoverage = true;
        if (this.premultipliedAlpha === true) data.premultipliedAlpha = true;
        if (this.forceSinglePass === true) data.forceSinglePass = true;
        if (this.wireframe === true) data.wireframe = true;
        if (this.wireframeLinewidth > 1) data.wireframeLinewidth = this.wireframeLinewidth;
        if (this.wireframeLinecap !== "round") data.wireframeLinecap = this.wireframeLinecap;
        if (this.wireframeLinejoin !== "round") data.wireframeLinejoin = this.wireframeLinejoin;
        if (this.flatShading === true) data.flatShading = true;
        if (this.visible === false) data.visible = false;
        if (this.toneMapped === false) data.toneMapped = false;
        if (this.fog === false) data.fog = false;
        if (Object.keys(this.userData).length > 0) data.userData = this.userData;
        // TODO: Copied from Object3D.toJSON
        function extractFromCache(cache) {
            const values = [];
            for(const key in cache){
                const data = cache[key];
                delete data.metadata;
                values.push(data);
            }
            return values;
        }
        if (isRootObject) {
            const textures = extractFromCache(meta.textures);
            const images = extractFromCache(meta.images);
            if (textures.length > 0) data.textures = textures;
            if (images.length > 0) data.images = images;
        }
        return data;
    }
    clone() {
        return new this.constructor().copy(this);
    }
    copy(source) {
        this.name = source.name;
        this.blending = source.blending;
        this.side = source.side;
        this.vertexColors = source.vertexColors;
        this.opacity = source.opacity;
        this.transparent = source.transparent;
        this.blendSrc = source.blendSrc;
        this.blendDst = source.blendDst;
        this.blendEquation = source.blendEquation;
        this.blendSrcAlpha = source.blendSrcAlpha;
        this.blendDstAlpha = source.blendDstAlpha;
        this.blendEquationAlpha = source.blendEquationAlpha;
        this.blendColor.copy(source.blendColor);
        this.blendAlpha = source.blendAlpha;
        this.depthFunc = source.depthFunc;
        this.depthTest = source.depthTest;
        this.depthWrite = source.depthWrite;
        this.stencilWriteMask = source.stencilWriteMask;
        this.stencilFunc = source.stencilFunc;
        this.stencilRef = source.stencilRef;
        this.stencilFuncMask = source.stencilFuncMask;
        this.stencilFail = source.stencilFail;
        this.stencilZFail = source.stencilZFail;
        this.stencilZPass = source.stencilZPass;
        this.stencilWrite = source.stencilWrite;
        const srcPlanes = source.clippingPlanes;
        let dstPlanes = null;
        if (srcPlanes !== null) {
            const n = srcPlanes.length;
            dstPlanes = new Array(n);
            for(let i = 0; i !== n; ++i)dstPlanes[i] = srcPlanes[i].clone();
        }
        this.clippingPlanes = dstPlanes;
        this.clipIntersection = source.clipIntersection;
        this.clipShadows = source.clipShadows;
        this.shadowSide = source.shadowSide;
        this.colorWrite = source.colorWrite;
        this.precision = source.precision;
        this.polygonOffset = source.polygonOffset;
        this.polygonOffsetFactor = source.polygonOffsetFactor;
        this.polygonOffsetUnits = source.polygonOffsetUnits;
        this.dithering = source.dithering;
        this.alphaTest = source.alphaTest;
        this.alphaHash = source.alphaHash;
        this.alphaToCoverage = source.alphaToCoverage;
        this.premultipliedAlpha = source.premultipliedAlpha;
        this.forceSinglePass = source.forceSinglePass;
        this.visible = source.visible;
        this.toneMapped = source.toneMapped;
        this.userData = JSON.parse(JSON.stringify(source.userData));
        return this;
    }
    dispose() {
        this.dispatchEvent({
            type: "dispose"
        });
    }
    set needsUpdate(value) {
        if (value === true) this.version++;
    }
    onBuild() {
        console.warn("Material: onBuild() has been removed."); // @deprecated, r166
    }
    onBeforeRender() {
        console.warn("Material: onBeforeRender() has been removed."); // @deprecated, r166
    }
}
class MeshBasicMaterial extends Material {
    constructor(parameters){
        super();
        this.isMeshBasicMaterial = true;
        this.type = "MeshBasicMaterial";
        this.color = new Color(0xffffff); // emissive
        this.map = null;
        this.lightMap = null;
        this.lightMapIntensity = 1.0;
        this.aoMap = null;
        this.aoMapIntensity = 1.0;
        this.specularMap = null;
        this.alphaMap = null;
        this.envMap = null;
        this.envMapRotation = new Euler();
        this.combine = MultiplyOperation;
        this.reflectivity = 1;
        this.refractionRatio = 0.98;
        this.wireframe = false;
        this.wireframeLinewidth = 1;
        this.wireframeLinecap = "round";
        this.wireframeLinejoin = "round";
        this.fog = true;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.color.copy(source.color);
        this.map = source.map;
        this.lightMap = source.lightMap;
        this.lightMapIntensity = source.lightMapIntensity;
        this.aoMap = source.aoMap;
        this.aoMapIntensity = source.aoMapIntensity;
        this.specularMap = source.specularMap;
        this.alphaMap = source.alphaMap;
        this.envMap = source.envMap;
        this.envMapRotation.copy(source.envMapRotation);
        this.combine = source.combine;
        this.reflectivity = source.reflectivity;
        this.refractionRatio = source.refractionRatio;
        this.wireframe = source.wireframe;
        this.wireframeLinewidth = source.wireframeLinewidth;
        this.wireframeLinecap = source.wireframeLinecap;
        this.wireframeLinejoin = source.wireframeLinejoin;
        this.fog = source.fog;
        return this;
    }
}
// Fast Half Float Conversions, http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf
const _tables = /*@__PURE__*/ _generateTables();
function _generateTables() {
    // float32 to float16 helpers
    const buffer = new ArrayBuffer(4);
    const floatView = new Float32Array(buffer);
    const uint32View = new Uint32Array(buffer);
    const baseTable = new Uint32Array(512);
    const shiftTable = new Uint32Array(512);
    for(let i = 0; i < 256; ++i){
        const e = i - 127;
        // very small number (0, -0)
        if (e < -27) {
            baseTable[i] = 0x0000;
            baseTable[i | 0x100] = 0x8000;
            shiftTable[i] = 24;
            shiftTable[i | 0x100] = 24;
        // small number (denorm)
        } else if (e < -14) {
            baseTable[i] = 0x0400 >> -e - 14;
            baseTable[i | 0x100] = 0x0400 >> -e - 14 | 0x8000;
            shiftTable[i] = -e - 1;
            shiftTable[i | 0x100] = -e - 1;
        // normal number
        } else if (e <= 15) {
            baseTable[i] = e + 15 << 10;
            baseTable[i | 0x100] = e + 15 << 10 | 0x8000;
            shiftTable[i] = 13;
            shiftTable[i | 0x100] = 13;
        // large number (Infinity, -Infinity)
        } else if (e < 128) {
            baseTable[i] = 0x7c00;
            baseTable[i | 0x100] = 0xfc00;
            shiftTable[i] = 24;
            shiftTable[i | 0x100] = 24;
        // stay (NaN, Infinity, -Infinity)
        } else {
            baseTable[i] = 0x7c00;
            baseTable[i | 0x100] = 0xfc00;
            shiftTable[i] = 13;
            shiftTable[i | 0x100] = 13;
        }
    }
    // float16 to float32 helpers
    const mantissaTable = new Uint32Array(2048);
    const exponentTable = new Uint32Array(64);
    const offsetTable = new Uint32Array(64);
    for(let i = 1; i < 1024; ++i){
        let m = i << 13; // zero pad mantissa bits
        let e = 0; // zero exponent
        // normalized
        while((m & 0x00800000) === 0){
            m <<= 1;
            e -= 0x00800000; // decrement exponent
        }
        m &= -8388609; // clear leading 1 bit
        e += 0x38800000; // adjust bias
        mantissaTable[i] = m | e;
    }
    for(let i = 1024; i < 2048; ++i)mantissaTable[i] = 0x38000000 + (i - 1024 << 13);
    for(let i = 1; i < 31; ++i)exponentTable[i] = i << 23;
    exponentTable[31] = 0x47800000;
    exponentTable[32] = 0x80000000;
    for(let i = 33; i < 63; ++i)exponentTable[i] = 0x80000000 + (i - 32 << 23);
    exponentTable[63] = 0xc7800000;
    for(let i = 1; i < 64; ++i)if (i !== 32) offsetTable[i] = 1024;
    return {
        floatView: floatView,
        uint32View: uint32View,
        baseTable: baseTable,
        shiftTable: shiftTable,
        mantissaTable: mantissaTable,
        exponentTable: exponentTable,
        offsetTable: offsetTable
    };
}
// float32 to float16
function toHalfFloat(val) {
    if (Math.abs(val) > 65504) console.warn("THREE.DataUtils.toHalfFloat(): Value out of range.");
    val = clamp(val, -65504, 65504);
    _tables.floatView[0] = val;
    const f = _tables.uint32View[0];
    const e = f >> 23 & 0x1ff;
    return _tables.baseTable[e] + ((f & 0x007fffff) >> _tables.shiftTable[e]);
}
// float16 to float32
function fromHalfFloat(val) {
    const m = val >> 10;
    _tables.uint32View[0] = _tables.mantissaTable[_tables.offsetTable[m] + (val & 0x3ff)] + _tables.exponentTable[m];
    return _tables.floatView[0];
}
const DataUtils = {
    toHalfFloat: toHalfFloat,
    fromHalfFloat: fromHalfFloat
};
const _vector$9 = /*@__PURE__*/ new Vector3();
const _vector2$1 = /*@__PURE__*/ new Vector2();
class BufferAttribute {
    constructor(array, itemSize, normalized = false){
        if (Array.isArray(array)) throw new TypeError("THREE.BufferAttribute: array should be a Typed Array.");
        this.isBufferAttribute = true;
        this.name = "";
        this.array = array;
        this.itemSize = itemSize;
        this.count = array !== undefined ? array.length / itemSize : 0;
        this.normalized = normalized;
        this.usage = StaticDrawUsage;
        this._updateRange = {
            offset: 0,
            count: -1
        };
        this.updateRanges = [];
        this.gpuType = FloatType;
        this.version = 0;
    }
    onUploadCallback() {}
    set needsUpdate(value) {
        if (value === true) this.version++;
    }
    get updateRange() {
        warnOnce("THREE.BufferAttribute: updateRange() is deprecated and will be removed in r169. Use addUpdateRange() instead."); // @deprecated, r159
        return this._updateRange;
    }
    setUsage(value) {
        this.usage = value;
        return this;
    }
    addUpdateRange(start, count) {
        this.updateRanges.push({
            start,
            count
        });
    }
    clearUpdateRanges() {
        this.updateRanges.length = 0;
    }
    copy(source) {
        this.name = source.name;
        this.array = new source.array.constructor(source.array);
        this.itemSize = source.itemSize;
        this.count = source.count;
        this.normalized = source.normalized;
        this.usage = source.usage;
        this.gpuType = source.gpuType;
        return this;
    }
    copyAt(index1, attribute, index2) {
        index1 *= this.itemSize;
        index2 *= attribute.itemSize;
        for(let i = 0, l = this.itemSize; i < l; i++)this.array[index1 + i] = attribute.array[index2 + i];
        return this;
    }
    copyArray(array) {
        this.array.set(array);
        return this;
    }
    applyMatrix3(m) {
        if (this.itemSize === 2) for(let i = 0, l = this.count; i < l; i++){
            _vector2$1.fromBufferAttribute(this, i);
            _vector2$1.applyMatrix3(m);
            this.setXY(i, _vector2$1.x, _vector2$1.y);
        }
        else if (this.itemSize === 3) for(let i = 0, l = this.count; i < l; i++){
            _vector$9.fromBufferAttribute(this, i);
            _vector$9.applyMatrix3(m);
            this.setXYZ(i, _vector$9.x, _vector$9.y, _vector$9.z);
        }
        return this;
    }
    applyMatrix4(m) {
        for(let i = 0, l = this.count; i < l; i++){
            _vector$9.fromBufferAttribute(this, i);
            _vector$9.applyMatrix4(m);
            this.setXYZ(i, _vector$9.x, _vector$9.y, _vector$9.z);
        }
        return this;
    }
    applyNormalMatrix(m) {
        for(let i = 0, l = this.count; i < l; i++){
            _vector$9.fromBufferAttribute(this, i);
            _vector$9.applyNormalMatrix(m);
            this.setXYZ(i, _vector$9.x, _vector$9.y, _vector$9.z);
        }
        return this;
    }
    transformDirection(m) {
        for(let i = 0, l = this.count; i < l; i++){
            _vector$9.fromBufferAttribute(this, i);
            _vector$9.transformDirection(m);
            this.setXYZ(i, _vector$9.x, _vector$9.y, _vector$9.z);
        }
        return this;
    }
    set(value, offset = 0) {
        // Matching BufferAttribute constructor, do not normalize the array.
        this.array.set(value, offset);
        return this;
    }
    getComponent(index, component) {
        let value = this.array[index * this.itemSize + component];
        if (this.normalized) value = denormalize(value, this.array);
        return value;
    }
    setComponent(index, component, value) {
        if (this.normalized) value = normalize(value, this.array);
        this.array[index * this.itemSize + component] = value;
        return this;
    }
    getX(index) {
        let x = this.array[index * this.itemSize];
        if (this.normalized) x = denormalize(x, this.array);
        return x;
    }
    setX(index, x) {
        if (this.normalized) x = normalize(x, this.array);
        this.array[index * this.itemSize] = x;
        return this;
    }
    getY(index) {
        let y = this.array[index * this.itemSize + 1];
        if (this.normalized) y = denormalize(y, this.array);
        return y;
    }
    setY(index, y) {
        if (this.normalized) y = normalize(y, this.array);
        this.array[index * this.itemSize + 1] = y;
        return this;
    }
    getZ(index) {
        let z = this.array[index * this.itemSize + 2];
        if (this.normalized) z = denormalize(z, this.array);
        return z;
    }
    setZ(index, z) {
        if (this.normalized) z = normalize(z, this.array);
        this.array[index * this.itemSize + 2] = z;
        return this;
    }
    getW(index) {
        let w = this.array[index * this.itemSize + 3];
        if (this.normalized) w = denormalize(w, this.array);
        return w;
    }
    setW(index, w) {
        if (this.normalized) w = normalize(w, this.array);
        this.array[index * this.itemSize + 3] = w;
        return this;
    }
    setXY(index, x, y) {
        index *= this.itemSize;
        if (this.normalized) {
            x = normalize(x, this.array);
            y = normalize(y, this.array);
        }
        this.array[index + 0] = x;
        this.array[index + 1] = y;
        return this;
    }
    setXYZ(index, x, y, z) {
        index *= this.itemSize;
        if (this.normalized) {
            x = normalize(x, this.array);
            y = normalize(y, this.array);
            z = normalize(z, this.array);
        }
        this.array[index + 0] = x;
        this.array[index + 1] = y;
        this.array[index + 2] = z;
        return this;
    }
    setXYZW(index, x, y, z, w) {
        index *= this.itemSize;
        if (this.normalized) {
            x = normalize(x, this.array);
            y = normalize(y, this.array);
            z = normalize(z, this.array);
            w = normalize(w, this.array);
        }
        this.array[index + 0] = x;
        this.array[index + 1] = y;
        this.array[index + 2] = z;
        this.array[index + 3] = w;
        return this;
    }
    onUpload(callback) {
        this.onUploadCallback = callback;
        return this;
    }
    clone() {
        return new this.constructor(this.array, this.itemSize).copy(this);
    }
    toJSON() {
        const data = {
            itemSize: this.itemSize,
            type: this.array.constructor.name,
            array: Array.from(this.array),
            normalized: this.normalized
        };
        if (this.name !== "") data.name = this.name;
        if (this.usage !== StaticDrawUsage) data.usage = this.usage;
        return data;
    }
}
//
class Int8BufferAttribute extends BufferAttribute {
    constructor(array, itemSize, normalized){
        super(new Int8Array(array), itemSize, normalized);
    }
}
class Uint8BufferAttribute extends BufferAttribute {
    constructor(array, itemSize, normalized){
        super(new Uint8Array(array), itemSize, normalized);
    }
}
class Uint8ClampedBufferAttribute extends BufferAttribute {
    constructor(array, itemSize, normalized){
        super(new Uint8ClampedArray(array), itemSize, normalized);
    }
}
class Int16BufferAttribute extends BufferAttribute {
    constructor(array, itemSize, normalized){
        super(new Int16Array(array), itemSize, normalized);
    }
}
class Uint16BufferAttribute extends BufferAttribute {
    constructor(array, itemSize, normalized){
        super(new Uint16Array(array), itemSize, normalized);
    }
}
class Int32BufferAttribute extends BufferAttribute {
    constructor(array, itemSize, normalized){
        super(new Int32Array(array), itemSize, normalized);
    }
}
class Uint32BufferAttribute extends BufferAttribute {
    constructor(array, itemSize, normalized){
        super(new Uint32Array(array), itemSize, normalized);
    }
}
class Float16BufferAttribute extends BufferAttribute {
    constructor(array, itemSize, normalized){
        super(new Uint16Array(array), itemSize, normalized);
        this.isFloat16BufferAttribute = true;
    }
    getX(index) {
        let x = fromHalfFloat(this.array[index * this.itemSize]);
        if (this.normalized) x = denormalize(x, this.array);
        return x;
    }
    setX(index, x) {
        if (this.normalized) x = normalize(x, this.array);
        this.array[index * this.itemSize] = toHalfFloat(x);
        return this;
    }
    getY(index) {
        let y = fromHalfFloat(this.array[index * this.itemSize + 1]);
        if (this.normalized) y = denormalize(y, this.array);
        return y;
    }
    setY(index, y) {
        if (this.normalized) y = normalize(y, this.array);
        this.array[index * this.itemSize + 1] = toHalfFloat(y);
        return this;
    }
    getZ(index) {
        let z = fromHalfFloat(this.array[index * this.itemSize + 2]);
        if (this.normalized) z = denormalize(z, this.array);
        return z;
    }
    setZ(index, z) {
        if (this.normalized) z = normalize(z, this.array);
        this.array[index * this.itemSize + 2] = toHalfFloat(z);
        return this;
    }
    getW(index) {
        let w = fromHalfFloat(this.array[index * this.itemSize + 3]);
        if (this.normalized) w = denormalize(w, this.array);
        return w;
    }
    setW(index, w) {
        if (this.normalized) w = normalize(w, this.array);
        this.array[index * this.itemSize + 3] = toHalfFloat(w);
        return this;
    }
    setXY(index, x, y) {
        index *= this.itemSize;
        if (this.normalized) {
            x = normalize(x, this.array);
            y = normalize(y, this.array);
        }
        this.array[index + 0] = toHalfFloat(x);
        this.array[index + 1] = toHalfFloat(y);
        return this;
    }
    setXYZ(index, x, y, z) {
        index *= this.itemSize;
        if (this.normalized) {
            x = normalize(x, this.array);
            y = normalize(y, this.array);
            z = normalize(z, this.array);
        }
        this.array[index + 0] = toHalfFloat(x);
        this.array[index + 1] = toHalfFloat(y);
        this.array[index + 2] = toHalfFloat(z);
        return this;
    }
    setXYZW(index, x, y, z, w) {
        index *= this.itemSize;
        if (this.normalized) {
            x = normalize(x, this.array);
            y = normalize(y, this.array);
            z = normalize(z, this.array);
            w = normalize(w, this.array);
        }
        this.array[index + 0] = toHalfFloat(x);
        this.array[index + 1] = toHalfFloat(y);
        this.array[index + 2] = toHalfFloat(z);
        this.array[index + 3] = toHalfFloat(w);
        return this;
    }
}
class Float32BufferAttribute extends BufferAttribute {
    constructor(array, itemSize, normalized){
        super(new Float32Array(array), itemSize, normalized);
    }
}
let _id$2 = 0;
const _m1$2 = /*@__PURE__*/ new Matrix4();
const _obj = /*@__PURE__*/ new Object3D();
const _offset = /*@__PURE__*/ new Vector3();
const _box$2 = /*@__PURE__*/ new Box3();
const _boxMorphTargets = /*@__PURE__*/ new Box3();
const _vector$8 = /*@__PURE__*/ new Vector3();
class BufferGeometry extends EventDispatcher {
    constructor(){
        super();
        this.isBufferGeometry = true;
        Object.defineProperty(this, "id", {
            value: _id$2++
        });
        this.uuid = generateUUID();
        this.name = "";
        this.type = "BufferGeometry";
        this.index = null;
        this.attributes = {};
        this.morphAttributes = {};
        this.morphTargetsRelative = false;
        this.groups = [];
        this.boundingBox = null;
        this.boundingSphere = null;
        this.drawRange = {
            start: 0,
            count: Infinity
        };
        this.userData = {};
    }
    getIndex() {
        return this.index;
    }
    setIndex(index) {
        if (Array.isArray(index)) this.index = new (arrayNeedsUint32(index) ? Uint32BufferAttribute : Uint16BufferAttribute)(index, 1);
        else this.index = index;
        return this;
    }
    getAttribute(name) {
        return this.attributes[name];
    }
    setAttribute(name, attribute) {
        this.attributes[name] = attribute;
        return this;
    }
    deleteAttribute(name) {
        delete this.attributes[name];
        return this;
    }
    hasAttribute(name) {
        return this.attributes[name] !== undefined;
    }
    addGroup(start, count, materialIndex = 0) {
        this.groups.push({
            start: start,
            count: count,
            materialIndex: materialIndex
        });
    }
    clearGroups() {
        this.groups = [];
    }
    setDrawRange(start, count) {
        this.drawRange.start = start;
        this.drawRange.count = count;
    }
    applyMatrix4(matrix) {
        const position = this.attributes.position;
        if (position !== undefined) {
            position.applyMatrix4(matrix);
            position.needsUpdate = true;
        }
        const normal = this.attributes.normal;
        if (normal !== undefined) {
            const normalMatrix = new Matrix3().getNormalMatrix(matrix);
            normal.applyNormalMatrix(normalMatrix);
            normal.needsUpdate = true;
        }
        const tangent = this.attributes.tangent;
        if (tangent !== undefined) {
            tangent.transformDirection(matrix);
            tangent.needsUpdate = true;
        }
        if (this.boundingBox !== null) this.computeBoundingBox();
        if (this.boundingSphere !== null) this.computeBoundingSphere();
        return this;
    }
    applyQuaternion(q) {
        _m1$2.makeRotationFromQuaternion(q);
        this.applyMatrix4(_m1$2);
        return this;
    }
    rotateX(angle) {
        // rotate geometry around world x-axis
        _m1$2.makeRotationX(angle);
        this.applyMatrix4(_m1$2);
        return this;
    }
    rotateY(angle) {
        // rotate geometry around world y-axis
        _m1$2.makeRotationY(angle);
        this.applyMatrix4(_m1$2);
        return this;
    }
    rotateZ(angle) {
        // rotate geometry around world z-axis
        _m1$2.makeRotationZ(angle);
        this.applyMatrix4(_m1$2);
        return this;
    }
    translate(x, y, z) {
        // translate geometry
        _m1$2.makeTranslation(x, y, z);
        this.applyMatrix4(_m1$2);
        return this;
    }
    scale(x, y, z) {
        // scale geometry
        _m1$2.makeScale(x, y, z);
        this.applyMatrix4(_m1$2);
        return this;
    }
    lookAt(vector) {
        _obj.lookAt(vector);
        _obj.updateMatrix();
        this.applyMatrix4(_obj.matrix);
        return this;
    }
    center() {
        this.computeBoundingBox();
        this.boundingBox.getCenter(_offset).negate();
        this.translate(_offset.x, _offset.y, _offset.z);
        return this;
    }
    setFromPoints(points) {
        const position = [];
        for(let i = 0, l = points.length; i < l; i++){
            const point = points[i];
            position.push(point.x, point.y, point.z || 0);
        }
        this.setAttribute("position", new Float32BufferAttribute(position, 3));
        return this;
    }
    computeBoundingBox() {
        if (this.boundingBox === null) this.boundingBox = new Box3();
        const position = this.attributes.position;
        const morphAttributesPosition = this.morphAttributes.position;
        if (position && position.isGLBufferAttribute) {
            console.error("THREE.BufferGeometry.computeBoundingBox(): GLBufferAttribute requires a manual bounding box.", this);
            this.boundingBox.set(new Vector3(-Infinity, -Infinity, -Infinity), new Vector3(Infinity, Infinity, Infinity));
            return;
        }
        if (position !== undefined) {
            this.boundingBox.setFromBufferAttribute(position);
            // process morph attributes if present
            if (morphAttributesPosition) for(let i = 0, il = morphAttributesPosition.length; i < il; i++){
                const morphAttribute = morphAttributesPosition[i];
                _box$2.setFromBufferAttribute(morphAttribute);
                if (this.morphTargetsRelative) {
                    _vector$8.addVectors(this.boundingBox.min, _box$2.min);
                    this.boundingBox.expandByPoint(_vector$8);
                    _vector$8.addVectors(this.boundingBox.max, _box$2.max);
                    this.boundingBox.expandByPoint(_vector$8);
                } else {
                    this.boundingBox.expandByPoint(_box$2.min);
                    this.boundingBox.expandByPoint(_box$2.max);
                }
            }
        } else this.boundingBox.makeEmpty();
        if (isNaN(this.boundingBox.min.x) || isNaN(this.boundingBox.min.y) || isNaN(this.boundingBox.min.z)) console.error('THREE.BufferGeometry.computeBoundingBox(): Computed min/max have NaN values. The "position" attribute is likely to have NaN values.', this);
    }
    computeBoundingSphere() {
        if (this.boundingSphere === null) this.boundingSphere = new Sphere();
        const position = this.attributes.position;
        const morphAttributesPosition = this.morphAttributes.position;
        if (position && position.isGLBufferAttribute) {
            console.error("THREE.BufferGeometry.computeBoundingSphere(): GLBufferAttribute requires a manual bounding sphere.", this);
            this.boundingSphere.set(new Vector3(), Infinity);
            return;
        }
        if (position) {
            // first, find the center of the bounding sphere
            const center = this.boundingSphere.center;
            _box$2.setFromBufferAttribute(position);
            // process morph attributes if present
            if (morphAttributesPosition) for(let i = 0, il = morphAttributesPosition.length; i < il; i++){
                const morphAttribute = morphAttributesPosition[i];
                _boxMorphTargets.setFromBufferAttribute(morphAttribute);
                if (this.morphTargetsRelative) {
                    _vector$8.addVectors(_box$2.min, _boxMorphTargets.min);
                    _box$2.expandByPoint(_vector$8);
                    _vector$8.addVectors(_box$2.max, _boxMorphTargets.max);
                    _box$2.expandByPoint(_vector$8);
                } else {
                    _box$2.expandByPoint(_boxMorphTargets.min);
                    _box$2.expandByPoint(_boxMorphTargets.max);
                }
            }
            _box$2.getCenter(center);
            // second, try to find a boundingSphere with a radius smaller than the
            // boundingSphere of the boundingBox: sqrt(3) smaller in the best case
            let maxRadiusSq = 0;
            for(let i = 0, il = position.count; i < il; i++){
                _vector$8.fromBufferAttribute(position, i);
                maxRadiusSq = Math.max(maxRadiusSq, center.distanceToSquared(_vector$8));
            }
            // process morph attributes if present
            if (morphAttributesPosition) for(let i = 0, il = morphAttributesPosition.length; i < il; i++){
                const morphAttribute = morphAttributesPosition[i];
                const morphTargetsRelative = this.morphTargetsRelative;
                for(let j = 0, jl = morphAttribute.count; j < jl; j++){
                    _vector$8.fromBufferAttribute(morphAttribute, j);
                    if (morphTargetsRelative) {
                        _offset.fromBufferAttribute(position, j);
                        _vector$8.add(_offset);
                    }
                    maxRadiusSq = Math.max(maxRadiusSq, center.distanceToSquared(_vector$8));
                }
            }
            this.boundingSphere.radius = Math.sqrt(maxRadiusSq);
            if (isNaN(this.boundingSphere.radius)) console.error('THREE.BufferGeometry.computeBoundingSphere(): Computed radius is NaN. The "position" attribute is likely to have NaN values.', this);
        }
    }
    computeTangents() {
        const index = this.index;
        const attributes = this.attributes;
        // based on http://www.terathon.com/code/tangent.html
        // (per vertex tangents)
        if (index === null || attributes.position === undefined || attributes.normal === undefined || attributes.uv === undefined) {
            console.error("THREE.BufferGeometry: .computeTangents() failed. Missing required attributes (index, position, normal or uv)");
            return;
        }
        const positionAttribute = attributes.position;
        const normalAttribute = attributes.normal;
        const uvAttribute = attributes.uv;
        if (this.hasAttribute("tangent") === false) this.setAttribute("tangent", new BufferAttribute(new Float32Array(4 * positionAttribute.count), 4));
        const tangentAttribute = this.getAttribute("tangent");
        const tan1 = [], tan2 = [];
        for(let i = 0; i < positionAttribute.count; i++){
            tan1[i] = new Vector3();
            tan2[i] = new Vector3();
        }
        const vA = new Vector3(), vB = new Vector3(), vC = new Vector3(), uvA = new Vector2(), uvB = new Vector2(), uvC = new Vector2(), sdir = new Vector3(), tdir = new Vector3();
        function handleTriangle(a, b, c) {
            vA.fromBufferAttribute(positionAttribute, a);
            vB.fromBufferAttribute(positionAttribute, b);
            vC.fromBufferAttribute(positionAttribute, c);
            uvA.fromBufferAttribute(uvAttribute, a);
            uvB.fromBufferAttribute(uvAttribute, b);
            uvC.fromBufferAttribute(uvAttribute, c);
            vB.sub(vA);
            vC.sub(vA);
            uvB.sub(uvA);
            uvC.sub(uvA);
            const r = 1.0 / (uvB.x * uvC.y - uvC.x * uvB.y);
            // silently ignore degenerate uv triangles having coincident or colinear vertices
            if (!isFinite(r)) return;
            sdir.copy(vB).multiplyScalar(uvC.y).addScaledVector(vC, -uvB.y).multiplyScalar(r);
            tdir.copy(vC).multiplyScalar(uvB.x).addScaledVector(vB, -uvC.x).multiplyScalar(r);
            tan1[a].add(sdir);
            tan1[b].add(sdir);
            tan1[c].add(sdir);
            tan2[a].add(tdir);
            tan2[b].add(tdir);
            tan2[c].add(tdir);
        }
        let groups = this.groups;
        if (groups.length === 0) groups = [
            {
                start: 0,
                count: index.count
            }
        ];
        for(let i = 0, il = groups.length; i < il; ++i){
            const group = groups[i];
            const start = group.start;
            const count = group.count;
            for(let j = start, jl = start + count; j < jl; j += 3)handleTriangle(index.getX(j + 0), index.getX(j + 1), index.getX(j + 2));
        }
        const tmp = new Vector3(), tmp2 = new Vector3();
        const n = new Vector3(), n2 = new Vector3();
        function handleVertex(v) {
            n.fromBufferAttribute(normalAttribute, v);
            n2.copy(n);
            const t = tan1[v];
            // Gram-Schmidt orthogonalize
            tmp.copy(t);
            tmp.sub(n.multiplyScalar(n.dot(t))).normalize();
            // Calculate handedness
            tmp2.crossVectors(n2, t);
            const test = tmp2.dot(tan2[v]);
            const w = test < 0.0 ? -1 : 1.0;
            tangentAttribute.setXYZW(v, tmp.x, tmp.y, tmp.z, w);
        }
        for(let i = 0, il = groups.length; i < il; ++i){
            const group = groups[i];
            const start = group.start;
            const count = group.count;
            for(let j = start, jl = start + count; j < jl; j += 3){
                handleVertex(index.getX(j + 0));
                handleVertex(index.getX(j + 1));
                handleVertex(index.getX(j + 2));
            }
        }
    }
    computeVertexNormals() {
        const index = this.index;
        const positionAttribute = this.getAttribute("position");
        if (positionAttribute !== undefined) {
            let normalAttribute = this.getAttribute("normal");
            if (normalAttribute === undefined) {
                normalAttribute = new BufferAttribute(new Float32Array(positionAttribute.count * 3), 3);
                this.setAttribute("normal", normalAttribute);
            } else // reset existing normals to zero
            for(let i = 0, il = normalAttribute.count; i < il; i++)normalAttribute.setXYZ(i, 0, 0, 0);
            const pA = new Vector3(), pB = new Vector3(), pC = new Vector3();
            const nA = new Vector3(), nB = new Vector3(), nC = new Vector3();
            const cb = new Vector3(), ab = new Vector3();
            // indexed elements
            if (index) for(let i = 0, il = index.count; i < il; i += 3){
                const vA = index.getX(i + 0);
                const vB = index.getX(i + 1);
                const vC = index.getX(i + 2);
                pA.fromBufferAttribute(positionAttribute, vA);
                pB.fromBufferAttribute(positionAttribute, vB);
                pC.fromBufferAttribute(positionAttribute, vC);
                cb.subVectors(pC, pB);
                ab.subVectors(pA, pB);
                cb.cross(ab);
                nA.fromBufferAttribute(normalAttribute, vA);
                nB.fromBufferAttribute(normalAttribute, vB);
                nC.fromBufferAttribute(normalAttribute, vC);
                nA.add(cb);
                nB.add(cb);
                nC.add(cb);
                normalAttribute.setXYZ(vA, nA.x, nA.y, nA.z);
                normalAttribute.setXYZ(vB, nB.x, nB.y, nB.z);
                normalAttribute.setXYZ(vC, nC.x, nC.y, nC.z);
            }
            else // non-indexed elements (unconnected triangle soup)
            for(let i = 0, il = positionAttribute.count; i < il; i += 3){
                pA.fromBufferAttribute(positionAttribute, i + 0);
                pB.fromBufferAttribute(positionAttribute, i + 1);
                pC.fromBufferAttribute(positionAttribute, i + 2);
                cb.subVectors(pC, pB);
                ab.subVectors(pA, pB);
                cb.cross(ab);
                normalAttribute.setXYZ(i + 0, cb.x, cb.y, cb.z);
                normalAttribute.setXYZ(i + 1, cb.x, cb.y, cb.z);
                normalAttribute.setXYZ(i + 2, cb.x, cb.y, cb.z);
            }
            this.normalizeNormals();
            normalAttribute.needsUpdate = true;
        }
    }
    normalizeNormals() {
        const normals = this.attributes.normal;
        for(let i = 0, il = normals.count; i < il; i++){
            _vector$8.fromBufferAttribute(normals, i);
            _vector$8.normalize();
            normals.setXYZ(i, _vector$8.x, _vector$8.y, _vector$8.z);
        }
    }
    toNonIndexed() {
        function convertBufferAttribute(attribute, indices) {
            const array = attribute.array;
            const itemSize = attribute.itemSize;
            const normalized = attribute.normalized;
            const array2 = new array.constructor(indices.length * itemSize);
            let index = 0, index2 = 0;
            for(let i = 0, l = indices.length; i < l; i++){
                if (attribute.isInterleavedBufferAttribute) index = indices[i] * attribute.data.stride + attribute.offset;
                else index = indices[i] * itemSize;
                for(let j = 0; j < itemSize; j++)array2[index2++] = array[index++];
            }
            return new BufferAttribute(array2, itemSize, normalized);
        }
        //
        if (this.index === null) {
            console.warn("THREE.BufferGeometry.toNonIndexed(): BufferGeometry is already non-indexed.");
            return this;
        }
        const geometry2 = new BufferGeometry();
        const indices = this.index.array;
        const attributes = this.attributes;
        // attributes
        for(const name in attributes){
            const attribute = attributes[name];
            const newAttribute = convertBufferAttribute(attribute, indices);
            geometry2.setAttribute(name, newAttribute);
        }
        // morph attributes
        const morphAttributes = this.morphAttributes;
        for(const name in morphAttributes){
            const morphArray = [];
            const morphAttribute = morphAttributes[name]; // morphAttribute: array of Float32BufferAttributes
            for(let i = 0, il = morphAttribute.length; i < il; i++){
                const attribute = morphAttribute[i];
                const newAttribute = convertBufferAttribute(attribute, indices);
                morphArray.push(newAttribute);
            }
            geometry2.morphAttributes[name] = morphArray;
        }
        geometry2.morphTargetsRelative = this.morphTargetsRelative;
        // groups
        const groups = this.groups;
        for(let i = 0, l = groups.length; i < l; i++){
            const group = groups[i];
            geometry2.addGroup(group.start, group.count, group.materialIndex);
        }
        return geometry2;
    }
    toJSON() {
        const data = {
            metadata: {
                version: 4.6,
                type: "BufferGeometry",
                generator: "BufferGeometry.toJSON"
            }
        };
        // standard BufferGeometry serialization
        data.uuid = this.uuid;
        data.type = this.type;
        if (this.name !== "") data.name = this.name;
        if (Object.keys(this.userData).length > 0) data.userData = this.userData;
        if (this.parameters !== undefined) {
            const parameters = this.parameters;
            for(const key in parameters)if (parameters[key] !== undefined) data[key] = parameters[key];
            return data;
        }
        // for simplicity the code assumes attributes are not shared across geometries, see #15811
        data.data = {
            attributes: {}
        };
        const index = this.index;
        if (index !== null) data.data.index = {
            type: index.array.constructor.name,
            array: Array.prototype.slice.call(index.array)
        };
        const attributes = this.attributes;
        for(const key in attributes){
            const attribute = attributes[key];
            data.data.attributes[key] = attribute.toJSON(data.data);
        }
        const morphAttributes = {};
        let hasMorphAttributes = false;
        for(const key in this.morphAttributes){
            const attributeArray = this.morphAttributes[key];
            const array = [];
            for(let i = 0, il = attributeArray.length; i < il; i++){
                const attribute = attributeArray[i];
                array.push(attribute.toJSON(data.data));
            }
            if (array.length > 0) {
                morphAttributes[key] = array;
                hasMorphAttributes = true;
            }
        }
        if (hasMorphAttributes) {
            data.data.morphAttributes = morphAttributes;
            data.data.morphTargetsRelative = this.morphTargetsRelative;
        }
        const groups = this.groups;
        if (groups.length > 0) data.data.groups = JSON.parse(JSON.stringify(groups));
        const boundingSphere = this.boundingSphere;
        if (boundingSphere !== null) data.data.boundingSphere = {
            center: boundingSphere.center.toArray(),
            radius: boundingSphere.radius
        };
        return data;
    }
    clone() {
        return new this.constructor().copy(this);
    }
    copy(source) {
        // reset
        this.index = null;
        this.attributes = {};
        this.morphAttributes = {};
        this.groups = [];
        this.boundingBox = null;
        this.boundingSphere = null;
        // used for storing cloned, shared data
        const data = {};
        // name
        this.name = source.name;
        // index
        const index = source.index;
        if (index !== null) this.setIndex(index.clone(data));
        // attributes
        const attributes = source.attributes;
        for(const name in attributes){
            const attribute = attributes[name];
            this.setAttribute(name, attribute.clone(data));
        }
        // morph attributes
        const morphAttributes = source.morphAttributes;
        for(const name in morphAttributes){
            const array = [];
            const morphAttribute = morphAttributes[name]; // morphAttribute: array of Float32BufferAttributes
            for(let i = 0, l = morphAttribute.length; i < l; i++)array.push(morphAttribute[i].clone(data));
            this.morphAttributes[name] = array;
        }
        this.morphTargetsRelative = source.morphTargetsRelative;
        // groups
        const groups = source.groups;
        for(let i = 0, l = groups.length; i < l; i++){
            const group = groups[i];
            this.addGroup(group.start, group.count, group.materialIndex);
        }
        // bounding box
        const boundingBox = source.boundingBox;
        if (boundingBox !== null) this.boundingBox = boundingBox.clone();
        // bounding sphere
        const boundingSphere = source.boundingSphere;
        if (boundingSphere !== null) this.boundingSphere = boundingSphere.clone();
        // draw range
        this.drawRange.start = source.drawRange.start;
        this.drawRange.count = source.drawRange.count;
        // user data
        this.userData = source.userData;
        return this;
    }
    dispose() {
        this.dispatchEvent({
            type: "dispose"
        });
    }
}
const _inverseMatrix$3 = /*@__PURE__*/ new Matrix4();
const _ray$3 = /*@__PURE__*/ new Ray();
const _sphere$6 = /*@__PURE__*/ new Sphere();
const _sphereHitAt = /*@__PURE__*/ new Vector3();
const _vA$1 = /*@__PURE__*/ new Vector3();
const _vB$1 = /*@__PURE__*/ new Vector3();
const _vC$1 = /*@__PURE__*/ new Vector3();
const _tempA = /*@__PURE__*/ new Vector3();
const _morphA = /*@__PURE__*/ new Vector3();
const _uvA$1 = /*@__PURE__*/ new Vector2();
const _uvB$1 = /*@__PURE__*/ new Vector2();
const _uvC$1 = /*@__PURE__*/ new Vector2();
const _normalA = /*@__PURE__*/ new Vector3();
const _normalB = /*@__PURE__*/ new Vector3();
const _normalC = /*@__PURE__*/ new Vector3();
const _intersectionPoint = /*@__PURE__*/ new Vector3();
const _intersectionPointWorld = /*@__PURE__*/ new Vector3();
class Mesh extends Object3D {
    constructor(geometry = new BufferGeometry(), material = new MeshBasicMaterial()){
        super();
        this.isMesh = true;
        this.type = "Mesh";
        this.geometry = geometry;
        this.material = material;
        this.updateMorphTargets();
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        if (source.morphTargetInfluences !== undefined) this.morphTargetInfluences = source.morphTargetInfluences.slice();
        if (source.morphTargetDictionary !== undefined) this.morphTargetDictionary = Object.assign({}, source.morphTargetDictionary);
        this.material = Array.isArray(source.material) ? source.material.slice() : source.material;
        this.geometry = source.geometry;
        return this;
    }
    updateMorphTargets() {
        const geometry = this.geometry;
        const morphAttributes = geometry.morphAttributes;
        const keys = Object.keys(morphAttributes);
        if (keys.length > 0) {
            const morphAttribute = morphAttributes[keys[0]];
            if (morphAttribute !== undefined) {
                this.morphTargetInfluences = [];
                this.morphTargetDictionary = {};
                for(let m = 0, ml = morphAttribute.length; m < ml; m++){
                    const name = morphAttribute[m].name || String(m);
                    this.morphTargetInfluences.push(0);
                    this.morphTargetDictionary[name] = m;
                }
            }
        }
    }
    getVertexPosition(index, target) {
        const geometry = this.geometry;
        const position = geometry.attributes.position;
        const morphPosition = geometry.morphAttributes.position;
        const morphTargetsRelative = geometry.morphTargetsRelative;
        target.fromBufferAttribute(position, index);
        const morphInfluences = this.morphTargetInfluences;
        if (morphPosition && morphInfluences) {
            _morphA.set(0, 0, 0);
            for(let i = 0, il = morphPosition.length; i < il; i++){
                const influence = morphInfluences[i];
                const morphAttribute = morphPosition[i];
                if (influence === 0) continue;
                _tempA.fromBufferAttribute(morphAttribute, index);
                if (morphTargetsRelative) _morphA.addScaledVector(_tempA, influence);
                else _morphA.addScaledVector(_tempA.sub(target), influence);
            }
            target.add(_morphA);
        }
        return target;
    }
    raycast(raycaster, intersects) {
        const geometry = this.geometry;
        const material = this.material;
        const matrixWorld = this.matrixWorld;
        if (material === undefined) return;
        // test with bounding sphere in world space
        if (geometry.boundingSphere === null) geometry.computeBoundingSphere();
        _sphere$6.copy(geometry.boundingSphere);
        _sphere$6.applyMatrix4(matrixWorld);
        // check distance from ray origin to bounding sphere
        _ray$3.copy(raycaster.ray).recast(raycaster.near);
        if (_sphere$6.containsPoint(_ray$3.origin) === false) {
            if (_ray$3.intersectSphere(_sphere$6, _sphereHitAt) === null) return;
            if (_ray$3.origin.distanceToSquared(_sphereHitAt) > (raycaster.far - raycaster.near) ** 2) return;
        }
        // convert ray to local space of mesh
        _inverseMatrix$3.copy(matrixWorld).invert();
        _ray$3.copy(raycaster.ray).applyMatrix4(_inverseMatrix$3);
        // test with bounding box in local space
        if (geometry.boundingBox !== null) {
            if (_ray$3.intersectsBox(geometry.boundingBox) === false) return;
        }
        // test for intersections with geometry
        this._computeIntersections(raycaster, intersects, _ray$3);
    }
    _computeIntersections(raycaster, intersects, rayLocalSpace) {
        let intersection;
        const geometry = this.geometry;
        const material = this.material;
        const index = geometry.index;
        const position = geometry.attributes.position;
        const uv = geometry.attributes.uv;
        const uv1 = geometry.attributes.uv1;
        const normal = geometry.attributes.normal;
        const groups = geometry.groups;
        const drawRange = geometry.drawRange;
        if (index !== null) {
            // indexed buffer geometry
            if (Array.isArray(material)) for(let i = 0, il = groups.length; i < il; i++){
                const group = groups[i];
                const groupMaterial = material[group.materialIndex];
                const start = Math.max(group.start, drawRange.start);
                const end = Math.min(index.count, Math.min(group.start + group.count, drawRange.start + drawRange.count));
                for(let j = start, jl = end; j < jl; j += 3){
                    const a = index.getX(j);
                    const b = index.getX(j + 1);
                    const c = index.getX(j + 2);
                    intersection = checkGeometryIntersection(this, groupMaterial, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c);
                    if (intersection) {
                        intersection.faceIndex = Math.floor(j / 3); // triangle number in indexed buffer semantics
                        intersection.face.materialIndex = group.materialIndex;
                        intersects.push(intersection);
                    }
                }
            }
            else {
                const start = Math.max(0, drawRange.start);
                const end = Math.min(index.count, drawRange.start + drawRange.count);
                for(let i = start, il = end; i < il; i += 3){
                    const a = index.getX(i);
                    const b = index.getX(i + 1);
                    const c = index.getX(i + 2);
                    intersection = checkGeometryIntersection(this, material, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c);
                    if (intersection) {
                        intersection.faceIndex = Math.floor(i / 3); // triangle number in indexed buffer semantics
                        intersects.push(intersection);
                    }
                }
            }
        } else if (position !== undefined) {
            // non-indexed buffer geometry
            if (Array.isArray(material)) for(let i = 0, il = groups.length; i < il; i++){
                const group = groups[i];
                const groupMaterial = material[group.materialIndex];
                const start = Math.max(group.start, drawRange.start);
                const end = Math.min(position.count, Math.min(group.start + group.count, drawRange.start + drawRange.count));
                for(let j = start, jl = end; j < jl; j += 3){
                    const a = j;
                    const b = j + 1;
                    const c = j + 2;
                    intersection = checkGeometryIntersection(this, groupMaterial, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c);
                    if (intersection) {
                        intersection.faceIndex = Math.floor(j / 3); // triangle number in non-indexed buffer semantics
                        intersection.face.materialIndex = group.materialIndex;
                        intersects.push(intersection);
                    }
                }
            }
            else {
                const start = Math.max(0, drawRange.start);
                const end = Math.min(position.count, drawRange.start + drawRange.count);
                for(let i = start, il = end; i < il; i += 3){
                    const a = i;
                    const b = i + 1;
                    const c = i + 2;
                    intersection = checkGeometryIntersection(this, material, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c);
                    if (intersection) {
                        intersection.faceIndex = Math.floor(i / 3); // triangle number in non-indexed buffer semantics
                        intersects.push(intersection);
                    }
                }
            }
        }
    }
}
function checkIntersection$1(object, material, raycaster, ray, pA, pB, pC, point) {
    let intersect;
    if (material.side === BackSide) intersect = ray.intersectTriangle(pC, pB, pA, true, point);
    else intersect = ray.intersectTriangle(pA, pB, pC, material.side === FrontSide, point);
    if (intersect === null) return null;
    _intersectionPointWorld.copy(point);
    _intersectionPointWorld.applyMatrix4(object.matrixWorld);
    const distance = raycaster.ray.origin.distanceTo(_intersectionPointWorld);
    if (distance < raycaster.near || distance > raycaster.far) return null;
    return {
        distance: distance,
        point: _intersectionPointWorld.clone(),
        object: object
    };
}
function checkGeometryIntersection(object, material, raycaster, ray, uv, uv1, normal, a, b, c) {
    object.getVertexPosition(a, _vA$1);
    object.getVertexPosition(b, _vB$1);
    object.getVertexPosition(c, _vC$1);
    const intersection = checkIntersection$1(object, material, raycaster, ray, _vA$1, _vB$1, _vC$1, _intersectionPoint);
    if (intersection) {
        if (uv) {
            _uvA$1.fromBufferAttribute(uv, a);
            _uvB$1.fromBufferAttribute(uv, b);
            _uvC$1.fromBufferAttribute(uv, c);
            intersection.uv = Triangle.getInterpolation(_intersectionPoint, _vA$1, _vB$1, _vC$1, _uvA$1, _uvB$1, _uvC$1, new Vector2());
        }
        if (uv1) {
            _uvA$1.fromBufferAttribute(uv1, a);
            _uvB$1.fromBufferAttribute(uv1, b);
            _uvC$1.fromBufferAttribute(uv1, c);
            intersection.uv1 = Triangle.getInterpolation(_intersectionPoint, _vA$1, _vB$1, _vC$1, _uvA$1, _uvB$1, _uvC$1, new Vector2());
        }
        if (normal) {
            _normalA.fromBufferAttribute(normal, a);
            _normalB.fromBufferAttribute(normal, b);
            _normalC.fromBufferAttribute(normal, c);
            intersection.normal = Triangle.getInterpolation(_intersectionPoint, _vA$1, _vB$1, _vC$1, _normalA, _normalB, _normalC, new Vector3());
            if (intersection.normal.dot(ray.direction) > 0) intersection.normal.multiplyScalar(-1);
        }
        const face = {
            a: a,
            b: b,
            c: c,
            normal: new Vector3(),
            materialIndex: 0
        };
        Triangle.getNormal(_vA$1, _vB$1, _vC$1, face.normal);
        intersection.face = face;
    }
    return intersection;
}
class BoxGeometry extends BufferGeometry {
    constructor(width = 1, height = 1, depth = 1, widthSegments = 1, heightSegments = 1, depthSegments = 1){
        super();
        this.type = "BoxGeometry";
        this.parameters = {
            width: width,
            height: height,
            depth: depth,
            widthSegments: widthSegments,
            heightSegments: heightSegments,
            depthSegments: depthSegments
        };
        const scope = this;
        // segments
        widthSegments = Math.floor(widthSegments);
        heightSegments = Math.floor(heightSegments);
        depthSegments = Math.floor(depthSegments);
        // buffers
        const indices = [];
        const vertices = [];
        const normals = [];
        const uvs = [];
        // helper variables
        let numberOfVertices = 0;
        let groupStart = 0;
        // build each side of the box geometry
        buildPlane("z", "y", "x", -1, -1, depth, height, width, depthSegments, heightSegments, 0); // px
        buildPlane("z", "y", "x", 1, -1, depth, height, -width, depthSegments, heightSegments, 1); // nx
        buildPlane("x", "z", "y", 1, 1, width, depth, height, widthSegments, depthSegments, 2); // py
        buildPlane("x", "z", "y", 1, -1, width, depth, -height, widthSegments, depthSegments, 3); // ny
        buildPlane("x", "y", "z", 1, -1, width, height, depth, widthSegments, heightSegments, 4); // pz
        buildPlane("x", "y", "z", -1, -1, width, height, -depth, widthSegments, heightSegments, 5); // nz
        // build geometry
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
        function buildPlane(u, v, w, udir, vdir, width, height, depth, gridX, gridY, materialIndex) {
            const segmentWidth = width / gridX;
            const segmentHeight = height / gridY;
            const widthHalf = width / 2;
            const heightHalf = height / 2;
            const depthHalf = depth / 2;
            const gridX1 = gridX + 1;
            const gridY1 = gridY + 1;
            let vertexCounter = 0;
            let groupCount = 0;
            const vector = new Vector3();
            // generate vertices, normals and uvs
            for(let iy = 0; iy < gridY1; iy++){
                const y = iy * segmentHeight - heightHalf;
                for(let ix = 0; ix < gridX1; ix++){
                    const x = ix * segmentWidth - widthHalf;
                    // set values to correct vector component
                    vector[u] = x * udir;
                    vector[v] = y * vdir;
                    vector[w] = depthHalf;
                    // now apply vector to vertex buffer
                    vertices.push(vector.x, vector.y, vector.z);
                    // set values to correct vector component
                    vector[u] = 0;
                    vector[v] = 0;
                    vector[w] = depth > 0 ? 1 : -1;
                    // now apply vector to normal buffer
                    normals.push(vector.x, vector.y, vector.z);
                    // uvs
                    uvs.push(ix / gridX);
                    uvs.push(1 - iy / gridY);
                    // counters
                    vertexCounter += 1;
                }
            }
            // indices
            // 1. you need three indices to draw a single face
            // 2. a single segment consists of two faces
            // 3. so we need to generate six (2*3) indices per segment
            for(let iy = 0; iy < gridY; iy++)for(let ix = 0; ix < gridX; ix++){
                const a = numberOfVertices + ix + gridX1 * iy;
                const b = numberOfVertices + ix + gridX1 * (iy + 1);
                const c = numberOfVertices + (ix + 1) + gridX1 * (iy + 1);
                const d = numberOfVertices + (ix + 1) + gridX1 * iy;
                // faces
                indices.push(a, b, d);
                indices.push(b, c, d);
                // increase counter
                groupCount += 6;
            }
            // add a group to the geometry. this will ensure multi material support
            scope.addGroup(groupStart, groupCount, materialIndex);
            // calculate new start value for groups
            groupStart += groupCount;
            // update total number of vertices
            numberOfVertices += vertexCounter;
        }
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    static fromJSON(data) {
        return new BoxGeometry(data.width, data.height, data.depth, data.widthSegments, data.heightSegments, data.depthSegments);
    }
}
/**
 * Uniform Utilities
 */ function cloneUniforms(src) {
    const dst = {};
    for(const u in src){
        dst[u] = {};
        for(const p in src[u]){
            const property = src[u][p];
            if (property && (property.isColor || property.isMatrix3 || property.isMatrix4 || property.isVector2 || property.isVector3 || property.isVector4 || property.isTexture || property.isQuaternion)) {
                if (property.isRenderTargetTexture) {
                    console.warn("UniformsUtils: Textures of render targets cannot be cloned via cloneUniforms() or mergeUniforms().");
                    dst[u][p] = null;
                } else dst[u][p] = property.clone();
            } else if (Array.isArray(property)) dst[u][p] = property.slice();
            else dst[u][p] = property;
        }
    }
    return dst;
}
function mergeUniforms(uniforms) {
    const merged = {};
    for(let u = 0; u < uniforms.length; u++){
        const tmp = cloneUniforms(uniforms[u]);
        for(const p in tmp)merged[p] = tmp[p];
    }
    return merged;
}
function cloneUniformsGroups(src) {
    const dst = [];
    for(let u = 0; u < src.length; u++)dst.push(src[u].clone());
    return dst;
}
function getUnlitUniformColorSpace(renderer) {
    const currentRenderTarget = renderer.getRenderTarget();
    if (currentRenderTarget === null) // https://github.com/mrdoob/three.js/pull/23937#issuecomment-1111067398
    return renderer.outputColorSpace;
    // https://github.com/mrdoob/three.js/issues/27868
    if (currentRenderTarget.isXRRenderTarget === true) return currentRenderTarget.texture.colorSpace;
    return ColorManagement.workingColorSpace;
}
// Legacy
const UniformsUtils = {
    clone: cloneUniforms,
    merge: mergeUniforms
};
var default_vertex = "void main() {\n	gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n}";
var default_fragment = "void main() {\n	gl_FragColor = vec4( 1.0, 0.0, 0.0, 1.0 );\n}";
class ShaderMaterial extends Material {
    constructor(parameters){
        super();
        this.isShaderMaterial = true;
        this.type = "ShaderMaterial";
        this.defines = {};
        this.uniforms = {};
        this.uniformsGroups = [];
        this.vertexShader = default_vertex;
        this.fragmentShader = default_fragment;
        this.linewidth = 1;
        this.wireframe = false;
        this.wireframeLinewidth = 1;
        this.fog = false; // set to use scene fog
        this.lights = false; // set to use scene lights
        this.clipping = false; // set to use user-defined clipping planes
        this.forceSinglePass = true;
        this.extensions = {
            clipCullDistance: false,
            multiDraw: false // set to use vertex shader multi_draw / enable gl_DrawID
        };
        // When rendered geometry doesn't include these attributes but the material does,
        // use these default values in WebGL. This avoids errors when buffer data is missing.
        this.defaultAttributeValues = {
            "color": [
                1,
                1,
                1
            ],
            "uv": [
                0,
                0
            ],
            "uv1": [
                0,
                0
            ]
        };
        this.index0AttributeName = undefined;
        this.uniformsNeedUpdate = false;
        this.glslVersion = null;
        if (parameters !== undefined) this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.fragmentShader = source.fragmentShader;
        this.vertexShader = source.vertexShader;
        this.uniforms = cloneUniforms(source.uniforms);
        this.uniformsGroups = cloneUniformsGroups(source.uniformsGroups);
        this.defines = Object.assign({}, source.defines);
        this.wireframe = source.wireframe;
        this.wireframeLinewidth = source.wireframeLinewidth;
        this.fog = source.fog;
        this.lights = source.lights;
        this.clipping = source.clipping;
        this.extensions = Object.assign({}, source.extensions);
        this.glslVersion = source.glslVersion;
        return this;
    }
    toJSON(meta) {
        const data = super.toJSON(meta);
        data.glslVersion = this.glslVersion;
        data.uniforms = {};
        for(const name in this.uniforms){
            const uniform = this.uniforms[name];
            const value = uniform.value;
            if (value && value.isTexture) data.uniforms[name] = {
                type: "t",
                value: value.toJSON(meta).uuid
            };
            else if (value && value.isColor) data.uniforms[name] = {
                type: "c",
                value: value.getHex()
            };
            else if (value && value.isVector2) data.uniforms[name] = {
                type: "v2",
                value: value.toArray()
            };
            else if (value && value.isVector3) data.uniforms[name] = {
                type: "v3",
                value: value.toArray()
            };
            else if (value && value.isVector4) data.uniforms[name] = {
                type: "v4",
                value: value.toArray()
            };
            else if (value && value.isMatrix3) data.uniforms[name] = {
                type: "m3",
                value: value.toArray()
            };
            else if (value && value.isMatrix4) data.uniforms[name] = {
                type: "m4",
                value: value.toArray()
            };
            else data.uniforms[name] = {
                value: value
            };
        }
        if (Object.keys(this.defines).length > 0) data.defines = this.defines;
        data.vertexShader = this.vertexShader;
        data.fragmentShader = this.fragmentShader;
        data.lights = this.lights;
        data.clipping = this.clipping;
        const extensions = {};
        for(const key in this.extensions)if (this.extensions[key] === true) extensions[key] = true;
        if (Object.keys(extensions).length > 0) data.extensions = extensions;
        return data;
    }
}
class Camera extends Object3D {
    constructor(){
        super();
        this.isCamera = true;
        this.type = "Camera";
        this.matrixWorldInverse = new Matrix4();
        this.projectionMatrix = new Matrix4();
        this.projectionMatrixInverse = new Matrix4();
        this.coordinateSystem = WebGLCoordinateSystem;
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.matrixWorldInverse.copy(source.matrixWorldInverse);
        this.projectionMatrix.copy(source.projectionMatrix);
        this.projectionMatrixInverse.copy(source.projectionMatrixInverse);
        this.coordinateSystem = source.coordinateSystem;
        return this;
    }
    getWorldDirection(target) {
        return super.getWorldDirection(target).negate();
    }
    updateMatrixWorld(force) {
        super.updateMatrixWorld(force);
        this.matrixWorldInverse.copy(this.matrixWorld).invert();
    }
    updateWorldMatrix(updateParents, updateChildren) {
        super.updateWorldMatrix(updateParents, updateChildren);
        this.matrixWorldInverse.copy(this.matrixWorld).invert();
    }
    clone() {
        return new this.constructor().copy(this);
    }
}
const _v3$1 = /*@__PURE__*/ new Vector3();
const _minTarget = /*@__PURE__*/ new Vector2();
const _maxTarget = /*@__PURE__*/ new Vector2();
class PerspectiveCamera extends Camera {
    constructor(fov = 50, aspect = 1, near = 0.1, far = 2000){
        super();
        this.isPerspectiveCamera = true;
        this.type = "PerspectiveCamera";
        this.fov = fov;
        this.zoom = 1;
        this.near = near;
        this.far = far;
        this.focus = 10;
        this.aspect = aspect;
        this.view = null;
        this.filmGauge = 35; // width of the film (default in millimeters)
        this.filmOffset = 0; // horizontal film offset (same unit as gauge)
        this.updateProjectionMatrix();
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.fov = source.fov;
        this.zoom = source.zoom;
        this.near = source.near;
        this.far = source.far;
        this.focus = source.focus;
        this.aspect = source.aspect;
        this.view = source.view === null ? null : Object.assign({}, source.view);
        this.filmGauge = source.filmGauge;
        this.filmOffset = source.filmOffset;
        return this;
    }
    /**
	 * Sets the FOV by focal length in respect to the current .filmGauge.
	 *
	 * The default film gauge is 35, so that the focal length can be specified for
	 * a 35mm (full frame) camera.
	 *
	 * Values for focal length and film gauge must have the same unit.
	 */ setFocalLength(focalLength) {
        /** see {@link http://www.bobatkins.com/photography/technical/field_of_view.html} */ const vExtentSlope = 0.5 * this.getFilmHeight() / focalLength;
        this.fov = RAD2DEG * 2 * Math.atan(vExtentSlope);
        this.updateProjectionMatrix();
    }
    /**
	 * Calculates the focal length from the current .fov and .filmGauge.
	 */ getFocalLength() {
        const vExtentSlope = Math.tan(DEG2RAD * 0.5 * this.fov);
        return 0.5 * this.getFilmHeight() / vExtentSlope;
    }
    getEffectiveFOV() {
        return RAD2DEG * 2 * Math.atan(Math.tan(DEG2RAD * 0.5 * this.fov) / this.zoom);
    }
    getFilmWidth() {
        // film not completely covered in portrait format (aspect < 1)
        return this.filmGauge * Math.min(this.aspect, 1);
    }
    getFilmHeight() {
        // film not completely covered in landscape format (aspect > 1)
        return this.filmGauge / Math.max(this.aspect, 1);
    }
    /**
	 * Computes the 2D bounds of the camera's viewable rectangle at a given distance along the viewing direction.
	 * Sets minTarget and maxTarget to the coordinates of the lower-left and upper-right corners of the view rectangle.
	 */ getViewBounds(distance, minTarget, maxTarget) {
        _v3$1.set(-1, -1, 0.5).applyMatrix4(this.projectionMatrixInverse);
        minTarget.set(_v3$1.x, _v3$1.y).multiplyScalar(-distance / _v3$1.z);
        _v3$1.set(1, 1, 0.5).applyMatrix4(this.projectionMatrixInverse);
        maxTarget.set(_v3$1.x, _v3$1.y).multiplyScalar(-distance / _v3$1.z);
    }
    /**
	 * Computes the width and height of the camera's viewable rectangle at a given distance along the viewing direction.
	 * Copies the result into the target Vector2, where x is width and y is height.
	 */ getViewSize(distance, target) {
        this.getViewBounds(distance, _minTarget, _maxTarget);
        return target.subVectors(_maxTarget, _minTarget);
    }
    /**
	 * Sets an offset in a larger frustum. This is useful for multi-window or
	 * multi-monitor/multi-machine setups.
	 *
	 * For example, if you have 3x2 monitors and each monitor is 1920x1080 and
	 * the monitors are in grid like this
	 *
	 *   +---+---+---+
	 *   | A | B | C |
	 *   +---+---+---+
	 *   | D | E | F |
	 *   +---+---+---+
	 *
	 * then for each monitor you would call it like this
	 *
	 *   const w = 1920;
	 *   const h = 1080;
	 *   const fullWidth = w * 3;
	 *   const fullHeight = h * 2;
	 *
	 *   --A--
	 *   camera.setViewOffset( fullWidth, fullHeight, w * 0, h * 0, w, h );
	 *   --B--
	 *   camera.setViewOffset( fullWidth, fullHeight, w * 1, h * 0, w, h );
	 *   --C--
	 *   camera.setViewOffset( fullWidth, fullHeight, w * 2, h * 0, w, h );
	 *   --D--
	 *   camera.setViewOffset( fullWidth, fullHeight, w * 0, h * 1, w, h );
	 *   --E--
	 *   camera.setViewOffset( fullWidth, fullHeight, w * 1, h * 1, w, h );
	 *   --F--
	 *   camera.setViewOffset( fullWidth, fullHeight, w * 2, h * 1, w, h );
	 *
	 *   Note there is no reason monitors have to be the same size or in a grid.
	 */ setViewOffset(fullWidth, fullHeight, x, y, width, height) {
        this.aspect = fullWidth / fullHeight;
        if (this.view === null) this.view = {
            enabled: true,
            fullWidth: 1,
            fullHeight: 1,
            offsetX: 0,
            offsetY: 0,
            width: 1,
            height: 1
        };
        this.view.enabled = true;
        this.view.fullWidth = fullWidth;
        this.view.fullHeight = fullHeight;
        this.view.offsetX = x;
        this.view.offsetY = y;
        this.view.width = width;
        this.view.height = height;
        this.updateProjectionMatrix();
    }
    clearViewOffset() {
        if (this.view !== null) this.view.enabled = false;
        this.updateProjectionMatrix();
    }
    updateProjectionMatrix() {
        const near = this.near;
        let top = near * Math.tan(DEG2RAD * 0.5 * this.fov) / this.zoom;
        let height = 2 * top;
        let width = this.aspect * height;
        let left = -0.5 * width;
        const view = this.view;
        if (this.view !== null && this.view.enabled) {
            const fullWidth = view.fullWidth, fullHeight = view.fullHeight;
            left += view.offsetX * width / fullWidth;
            top -= view.offsetY * height / fullHeight;
            width *= view.width / fullWidth;
            height *= view.height / fullHeight;
        }
        const skew = this.filmOffset;
        if (skew !== 0) left += near * skew / this.getFilmWidth();
        this.projectionMatrix.makePerspective(left, left + width, top, top - height, near, this.far, this.coordinateSystem);
        this.projectionMatrixInverse.copy(this.projectionMatrix).invert();
    }
    toJSON(meta) {
        const data = super.toJSON(meta);
        data.object.fov = this.fov;
        data.object.zoom = this.zoom;
        data.object.near = this.near;
        data.object.far = this.far;
        data.object.focus = this.focus;
        data.object.aspect = this.aspect;
        if (this.view !== null) data.object.view = Object.assign({}, this.view);
        data.object.filmGauge = this.filmGauge;
        data.object.filmOffset = this.filmOffset;
        return data;
    }
}
const fov = -90; // negative fov is not an error
const aspect = 1;
class CubeCamera extends Object3D {
    constructor(near, far, renderTarget){
        super();
        this.type = "CubeCamera";
        this.renderTarget = renderTarget;
        this.coordinateSystem = null;
        this.activeMipmapLevel = 0;
        const cameraPX = new PerspectiveCamera(fov, aspect, near, far);
        cameraPX.layers = this.layers;
        this.add(cameraPX);
        const cameraNX = new PerspectiveCamera(fov, aspect, near, far);
        cameraNX.layers = this.layers;
        this.add(cameraNX);
        const cameraPY = new PerspectiveCamera(fov, aspect, near, far);
        cameraPY.layers = this.layers;
        this.add(cameraPY);
        const cameraNY = new PerspectiveCamera(fov, aspect, near, far);
        cameraNY.layers = this.layers;
        this.add(cameraNY);
        const cameraPZ = new PerspectiveCamera(fov, aspect, near, far);
        cameraPZ.layers = this.layers;
        this.add(cameraPZ);
        const cameraNZ = new PerspectiveCamera(fov, aspect, near, far);
        cameraNZ.layers = this.layers;
        this.add(cameraNZ);
    }
    updateCoordinateSystem() {
        const coordinateSystem = this.coordinateSystem;
        const cameras = this.children.concat();
        const [cameraPX, cameraNX, cameraPY, cameraNY, cameraPZ, cameraNZ] = cameras;
        for (const camera of cameras)this.remove(camera);
        if (coordinateSystem === WebGLCoordinateSystem) {
            cameraPX.up.set(0, 1, 0);
            cameraPX.lookAt(1, 0, 0);
            cameraNX.up.set(0, 1, 0);
            cameraNX.lookAt(-1, 0, 0);
            cameraPY.up.set(0, 0, -1);
            cameraPY.lookAt(0, 1, 0);
            cameraNY.up.set(0, 0, 1);
            cameraNY.lookAt(0, -1, 0);
            cameraPZ.up.set(0, 1, 0);
            cameraPZ.lookAt(0, 0, 1);
            cameraNZ.up.set(0, 1, 0);
            cameraNZ.lookAt(0, 0, -1);
        } else if (coordinateSystem === WebGPUCoordinateSystem) {
            cameraPX.up.set(0, -1, 0);
            cameraPX.lookAt(-1, 0, 0);
            cameraNX.up.set(0, -1, 0);
            cameraNX.lookAt(1, 0, 0);
            cameraPY.up.set(0, 0, 1);
            cameraPY.lookAt(0, 1, 0);
            cameraNY.up.set(0, 0, -1);
            cameraNY.lookAt(0, -1, 0);
            cameraPZ.up.set(0, -1, 0);
            cameraPZ.lookAt(0, 0, 1);
            cameraNZ.up.set(0, -1, 0);
            cameraNZ.lookAt(0, 0, -1);
        } else throw new Error("THREE.CubeCamera.updateCoordinateSystem(): Invalid coordinate system: " + coordinateSystem);
        for (const camera of cameras){
            this.add(camera);
            camera.updateMatrixWorld();
        }
    }
    update(renderer, scene) {
        if (this.parent === null) this.updateMatrixWorld();
        const { renderTarget, activeMipmapLevel } = this;
        if (this.coordinateSystem !== renderer.coordinateSystem) {
            this.coordinateSystem = renderer.coordinateSystem;
            this.updateCoordinateSystem();
        }
        const [cameraPX, cameraNX, cameraPY, cameraNY, cameraPZ, cameraNZ] = this.children;
        const currentRenderTarget = renderer.getRenderTarget();
        const currentActiveCubeFace = renderer.getActiveCubeFace();
        const currentActiveMipmapLevel = renderer.getActiveMipmapLevel();
        const currentXrEnabled = renderer.xr.enabled;
        renderer.xr.enabled = false;
        const generateMipmaps = renderTarget.texture.generateMipmaps;
        renderTarget.texture.generateMipmaps = false;
        renderer.setRenderTarget(renderTarget, 0, activeMipmapLevel);
        renderer.render(scene, cameraPX);
        renderer.setRenderTarget(renderTarget, 1, activeMipmapLevel);
        renderer.render(scene, cameraNX);
        renderer.setRenderTarget(renderTarget, 2, activeMipmapLevel);
        renderer.render(scene, cameraPY);
        renderer.setRenderTarget(renderTarget, 3, activeMipmapLevel);
        renderer.render(scene, cameraNY);
        renderer.setRenderTarget(renderTarget, 4, activeMipmapLevel);
        renderer.render(scene, cameraPZ);
        // mipmaps are generated during the last call of render()
        // at this point, all sides of the cube render target are defined
        renderTarget.texture.generateMipmaps = generateMipmaps;
        renderer.setRenderTarget(renderTarget, 5, activeMipmapLevel);
        renderer.render(scene, cameraNZ);
        renderer.setRenderTarget(currentRenderTarget, currentActiveCubeFace, currentActiveMipmapLevel);
        renderer.xr.enabled = currentXrEnabled;
        renderTarget.texture.needsPMREMUpdate = true;
    }
}
class CubeTexture extends Texture {
    constructor(images, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace1){
        images = images !== undefined ? images : [];
        mapping = mapping !== undefined ? mapping : CubeReflectionMapping;
        super(images, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace1);
        this.isCubeTexture = true;
        this.flipY = false;
    }
    get images() {
        return this.image;
    }
    set images(value) {
        this.image = value;
    }
}
class WebGLCubeRenderTarget extends WebGLRenderTarget {
    constructor(size = 1, options = {}){
        super(size, size, options);
        this.isWebGLCubeRenderTarget = true;
        const image = {
            width: size,
            height: size,
            depth: 1
        };
        const images = [
            image,
            image,
            image,
            image,
            image,
            image
        ];
        this.texture = new CubeTexture(images, options.mapping, options.wrapS, options.wrapT, options.magFilter, options.minFilter, options.format, options.type, options.anisotropy, options.colorSpace);
        // By convention -- likely based on the RenderMan spec from the 1990's -- cube maps are specified by WebGL (and three.js)
        // in a coordinate system in which positive-x is to the right when looking up the positive-z axis -- in other words,
        // in a left-handed coordinate system. By continuing this convention, preexisting cube maps continued to render correctly.
        // three.js uses a right-handed coordinate system. So environment maps used in three.js appear to have px and nx swapped
        // and the flag isRenderTargetTexture controls this conversion. The flip is not required when using WebGLCubeRenderTarget.texture
        // as a cube texture (this is detected when isRenderTargetTexture is set to true for cube textures).
        this.texture.isRenderTargetTexture = true;
        this.texture.generateMipmaps = options.generateMipmaps !== undefined ? options.generateMipmaps : false;
        this.texture.minFilter = options.minFilter !== undefined ? options.minFilter : LinearFilter;
    }
    fromEquirectangularTexture(renderer, texture) {
        this.texture.type = texture.type;
        this.texture.colorSpace = texture.colorSpace;
        this.texture.generateMipmaps = texture.generateMipmaps;
        this.texture.minFilter = texture.minFilter;
        this.texture.magFilter = texture.magFilter;
        const shader = {
            uniforms: {
                tEquirect: {
                    value: null
                }
            },
            vertexShader: /* glsl */ `

				varying vec3 vWorldDirection;

				vec3 transformDirection( in vec3 dir, in mat4 matrix ) {

					return normalize( ( matrix * vec4( dir, 0.0 ) ).xyz );

				}

				void main() {

					vWorldDirection = transformDirection( position, modelMatrix );

					#include <begin_vertex>
					#include <project_vertex>

				}
			`,
            fragmentShader: /* glsl */ `

				uniform sampler2D tEquirect;

				varying vec3 vWorldDirection;

				#include <common>

				void main() {

					vec3 direction = normalize( vWorldDirection );

					vec2 sampleUV = equirectUv( direction );

					gl_FragColor = texture2D( tEquirect, sampleUV );

				}
			`
        };
        const geometry = new BoxGeometry(5, 5, 5);
        const material = new ShaderMaterial({
            name: "CubemapFromEquirect",
            uniforms: cloneUniforms(shader.uniforms),
            vertexShader: shader.vertexShader,
            fragmentShader: shader.fragmentShader,
            side: BackSide,
            blending: NoBlending
        });
        material.uniforms.tEquirect.value = texture;
        const mesh = new Mesh(geometry, material);
        const currentMinFilter = texture.minFilter;
        // Avoid blurred poles
        if (texture.minFilter === LinearMipmapLinearFilter) texture.minFilter = LinearFilter;
        const camera = new CubeCamera(1, 10, this);
        camera.update(renderer, mesh);
        texture.minFilter = currentMinFilter;
        mesh.geometry.dispose();
        mesh.material.dispose();
        return this;
    }
    clear(renderer, color, depth, stencil) {
        const currentRenderTarget = renderer.getRenderTarget();
        for(let i = 0; i < 6; i++){
            renderer.setRenderTarget(this, i);
            renderer.clear(color, depth, stencil);
        }
        renderer.setRenderTarget(currentRenderTarget);
    }
}
const _vector1 = /*@__PURE__*/ new Vector3();
const _vector2 = /*@__PURE__*/ new Vector3();
const _normalMatrix = /*@__PURE__*/ new Matrix3();
class Plane {
    constructor(normal = new Vector3(1, 0, 0), constant = 0){
        this.isPlane = true;
        // normal is assumed to be normalized
        this.normal = normal;
        this.constant = constant;
    }
    set(normal, constant) {
        this.normal.copy(normal);
        this.constant = constant;
        return this;
    }
    setComponents(x, y, z, w) {
        this.normal.set(x, y, z);
        this.constant = w;
        return this;
    }
    setFromNormalAndCoplanarPoint(normal, point) {
        this.normal.copy(normal);
        this.constant = -point.dot(this.normal);
        return this;
    }
    setFromCoplanarPoints(a, b, c) {
        const normal = _vector1.subVectors(c, b).cross(_vector2.subVectors(a, b)).normalize();
        // Q: should an error be thrown if normal is zero (e.g. degenerate plane)?
        this.setFromNormalAndCoplanarPoint(normal, a);
        return this;
    }
    copy(plane) {
        this.normal.copy(plane.normal);
        this.constant = plane.constant;
        return this;
    }
    normalize() {
        // Note: will lead to a divide by zero if the plane is invalid.
        const inverseNormalLength = 1.0 / this.normal.length();
        this.normal.multiplyScalar(inverseNormalLength);
        this.constant *= inverseNormalLength;
        return this;
    }
    negate() {
        this.constant *= -1;
        this.normal.negate();
        return this;
    }
    distanceToPoint(point) {
        return this.normal.dot(point) + this.constant;
    }
    distanceToSphere(sphere) {
        return this.distanceToPoint(sphere.center) - sphere.radius;
    }
    projectPoint(point, target) {
        return target.copy(point).addScaledVector(this.normal, -this.distanceToPoint(point));
    }
    intersectLine(line, target) {
        const direction = line.delta(_vector1);
        const denominator = this.normal.dot(direction);
        if (denominator === 0) {
            // line is coplanar, return origin
            if (this.distanceToPoint(line.start) === 0) return target.copy(line.start);
            // Unsure if this is the correct method to handle this case.
            return null;
        }
        const t = -(line.start.dot(this.normal) + this.constant) / denominator;
        if (t < 0 || t > 1) return null;
        return target.copy(line.start).addScaledVector(direction, t);
    }
    intersectsLine(line) {
        // Note: this tests if a line intersects the plane, not whether it (or its end-points) are coplanar with it.
        const startSign = this.distanceToPoint(line.start);
        const endSign = this.distanceToPoint(line.end);
        return startSign < 0 && endSign > 0 || endSign < 0 && startSign > 0;
    }
    intersectsBox(box) {
        return box.intersectsPlane(this);
    }
    intersectsSphere(sphere) {
        return sphere.intersectsPlane(this);
    }
    coplanarPoint(target) {
        return target.copy(this.normal).multiplyScalar(-this.constant);
    }
    applyMatrix4(matrix, optionalNormalMatrix) {
        const normalMatrix = optionalNormalMatrix || _normalMatrix.getNormalMatrix(matrix);
        const referencePoint = this.coplanarPoint(_vector1).applyMatrix4(matrix);
        const normal = this.normal.applyMatrix3(normalMatrix).normalize();
        this.constant = -referencePoint.dot(normal);
        return this;
    }
    translate(offset) {
        this.constant -= offset.dot(this.normal);
        return this;
    }
    equals(plane) {
        return plane.normal.equals(this.normal) && plane.constant === this.constant;
    }
    clone() {
        return new this.constructor().copy(this);
    }
}
const _sphere$5 = /*@__PURE__*/ new Sphere();
const _vector$7 = /*@__PURE__*/ new Vector3();
class Frustum {
    constructor(p0 = new Plane(), p1 = new Plane(), p2 = new Plane(), p3 = new Plane(), p4 = new Plane(), p5 = new Plane()){
        this.planes = [
            p0,
            p1,
            p2,
            p3,
            p4,
            p5
        ];
    }
    set(p0, p1, p2, p3, p4, p5) {
        const planes = this.planes;
        planes[0].copy(p0);
        planes[1].copy(p1);
        planes[2].copy(p2);
        planes[3].copy(p3);
        planes[4].copy(p4);
        planes[5].copy(p5);
        return this;
    }
    copy(frustum) {
        const planes = this.planes;
        for(let i = 0; i < 6; i++)planes[i].copy(frustum.planes[i]);
        return this;
    }
    setFromProjectionMatrix(m, coordinateSystem = WebGLCoordinateSystem) {
        const planes = this.planes;
        const me = m.elements;
        const me0 = me[0], me1 = me[1], me2 = me[2], me3 = me[3];
        const me4 = me[4], me5 = me[5], me6 = me[6], me7 = me[7];
        const me8 = me[8], me9 = me[9], me10 = me[10], me11 = me[11];
        const me12 = me[12], me13 = me[13], me14 = me[14], me15 = me[15];
        planes[0].setComponents(me3 - me0, me7 - me4, me11 - me8, me15 - me12).normalize();
        planes[1].setComponents(me3 + me0, me7 + me4, me11 + me8, me15 + me12).normalize();
        planes[2].setComponents(me3 + me1, me7 + me5, me11 + me9, me15 + me13).normalize();
        planes[3].setComponents(me3 - me1, me7 - me5, me11 - me9, me15 - me13).normalize();
        planes[4].setComponents(me3 - me2, me7 - me6, me11 - me10, me15 - me14).normalize();
        if (coordinateSystem === WebGLCoordinateSystem) planes[5].setComponents(me3 + me2, me7 + me6, me11 + me10, me15 + me14).normalize();
        else if (coordinateSystem === WebGPUCoordinateSystem) planes[5].setComponents(me2, me6, me10, me14).normalize();
        else throw new Error("THREE.Frustum.setFromProjectionMatrix(): Invalid coordinate system: " + coordinateSystem);
        return this;
    }
    intersectsObject(object) {
        if (object.boundingSphere !== undefined) {
            if (object.boundingSphere === null) object.computeBoundingSphere();
            _sphere$5.copy(object.boundingSphere).applyMatrix4(object.matrixWorld);
        } else {
            const geometry = object.geometry;
            if (geometry.boundingSphere === null) geometry.computeBoundingSphere();
            _sphere$5.copy(geometry.boundingSphere).applyMatrix4(object.matrixWorld);
        }
        return this.intersectsSphere(_sphere$5);
    }
    intersectsSprite(sprite) {
        _sphere$5.center.set(0, 0, 0);
        _sphere$5.radius = 0.7071067811865476;
        _sphere$5.applyMatrix4(sprite.matrixWorld);
        return this.intersectsSphere(_sphere$5);
    }
    intersectsSphere(sphere) {
        const planes = this.planes;
        const center = sphere.center;
        const negRadius = -sphere.radius;
        for(let i = 0; i < 6; i++){
            const distance = planes[i].distanceToPoint(center);
            if (distance < negRadius) return false;
        }
        return true;
    }
    intersectsBox(box) {
        const planes = this.planes;
        for(let i = 0; i < 6; i++){
            const plane = planes[i];
            // corner at max distance
            _vector$7.x = plane.normal.x > 0 ? box.max.x : box.min.x;
            _vector$7.y = plane.normal.y > 0 ? box.max.y : box.min.y;
            _vector$7.z = plane.normal.z > 0 ? box.max.z : box.min.z;
            if (plane.distanceToPoint(_vector$7) < 0) return false;
        }
        return true;
    }
    containsPoint(point) {
        const planes = this.planes;
        for(let i = 0; i < 6; i++){
            if (planes[i].distanceToPoint(point) < 0) return false;
        }
        return true;
    }
    clone() {
        return new this.constructor().copy(this);
    }
}
function WebGLAnimation() {
    let context = null;
    let isAnimating = false;
    let animationLoop = null;
    let requestId = null;
    function onAnimationFrame(time, frame) {
        animationLoop(time, frame);
        requestId = context.requestAnimationFrame(onAnimationFrame);
    }
    return {
        start: function() {
            if (isAnimating === true) return;
            if (animationLoop === null) return;
            requestId = context.requestAnimationFrame(onAnimationFrame);
            isAnimating = true;
        },
        stop: function() {
            context.cancelAnimationFrame(requestId);
            isAnimating = false;
        },
        setAnimationLoop: function(callback) {
            animationLoop = callback;
        },
        setContext: function(value) {
            context = value;
        }
    };
}
function WebGLAttributes(gl) {
    const buffers = new WeakMap();
    function createBuffer(attribute, bufferType) {
        const array = attribute.array;
        const usage = attribute.usage;
        const size = array.byteLength;
        const buffer = gl.createBuffer();
        gl.bindBuffer(bufferType, buffer);
        gl.bufferData(bufferType, array, usage);
        attribute.onUploadCallback();
        let type;
        if (array instanceof Float32Array) type = gl.FLOAT;
        else if (array instanceof Uint16Array) {
            if (attribute.isFloat16BufferAttribute) type = gl.HALF_FLOAT;
            else type = gl.UNSIGNED_SHORT;
        } else if (array instanceof Int16Array) type = gl.SHORT;
        else if (array instanceof Uint32Array) type = gl.UNSIGNED_INT;
        else if (array instanceof Int32Array) type = gl.INT;
        else if (array instanceof Int8Array) type = gl.BYTE;
        else if (array instanceof Uint8Array) type = gl.UNSIGNED_BYTE;
        else if (array instanceof Uint8ClampedArray) type = gl.UNSIGNED_BYTE;
        else throw new Error("THREE.WebGLAttributes: Unsupported buffer data format: " + array);
        return {
            buffer: buffer,
            type: type,
            bytesPerElement: array.BYTES_PER_ELEMENT,
            version: attribute.version,
            size: size
        };
    }
    function updateBuffer(buffer, attribute, bufferType) {
        const array = attribute.array;
        const updateRange = attribute._updateRange; // @deprecated, r159
        const updateRanges = attribute.updateRanges;
        gl.bindBuffer(bufferType, buffer);
        if (updateRange.count === -1 && updateRanges.length === 0) // Not using update ranges
        gl.bufferSubData(bufferType, 0, array);
        if (updateRanges.length !== 0) {
            for(let i = 0, l = updateRanges.length; i < l; i++){
                const range = updateRanges[i];
                gl.bufferSubData(bufferType, range.start * array.BYTES_PER_ELEMENT, array, range.start, range.count);
            }
            attribute.clearUpdateRanges();
        }
        // @deprecated, r159
        if (updateRange.count !== -1) {
            gl.bufferSubData(bufferType, updateRange.offset * array.BYTES_PER_ELEMENT, array, updateRange.offset, updateRange.count);
            updateRange.count = -1; // reset range
        }
        attribute.onUploadCallback();
    }
    //
    function get(attribute) {
        if (attribute.isInterleavedBufferAttribute) attribute = attribute.data;
        return buffers.get(attribute);
    }
    function remove(attribute) {
        if (attribute.isInterleavedBufferAttribute) attribute = attribute.data;
        const data = buffers.get(attribute);
        if (data) {
            gl.deleteBuffer(data.buffer);
            buffers.delete(attribute);
        }
    }
    function update(attribute, bufferType) {
        if (attribute.isGLBufferAttribute) {
            const cached = buffers.get(attribute);
            if (!cached || cached.version < attribute.version) buffers.set(attribute, {
                buffer: attribute.buffer,
                type: attribute.type,
                bytesPerElement: attribute.elementSize,
                version: attribute.version
            });
            return;
        }
        if (attribute.isInterleavedBufferAttribute) attribute = attribute.data;
        const data = buffers.get(attribute);
        if (data === undefined) buffers.set(attribute, createBuffer(attribute, bufferType));
        else if (data.version < attribute.version) {
            if (data.size !== attribute.array.byteLength) throw new Error("THREE.WebGLAttributes: The size of the buffer attribute's array buffer does not match the original size. Resizing buffer attributes is not supported.");
            updateBuffer(data.buffer, attribute, bufferType);
            data.version = attribute.version;
        }
    }
    return {
        get: get,
        remove: remove,
        update: update
    };
}
class PlaneGeometry extends BufferGeometry {
    constructor(width = 1, height = 1, widthSegments = 1, heightSegments = 1){
        super();
        this.type = "PlaneGeometry";
        this.parameters = {
            width: width,
            height: height,
            widthSegments: widthSegments,
            heightSegments: heightSegments
        };
        const width_half = width / 2;
        const height_half = height / 2;
        const gridX = Math.floor(widthSegments);
        const gridY = Math.floor(heightSegments);
        const gridX1 = gridX + 1;
        const gridY1 = gridY + 1;
        const segment_width = width / gridX;
        const segment_height = height / gridY;
        //
        const indices = [];
        const vertices = [];
        const normals = [];
        const uvs = [];
        for(let iy = 0; iy < gridY1; iy++){
            const y = iy * segment_height - height_half;
            for(let ix = 0; ix < gridX1; ix++){
                const x = ix * segment_width - width_half;
                vertices.push(x, -y, 0);
                normals.push(0, 0, 1);
                uvs.push(ix / gridX);
                uvs.push(1 - iy / gridY);
            }
        }
        for(let iy = 0; iy < gridY; iy++)for(let ix = 0; ix < gridX; ix++){
            const a = ix + gridX1 * iy;
            const b = ix + gridX1 * (iy + 1);
            const c = ix + 1 + gridX1 * (iy + 1);
            const d = ix + 1 + gridX1 * iy;
            indices.push(a, b, d);
            indices.push(b, c, d);
        }
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    static fromJSON(data) {
        return new PlaneGeometry(data.width, data.height, data.widthSegments, data.heightSegments);
    }
}
var alphahash_fragment = "#ifdef USE_ALPHAHASH\n	if ( diffuseColor.a < getAlphaHashThreshold( vPosition ) ) discard;\n#endif";
var alphahash_pars_fragment = "#ifdef USE_ALPHAHASH\n	const float ALPHA_HASH_SCALE = 0.05;\n	float hash2D( vec2 value ) {\n		return fract( 1.0e4 * sin( 17.0 * value.x + 0.1 * value.y ) * ( 0.1 + abs( sin( 13.0 * value.y + value.x ) ) ) );\n	}\n	float hash3D( vec3 value ) {\n		return hash2D( vec2( hash2D( value.xy ), value.z ) );\n	}\n	float getAlphaHashThreshold( vec3 position ) {\n		float maxDeriv = max(\n			length( dFdx( position.xyz ) ),\n			length( dFdy( position.xyz ) )\n		);\n		float pixScale = 1.0 / ( ALPHA_HASH_SCALE * maxDeriv );\n		vec2 pixScales = vec2(\n			exp2( floor( log2( pixScale ) ) ),\n			exp2( ceil( log2( pixScale ) ) )\n		);\n		vec2 alpha = vec2(\n			hash3D( floor( pixScales.x * position.xyz ) ),\n			hash3D( floor( pixScales.y * position.xyz ) )\n		);\n		float lerpFactor = fract( log2( pixScale ) );\n		float x = ( 1.0 - lerpFactor ) * alpha.x + lerpFactor * alpha.y;\n		float a = min( lerpFactor, 1.0 - lerpFactor );\n		vec3 cases = vec3(\n			x * x / ( 2.0 * a * ( 1.0 - a ) ),\n			( x - 0.5 * a ) / ( 1.0 - a ),\n			1.0 - ( ( 1.0 - x ) * ( 1.0 - x ) / ( 2.0 * a * ( 1.0 - a ) ) )\n		);\n		float threshold = ( x < ( 1.0 - a ) )\n			? ( ( x < a ) ? cases.x : cases.y )\n			: cases.z;\n		return clamp( threshold , 1.0e-6, 1.0 );\n	}\n#endif";
var alphamap_fragment = "#ifdef USE_ALPHAMAP\n	diffuseColor.a *= texture2D( alphaMap, vAlphaMapUv ).g;\n#endif";
var alphamap_pars_fragment = "#ifdef USE_ALPHAMAP\n	uniform sampler2D alphaMap;\n#endif";
var alphatest_fragment = "#ifdef USE_ALPHATEST\n	#ifdef ALPHA_TO_COVERAGE\n	diffuseColor.a = smoothstep( alphaTest, alphaTest + fwidth( diffuseColor.a ), diffuseColor.a );\n	if ( diffuseColor.a == 0.0 ) discard;\n	#else\n	if ( diffuseColor.a < alphaTest ) discard;\n	#endif\n#endif";
var alphatest_pars_fragment = "#ifdef USE_ALPHATEST\n	uniform float alphaTest;\n#endif";
var aomap_fragment = "#ifdef USE_AOMAP\n	float ambientOcclusion = ( texture2D( aoMap, vAoMapUv ).r - 1.0 ) * aoMapIntensity + 1.0;\n	reflectedLight.indirectDiffuse *= ambientOcclusion;\n	#if defined( USE_CLEARCOAT ) \n		clearcoatSpecularIndirect *= ambientOcclusion;\n	#endif\n	#if defined( USE_SHEEN ) \n		sheenSpecularIndirect *= ambientOcclusion;\n	#endif\n	#if defined( USE_ENVMAP ) && defined( STANDARD )\n		float dotNV = saturate( dot( geometryNormal, geometryViewDir ) );\n		reflectedLight.indirectSpecular *= computeSpecularOcclusion( dotNV, ambientOcclusion, material.roughness );\n	#endif\n#endif";
var aomap_pars_fragment = "#ifdef USE_AOMAP\n	uniform sampler2D aoMap;\n	uniform float aoMapIntensity;\n#endif";
var batching_pars_vertex = "#ifdef USE_BATCHING\n	#if ! defined( GL_ANGLE_multi_draw )\n	#define gl_DrawID _gl_DrawID\n	uniform int _gl_DrawID;\n	#endif\n	uniform highp sampler2D batchingTexture;\n	uniform highp usampler2D batchingIdTexture;\n	mat4 getBatchingMatrix( const in float i ) {\n		int size = textureSize( batchingTexture, 0 ).x;\n		int j = int( i ) * 4;\n		int x = j % size;\n		int y = j / size;\n		vec4 v1 = texelFetch( batchingTexture, ivec2( x, y ), 0 );\n		vec4 v2 = texelFetch( batchingTexture, ivec2( x + 1, y ), 0 );\n		vec4 v3 = texelFetch( batchingTexture, ivec2( x + 2, y ), 0 );\n		vec4 v4 = texelFetch( batchingTexture, ivec2( x + 3, y ), 0 );\n		return mat4( v1, v2, v3, v4 );\n	}\n	float getIndirectIndex( const in int i ) {\n		int size = textureSize( batchingIdTexture, 0 ).x;\n		int x = i % size;\n		int y = i / size;\n		return float( texelFetch( batchingIdTexture, ivec2( x, y ), 0 ).r );\n	}\n#endif\n#ifdef USE_BATCHING_COLOR\n	uniform sampler2D batchingColorTexture;\n	vec3 getBatchingColor( const in float i ) {\n		int size = textureSize( batchingColorTexture, 0 ).x;\n		int j = int( i );\n		int x = j % size;\n		int y = j / size;\n		return texelFetch( batchingColorTexture, ivec2( x, y ), 0 ).rgb;\n	}\n#endif";
var batching_vertex = "#ifdef USE_BATCHING\n	mat4 batchingMatrix = getBatchingMatrix( getIndirectIndex( gl_DrawID ) );\n#endif";
var begin_vertex = "vec3 transformed = vec3( position );\n#ifdef USE_ALPHAHASH\n	vPosition = vec3( position );\n#endif";
var beginnormal_vertex = "vec3 objectNormal = vec3( normal );\n#ifdef USE_TANGENT\n	vec3 objectTangent = vec3( tangent.xyz );\n#endif";
var bsdfs = "float G_BlinnPhong_Implicit( ) {\n	return 0.25;\n}\nfloat D_BlinnPhong( const in float shininess, const in float dotNH ) {\n	return RECIPROCAL_PI * ( shininess * 0.5 + 1.0 ) * pow( dotNH, shininess );\n}\nvec3 BRDF_BlinnPhong( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in vec3 specularColor, const in float shininess ) {\n	vec3 halfDir = normalize( lightDir + viewDir );\n	float dotNH = saturate( dot( normal, halfDir ) );\n	float dotVH = saturate( dot( viewDir, halfDir ) );\n	vec3 F = F_Schlick( specularColor, 1.0, dotVH );\n	float G = G_BlinnPhong_Implicit( );\n	float D = D_BlinnPhong( shininess, dotNH );\n	return F * ( G * D );\n} // validated";
var iridescence_fragment = "#ifdef USE_IRIDESCENCE\n	const mat3 XYZ_TO_REC709 = mat3(\n		 3.2404542, -0.9692660,  0.0556434,\n		-1.5371385,  1.8760108, -0.2040259,\n		-0.4985314,  0.0415560,  1.0572252\n	);\n	vec3 Fresnel0ToIor( vec3 fresnel0 ) {\n		vec3 sqrtF0 = sqrt( fresnel0 );\n		return ( vec3( 1.0 ) + sqrtF0 ) / ( vec3( 1.0 ) - sqrtF0 );\n	}\n	vec3 IorToFresnel0( vec3 transmittedIor, float incidentIor ) {\n		return pow2( ( transmittedIor - vec3( incidentIor ) ) / ( transmittedIor + vec3( incidentIor ) ) );\n	}\n	float IorToFresnel0( float transmittedIor, float incidentIor ) {\n		return pow2( ( transmittedIor - incidentIor ) / ( transmittedIor + incidentIor ));\n	}\n	vec3 evalSensitivity( float OPD, vec3 shift ) {\n		float phase = 2.0 * PI * OPD * 1.0e-9;\n		vec3 val = vec3( 5.4856e-13, 4.4201e-13, 5.2481e-13 );\n		vec3 pos = vec3( 1.6810e+06, 1.7953e+06, 2.2084e+06 );\n		vec3 var = vec3( 4.3278e+09, 9.3046e+09, 6.6121e+09 );\n		vec3 xyz = val * sqrt( 2.0 * PI * var ) * cos( pos * phase + shift ) * exp( - pow2( phase ) * var );\n		xyz.x += 9.7470e-14 * sqrt( 2.0 * PI * 4.5282e+09 ) * cos( 2.2399e+06 * phase + shift[ 0 ] ) * exp( - 4.5282e+09 * pow2( phase ) );\n		xyz /= 1.0685e-7;\n		vec3 rgb = XYZ_TO_REC709 * xyz;\n		return rgb;\n	}\n	vec3 evalIridescence( float outsideIOR, float eta2, float cosTheta1, float thinFilmThickness, vec3 baseF0 ) {\n		vec3 I;\n		float iridescenceIOR = mix( outsideIOR, eta2, smoothstep( 0.0, 0.03, thinFilmThickness ) );\n		float sinTheta2Sq = pow2( outsideIOR / iridescenceIOR ) * ( 1.0 - pow2( cosTheta1 ) );\n		float cosTheta2Sq = 1.0 - sinTheta2Sq;\n		if ( cosTheta2Sq < 0.0 ) {\n			return vec3( 1.0 );\n		}\n		float cosTheta2 = sqrt( cosTheta2Sq );\n		float R0 = IorToFresnel0( iridescenceIOR, outsideIOR );\n		float R12 = F_Schlick( R0, 1.0, cosTheta1 );\n		float T121 = 1.0 - R12;\n		float phi12 = 0.0;\n		if ( iridescenceIOR < outsideIOR ) phi12 = PI;\n		float phi21 = PI - phi12;\n		vec3 baseIOR = Fresnel0ToIor( clamp( baseF0, 0.0, 0.9999 ) );		vec3 R1 = IorToFresnel0( baseIOR, iridescenceIOR );\n		vec3 R23 = F_Schlick( R1, 1.0, cosTheta2 );\n		vec3 phi23 = vec3( 0.0 );\n		if ( baseIOR[ 0 ] < iridescenceIOR ) phi23[ 0 ] = PI;\n		if ( baseIOR[ 1 ] < iridescenceIOR ) phi23[ 1 ] = PI;\n		if ( baseIOR[ 2 ] < iridescenceIOR ) phi23[ 2 ] = PI;\n		float OPD = 2.0 * iridescenceIOR * thinFilmThickness * cosTheta2;\n		vec3 phi = vec3( phi21 ) + phi23;\n		vec3 R123 = clamp( R12 * R23, 1e-5, 0.9999 );\n		vec3 r123 = sqrt( R123 );\n		vec3 Rs = pow2( T121 ) * R23 / ( vec3( 1.0 ) - R123 );\n		vec3 C0 = R12 + Rs;\n		I = C0;\n		vec3 Cm = Rs - T121;\n		for ( int m = 1; m <= 2; ++ m ) {\n			Cm *= r123;\n			vec3 Sm = 2.0 * evalSensitivity( float( m ) * OPD, float( m ) * phi );\n			I += Cm * Sm;\n		}\n		return max( I, vec3( 0.0 ) );\n	}\n#endif";
var bumpmap_pars_fragment = "#ifdef USE_BUMPMAP\n	uniform sampler2D bumpMap;\n	uniform float bumpScale;\n	vec2 dHdxy_fwd() {\n		vec2 dSTdx = dFdx( vBumpMapUv );\n		vec2 dSTdy = dFdy( vBumpMapUv );\n		float Hll = bumpScale * texture2D( bumpMap, vBumpMapUv ).x;\n		float dBx = bumpScale * texture2D( bumpMap, vBumpMapUv + dSTdx ).x - Hll;\n		float dBy = bumpScale * texture2D( bumpMap, vBumpMapUv + dSTdy ).x - Hll;\n		return vec2( dBx, dBy );\n	}\n	vec3 perturbNormalArb( vec3 surf_pos, vec3 surf_norm, vec2 dHdxy, float faceDirection ) {\n		vec3 vSigmaX = normalize( dFdx( surf_pos.xyz ) );\n		vec3 vSigmaY = normalize( dFdy( surf_pos.xyz ) );\n		vec3 vN = surf_norm;\n		vec3 R1 = cross( vSigmaY, vN );\n		vec3 R2 = cross( vN, vSigmaX );\n		float fDet = dot( vSigmaX, R1 ) * faceDirection;\n		vec3 vGrad = sign( fDet ) * ( dHdxy.x * R1 + dHdxy.y * R2 );\n		return normalize( abs( fDet ) * surf_norm - vGrad );\n	}\n#endif";
var clipping_planes_fragment = "#if NUM_CLIPPING_PLANES > 0\n	vec4 plane;\n	#ifdef ALPHA_TO_COVERAGE\n		float distanceToPlane, distanceGradient;\n		float clipOpacity = 1.0;\n		#pragma unroll_loop_start\n		for ( int i = 0; i < UNION_CLIPPING_PLANES; i ++ ) {\n			plane = clippingPlanes[ i ];\n			distanceToPlane = - dot( vClipPosition, plane.xyz ) + plane.w;\n			distanceGradient = fwidth( distanceToPlane ) / 2.0;\n			clipOpacity *= smoothstep( - distanceGradient, distanceGradient, distanceToPlane );\n			if ( clipOpacity == 0.0 ) discard;\n		}\n		#pragma unroll_loop_end\n		#if UNION_CLIPPING_PLANES < NUM_CLIPPING_PLANES\n			float unionClipOpacity = 1.0;\n			#pragma unroll_loop_start\n			for ( int i = UNION_CLIPPING_PLANES; i < NUM_CLIPPING_PLANES; i ++ ) {\n				plane = clippingPlanes[ i ];\n				distanceToPlane = - dot( vClipPosition, plane.xyz ) + plane.w;\n				distanceGradient = fwidth( distanceToPlane ) / 2.0;\n				unionClipOpacity *= 1.0 - smoothstep( - distanceGradient, distanceGradient, distanceToPlane );\n			}\n			#pragma unroll_loop_end\n			clipOpacity *= 1.0 - unionClipOpacity;\n		#endif\n		diffuseColor.a *= clipOpacity;\n		if ( diffuseColor.a == 0.0 ) discard;\n	#else\n		#pragma unroll_loop_start\n		for ( int i = 0; i < UNION_CLIPPING_PLANES; i ++ ) {\n			plane = clippingPlanes[ i ];\n			if ( dot( vClipPosition, plane.xyz ) > plane.w ) discard;\n		}\n		#pragma unroll_loop_end\n		#if UNION_CLIPPING_PLANES < NUM_CLIPPING_PLANES\n			bool clipped = true;\n			#pragma unroll_loop_start\n			for ( int i = UNION_CLIPPING_PLANES; i < NUM_CLIPPING_PLANES; i ++ ) {\n				plane = clippingPlanes[ i ];\n				clipped = ( dot( vClipPosition, plane.xyz ) > plane.w ) && clipped;\n			}\n			#pragma unroll_loop_end\n			if ( clipped ) discard;\n		#endif\n	#endif\n#endif";
var clipping_planes_pars_fragment = "#if NUM_CLIPPING_PLANES > 0\n	varying vec3 vClipPosition;\n	uniform vec4 clippingPlanes[ NUM_CLIPPING_PLANES ];\n#endif";
var clipping_planes_pars_vertex = "#if NUM_CLIPPING_PLANES > 0\n	varying vec3 vClipPosition;\n#endif";
var clipping_planes_vertex = "#if NUM_CLIPPING_PLANES > 0\n	vClipPosition = - mvPosition.xyz;\n#endif";
var color_fragment = "#if defined( USE_COLOR_ALPHA )\n	diffuseColor *= vColor;\n#elif defined( USE_COLOR )\n	diffuseColor.rgb *= vColor;\n#endif";
var color_pars_fragment = "#if defined( USE_COLOR_ALPHA )\n	varying vec4 vColor;\n#elif defined( USE_COLOR )\n	varying vec3 vColor;\n#endif";
var color_pars_vertex = "#if defined( USE_COLOR_ALPHA )\n	varying vec4 vColor;\n#elif defined( USE_COLOR ) || defined( USE_INSTANCING_COLOR ) || defined( USE_BATCHING_COLOR )\n	varying vec3 vColor;\n#endif";
var color_vertex = "#if defined( USE_COLOR_ALPHA )\n	vColor = vec4( 1.0 );\n#elif defined( USE_COLOR ) || defined( USE_INSTANCING_COLOR ) || defined( USE_BATCHING_COLOR )\n	vColor = vec3( 1.0 );\n#endif\n#ifdef USE_COLOR\n	vColor *= color;\n#endif\n#ifdef USE_INSTANCING_COLOR\n	vColor.xyz *= instanceColor.xyz;\n#endif\n#ifdef USE_BATCHING_COLOR\n	vec3 batchingColor = getBatchingColor( getIndirectIndex( gl_DrawID ) );\n	vColor.xyz *= batchingColor.xyz;\n#endif";
var common = "#define PI 3.141592653589793\n#define PI2 6.283185307179586\n#define PI_HALF 1.5707963267948966\n#define RECIPROCAL_PI 0.3183098861837907\n#define RECIPROCAL_PI2 0.15915494309189535\n#define EPSILON 1e-6\n#ifndef saturate\n#define saturate( a ) clamp( a, 0.0, 1.0 )\n#endif\n#define whiteComplement( a ) ( 1.0 - saturate( a ) )\nfloat pow2( const in float x ) { return x*x; }\nvec3 pow2( const in vec3 x ) { return x*x; }\nfloat pow3( const in float x ) { return x*x*x; }\nfloat pow4( const in float x ) { float x2 = x*x; return x2*x2; }\nfloat max3( const in vec3 v ) { return max( max( v.x, v.y ), v.z ); }\nfloat average( const in vec3 v ) { return dot( v, vec3( 0.3333333 ) ); }\nhighp float rand( const in vec2 uv ) {\n	const highp float a = 12.9898, b = 78.233, c = 43758.5453;\n	highp float dt = dot( uv.xy, vec2( a,b ) ), sn = mod( dt, PI );\n	return fract( sin( sn ) * c );\n}\n#ifdef HIGH_PRECISION\n	float precisionSafeLength( vec3 v ) { return length( v ); }\n#else\n	float precisionSafeLength( vec3 v ) {\n		float maxComponent = max3( abs( v ) );\n		return length( v / maxComponent ) * maxComponent;\n	}\n#endif\nstruct IncidentLight {\n	vec3 color;\n	vec3 direction;\n	bool visible;\n};\nstruct ReflectedLight {\n	vec3 directDiffuse;\n	vec3 directSpecular;\n	vec3 indirectDiffuse;\n	vec3 indirectSpecular;\n};\n#ifdef USE_ALPHAHASH\n	varying vec3 vPosition;\n#endif\nvec3 transformDirection( in vec3 dir, in mat4 matrix ) {\n	return normalize( ( matrix * vec4( dir, 0.0 ) ).xyz );\n}\nvec3 inverseTransformDirection( in vec3 dir, in mat4 matrix ) {\n	return normalize( ( vec4( dir, 0.0 ) * matrix ).xyz );\n}\nmat3 transposeMat3( const in mat3 m ) {\n	mat3 tmp;\n	tmp[ 0 ] = vec3( m[ 0 ].x, m[ 1 ].x, m[ 2 ].x );\n	tmp[ 1 ] = vec3( m[ 0 ].y, m[ 1 ].y, m[ 2 ].y );\n	tmp[ 2 ] = vec3( m[ 0 ].z, m[ 1 ].z, m[ 2 ].z );\n	return tmp;\n}\nfloat luminance( const in vec3 rgb ) {\n	const vec3 weights = vec3( 0.2126729, 0.7151522, 0.0721750 );\n	return dot( weights, rgb );\n}\nbool isPerspectiveMatrix( mat4 m ) {\n	return m[ 2 ][ 3 ] == - 1.0;\n}\nvec2 equirectUv( in vec3 dir ) {\n	float u = atan( dir.z, dir.x ) * RECIPROCAL_PI2 + 0.5;\n	float v = asin( clamp( dir.y, - 1.0, 1.0 ) ) * RECIPROCAL_PI + 0.5;\n	return vec2( u, v );\n}\nvec3 BRDF_Lambert( const in vec3 diffuseColor ) {\n	return RECIPROCAL_PI * diffuseColor;\n}\nvec3 F_Schlick( const in vec3 f0, const in float f90, const in float dotVH ) {\n	float fresnel = exp2( ( - 5.55473 * dotVH - 6.98316 ) * dotVH );\n	return f0 * ( 1.0 - fresnel ) + ( f90 * fresnel );\n}\nfloat F_Schlick( const in float f0, const in float f90, const in float dotVH ) {\n	float fresnel = exp2( ( - 5.55473 * dotVH - 6.98316 ) * dotVH );\n	return f0 * ( 1.0 - fresnel ) + ( f90 * fresnel );\n} // validated";
var cube_uv_reflection_fragment = "#ifdef ENVMAP_TYPE_CUBE_UV\n	#define cubeUV_minMipLevel 4.0\n	#define cubeUV_minTileSize 16.0\n	float getFace( vec3 direction ) {\n		vec3 absDirection = abs( direction );\n		float face = - 1.0;\n		if ( absDirection.x > absDirection.z ) {\n			if ( absDirection.x > absDirection.y )\n				face = direction.x > 0.0 ? 0.0 : 3.0;\n			else\n				face = direction.y > 0.0 ? 1.0 : 4.0;\n		} else {\n			if ( absDirection.z > absDirection.y )\n				face = direction.z > 0.0 ? 2.0 : 5.0;\n			else\n				face = direction.y > 0.0 ? 1.0 : 4.0;\n		}\n		return face;\n	}\n	vec2 getUV( vec3 direction, float face ) {\n		vec2 uv;\n		if ( face == 0.0 ) {\n			uv = vec2( direction.z, direction.y ) / abs( direction.x );\n		} else if ( face == 1.0 ) {\n			uv = vec2( - direction.x, - direction.z ) / abs( direction.y );\n		} else if ( face == 2.0 ) {\n			uv = vec2( - direction.x, direction.y ) / abs( direction.z );\n		} else if ( face == 3.0 ) {\n			uv = vec2( - direction.z, direction.y ) / abs( direction.x );\n		} else if ( face == 4.0 ) {\n			uv = vec2( - direction.x, direction.z ) / abs( direction.y );\n		} else {\n			uv = vec2( direction.x, direction.y ) / abs( direction.z );\n		}\n		return 0.5 * ( uv + 1.0 );\n	}\n	vec3 bilinearCubeUV( sampler2D envMap, vec3 direction, float mipInt ) {\n		float face = getFace( direction );\n		float filterInt = max( cubeUV_minMipLevel - mipInt, 0.0 );\n		mipInt = max( mipInt, cubeUV_minMipLevel );\n		float faceSize = exp2( mipInt );\n		highp vec2 uv = getUV( direction, face ) * ( faceSize - 2.0 ) + 1.0;\n		if ( face > 2.0 ) {\n			uv.y += faceSize;\n			face -= 3.0;\n		}\n		uv.x += face * faceSize;\n		uv.x += filterInt * 3.0 * cubeUV_minTileSize;\n		uv.y += 4.0 * ( exp2( CUBEUV_MAX_MIP ) - faceSize );\n		uv.x *= CUBEUV_TEXEL_WIDTH;\n		uv.y *= CUBEUV_TEXEL_HEIGHT;\n		#ifdef texture2DGradEXT\n			return texture2DGradEXT( envMap, uv, vec2( 0.0 ), vec2( 0.0 ) ).rgb;\n		#else\n			return texture2D( envMap, uv ).rgb;\n		#endif\n	}\n	#define cubeUV_r0 1.0\n	#define cubeUV_m0 - 2.0\n	#define cubeUV_r1 0.8\n	#define cubeUV_m1 - 1.0\n	#define cubeUV_r4 0.4\n	#define cubeUV_m4 2.0\n	#define cubeUV_r5 0.305\n	#define cubeUV_m5 3.0\n	#define cubeUV_r6 0.21\n	#define cubeUV_m6 4.0\n	float roughnessToMip( float roughness ) {\n		float mip = 0.0;\n		if ( roughness >= cubeUV_r1 ) {\n			mip = ( cubeUV_r0 - roughness ) * ( cubeUV_m1 - cubeUV_m0 ) / ( cubeUV_r0 - cubeUV_r1 ) + cubeUV_m0;\n		} else if ( roughness >= cubeUV_r4 ) {\n			mip = ( cubeUV_r1 - roughness ) * ( cubeUV_m4 - cubeUV_m1 ) / ( cubeUV_r1 - cubeUV_r4 ) + cubeUV_m1;\n		} else if ( roughness >= cubeUV_r5 ) {\n			mip = ( cubeUV_r4 - roughness ) * ( cubeUV_m5 - cubeUV_m4 ) / ( cubeUV_r4 - cubeUV_r5 ) + cubeUV_m4;\n		} else if ( roughness >= cubeUV_r6 ) {\n			mip = ( cubeUV_r5 - roughness ) * ( cubeUV_m6 - cubeUV_m5 ) / ( cubeUV_r5 - cubeUV_r6 ) + cubeUV_m5;\n		} else {\n			mip = - 2.0 * log2( 1.16 * roughness );		}\n		return mip;\n	}\n	vec4 textureCubeUV( sampler2D envMap, vec3 sampleDir, float roughness ) {\n		float mip = clamp( roughnessToMip( roughness ), cubeUV_m0, CUBEUV_MAX_MIP );\n		float mipF = fract( mip );\n		float mipInt = floor( mip );\n		vec3 color0 = bilinearCubeUV( envMap, sampleDir, mipInt );\n		if ( mipF == 0.0 ) {\n			return vec4( color0, 1.0 );\n		} else {\n			vec3 color1 = bilinearCubeUV( envMap, sampleDir, mipInt + 1.0 );\n			return vec4( mix( color0, color1, mipF ), 1.0 );\n		}\n	}\n#endif";
var defaultnormal_vertex = "vec3 transformedNormal = objectNormal;\n#ifdef USE_TANGENT\n	vec3 transformedTangent = objectTangent;\n#endif\n#ifdef USE_BATCHING\n	mat3 bm = mat3( batchingMatrix );\n	transformedNormal /= vec3( dot( bm[ 0 ], bm[ 0 ] ), dot( bm[ 1 ], bm[ 1 ] ), dot( bm[ 2 ], bm[ 2 ] ) );\n	transformedNormal = bm * transformedNormal;\n	#ifdef USE_TANGENT\n		transformedTangent = bm * transformedTangent;\n	#endif\n#endif\n#ifdef USE_INSTANCING\n	mat3 im = mat3( instanceMatrix );\n	transformedNormal /= vec3( dot( im[ 0 ], im[ 0 ] ), dot( im[ 1 ], im[ 1 ] ), dot( im[ 2 ], im[ 2 ] ) );\n	transformedNormal = im * transformedNormal;\n	#ifdef USE_TANGENT\n		transformedTangent = im * transformedTangent;\n	#endif\n#endif\ntransformedNormal = normalMatrix * transformedNormal;\n#ifdef FLIP_SIDED\n	transformedNormal = - transformedNormal;\n#endif\n#ifdef USE_TANGENT\n	transformedTangent = ( modelViewMatrix * vec4( transformedTangent, 0.0 ) ).xyz;\n	#ifdef FLIP_SIDED\n		transformedTangent = - transformedTangent;\n	#endif\n#endif";
var displacementmap_pars_vertex = "#ifdef USE_DISPLACEMENTMAP\n	uniform sampler2D displacementMap;\n	uniform float displacementScale;\n	uniform float displacementBias;\n#endif";
var displacementmap_vertex = "#ifdef USE_DISPLACEMENTMAP\n	transformed += normalize( objectNormal ) * ( texture2D( displacementMap, vDisplacementMapUv ).x * displacementScale + displacementBias );\n#endif";
var emissivemap_fragment = "#ifdef USE_EMISSIVEMAP\n	vec4 emissiveColor = texture2D( emissiveMap, vEmissiveMapUv );\n	totalEmissiveRadiance *= emissiveColor.rgb;\n#endif";
var emissivemap_pars_fragment = "#ifdef USE_EMISSIVEMAP\n	uniform sampler2D emissiveMap;\n#endif";
var colorspace_fragment = "gl_FragColor = linearToOutputTexel( gl_FragColor );";
var colorspace_pars_fragment = "\nconst mat3 LINEAR_SRGB_TO_LINEAR_DISPLAY_P3 = mat3(\n	vec3( 0.8224621, 0.177538, 0.0 ),\n	vec3( 0.0331941, 0.9668058, 0.0 ),\n	vec3( 0.0170827, 0.0723974, 0.9105199 )\n);\nconst mat3 LINEAR_DISPLAY_P3_TO_LINEAR_SRGB = mat3(\n	vec3( 1.2249401, - 0.2249404, 0.0 ),\n	vec3( - 0.0420569, 1.0420571, 0.0 ),\n	vec3( - 0.0196376, - 0.0786361, 1.0982735 )\n);\nvec4 LinearSRGBToLinearDisplayP3( in vec4 value ) {\n	return vec4( value.rgb * LINEAR_SRGB_TO_LINEAR_DISPLAY_P3, value.a );\n}\nvec4 LinearDisplayP3ToLinearSRGB( in vec4 value ) {\n	return vec4( value.rgb * LINEAR_DISPLAY_P3_TO_LINEAR_SRGB, value.a );\n}\nvec4 LinearTransferOETF( in vec4 value ) {\n	return value;\n}\nvec4 sRGBTransferOETF( in vec4 value ) {\n	return vec4( mix( pow( value.rgb, vec3( 0.41666 ) ) * 1.055 - vec3( 0.055 ), value.rgb * 12.92, vec3( lessThanEqual( value.rgb, vec3( 0.0031308 ) ) ) ), value.a );\n}\nvec4 LinearToLinear( in vec4 value ) {\n	return value;\n}\nvec4 LinearTosRGB( in vec4 value ) {\n	return sRGBTransferOETF( value );\n}";
var envmap_fragment = "#ifdef USE_ENVMAP\n	#ifdef ENV_WORLDPOS\n		vec3 cameraToFrag;\n		if ( isOrthographic ) {\n			cameraToFrag = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );\n		} else {\n			cameraToFrag = normalize( vWorldPosition - cameraPosition );\n		}\n		vec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\n		#ifdef ENVMAP_MODE_REFLECTION\n			vec3 reflectVec = reflect( cameraToFrag, worldNormal );\n		#else\n			vec3 reflectVec = refract( cameraToFrag, worldNormal, refractionRatio );\n		#endif\n	#else\n		vec3 reflectVec = vReflect;\n	#endif\n	#ifdef ENVMAP_TYPE_CUBE\n		vec4 envColor = textureCube( envMap, envMapRotation * vec3( flipEnvMap * reflectVec.x, reflectVec.yz ) );\n	#else\n		vec4 envColor = vec4( 0.0 );\n	#endif\n	#ifdef ENVMAP_BLENDING_MULTIPLY\n		outgoingLight = mix( outgoingLight, outgoingLight * envColor.xyz, specularStrength * reflectivity );\n	#elif defined( ENVMAP_BLENDING_MIX )\n		outgoingLight = mix( outgoingLight, envColor.xyz, specularStrength * reflectivity );\n	#elif defined( ENVMAP_BLENDING_ADD )\n		outgoingLight += envColor.xyz * specularStrength * reflectivity;\n	#endif\n#endif";
var envmap_common_pars_fragment = "#ifdef USE_ENVMAP\n	uniform float envMapIntensity;\n	uniform float flipEnvMap;\n	uniform mat3 envMapRotation;\n	#ifdef ENVMAP_TYPE_CUBE\n		uniform samplerCube envMap;\n	#else\n		uniform sampler2D envMap;\n	#endif\n	\n#endif";
var envmap_pars_fragment = "#ifdef USE_ENVMAP\n	uniform float reflectivity;\n	#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP ) || defined( PHONG ) || defined( LAMBERT )\n		#define ENV_WORLDPOS\n	#endif\n	#ifdef ENV_WORLDPOS\n		varying vec3 vWorldPosition;\n		uniform float refractionRatio;\n	#else\n		varying vec3 vReflect;\n	#endif\n#endif";
var envmap_pars_vertex = "#ifdef USE_ENVMAP\n	#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP ) || defined( PHONG ) || defined( LAMBERT )\n		#define ENV_WORLDPOS\n	#endif\n	#ifdef ENV_WORLDPOS\n		\n		varying vec3 vWorldPosition;\n	#else\n		varying vec3 vReflect;\n		uniform float refractionRatio;\n	#endif\n#endif";
var envmap_vertex = "#ifdef USE_ENVMAP\n	#ifdef ENV_WORLDPOS\n		vWorldPosition = worldPosition.xyz;\n	#else\n		vec3 cameraToVertex;\n		if ( isOrthographic ) {\n			cameraToVertex = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );\n		} else {\n			cameraToVertex = normalize( worldPosition.xyz - cameraPosition );\n		}\n		vec3 worldNormal = inverseTransformDirection( transformedNormal, viewMatrix );\n		#ifdef ENVMAP_MODE_REFLECTION\n			vReflect = reflect( cameraToVertex, worldNormal );\n		#else\n			vReflect = refract( cameraToVertex, worldNormal, refractionRatio );\n		#endif\n	#endif\n#endif";
var fog_vertex = "#ifdef USE_FOG\n	vFogDepth = - mvPosition.z;\n#endif";
var fog_pars_vertex = "#ifdef USE_FOG\n	varying float vFogDepth;\n#endif";
var fog_fragment = "#ifdef USE_FOG\n	#ifdef FOG_EXP2\n		float fogFactor = 1.0 - exp( - fogDensity * fogDensity * vFogDepth * vFogDepth );\n	#else\n		float fogFactor = smoothstep( fogNear, fogFar, vFogDepth );\n	#endif\n	gl_FragColor.rgb = mix( gl_FragColor.rgb, fogColor, fogFactor );\n#endif";
var fog_pars_fragment = "#ifdef USE_FOG\n	uniform vec3 fogColor;\n	varying float vFogDepth;\n	#ifdef FOG_EXP2\n		uniform float fogDensity;\n	#else\n		uniform float fogNear;\n		uniform float fogFar;\n	#endif\n#endif";
var gradientmap_pars_fragment = "#ifdef USE_GRADIENTMAP\n	uniform sampler2D gradientMap;\n#endif\nvec3 getGradientIrradiance( vec3 normal, vec3 lightDirection ) {\n	float dotNL = dot( normal, lightDirection );\n	vec2 coord = vec2( dotNL * 0.5 + 0.5, 0.0 );\n	#ifdef USE_GRADIENTMAP\n		return vec3( texture2D( gradientMap, coord ).r );\n	#else\n		vec2 fw = fwidth( coord ) * 0.5;\n		return mix( vec3( 0.7 ), vec3( 1.0 ), smoothstep( 0.7 - fw.x, 0.7 + fw.x, coord.x ) );\n	#endif\n}";
var lightmap_pars_fragment = "#ifdef USE_LIGHTMAP\n	uniform sampler2D lightMap;\n	uniform float lightMapIntensity;\n#endif";
var lights_lambert_fragment = "LambertMaterial material;\nmaterial.diffuseColor = diffuseColor.rgb;\nmaterial.specularStrength = specularStrength;";
var lights_lambert_pars_fragment = "varying vec3 vViewPosition;\nstruct LambertMaterial {\n	vec3 diffuseColor;\n	float specularStrength;\n};\nvoid RE_Direct_Lambert( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in LambertMaterial material, inout ReflectedLight reflectedLight ) {\n	float dotNL = saturate( dot( geometryNormal, directLight.direction ) );\n	vec3 irradiance = dotNL * directLight.color;\n	reflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\nvoid RE_IndirectDiffuse_Lambert( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in LambertMaterial material, inout ReflectedLight reflectedLight ) {\n	reflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\n#define RE_Direct				RE_Direct_Lambert\n#define RE_IndirectDiffuse		RE_IndirectDiffuse_Lambert";
var lights_pars_begin = "uniform bool receiveShadow;\nuniform vec3 ambientLightColor;\n#if defined( USE_LIGHT_PROBES )\n	uniform vec3 lightProbe[ 9 ];\n#endif\nvec3 shGetIrradianceAt( in vec3 normal, in vec3 shCoefficients[ 9 ] ) {\n	float x = normal.x, y = normal.y, z = normal.z;\n	vec3 result = shCoefficients[ 0 ] * 0.886227;\n	result += shCoefficients[ 1 ] * 2.0 * 0.511664 * y;\n	result += shCoefficients[ 2 ] * 2.0 * 0.511664 * z;\n	result += shCoefficients[ 3 ] * 2.0 * 0.511664 * x;\n	result += shCoefficients[ 4 ] * 2.0 * 0.429043 * x * y;\n	result += shCoefficients[ 5 ] * 2.0 * 0.429043 * y * z;\n	result += shCoefficients[ 6 ] * ( 0.743125 * z * z - 0.247708 );\n	result += shCoefficients[ 7 ] * 2.0 * 0.429043 * x * z;\n	result += shCoefficients[ 8 ] * 0.429043 * ( x * x - y * y );\n	return result;\n}\nvec3 getLightProbeIrradiance( const in vec3 lightProbe[ 9 ], const in vec3 normal ) {\n	vec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\n	vec3 irradiance = shGetIrradianceAt( worldNormal, lightProbe );\n	return irradiance;\n}\nvec3 getAmbientLightIrradiance( const in vec3 ambientLightColor ) {\n	vec3 irradiance = ambientLightColor;\n	return irradiance;\n}\nfloat getDistanceAttenuation( const in float lightDistance, const in float cutoffDistance, const in float decayExponent ) {\n	float distanceFalloff = 1.0 / max( pow( lightDistance, decayExponent ), 0.01 );\n	if ( cutoffDistance > 0.0 ) {\n		distanceFalloff *= pow2( saturate( 1.0 - pow4( lightDistance / cutoffDistance ) ) );\n	}\n	return distanceFalloff;\n}\nfloat getSpotAttenuation( const in float coneCosine, const in float penumbraCosine, const in float angleCosine ) {\n	return smoothstep( coneCosine, penumbraCosine, angleCosine );\n}\n#if NUM_DIR_LIGHTS > 0\n	struct DirectionalLight {\n		vec3 direction;\n		vec3 color;\n	};\n	uniform DirectionalLight directionalLights[ NUM_DIR_LIGHTS ];\n	void getDirectionalLightInfo( const in DirectionalLight directionalLight, out IncidentLight light ) {\n		light.color = directionalLight.color;\n		light.direction = directionalLight.direction;\n		light.visible = true;\n	}\n#endif\n#if NUM_POINT_LIGHTS > 0\n	struct PointLight {\n		vec3 position;\n		vec3 color;\n		float distance;\n		float decay;\n	};\n	uniform PointLight pointLights[ NUM_POINT_LIGHTS ];\n	void getPointLightInfo( const in PointLight pointLight, const in vec3 geometryPosition, out IncidentLight light ) {\n		vec3 lVector = pointLight.position - geometryPosition;\n		light.direction = normalize( lVector );\n		float lightDistance = length( lVector );\n		light.color = pointLight.color;\n		light.color *= getDistanceAttenuation( lightDistance, pointLight.distance, pointLight.decay );\n		light.visible = ( light.color != vec3( 0.0 ) );\n	}\n#endif\n#if NUM_SPOT_LIGHTS > 0\n	struct SpotLight {\n		vec3 position;\n		vec3 direction;\n		vec3 color;\n		float distance;\n		float decay;\n		float coneCos;\n		float penumbraCos;\n	};\n	uniform SpotLight spotLights[ NUM_SPOT_LIGHTS ];\n	void getSpotLightInfo( const in SpotLight spotLight, const in vec3 geometryPosition, out IncidentLight light ) {\n		vec3 lVector = spotLight.position - geometryPosition;\n		light.direction = normalize( lVector );\n		float angleCos = dot( light.direction, spotLight.direction );\n		float spotAttenuation = getSpotAttenuation( spotLight.coneCos, spotLight.penumbraCos, angleCos );\n		if ( spotAttenuation > 0.0 ) {\n			float lightDistance = length( lVector );\n			light.color = spotLight.color * spotAttenuation;\n			light.color *= getDistanceAttenuation( lightDistance, spotLight.distance, spotLight.decay );\n			light.visible = ( light.color != vec3( 0.0 ) );\n		} else {\n			light.color = vec3( 0.0 );\n			light.visible = false;\n		}\n	}\n#endif\n#if NUM_RECT_AREA_LIGHTS > 0\n	struct RectAreaLight {\n		vec3 color;\n		vec3 position;\n		vec3 halfWidth;\n		vec3 halfHeight;\n	};\n	uniform sampler2D ltc_1;	uniform sampler2D ltc_2;\n	uniform RectAreaLight rectAreaLights[ NUM_RECT_AREA_LIGHTS ];\n#endif\n#if NUM_HEMI_LIGHTS > 0\n	struct HemisphereLight {\n		vec3 direction;\n		vec3 skyColor;\n		vec3 groundColor;\n	};\n	uniform HemisphereLight hemisphereLights[ NUM_HEMI_LIGHTS ];\n	vec3 getHemisphereLightIrradiance( const in HemisphereLight hemiLight, const in vec3 normal ) {\n		float dotNL = dot( normal, hemiLight.direction );\n		float hemiDiffuseWeight = 0.5 * dotNL + 0.5;\n		vec3 irradiance = mix( hemiLight.groundColor, hemiLight.skyColor, hemiDiffuseWeight );\n		return irradiance;\n	}\n#endif";
var envmap_physical_pars_fragment = "#ifdef USE_ENVMAP\n	vec3 getIBLIrradiance( const in vec3 normal ) {\n		#ifdef ENVMAP_TYPE_CUBE_UV\n			vec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\n			vec4 envMapColor = textureCubeUV( envMap, envMapRotation * worldNormal, 1.0 );\n			return PI * envMapColor.rgb * envMapIntensity;\n		#else\n			return vec3( 0.0 );\n		#endif\n	}\n	vec3 getIBLRadiance( const in vec3 viewDir, const in vec3 normal, const in float roughness ) {\n		#ifdef ENVMAP_TYPE_CUBE_UV\n			vec3 reflectVec = reflect( - viewDir, normal );\n			reflectVec = normalize( mix( reflectVec, normal, roughness * roughness) );\n			reflectVec = inverseTransformDirection( reflectVec, viewMatrix );\n			vec4 envMapColor = textureCubeUV( envMap, envMapRotation * reflectVec, roughness );\n			return envMapColor.rgb * envMapIntensity;\n		#else\n			return vec3( 0.0 );\n		#endif\n	}\n	#ifdef USE_ANISOTROPY\n		vec3 getIBLAnisotropyRadiance( const in vec3 viewDir, const in vec3 normal, const in float roughness, const in vec3 bitangent, const in float anisotropy ) {\n			#ifdef ENVMAP_TYPE_CUBE_UV\n				vec3 bentNormal = cross( bitangent, viewDir );\n				bentNormal = normalize( cross( bentNormal, bitangent ) );\n				bentNormal = normalize( mix( bentNormal, normal, pow2( pow2( 1.0 - anisotropy * ( 1.0 - roughness ) ) ) ) );\n				return getIBLRadiance( viewDir, bentNormal, roughness );\n			#else\n				return vec3( 0.0 );\n			#endif\n		}\n	#endif\n#endif";
var lights_toon_fragment = "ToonMaterial material;\nmaterial.diffuseColor = diffuseColor.rgb;";
var lights_toon_pars_fragment = "varying vec3 vViewPosition;\nstruct ToonMaterial {\n	vec3 diffuseColor;\n};\nvoid RE_Direct_Toon( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in ToonMaterial material, inout ReflectedLight reflectedLight ) {\n	vec3 irradiance = getGradientIrradiance( geometryNormal, directLight.direction ) * directLight.color;\n	reflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\nvoid RE_IndirectDiffuse_Toon( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in ToonMaterial material, inout ReflectedLight reflectedLight ) {\n	reflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\n#define RE_Direct				RE_Direct_Toon\n#define RE_IndirectDiffuse		RE_IndirectDiffuse_Toon";
var lights_phong_fragment = "BlinnPhongMaterial material;\nmaterial.diffuseColor = diffuseColor.rgb;\nmaterial.specularColor = specular;\nmaterial.specularShininess = shininess;\nmaterial.specularStrength = specularStrength;";
var lights_phong_pars_fragment = "varying vec3 vViewPosition;\nstruct BlinnPhongMaterial {\n	vec3 diffuseColor;\n	vec3 specularColor;\n	float specularShininess;\n	float specularStrength;\n};\nvoid RE_Direct_BlinnPhong( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in BlinnPhongMaterial material, inout ReflectedLight reflectedLight ) {\n	float dotNL = saturate( dot( geometryNormal, directLight.direction ) );\n	vec3 irradiance = dotNL * directLight.color;\n	reflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n	reflectedLight.directSpecular += irradiance * BRDF_BlinnPhong( directLight.direction, geometryViewDir, geometryNormal, material.specularColor, material.specularShininess ) * material.specularStrength;\n}\nvoid RE_IndirectDiffuse_BlinnPhong( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in BlinnPhongMaterial material, inout ReflectedLight reflectedLight ) {\n	reflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\n#define RE_Direct				RE_Direct_BlinnPhong\n#define RE_IndirectDiffuse		RE_IndirectDiffuse_BlinnPhong";
var lights_physical_fragment = "PhysicalMaterial material;\nmaterial.diffuseColor = diffuseColor.rgb * ( 1.0 - metalnessFactor );\nvec3 dxy = max( abs( dFdx( nonPerturbedNormal ) ), abs( dFdy( nonPerturbedNormal ) ) );\nfloat geometryRoughness = max( max( dxy.x, dxy.y ), dxy.z );\nmaterial.roughness = max( roughnessFactor, 0.0525 );material.roughness += geometryRoughness;\nmaterial.roughness = min( material.roughness, 1.0 );\n#ifdef IOR\n	material.ior = ior;\n	#ifdef USE_SPECULAR\n		float specularIntensityFactor = specularIntensity;\n		vec3 specularColorFactor = specularColor;\n		#ifdef USE_SPECULAR_COLORMAP\n			specularColorFactor *= texture2D( specularColorMap, vSpecularColorMapUv ).rgb;\n		#endif\n		#ifdef USE_SPECULAR_INTENSITYMAP\n			specularIntensityFactor *= texture2D( specularIntensityMap, vSpecularIntensityMapUv ).a;\n		#endif\n		material.specularF90 = mix( specularIntensityFactor, 1.0, metalnessFactor );\n	#else\n		float specularIntensityFactor = 1.0;\n		vec3 specularColorFactor = vec3( 1.0 );\n		material.specularF90 = 1.0;\n	#endif\n	material.specularColor = mix( min( pow2( ( material.ior - 1.0 ) / ( material.ior + 1.0 ) ) * specularColorFactor, vec3( 1.0 ) ) * specularIntensityFactor, diffuseColor.rgb, metalnessFactor );\n#else\n	material.specularColor = mix( vec3( 0.04 ), diffuseColor.rgb, metalnessFactor );\n	material.specularF90 = 1.0;\n#endif\n#ifdef USE_CLEARCOAT\n	material.clearcoat = clearcoat;\n	material.clearcoatRoughness = clearcoatRoughness;\n	material.clearcoatF0 = vec3( 0.04 );\n	material.clearcoatF90 = 1.0;\n	#ifdef USE_CLEARCOATMAP\n		material.clearcoat *= texture2D( clearcoatMap, vClearcoatMapUv ).x;\n	#endif\n	#ifdef USE_CLEARCOAT_ROUGHNESSMAP\n		material.clearcoatRoughness *= texture2D( clearcoatRoughnessMap, vClearcoatRoughnessMapUv ).y;\n	#endif\n	material.clearcoat = saturate( material.clearcoat );	material.clearcoatRoughness = max( material.clearcoatRoughness, 0.0525 );\n	material.clearcoatRoughness += geometryRoughness;\n	material.clearcoatRoughness = min( material.clearcoatRoughness, 1.0 );\n#endif\n#ifdef USE_DISPERSION\n	material.dispersion = dispersion;\n#endif\n#ifdef USE_IRIDESCENCE\n	material.iridescence = iridescence;\n	material.iridescenceIOR = iridescenceIOR;\n	#ifdef USE_IRIDESCENCEMAP\n		material.iridescence *= texture2D( iridescenceMap, vIridescenceMapUv ).r;\n	#endif\n	#ifdef USE_IRIDESCENCE_THICKNESSMAP\n		material.iridescenceThickness = (iridescenceThicknessMaximum - iridescenceThicknessMinimum) * texture2D( iridescenceThicknessMap, vIridescenceThicknessMapUv ).g + iridescenceThicknessMinimum;\n	#else\n		material.iridescenceThickness = iridescenceThicknessMaximum;\n	#endif\n#endif\n#ifdef USE_SHEEN\n	material.sheenColor = sheenColor;\n	#ifdef USE_SHEEN_COLORMAP\n		material.sheenColor *= texture2D( sheenColorMap, vSheenColorMapUv ).rgb;\n	#endif\n	material.sheenRoughness = clamp( sheenRoughness, 0.07, 1.0 );\n	#ifdef USE_SHEEN_ROUGHNESSMAP\n		material.sheenRoughness *= texture2D( sheenRoughnessMap, vSheenRoughnessMapUv ).a;\n	#endif\n#endif\n#ifdef USE_ANISOTROPY\n	#ifdef USE_ANISOTROPYMAP\n		mat2 anisotropyMat = mat2( anisotropyVector.x, anisotropyVector.y, - anisotropyVector.y, anisotropyVector.x );\n		vec3 anisotropyPolar = texture2D( anisotropyMap, vAnisotropyMapUv ).rgb;\n		vec2 anisotropyV = anisotropyMat * normalize( 2.0 * anisotropyPolar.rg - vec2( 1.0 ) ) * anisotropyPolar.b;\n	#else\n		vec2 anisotropyV = anisotropyVector;\n	#endif\n	material.anisotropy = length( anisotropyV );\n	if( material.anisotropy == 0.0 ) {\n		anisotropyV = vec2( 1.0, 0.0 );\n	} else {\n		anisotropyV /= material.anisotropy;\n		material.anisotropy = saturate( material.anisotropy );\n	}\n	material.alphaT = mix( pow2( material.roughness ), 1.0, pow2( material.anisotropy ) );\n	material.anisotropyT = tbn[ 0 ] * anisotropyV.x + tbn[ 1 ] * anisotropyV.y;\n	material.anisotropyB = tbn[ 1 ] * anisotropyV.x - tbn[ 0 ] * anisotropyV.y;\n#endif";
var lights_physical_pars_fragment = "struct PhysicalMaterial {\n	vec3 diffuseColor;\n	float roughness;\n	vec3 specularColor;\n	float specularF90;\n	float dispersion;\n	#ifdef USE_CLEARCOAT\n		float clearcoat;\n		float clearcoatRoughness;\n		vec3 clearcoatF0;\n		float clearcoatF90;\n	#endif\n	#ifdef USE_IRIDESCENCE\n		float iridescence;\n		float iridescenceIOR;\n		float iridescenceThickness;\n		vec3 iridescenceFresnel;\n		vec3 iridescenceF0;\n	#endif\n	#ifdef USE_SHEEN\n		vec3 sheenColor;\n		float sheenRoughness;\n	#endif\n	#ifdef IOR\n		float ior;\n	#endif\n	#ifdef USE_TRANSMISSION\n		float transmission;\n		float transmissionAlpha;\n		float thickness;\n		float attenuationDistance;\n		vec3 attenuationColor;\n	#endif\n	#ifdef USE_ANISOTROPY\n		float anisotropy;\n		float alphaT;\n		vec3 anisotropyT;\n		vec3 anisotropyB;\n	#endif\n};\nvec3 clearcoatSpecularDirect = vec3( 0.0 );\nvec3 clearcoatSpecularIndirect = vec3( 0.0 );\nvec3 sheenSpecularDirect = vec3( 0.0 );\nvec3 sheenSpecularIndirect = vec3(0.0 );\nvec3 Schlick_to_F0( const in vec3 f, const in float f90, const in float dotVH ) {\n    float x = clamp( 1.0 - dotVH, 0.0, 1.0 );\n    float x2 = x * x;\n    float x5 = clamp( x * x2 * x2, 0.0, 0.9999 );\n    return ( f - vec3( f90 ) * x5 ) / ( 1.0 - x5 );\n}\nfloat V_GGX_SmithCorrelated( const in float alpha, const in float dotNL, const in float dotNV ) {\n	float a2 = pow2( alpha );\n	float gv = dotNL * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNV ) );\n	float gl = dotNV * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNL ) );\n	return 0.5 / max( gv + gl, EPSILON );\n}\nfloat D_GGX( const in float alpha, const in float dotNH ) {\n	float a2 = pow2( alpha );\n	float denom = pow2( dotNH ) * ( a2 - 1.0 ) + 1.0;\n	return RECIPROCAL_PI * a2 / pow2( denom );\n}\n#ifdef USE_ANISOTROPY\n	float V_GGX_SmithCorrelated_Anisotropic( const in float alphaT, const in float alphaB, const in float dotTV, const in float dotBV, const in float dotTL, const in float dotBL, const in float dotNV, const in float dotNL ) {\n		float gv = dotNL * length( vec3( alphaT * dotTV, alphaB * dotBV, dotNV ) );\n		float gl = dotNV * length( vec3( alphaT * dotTL, alphaB * dotBL, dotNL ) );\n		float v = 0.5 / ( gv + gl );\n		return saturate(v);\n	}\n	float D_GGX_Anisotropic( const in float alphaT, const in float alphaB, const in float dotNH, const in float dotTH, const in float dotBH ) {\n		float a2 = alphaT * alphaB;\n		highp vec3 v = vec3( alphaB * dotTH, alphaT * dotBH, a2 * dotNH );\n		highp float v2 = dot( v, v );\n		float w2 = a2 / v2;\n		return RECIPROCAL_PI * a2 * pow2 ( w2 );\n	}\n#endif\n#ifdef USE_CLEARCOAT\n	vec3 BRDF_GGX_Clearcoat( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in PhysicalMaterial material) {\n		vec3 f0 = material.clearcoatF0;\n		float f90 = material.clearcoatF90;\n		float roughness = material.clearcoatRoughness;\n		float alpha = pow2( roughness );\n		vec3 halfDir = normalize( lightDir + viewDir );\n		float dotNL = saturate( dot( normal, lightDir ) );\n		float dotNV = saturate( dot( normal, viewDir ) );\n		float dotNH = saturate( dot( normal, halfDir ) );\n		float dotVH = saturate( dot( viewDir, halfDir ) );\n		vec3 F = F_Schlick( f0, f90, dotVH );\n		float V = V_GGX_SmithCorrelated( alpha, dotNL, dotNV );\n		float D = D_GGX( alpha, dotNH );\n		return F * ( V * D );\n	}\n#endif\nvec3 BRDF_GGX( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in PhysicalMaterial material ) {\n	vec3 f0 = material.specularColor;\n	float f90 = material.specularF90;\n	float roughness = material.roughness;\n	float alpha = pow2( roughness );\n	vec3 halfDir = normalize( lightDir + viewDir );\n	float dotNL = saturate( dot( normal, lightDir ) );\n	float dotNV = saturate( dot( normal, viewDir ) );\n	float dotNH = saturate( dot( normal, halfDir ) );\n	float dotVH = saturate( dot( viewDir, halfDir ) );\n	vec3 F = F_Schlick( f0, f90, dotVH );\n	#ifdef USE_IRIDESCENCE\n		F = mix( F, material.iridescenceFresnel, material.iridescence );\n	#endif\n	#ifdef USE_ANISOTROPY\n		float dotTL = dot( material.anisotropyT, lightDir );\n		float dotTV = dot( material.anisotropyT, viewDir );\n		float dotTH = dot( material.anisotropyT, halfDir );\n		float dotBL = dot( material.anisotropyB, lightDir );\n		float dotBV = dot( material.anisotropyB, viewDir );\n		float dotBH = dot( material.anisotropyB, halfDir );\n		float V = V_GGX_SmithCorrelated_Anisotropic( material.alphaT, alpha, dotTV, dotBV, dotTL, dotBL, dotNV, dotNL );\n		float D = D_GGX_Anisotropic( material.alphaT, alpha, dotNH, dotTH, dotBH );\n	#else\n		float V = V_GGX_SmithCorrelated( alpha, dotNL, dotNV );\n		float D = D_GGX( alpha, dotNH );\n	#endif\n	return F * ( V * D );\n}\nvec2 LTC_Uv( const in vec3 N, const in vec3 V, const in float roughness ) {\n	const float LUT_SIZE = 64.0;\n	const float LUT_SCALE = ( LUT_SIZE - 1.0 ) / LUT_SIZE;\n	const float LUT_BIAS = 0.5 / LUT_SIZE;\n	float dotNV = saturate( dot( N, V ) );\n	vec2 uv = vec2( roughness, sqrt( 1.0 - dotNV ) );\n	uv = uv * LUT_SCALE + LUT_BIAS;\n	return uv;\n}\nfloat LTC_ClippedSphereFormFactor( const in vec3 f ) {\n	float l = length( f );\n	return max( ( l * l + f.z ) / ( l + 1.0 ), 0.0 );\n}\nvec3 LTC_EdgeVectorFormFactor( const in vec3 v1, const in vec3 v2 ) {\n	float x = dot( v1, v2 );\n	float y = abs( x );\n	float a = 0.8543985 + ( 0.4965155 + 0.0145206 * y ) * y;\n	float b = 3.4175940 + ( 4.1616724 + y ) * y;\n	float v = a / b;\n	float theta_sintheta = ( x > 0.0 ) ? v : 0.5 * inversesqrt( max( 1.0 - x * x, 1e-7 ) ) - v;\n	return cross( v1, v2 ) * theta_sintheta;\n}\nvec3 LTC_Evaluate( const in vec3 N, const in vec3 V, const in vec3 P, const in mat3 mInv, const in vec3 rectCoords[ 4 ] ) {\n	vec3 v1 = rectCoords[ 1 ] - rectCoords[ 0 ];\n	vec3 v2 = rectCoords[ 3 ] - rectCoords[ 0 ];\n	vec3 lightNormal = cross( v1, v2 );\n	if( dot( lightNormal, P - rectCoords[ 0 ] ) < 0.0 ) return vec3( 0.0 );\n	vec3 T1, T2;\n	T1 = normalize( V - N * dot( V, N ) );\n	T2 = - cross( N, T1 );\n	mat3 mat = mInv * transposeMat3( mat3( T1, T2, N ) );\n	vec3 coords[ 4 ];\n	coords[ 0 ] = mat * ( rectCoords[ 0 ] - P );\n	coords[ 1 ] = mat * ( rectCoords[ 1 ] - P );\n	coords[ 2 ] = mat * ( rectCoords[ 2 ] - P );\n	coords[ 3 ] = mat * ( rectCoords[ 3 ] - P );\n	coords[ 0 ] = normalize( coords[ 0 ] );\n	coords[ 1 ] = normalize( coords[ 1 ] );\n	coords[ 2 ] = normalize( coords[ 2 ] );\n	coords[ 3 ] = normalize( coords[ 3 ] );\n	vec3 vectorFormFactor = vec3( 0.0 );\n	vectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 0 ], coords[ 1 ] );\n	vectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 1 ], coords[ 2 ] );\n	vectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 2 ], coords[ 3 ] );\n	vectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 3 ], coords[ 0 ] );\n	float result = LTC_ClippedSphereFormFactor( vectorFormFactor );\n	return vec3( result );\n}\n#if defined( USE_SHEEN )\nfloat D_Charlie( float roughness, float dotNH ) {\n	float alpha = pow2( roughness );\n	float invAlpha = 1.0 / alpha;\n	float cos2h = dotNH * dotNH;\n	float sin2h = max( 1.0 - cos2h, 0.0078125 );\n	return ( 2.0 + invAlpha ) * pow( sin2h, invAlpha * 0.5 ) / ( 2.0 * PI );\n}\nfloat V_Neubelt( float dotNV, float dotNL ) {\n	return saturate( 1.0 / ( 4.0 * ( dotNL + dotNV - dotNL * dotNV ) ) );\n}\nvec3 BRDF_Sheen( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, vec3 sheenColor, const in float sheenRoughness ) {\n	vec3 halfDir = normalize( lightDir + viewDir );\n	float dotNL = saturate( dot( normal, lightDir ) );\n	float dotNV = saturate( dot( normal, viewDir ) );\n	float dotNH = saturate( dot( normal, halfDir ) );\n	float D = D_Charlie( sheenRoughness, dotNH );\n	float V = V_Neubelt( dotNV, dotNL );\n	return sheenColor * ( D * V );\n}\n#endif\nfloat IBLSheenBRDF( const in vec3 normal, const in vec3 viewDir, const in float roughness ) {\n	float dotNV = saturate( dot( normal, viewDir ) );\n	float r2 = roughness * roughness;\n	float a = roughness < 0.25 ? -339.2 * r2 + 161.4 * roughness - 25.9 : -8.48 * r2 + 14.3 * roughness - 9.95;\n	float b = roughness < 0.25 ? 44.0 * r2 - 23.7 * roughness + 3.26 : 1.97 * r2 - 3.27 * roughness + 0.72;\n	float DG = exp( a * dotNV + b ) + ( roughness < 0.25 ? 0.0 : 0.1 * ( roughness - 0.25 ) );\n	return saturate( DG * RECIPROCAL_PI );\n}\nvec2 DFGApprox( const in vec3 normal, const in vec3 viewDir, const in float roughness ) {\n	float dotNV = saturate( dot( normal, viewDir ) );\n	const vec4 c0 = vec4( - 1, - 0.0275, - 0.572, 0.022 );\n	const vec4 c1 = vec4( 1, 0.0425, 1.04, - 0.04 );\n	vec4 r = roughness * c0 + c1;\n	float a004 = min( r.x * r.x, exp2( - 9.28 * dotNV ) ) * r.x + r.y;\n	vec2 fab = vec2( - 1.04, 1.04 ) * a004 + r.zw;\n	return fab;\n}\nvec3 EnvironmentBRDF( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float roughness ) {\n	vec2 fab = DFGApprox( normal, viewDir, roughness );\n	return specularColor * fab.x + specularF90 * fab.y;\n}\n#ifdef USE_IRIDESCENCE\nvoid computeMultiscatteringIridescence( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float iridescence, const in vec3 iridescenceF0, const in float roughness, inout vec3 singleScatter, inout vec3 multiScatter ) {\n#else\nvoid computeMultiscattering( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float roughness, inout vec3 singleScatter, inout vec3 multiScatter ) {\n#endif\n	vec2 fab = DFGApprox( normal, viewDir, roughness );\n	#ifdef USE_IRIDESCENCE\n		vec3 Fr = mix( specularColor, iridescenceF0, iridescence );\n	#else\n		vec3 Fr = specularColor;\n	#endif\n	vec3 FssEss = Fr * fab.x + specularF90 * fab.y;\n	float Ess = fab.x + fab.y;\n	float Ems = 1.0 - Ess;\n	vec3 Favg = Fr + ( 1.0 - Fr ) * 0.047619;	vec3 Fms = FssEss * Favg / ( 1.0 - Ems * Favg );\n	singleScatter += FssEss;\n	multiScatter += Fms * Ems;\n}\n#if NUM_RECT_AREA_LIGHTS > 0\n	void RE_Direct_RectArea_Physical( const in RectAreaLight rectAreaLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\n		vec3 normal = geometryNormal;\n		vec3 viewDir = geometryViewDir;\n		vec3 position = geometryPosition;\n		vec3 lightPos = rectAreaLight.position;\n		vec3 halfWidth = rectAreaLight.halfWidth;\n		vec3 halfHeight = rectAreaLight.halfHeight;\n		vec3 lightColor = rectAreaLight.color;\n		float roughness = material.roughness;\n		vec3 rectCoords[ 4 ];\n		rectCoords[ 0 ] = lightPos + halfWidth - halfHeight;		rectCoords[ 1 ] = lightPos - halfWidth - halfHeight;\n		rectCoords[ 2 ] = lightPos - halfWidth + halfHeight;\n		rectCoords[ 3 ] = lightPos + halfWidth + halfHeight;\n		vec2 uv = LTC_Uv( normal, viewDir, roughness );\n		vec4 t1 = texture2D( ltc_1, uv );\n		vec4 t2 = texture2D( ltc_2, uv );\n		mat3 mInv = mat3(\n			vec3( t1.x, 0, t1.y ),\n			vec3(    0, 1,    0 ),\n			vec3( t1.z, 0, t1.w )\n		);\n		vec3 fresnel = ( material.specularColor * t2.x + ( vec3( 1.0 ) - material.specularColor ) * t2.y );\n		reflectedLight.directSpecular += lightColor * fresnel * LTC_Evaluate( normal, viewDir, position, mInv, rectCoords );\n		reflectedLight.directDiffuse += lightColor * material.diffuseColor * LTC_Evaluate( normal, viewDir, position, mat3( 1.0 ), rectCoords );\n	}\n#endif\nvoid RE_Direct_Physical( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\n	float dotNL = saturate( dot( geometryNormal, directLight.direction ) );\n	vec3 irradiance = dotNL * directLight.color;\n	#ifdef USE_CLEARCOAT\n		float dotNLcc = saturate( dot( geometryClearcoatNormal, directLight.direction ) );\n		vec3 ccIrradiance = dotNLcc * directLight.color;\n		clearcoatSpecularDirect += ccIrradiance * BRDF_GGX_Clearcoat( directLight.direction, geometryViewDir, geometryClearcoatNormal, material );\n	#endif\n	#ifdef USE_SHEEN\n		sheenSpecularDirect += irradiance * BRDF_Sheen( directLight.direction, geometryViewDir, geometryNormal, material.sheenColor, material.sheenRoughness );\n	#endif\n	reflectedLight.directSpecular += irradiance * BRDF_GGX( directLight.direction, geometryViewDir, geometryNormal, material );\n	reflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\nvoid RE_IndirectDiffuse_Physical( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\n	reflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\n}\nvoid RE_IndirectSpecular_Physical( const in vec3 radiance, const in vec3 irradiance, const in vec3 clearcoatRadiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight) {\n	#ifdef USE_CLEARCOAT\n		clearcoatSpecularIndirect += clearcoatRadiance * EnvironmentBRDF( geometryClearcoatNormal, geometryViewDir, material.clearcoatF0, material.clearcoatF90, material.clearcoatRoughness );\n	#endif\n	#ifdef USE_SHEEN\n		sheenSpecularIndirect += irradiance * material.sheenColor * IBLSheenBRDF( geometryNormal, geometryViewDir, material.sheenRoughness );\n	#endif\n	vec3 singleScattering = vec3( 0.0 );\n	vec3 multiScattering = vec3( 0.0 );\n	vec3 cosineWeightedIrradiance = irradiance * RECIPROCAL_PI;\n	#ifdef USE_IRIDESCENCE\n		computeMultiscatteringIridescence( geometryNormal, geometryViewDir, material.specularColor, material.specularF90, material.iridescence, material.iridescenceFresnel, material.roughness, singleScattering, multiScattering );\n	#else\n		computeMultiscattering( geometryNormal, geometryViewDir, material.specularColor, material.specularF90, material.roughness, singleScattering, multiScattering );\n	#endif\n	vec3 totalScattering = singleScattering + multiScattering;\n	vec3 diffuse = material.diffuseColor * ( 1.0 - max( max( totalScattering.r, totalScattering.g ), totalScattering.b ) );\n	reflectedLight.indirectSpecular += radiance * singleScattering;\n	reflectedLight.indirectSpecular += multiScattering * cosineWeightedIrradiance;\n	reflectedLight.indirectDiffuse += diffuse * cosineWeightedIrradiance;\n}\n#define RE_Direct				RE_Direct_Physical\n#define RE_Direct_RectArea		RE_Direct_RectArea_Physical\n#define RE_IndirectDiffuse		RE_IndirectDiffuse_Physical\n#define RE_IndirectSpecular		RE_IndirectSpecular_Physical\nfloat computeSpecularOcclusion( const in float dotNV, const in float ambientOcclusion, const in float roughness ) {\n	return saturate( pow( dotNV + ambientOcclusion, exp2( - 16.0 * roughness - 1.0 ) ) - 1.0 + ambientOcclusion );\n}";
var lights_fragment_begin = "\nvec3 geometryPosition = - vViewPosition;\nvec3 geometryNormal = normal;\nvec3 geometryViewDir = ( isOrthographic ) ? vec3( 0, 0, 1 ) : normalize( vViewPosition );\nvec3 geometryClearcoatNormal = vec3( 0.0 );\n#ifdef USE_CLEARCOAT\n	geometryClearcoatNormal = clearcoatNormal;\n#endif\n#ifdef USE_IRIDESCENCE\n	float dotNVi = saturate( dot( normal, geometryViewDir ) );\n	if ( material.iridescenceThickness == 0.0 ) {\n		material.iridescence = 0.0;\n	} else {\n		material.iridescence = saturate( material.iridescence );\n	}\n	if ( material.iridescence > 0.0 ) {\n		material.iridescenceFresnel = evalIridescence( 1.0, material.iridescenceIOR, dotNVi, material.iridescenceThickness, material.specularColor );\n		material.iridescenceF0 = Schlick_to_F0( material.iridescenceFresnel, 1.0, dotNVi );\n	}\n#endif\nIncidentLight directLight;\n#if ( NUM_POINT_LIGHTS > 0 ) && defined( RE_Direct )\n	PointLight pointLight;\n	#if defined( USE_SHADOWMAP ) && NUM_POINT_LIGHT_SHADOWS > 0\n	PointLightShadow pointLightShadow;\n	#endif\n	#pragma unroll_loop_start\n	for ( int i = 0; i < NUM_POINT_LIGHTS; i ++ ) {\n		pointLight = pointLights[ i ];\n		getPointLightInfo( pointLight, geometryPosition, directLight );\n		#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_POINT_LIGHT_SHADOWS )\n		pointLightShadow = pointLightShadows[ i ];\n		directLight.color *= ( directLight.visible && receiveShadow ) ? getPointShadow( pointShadowMap[ i ], pointLightShadow.shadowMapSize, pointLightShadow.shadowIntensity, pointLightShadow.shadowBias, pointLightShadow.shadowRadius, vPointShadowCoord[ i ], pointLightShadow.shadowCameraNear, pointLightShadow.shadowCameraFar ) : 1.0;\n		#endif\n		RE_Direct( directLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n	}\n	#pragma unroll_loop_end\n#endif\n#if ( NUM_SPOT_LIGHTS > 0 ) && defined( RE_Direct )\n	SpotLight spotLight;\n	vec4 spotColor;\n	vec3 spotLightCoord;\n	bool inSpotLightMap;\n	#if defined( USE_SHADOWMAP ) && NUM_SPOT_LIGHT_SHADOWS > 0\n	SpotLightShadow spotLightShadow;\n	#endif\n	#pragma unroll_loop_start\n	for ( int i = 0; i < NUM_SPOT_LIGHTS; i ++ ) {\n		spotLight = spotLights[ i ];\n		getSpotLightInfo( spotLight, geometryPosition, directLight );\n		#if ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS_WITH_MAPS )\n		#define SPOT_LIGHT_MAP_INDEX UNROLLED_LOOP_INDEX\n		#elif ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )\n		#define SPOT_LIGHT_MAP_INDEX NUM_SPOT_LIGHT_MAPS\n		#else\n		#define SPOT_LIGHT_MAP_INDEX ( UNROLLED_LOOP_INDEX - NUM_SPOT_LIGHT_SHADOWS + NUM_SPOT_LIGHT_SHADOWS_WITH_MAPS )\n		#endif\n		#if ( SPOT_LIGHT_MAP_INDEX < NUM_SPOT_LIGHT_MAPS )\n			spotLightCoord = vSpotLightCoord[ i ].xyz / vSpotLightCoord[ i ].w;\n			inSpotLightMap = all( lessThan( abs( spotLightCoord * 2. - 1. ), vec3( 1.0 ) ) );\n			spotColor = texture2D( spotLightMap[ SPOT_LIGHT_MAP_INDEX ], spotLightCoord.xy );\n			directLight.color = inSpotLightMap ? directLight.color * spotColor.rgb : directLight.color;\n		#endif\n		#undef SPOT_LIGHT_MAP_INDEX\n		#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )\n		spotLightShadow = spotLightShadows[ i ];\n		directLight.color *= ( directLight.visible && receiveShadow ) ? getShadow( spotShadowMap[ i ], spotLightShadow.shadowMapSize, spotLightShadow.shadowIntensity, spotLightShadow.shadowBias, spotLightShadow.shadowRadius, vSpotLightCoord[ i ] ) : 1.0;\n		#endif\n		RE_Direct( directLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n	}\n	#pragma unroll_loop_end\n#endif\n#if ( NUM_DIR_LIGHTS > 0 ) && defined( RE_Direct )\n	DirectionalLight directionalLight;\n	#if defined( USE_SHADOWMAP ) && NUM_DIR_LIGHT_SHADOWS > 0\n	DirectionalLightShadow directionalLightShadow;\n	#endif\n	#pragma unroll_loop_start\n	for ( int i = 0; i < NUM_DIR_LIGHTS; i ++ ) {\n		directionalLight = directionalLights[ i ];\n		getDirectionalLightInfo( directionalLight, directLight );\n		#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_DIR_LIGHT_SHADOWS )\n		directionalLightShadow = directionalLightShadows[ i ];\n		directLight.color *= ( directLight.visible && receiveShadow ) ? getShadow( directionalShadowMap[ i ], directionalLightShadow.shadowMapSize, directionalLightShadow.shadowIntensity, directionalLightShadow.shadowBias, directionalLightShadow.shadowRadius, vDirectionalShadowCoord[ i ] ) : 1.0;\n		#endif\n		RE_Direct( directLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n	}\n	#pragma unroll_loop_end\n#endif\n#if ( NUM_RECT_AREA_LIGHTS > 0 ) && defined( RE_Direct_RectArea )\n	RectAreaLight rectAreaLight;\n	#pragma unroll_loop_start\n	for ( int i = 0; i < NUM_RECT_AREA_LIGHTS; i ++ ) {\n		rectAreaLight = rectAreaLights[ i ];\n		RE_Direct_RectArea( rectAreaLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n	}\n	#pragma unroll_loop_end\n#endif\n#if defined( RE_IndirectDiffuse )\n	vec3 iblIrradiance = vec3( 0.0 );\n	vec3 irradiance = getAmbientLightIrradiance( ambientLightColor );\n	#if defined( USE_LIGHT_PROBES )\n		irradiance += getLightProbeIrradiance( lightProbe, geometryNormal );\n	#endif\n	#if ( NUM_HEMI_LIGHTS > 0 )\n		#pragma unroll_loop_start\n		for ( int i = 0; i < NUM_HEMI_LIGHTS; i ++ ) {\n			irradiance += getHemisphereLightIrradiance( hemisphereLights[ i ], geometryNormal );\n		}\n		#pragma unroll_loop_end\n	#endif\n#endif\n#if defined( RE_IndirectSpecular )\n	vec3 radiance = vec3( 0.0 );\n	vec3 clearcoatRadiance = vec3( 0.0 );\n#endif";
var lights_fragment_maps = "#if defined( RE_IndirectDiffuse )\n	#ifdef USE_LIGHTMAP\n		vec4 lightMapTexel = texture2D( lightMap, vLightMapUv );\n		vec3 lightMapIrradiance = lightMapTexel.rgb * lightMapIntensity;\n		irradiance += lightMapIrradiance;\n	#endif\n	#if defined( USE_ENVMAP ) && defined( STANDARD ) && defined( ENVMAP_TYPE_CUBE_UV )\n		iblIrradiance += getIBLIrradiance( geometryNormal );\n	#endif\n#endif\n#if defined( USE_ENVMAP ) && defined( RE_IndirectSpecular )\n	#ifdef USE_ANISOTROPY\n		radiance += getIBLAnisotropyRadiance( geometryViewDir, geometryNormal, material.roughness, material.anisotropyB, material.anisotropy );\n	#else\n		radiance += getIBLRadiance( geometryViewDir, geometryNormal, material.roughness );\n	#endif\n	#ifdef USE_CLEARCOAT\n		clearcoatRadiance += getIBLRadiance( geometryViewDir, geometryClearcoatNormal, material.clearcoatRoughness );\n	#endif\n#endif";
var lights_fragment_end = "#if defined( RE_IndirectDiffuse )\n	RE_IndirectDiffuse( irradiance, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n#endif\n#if defined( RE_IndirectSpecular )\n	RE_IndirectSpecular( radiance, iblIrradiance, clearcoatRadiance, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\n#endif";
var logdepthbuf_fragment = "#if defined( USE_LOGDEPTHBUF )\n	gl_FragDepth = vIsPerspective == 0.0 ? gl_FragCoord.z : log2( vFragDepth ) * logDepthBufFC * 0.5;\n#endif";
var logdepthbuf_pars_fragment = "#if defined( USE_LOGDEPTHBUF )\n	uniform float logDepthBufFC;\n	varying float vFragDepth;\n	varying float vIsPerspective;\n#endif";
var logdepthbuf_pars_vertex = "#ifdef USE_LOGDEPTHBUF\n	varying float vFragDepth;\n	varying float vIsPerspective;\n#endif";
var logdepthbuf_vertex = "#ifdef USE_LOGDEPTHBUF\n	vFragDepth = 1.0 + gl_Position.w;\n	vIsPerspective = float( isPerspectiveMatrix( projectionMatrix ) );\n#endif";
var map_fragment = "#ifdef USE_MAP\n	vec4 sampledDiffuseColor = texture2D( map, vMapUv );\n	#ifdef DECODE_VIDEO_TEXTURE\n		sampledDiffuseColor = vec4( mix( pow( sampledDiffuseColor.rgb * 0.9478672986 + vec3( 0.0521327014 ), vec3( 2.4 ) ), sampledDiffuseColor.rgb * 0.0773993808, vec3( lessThanEqual( sampledDiffuseColor.rgb, vec3( 0.04045 ) ) ) ), sampledDiffuseColor.w );\n	\n	#endif\n	diffuseColor *= sampledDiffuseColor;\n#endif";
var map_pars_fragment = "#ifdef USE_MAP\n	uniform sampler2D map;\n#endif";
var map_particle_fragment = "#if defined( USE_MAP ) || defined( USE_ALPHAMAP )\n	#if defined( USE_POINTS_UV )\n		vec2 uv = vUv;\n	#else\n		vec2 uv = ( uvTransform * vec3( gl_PointCoord.x, 1.0 - gl_PointCoord.y, 1 ) ).xy;\n	#endif\n#endif\n#ifdef USE_MAP\n	diffuseColor *= texture2D( map, uv );\n#endif\n#ifdef USE_ALPHAMAP\n	diffuseColor.a *= texture2D( alphaMap, uv ).g;\n#endif";
var map_particle_pars_fragment = "#if defined( USE_POINTS_UV )\n	varying vec2 vUv;\n#else\n	#if defined( USE_MAP ) || defined( USE_ALPHAMAP )\n		uniform mat3 uvTransform;\n	#endif\n#endif\n#ifdef USE_MAP\n	uniform sampler2D map;\n#endif\n#ifdef USE_ALPHAMAP\n	uniform sampler2D alphaMap;\n#endif";
var metalnessmap_fragment = "float metalnessFactor = metalness;\n#ifdef USE_METALNESSMAP\n	vec4 texelMetalness = texture2D( metalnessMap, vMetalnessMapUv );\n	metalnessFactor *= texelMetalness.b;\n#endif";
var metalnessmap_pars_fragment = "#ifdef USE_METALNESSMAP\n	uniform sampler2D metalnessMap;\n#endif";
var morphinstance_vertex = "#ifdef USE_INSTANCING_MORPH\n	float morphTargetInfluences[ MORPHTARGETS_COUNT ];\n	float morphTargetBaseInfluence = texelFetch( morphTexture, ivec2( 0, gl_InstanceID ), 0 ).r;\n	for ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\n		morphTargetInfluences[i] =  texelFetch( morphTexture, ivec2( i + 1, gl_InstanceID ), 0 ).r;\n	}\n#endif";
var morphcolor_vertex = "#if defined( USE_MORPHCOLORS )\n	vColor *= morphTargetBaseInfluence;\n	for ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\n		#if defined( USE_COLOR_ALPHA )\n			if ( morphTargetInfluences[ i ] != 0.0 ) vColor += getMorph( gl_VertexID, i, 2 ) * morphTargetInfluences[ i ];\n		#elif defined( USE_COLOR )\n			if ( morphTargetInfluences[ i ] != 0.0 ) vColor += getMorph( gl_VertexID, i, 2 ).rgb * morphTargetInfluences[ i ];\n		#endif\n	}\n#endif";
var morphnormal_vertex = "#ifdef USE_MORPHNORMALS\n	objectNormal *= morphTargetBaseInfluence;\n	for ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\n		if ( morphTargetInfluences[ i ] != 0.0 ) objectNormal += getMorph( gl_VertexID, i, 1 ).xyz * morphTargetInfluences[ i ];\n	}\n#endif";
var morphtarget_pars_vertex = "#ifdef USE_MORPHTARGETS\n	#ifndef USE_INSTANCING_MORPH\n		uniform float morphTargetBaseInfluence;\n		uniform float morphTargetInfluences[ MORPHTARGETS_COUNT ];\n	#endif\n	uniform sampler2DArray morphTargetsTexture;\n	uniform ivec2 morphTargetsTextureSize;\n	vec4 getMorph( const in int vertexIndex, const in int morphTargetIndex, const in int offset ) {\n		int texelIndex = vertexIndex * MORPHTARGETS_TEXTURE_STRIDE + offset;\n		int y = texelIndex / morphTargetsTextureSize.x;\n		int x = texelIndex - y * morphTargetsTextureSize.x;\n		ivec3 morphUV = ivec3( x, y, morphTargetIndex );\n		return texelFetch( morphTargetsTexture, morphUV, 0 );\n	}\n#endif";
var morphtarget_vertex = "#ifdef USE_MORPHTARGETS\n	transformed *= morphTargetBaseInfluence;\n	for ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\n		if ( morphTargetInfluences[ i ] != 0.0 ) transformed += getMorph( gl_VertexID, i, 0 ).xyz * morphTargetInfluences[ i ];\n	}\n#endif";
var normal_fragment_begin = "float faceDirection = gl_FrontFacing ? 1.0 : - 1.0;\n#ifdef FLAT_SHADED\n	vec3 fdx = dFdx( vViewPosition );\n	vec3 fdy = dFdy( vViewPosition );\n	vec3 normal = normalize( cross( fdx, fdy ) );\n#else\n	vec3 normal = normalize( vNormal );\n	#ifdef DOUBLE_SIDED\n		normal *= faceDirection;\n	#endif\n#endif\n#if defined( USE_NORMALMAP_TANGENTSPACE ) || defined( USE_CLEARCOAT_NORMALMAP ) || defined( USE_ANISOTROPY )\n	#ifdef USE_TANGENT\n		mat3 tbn = mat3( normalize( vTangent ), normalize( vBitangent ), normal );\n	#else\n		mat3 tbn = getTangentFrame( - vViewPosition, normal,\n		#if defined( USE_NORMALMAP )\n			vNormalMapUv\n		#elif defined( USE_CLEARCOAT_NORMALMAP )\n			vClearcoatNormalMapUv\n		#else\n			vUv\n		#endif\n		);\n	#endif\n	#if defined( DOUBLE_SIDED ) && ! defined( FLAT_SHADED )\n		tbn[0] *= faceDirection;\n		tbn[1] *= faceDirection;\n	#endif\n#endif\n#ifdef USE_CLEARCOAT_NORMALMAP\n	#ifdef USE_TANGENT\n		mat3 tbn2 = mat3( normalize( vTangent ), normalize( vBitangent ), normal );\n	#else\n		mat3 tbn2 = getTangentFrame( - vViewPosition, normal, vClearcoatNormalMapUv );\n	#endif\n	#if defined( DOUBLE_SIDED ) && ! defined( FLAT_SHADED )\n		tbn2[0] *= faceDirection;\n		tbn2[1] *= faceDirection;\n	#endif\n#endif\nvec3 nonPerturbedNormal = normal;";
var normal_fragment_maps = "#ifdef USE_NORMALMAP_OBJECTSPACE\n	normal = texture2D( normalMap, vNormalMapUv ).xyz * 2.0 - 1.0;\n	#ifdef FLIP_SIDED\n		normal = - normal;\n	#endif\n	#ifdef DOUBLE_SIDED\n		normal = normal * faceDirection;\n	#endif\n	normal = normalize( normalMatrix * normal );\n#elif defined( USE_NORMALMAP_TANGENTSPACE )\n	vec3 mapN = texture2D( normalMap, vNormalMapUv ).xyz * 2.0 - 1.0;\n	mapN.xy *= normalScale;\n	normal = normalize( tbn * mapN );\n#elif defined( USE_BUMPMAP )\n	normal = perturbNormalArb( - vViewPosition, normal, dHdxy_fwd(), faceDirection );\n#endif";
var normal_pars_fragment = "#ifndef FLAT_SHADED\n	varying vec3 vNormal;\n	#ifdef USE_TANGENT\n		varying vec3 vTangent;\n		varying vec3 vBitangent;\n	#endif\n#endif";
var normal_pars_vertex = "#ifndef FLAT_SHADED\n	varying vec3 vNormal;\n	#ifdef USE_TANGENT\n		varying vec3 vTangent;\n		varying vec3 vBitangent;\n	#endif\n#endif";
var normal_vertex = "#ifndef FLAT_SHADED\n	vNormal = normalize( transformedNormal );\n	#ifdef USE_TANGENT\n		vTangent = normalize( transformedTangent );\n		vBitangent = normalize( cross( vNormal, vTangent ) * tangent.w );\n	#endif\n#endif";
var normalmap_pars_fragment = "#ifdef USE_NORMALMAP\n	uniform sampler2D normalMap;\n	uniform vec2 normalScale;\n#endif\n#ifdef USE_NORMALMAP_OBJECTSPACE\n	uniform mat3 normalMatrix;\n#endif\n#if ! defined ( USE_TANGENT ) && ( defined ( USE_NORMALMAP_TANGENTSPACE ) || defined ( USE_CLEARCOAT_NORMALMAP ) || defined( USE_ANISOTROPY ) )\n	mat3 getTangentFrame( vec3 eye_pos, vec3 surf_norm, vec2 uv ) {\n		vec3 q0 = dFdx( eye_pos.xyz );\n		vec3 q1 = dFdy( eye_pos.xyz );\n		vec2 st0 = dFdx( uv.st );\n		vec2 st1 = dFdy( uv.st );\n		vec3 N = surf_norm;\n		vec3 q1perp = cross( q1, N );\n		vec3 q0perp = cross( N, q0 );\n		vec3 T = q1perp * st0.x + q0perp * st1.x;\n		vec3 B = q1perp * st0.y + q0perp * st1.y;\n		float det = max( dot( T, T ), dot( B, B ) );\n		float scale = ( det == 0.0 ) ? 0.0 : inversesqrt( det );\n		return mat3( T * scale, B * scale, N );\n	}\n#endif";
var clearcoat_normal_fragment_begin = "#ifdef USE_CLEARCOAT\n	vec3 clearcoatNormal = nonPerturbedNormal;\n#endif";
var clearcoat_normal_fragment_maps = "#ifdef USE_CLEARCOAT_NORMALMAP\n	vec3 clearcoatMapN = texture2D( clearcoatNormalMap, vClearcoatNormalMapUv ).xyz * 2.0 - 1.0;\n	clearcoatMapN.xy *= clearcoatNormalScale;\n	clearcoatNormal = normalize( tbn2 * clearcoatMapN );\n#endif";
var clearcoat_pars_fragment = "#ifdef USE_CLEARCOATMAP\n	uniform sampler2D clearcoatMap;\n#endif\n#ifdef USE_CLEARCOAT_NORMALMAP\n	uniform sampler2D clearcoatNormalMap;\n	uniform vec2 clearcoatNormalScale;\n#endif\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\n	uniform sampler2D clearcoatRoughnessMap;\n#endif";
var iridescence_pars_fragment = "#ifdef USE_IRIDESCENCEMAP\n	uniform sampler2D iridescenceMap;\n#endif\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\n	uniform sampler2D iridescenceThicknessMap;\n#endif";
var opaque_fragment = "#ifdef OPAQUE\ndiffuseColor.a = 1.0;\n#endif\n#ifdef USE_TRANSMISSION\ndiffuseColor.a *= material.transmissionAlpha;\n#endif\ngl_FragColor = vec4( outgoingLight, diffuseColor.a );";
var packing = "vec3 packNormalToRGB( const in vec3 normal ) {\n	return normalize( normal ) * 0.5 + 0.5;\n}\nvec3 unpackRGBToNormal( const in vec3 rgb ) {\n	return 2.0 * rgb.xyz - 1.0;\n}\nconst float PackUpscale = 256. / 255.;const float UnpackDownscale = 255. / 256.;\nconst vec3 PackFactors = vec3( 256. * 256. * 256., 256. * 256., 256. );\nconst vec4 UnpackFactors = UnpackDownscale / vec4( PackFactors, 1. );\nconst float ShiftRight8 = 1. / 256.;\nvec4 packDepthToRGBA( const in float v ) {\n	vec4 r = vec4( fract( v * PackFactors ), v );\n	r.yzw -= r.xyz * ShiftRight8;	return r * PackUpscale;\n}\nfloat unpackRGBAToDepth( const in vec4 v ) {\n	return dot( v, UnpackFactors );\n}\nvec2 packDepthToRG( in highp float v ) {\n	return packDepthToRGBA( v ).yx;\n}\nfloat unpackRGToDepth( const in highp vec2 v ) {\n	return unpackRGBAToDepth( vec4( v.xy, 0.0, 0.0 ) );\n}\nvec4 pack2HalfToRGBA( vec2 v ) {\n	vec4 r = vec4( v.x, fract( v.x * 255.0 ), v.y, fract( v.y * 255.0 ) );\n	return vec4( r.x - r.y / 255.0, r.y, r.z - r.w / 255.0, r.w );\n}\nvec2 unpackRGBATo2Half( vec4 v ) {\n	return vec2( v.x + ( v.y / 255.0 ), v.z + ( v.w / 255.0 ) );\n}\nfloat viewZToOrthographicDepth( const in float viewZ, const in float near, const in float far ) {\n	return ( viewZ + near ) / ( near - far );\n}\nfloat orthographicDepthToViewZ( const in float depth, const in float near, const in float far ) {\n	return depth * ( near - far ) - near;\n}\nfloat viewZToPerspectiveDepth( const in float viewZ, const in float near, const in float far ) {\n	return ( ( near + viewZ ) * far ) / ( ( far - near ) * viewZ );\n}\nfloat perspectiveDepthToViewZ( const in float depth, const in float near, const in float far ) {\n	return ( near * far ) / ( ( far - near ) * depth - far );\n}";
var premultiplied_alpha_fragment = "#ifdef PREMULTIPLIED_ALPHA\n	gl_FragColor.rgb *= gl_FragColor.a;\n#endif";
var project_vertex = "vec4 mvPosition = vec4( transformed, 1.0 );\n#ifdef USE_BATCHING\n	mvPosition = batchingMatrix * mvPosition;\n#endif\n#ifdef USE_INSTANCING\n	mvPosition = instanceMatrix * mvPosition;\n#endif\nmvPosition = modelViewMatrix * mvPosition;\ngl_Position = projectionMatrix * mvPosition;";
var dithering_fragment = "#ifdef DITHERING\n	gl_FragColor.rgb = dithering( gl_FragColor.rgb );\n#endif";
var dithering_pars_fragment = "#ifdef DITHERING\n	vec3 dithering( vec3 color ) {\n		float grid_position = rand( gl_FragCoord.xy );\n		vec3 dither_shift_RGB = vec3( 0.25 / 255.0, -0.25 / 255.0, 0.25 / 255.0 );\n		dither_shift_RGB = mix( 2.0 * dither_shift_RGB, -2.0 * dither_shift_RGB, grid_position );\n		return color + dither_shift_RGB;\n	}\n#endif";
var roughnessmap_fragment = "float roughnessFactor = roughness;\n#ifdef USE_ROUGHNESSMAP\n	vec4 texelRoughness = texture2D( roughnessMap, vRoughnessMapUv );\n	roughnessFactor *= texelRoughness.g;\n#endif";
var roughnessmap_pars_fragment = "#ifdef USE_ROUGHNESSMAP\n	uniform sampler2D roughnessMap;\n#endif";
var shadowmap_pars_fragment = "#if NUM_SPOT_LIGHT_COORDS > 0\n	varying vec4 vSpotLightCoord[ NUM_SPOT_LIGHT_COORDS ];\n#endif\n#if NUM_SPOT_LIGHT_MAPS > 0\n	uniform sampler2D spotLightMap[ NUM_SPOT_LIGHT_MAPS ];\n#endif\n#ifdef USE_SHADOWMAP\n	#if NUM_DIR_LIGHT_SHADOWS > 0\n		uniform sampler2D directionalShadowMap[ NUM_DIR_LIGHT_SHADOWS ];\n		varying vec4 vDirectionalShadowCoord[ NUM_DIR_LIGHT_SHADOWS ];\n		struct DirectionalLightShadow {\n			float shadowIntensity;\n			float shadowBias;\n			float shadowNormalBias;\n			float shadowRadius;\n			vec2 shadowMapSize;\n		};\n		uniform DirectionalLightShadow directionalLightShadows[ NUM_DIR_LIGHT_SHADOWS ];\n	#endif\n	#if NUM_SPOT_LIGHT_SHADOWS > 0\n		uniform sampler2D spotShadowMap[ NUM_SPOT_LIGHT_SHADOWS ];\n		struct SpotLightShadow {\n			float shadowIntensity;\n			float shadowBias;\n			float shadowNormalBias;\n			float shadowRadius;\n			vec2 shadowMapSize;\n		};\n		uniform SpotLightShadow spotLightShadows[ NUM_SPOT_LIGHT_SHADOWS ];\n	#endif\n	#if NUM_POINT_LIGHT_SHADOWS > 0\n		uniform sampler2D pointShadowMap[ NUM_POINT_LIGHT_SHADOWS ];\n		varying vec4 vPointShadowCoord[ NUM_POINT_LIGHT_SHADOWS ];\n		struct PointLightShadow {\n			float shadowIntensity;\n			float shadowBias;\n			float shadowNormalBias;\n			float shadowRadius;\n			vec2 shadowMapSize;\n			float shadowCameraNear;\n			float shadowCameraFar;\n		};\n		uniform PointLightShadow pointLightShadows[ NUM_POINT_LIGHT_SHADOWS ];\n	#endif\n	float texture2DCompare( sampler2D depths, vec2 uv, float compare ) {\n		return step( compare, unpackRGBAToDepth( texture2D( depths, uv ) ) );\n	}\n	vec2 texture2DDistribution( sampler2D shadow, vec2 uv ) {\n		return unpackRGBATo2Half( texture2D( shadow, uv ) );\n	}\n	float VSMShadow (sampler2D shadow, vec2 uv, float compare ){\n		float occlusion = 1.0;\n		vec2 distribution = texture2DDistribution( shadow, uv );\n		float hard_shadow = step( compare , distribution.x );\n		if (hard_shadow != 1.0 ) {\n			float distance = compare - distribution.x ;\n			float variance = max( 0.00000, distribution.y * distribution.y );\n			float softness_probability = variance / (variance + distance * distance );			softness_probability = clamp( ( softness_probability - 0.3 ) / ( 0.95 - 0.3 ), 0.0, 1.0 );			occlusion = clamp( max( hard_shadow, softness_probability ), 0.0, 1.0 );\n		}\n		return occlusion;\n	}\n	float getShadow( sampler2D shadowMap, vec2 shadowMapSize, float shadowIntensity, float shadowBias, float shadowRadius, vec4 shadowCoord ) {\n		float shadow = 1.0;\n		shadowCoord.xyz /= shadowCoord.w;\n		shadowCoord.z += shadowBias;\n		bool inFrustum = shadowCoord.x >= 0.0 && shadowCoord.x <= 1.0 && shadowCoord.y >= 0.0 && shadowCoord.y <= 1.0;\n		bool frustumTest = inFrustum && shadowCoord.z <= 1.0;\n		if ( frustumTest ) {\n		#if defined( SHADOWMAP_TYPE_PCF )\n			vec2 texelSize = vec2( 1.0 ) / shadowMapSize;\n			float dx0 = - texelSize.x * shadowRadius;\n			float dy0 = - texelSize.y * shadowRadius;\n			float dx1 = + texelSize.x * shadowRadius;\n			float dy1 = + texelSize.y * shadowRadius;\n			float dx2 = dx0 / 2.0;\n			float dy2 = dy0 / 2.0;\n			float dx3 = dx1 / 2.0;\n			float dy3 = dy1 / 2.0;\n			shadow = (\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, dy0 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy0 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, dy0 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, dy2 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy2 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, dy2 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, 0.0 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, 0.0 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy, shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, 0.0 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, 0.0 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, dy3 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy3 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, dy3 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, dy1 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy1 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, dy1 ), shadowCoord.z )\n			) * ( 1.0 / 17.0 );\n		#elif defined( SHADOWMAP_TYPE_PCF_SOFT )\n			vec2 texelSize = vec2( 1.0 ) / shadowMapSize;\n			float dx = texelSize.x;\n			float dy = texelSize.y;\n			vec2 uv = shadowCoord.xy;\n			vec2 f = fract( uv * shadowMapSize + 0.5 );\n			uv -= f * texelSize;\n			shadow = (\n				texture2DCompare( shadowMap, uv, shadowCoord.z ) +\n				texture2DCompare( shadowMap, uv + vec2( dx, 0.0 ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, uv + vec2( 0.0, dy ), shadowCoord.z ) +\n				texture2DCompare( shadowMap, uv + texelSize, shadowCoord.z ) +\n				mix( texture2DCompare( shadowMap, uv + vec2( -dx, 0.0 ), shadowCoord.z ),\n					 texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, 0.0 ), shadowCoord.z ),\n					 f.x ) +\n				mix( texture2DCompare( shadowMap, uv + vec2( -dx, dy ), shadowCoord.z ),\n					 texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, dy ), shadowCoord.z ),\n					 f.x ) +\n				mix( texture2DCompare( shadowMap, uv + vec2( 0.0, -dy ), shadowCoord.z ),\n					 texture2DCompare( shadowMap, uv + vec2( 0.0, 2.0 * dy ), shadowCoord.z ),\n					 f.y ) +\n				mix( texture2DCompare( shadowMap, uv + vec2( dx, -dy ), shadowCoord.z ),\n					 texture2DCompare( shadowMap, uv + vec2( dx, 2.0 * dy ), shadowCoord.z ),\n					 f.y ) +\n				mix( mix( texture2DCompare( shadowMap, uv + vec2( -dx, -dy ), shadowCoord.z ),\n						  texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, -dy ), shadowCoord.z ),\n						  f.x ),\n					 mix( texture2DCompare( shadowMap, uv + vec2( -dx, 2.0 * dy ), shadowCoord.z ),\n						  texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, 2.0 * dy ), shadowCoord.z ),\n						  f.x ),\n					 f.y )\n			) * ( 1.0 / 9.0 );\n		#elif defined( SHADOWMAP_TYPE_VSM )\n			shadow = VSMShadow( shadowMap, shadowCoord.xy, shadowCoord.z );\n		#else\n			shadow = texture2DCompare( shadowMap, shadowCoord.xy, shadowCoord.z );\n		#endif\n		}\n		return mix( 1.0, shadow, shadowIntensity );\n	}\n	vec2 cubeToUV( vec3 v, float texelSizeY ) {\n		vec3 absV = abs( v );\n		float scaleToCube = 1.0 / max( absV.x, max( absV.y, absV.z ) );\n		absV *= scaleToCube;\n		v *= scaleToCube * ( 1.0 - 2.0 * texelSizeY );\n		vec2 planar = v.xy;\n		float almostATexel = 1.5 * texelSizeY;\n		float almostOne = 1.0 - almostATexel;\n		if ( absV.z >= almostOne ) {\n			if ( v.z > 0.0 )\n				planar.x = 4.0 - v.x;\n		} else if ( absV.x >= almostOne ) {\n			float signX = sign( v.x );\n			planar.x = v.z * signX + 2.0 * signX;\n		} else if ( absV.y >= almostOne ) {\n			float signY = sign( v.y );\n			planar.x = v.x + 2.0 * signY + 2.0;\n			planar.y = v.z * signY - 2.0;\n		}\n		return vec2( 0.125, 0.25 ) * planar + vec2( 0.375, 0.75 );\n	}\n	float getPointShadow( sampler2D shadowMap, vec2 shadowMapSize, float shadowIntensity, float shadowBias, float shadowRadius, vec4 shadowCoord, float shadowCameraNear, float shadowCameraFar ) {\n		float shadow = 1.0;\n		vec3 lightToPosition = shadowCoord.xyz;\n		\n		float lightToPositionLength = length( lightToPosition );\n		if ( lightToPositionLength - shadowCameraFar <= 0.0 && lightToPositionLength - shadowCameraNear >= 0.0 ) {\n			float dp = ( lightToPositionLength - shadowCameraNear ) / ( shadowCameraFar - shadowCameraNear );			dp += shadowBias;\n			vec3 bd3D = normalize( lightToPosition );\n			vec2 texelSize = vec2( 1.0 ) / ( shadowMapSize * vec2( 4.0, 2.0 ) );\n			#if defined( SHADOWMAP_TYPE_PCF ) || defined( SHADOWMAP_TYPE_PCF_SOFT ) || defined( SHADOWMAP_TYPE_VSM )\n				vec2 offset = vec2( - 1, 1 ) * shadowRadius * texelSize.y;\n				shadow = (\n					texture2DCompare( shadowMap, cubeToUV( bd3D + offset.xyy, texelSize.y ), dp ) +\n					texture2DCompare( shadowMap, cubeToUV( bd3D + offset.yyy, texelSize.y ), dp ) +\n					texture2DCompare( shadowMap, cubeToUV( bd3D + offset.xyx, texelSize.y ), dp ) +\n					texture2DCompare( shadowMap, cubeToUV( bd3D + offset.yyx, texelSize.y ), dp ) +\n					texture2DCompare( shadowMap, cubeToUV( bd3D, texelSize.y ), dp ) +\n					texture2DCompare( shadowMap, cubeToUV( bd3D + offset.xxy, texelSize.y ), dp ) +\n					texture2DCompare( shadowMap, cubeToUV( bd3D + offset.yxy, texelSize.y ), dp ) +\n					texture2DCompare( shadowMap, cubeToUV( bd3D + offset.xxx, texelSize.y ), dp ) +\n					texture2DCompare( shadowMap, cubeToUV( bd3D + offset.yxx, texelSize.y ), dp )\n				) * ( 1.0 / 9.0 );\n			#else\n				shadow = texture2DCompare( shadowMap, cubeToUV( bd3D, texelSize.y ), dp );\n			#endif\n		}\n		return mix( 1.0, shadow, shadowIntensity );\n	}\n#endif";
var shadowmap_pars_vertex = "#if NUM_SPOT_LIGHT_COORDS > 0\n	uniform mat4 spotLightMatrix[ NUM_SPOT_LIGHT_COORDS ];\n	varying vec4 vSpotLightCoord[ NUM_SPOT_LIGHT_COORDS ];\n#endif\n#ifdef USE_SHADOWMAP\n	#if NUM_DIR_LIGHT_SHADOWS > 0\n		uniform mat4 directionalShadowMatrix[ NUM_DIR_LIGHT_SHADOWS ];\n		varying vec4 vDirectionalShadowCoord[ NUM_DIR_LIGHT_SHADOWS ];\n		struct DirectionalLightShadow {\n			float shadowIntensity;\n			float shadowBias;\n			float shadowNormalBias;\n			float shadowRadius;\n			vec2 shadowMapSize;\n		};\n		uniform DirectionalLightShadow directionalLightShadows[ NUM_DIR_LIGHT_SHADOWS ];\n	#endif\n	#if NUM_SPOT_LIGHT_SHADOWS > 0\n		struct SpotLightShadow {\n			float shadowIntensity;\n			float shadowBias;\n			float shadowNormalBias;\n			float shadowRadius;\n			vec2 shadowMapSize;\n		};\n		uniform SpotLightShadow spotLightShadows[ NUM_SPOT_LIGHT_SHADOWS ];\n	#endif\n	#if NUM_POINT_LIGHT_SHADOWS > 0\n		uniform mat4 pointShadowMatrix[ NUM_POINT_LIGHT_SHADOWS ];\n		varying vec4 vPointShadowCoord[ NUM_POINT_LIGHT_SHADOWS ];\n		struct PointLightShadow {\n			float shadowIntensity;\n			float shadowBias;\n			float shadowNormalBias;\n			float shadowRadius;\n			vec2 shadowMapSize;\n			float shadowCameraNear;\n			float shadowCameraFar;\n		};\n		uniform PointLightShadow pointLightShadows[ NUM_POINT_LIGHT_SHADOWS ];\n	#endif\n#endif";
var shadowmap_vertex = "#if ( defined( USE_SHADOWMAP ) && ( NUM_DIR_LIGHT_SHADOWS > 0 || NUM_POINT_LIGHT_SHADOWS > 0 ) ) || ( NUM_SPOT_LIGHT_COORDS > 0 )\n	vec3 shadowWorldNormal = inverseTransformDirection( transformedNormal, viewMatrix );\n	vec4 shadowWorldPosition;\n#endif\n#if defined( USE_SHADOWMAP )\n	#if NUM_DIR_LIGHT_SHADOWS > 0\n		#pragma unroll_loop_start\n		for ( int i = 0; i < NUM_DIR_LIGHT_SHADOWS; i ++ ) {\n			shadowWorldPosition = worldPosition + vec4( shadowWorldNormal * directionalLightShadows[ i ].shadowNormalBias, 0 );\n			vDirectionalShadowCoord[ i ] = directionalShadowMatrix[ i ] * shadowWorldPosition;\n		}\n		#pragma unroll_loop_end\n	#endif\n	#if NUM_POINT_LIGHT_SHADOWS > 0\n		#pragma unroll_loop_start\n		for ( int i = 0; i < NUM_POINT_LIGHT_SHADOWS; i ++ ) {\n			shadowWorldPosition = worldPosition + vec4( shadowWorldNormal * pointLightShadows[ i ].shadowNormalBias, 0 );\n			vPointShadowCoord[ i ] = pointShadowMatrix[ i ] * shadowWorldPosition;\n		}\n		#pragma unroll_loop_end\n	#endif\n#endif\n#if NUM_SPOT_LIGHT_COORDS > 0\n	#pragma unroll_loop_start\n	for ( int i = 0; i < NUM_SPOT_LIGHT_COORDS; i ++ ) {\n		shadowWorldPosition = worldPosition;\n		#if ( defined( USE_SHADOWMAP ) && UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )\n			shadowWorldPosition.xyz += shadowWorldNormal * spotLightShadows[ i ].shadowNormalBias;\n		#endif\n		vSpotLightCoord[ i ] = spotLightMatrix[ i ] * shadowWorldPosition;\n	}\n	#pragma unroll_loop_end\n#endif";
var shadowmask_pars_fragment = "float getShadowMask() {\n	float shadow = 1.0;\n	#ifdef USE_SHADOWMAP\n	#if NUM_DIR_LIGHT_SHADOWS > 0\n	DirectionalLightShadow directionalLight;\n	#pragma unroll_loop_start\n	for ( int i = 0; i < NUM_DIR_LIGHT_SHADOWS; i ++ ) {\n		directionalLight = directionalLightShadows[ i ];\n		shadow *= receiveShadow ? getShadow( directionalShadowMap[ i ], directionalLight.shadowMapSize, directionalLight.shadowIntensity, directionalLight.shadowBias, directionalLight.shadowRadius, vDirectionalShadowCoord[ i ] ) : 1.0;\n	}\n	#pragma unroll_loop_end\n	#endif\n	#if NUM_SPOT_LIGHT_SHADOWS > 0\n	SpotLightShadow spotLight;\n	#pragma unroll_loop_start\n	for ( int i = 0; i < NUM_SPOT_LIGHT_SHADOWS; i ++ ) {\n		spotLight = spotLightShadows[ i ];\n		shadow *= receiveShadow ? getShadow( spotShadowMap[ i ], spotLight.shadowMapSize, spotLight.shadowIntensity, spotLight.shadowBias, spotLight.shadowRadius, vSpotLightCoord[ i ] ) : 1.0;\n	}\n	#pragma unroll_loop_end\n	#endif\n	#if NUM_POINT_LIGHT_SHADOWS > 0\n	PointLightShadow pointLight;\n	#pragma unroll_loop_start\n	for ( int i = 0; i < NUM_POINT_LIGHT_SHADOWS; i ++ ) {\n		pointLight = pointLightShadows[ i ];\n		shadow *= receiveShadow ? getPointShadow( pointShadowMap[ i ], pointLight.shadowMapSize, pointLight.shadowIntensity, pointLight.shadowBias, pointLight.shadowRadius, vPointShadowCoord[ i ], pointLight.shadowCameraNear, pointLight.shadowCameraFar ) : 1.0;\n	}\n	#pragma unroll_loop_end\n	#endif\n	#endif\n	return shadow;\n}";
var skinbase_vertex = "#ifdef USE_SKINNING\n	mat4 boneMatX = getBoneMatrix( skinIndex.x );\n	mat4 boneMatY = getBoneMatrix( skinIndex.y );\n	mat4 boneMatZ = getBoneMatrix( skinIndex.z );\n	mat4 boneMatW = getBoneMatrix( skinIndex.w );\n#endif";
var skinning_pars_vertex = "#ifdef USE_SKINNING\n	uniform mat4 bindMatrix;\n	uniform mat4 bindMatrixInverse;\n	uniform highp sampler2D boneTexture;\n	mat4 getBoneMatrix( const in float i ) {\n		int size = textureSize( boneTexture, 0 ).x;\n		int j = int( i ) * 4;\n		int x = j % size;\n		int y = j / size;\n		vec4 v1 = texelFetch( boneTexture, ivec2( x, y ), 0 );\n		vec4 v2 = texelFetch( boneTexture, ivec2( x + 1, y ), 0 );\n		vec4 v3 = texelFetch( boneTexture, ivec2( x + 2, y ), 0 );\n		vec4 v4 = texelFetch( boneTexture, ivec2( x + 3, y ), 0 );\n		return mat4( v1, v2, v3, v4 );\n	}\n#endif";
var skinning_vertex = "#ifdef USE_SKINNING\n	vec4 skinVertex = bindMatrix * vec4( transformed, 1.0 );\n	vec4 skinned = vec4( 0.0 );\n	skinned += boneMatX * skinVertex * skinWeight.x;\n	skinned += boneMatY * skinVertex * skinWeight.y;\n	skinned += boneMatZ * skinVertex * skinWeight.z;\n	skinned += boneMatW * skinVertex * skinWeight.w;\n	transformed = ( bindMatrixInverse * skinned ).xyz;\n#endif";
var skinnormal_vertex = "#ifdef USE_SKINNING\n	mat4 skinMatrix = mat4( 0.0 );\n	skinMatrix += skinWeight.x * boneMatX;\n	skinMatrix += skinWeight.y * boneMatY;\n	skinMatrix += skinWeight.z * boneMatZ;\n	skinMatrix += skinWeight.w * boneMatW;\n	skinMatrix = bindMatrixInverse * skinMatrix * bindMatrix;\n	objectNormal = vec4( skinMatrix * vec4( objectNormal, 0.0 ) ).xyz;\n	#ifdef USE_TANGENT\n		objectTangent = vec4( skinMatrix * vec4( objectTangent, 0.0 ) ).xyz;\n	#endif\n#endif";
var specularmap_fragment = "float specularStrength;\n#ifdef USE_SPECULARMAP\n	vec4 texelSpecular = texture2D( specularMap, vSpecularMapUv );\n	specularStrength = texelSpecular.r;\n#else\n	specularStrength = 1.0;\n#endif";
var specularmap_pars_fragment = "#ifdef USE_SPECULARMAP\n	uniform sampler2D specularMap;\n#endif";
var tonemapping_fragment = "#if defined( TONE_MAPPING )\n	gl_FragColor.rgb = toneMapping( gl_FragColor.rgb );\n#endif";
var tonemapping_pars_fragment = "#ifndef saturate\n#define saturate( a ) clamp( a, 0.0, 1.0 )\n#endif\nuniform float toneMappingExposure;\nvec3 LinearToneMapping( vec3 color ) {\n	return saturate( toneMappingExposure * color );\n}\nvec3 ReinhardToneMapping( vec3 color ) {\n	color *= toneMappingExposure;\n	return saturate( color / ( vec3( 1.0 ) + color ) );\n}\nvec3 OptimizedCineonToneMapping( vec3 color ) {\n	color *= toneMappingExposure;\n	color = max( vec3( 0.0 ), color - 0.004 );\n	return pow( ( color * ( 6.2 * color + 0.5 ) ) / ( color * ( 6.2 * color + 1.7 ) + 0.06 ), vec3( 2.2 ) );\n}\nvec3 RRTAndODTFit( vec3 v ) {\n	vec3 a = v * ( v + 0.0245786 ) - 0.000090537;\n	vec3 b = v * ( 0.983729 * v + 0.4329510 ) + 0.238081;\n	return a / b;\n}\nvec3 ACESFilmicToneMapping( vec3 color ) {\n	const mat3 ACESInputMat = mat3(\n		vec3( 0.59719, 0.07600, 0.02840 ),		vec3( 0.35458, 0.90834, 0.13383 ),\n		vec3( 0.04823, 0.01566, 0.83777 )\n	);\n	const mat3 ACESOutputMat = mat3(\n		vec3(  1.60475, -0.10208, -0.00327 ),		vec3( -0.53108,  1.10813, -0.07276 ),\n		vec3( -0.07367, -0.00605,  1.07602 )\n	);\n	color *= toneMappingExposure / 0.6;\n	color = ACESInputMat * color;\n	color = RRTAndODTFit( color );\n	color = ACESOutputMat * color;\n	return saturate( color );\n}\nconst mat3 LINEAR_REC2020_TO_LINEAR_SRGB = mat3(\n	vec3( 1.6605, - 0.1246, - 0.0182 ),\n	vec3( - 0.5876, 1.1329, - 0.1006 ),\n	vec3( - 0.0728, - 0.0083, 1.1187 )\n);\nconst mat3 LINEAR_SRGB_TO_LINEAR_REC2020 = mat3(\n	vec3( 0.6274, 0.0691, 0.0164 ),\n	vec3( 0.3293, 0.9195, 0.0880 ),\n	vec3( 0.0433, 0.0113, 0.8956 )\n);\nvec3 agxDefaultContrastApprox( vec3 x ) {\n	vec3 x2 = x * x;\n	vec3 x4 = x2 * x2;\n	return + 15.5 * x4 * x2\n		- 40.14 * x4 * x\n		+ 31.96 * x4\n		- 6.868 * x2 * x\n		+ 0.4298 * x2\n		+ 0.1191 * x\n		- 0.00232;\n}\nvec3 AgXToneMapping( vec3 color ) {\n	const mat3 AgXInsetMatrix = mat3(\n		vec3( 0.856627153315983, 0.137318972929847, 0.11189821299995 ),\n		vec3( 0.0951212405381588, 0.761241990602591, 0.0767994186031903 ),\n		vec3( 0.0482516061458583, 0.101439036467562, 0.811302368396859 )\n	);\n	const mat3 AgXOutsetMatrix = mat3(\n		vec3( 1.1271005818144368, - 0.1413297634984383, - 0.14132976349843826 ),\n		vec3( - 0.11060664309660323, 1.157823702216272, - 0.11060664309660294 ),\n		vec3( - 0.016493938717834573, - 0.016493938717834257, 1.2519364065950405 )\n	);\n	const float AgxMinEv = - 12.47393;	const float AgxMaxEv = 4.026069;\n	color *= toneMappingExposure;\n	color = LINEAR_SRGB_TO_LINEAR_REC2020 * color;\n	color = AgXInsetMatrix * color;\n	color = max( color, 1e-10 );	color = log2( color );\n	color = ( color - AgxMinEv ) / ( AgxMaxEv - AgxMinEv );\n	color = clamp( color, 0.0, 1.0 );\n	color = agxDefaultContrastApprox( color );\n	color = AgXOutsetMatrix * color;\n	color = pow( max( vec3( 0.0 ), color ), vec3( 2.2 ) );\n	color = LINEAR_REC2020_TO_LINEAR_SRGB * color;\n	color = clamp( color, 0.0, 1.0 );\n	return color;\n}\nvec3 NeutralToneMapping( vec3 color ) {\n	const float StartCompression = 0.8 - 0.04;\n	const float Desaturation = 0.15;\n	color *= toneMappingExposure;\n	float x = min( color.r, min( color.g, color.b ) );\n	float offset = x < 0.08 ? x - 6.25 * x * x : 0.04;\n	color -= offset;\n	float peak = max( color.r, max( color.g, color.b ) );\n	if ( peak < StartCompression ) return color;\n	float d = 1. - StartCompression;\n	float newPeak = 1. - d * d / ( peak + d - StartCompression );\n	color *= newPeak / peak;\n	float g = 1. - 1. / ( Desaturation * ( peak - newPeak ) + 1. );\n	return mix( color, vec3( newPeak ), g );\n}\nvec3 CustomToneMapping( vec3 color ) { return color; }";
var transmission_fragment = "#ifdef USE_TRANSMISSION\n	material.transmission = transmission;\n	material.transmissionAlpha = 1.0;\n	material.thickness = thickness;\n	material.attenuationDistance = attenuationDistance;\n	material.attenuationColor = attenuationColor;\n	#ifdef USE_TRANSMISSIONMAP\n		material.transmission *= texture2D( transmissionMap, vTransmissionMapUv ).r;\n	#endif\n	#ifdef USE_THICKNESSMAP\n		material.thickness *= texture2D( thicknessMap, vThicknessMapUv ).g;\n	#endif\n	vec3 pos = vWorldPosition;\n	vec3 v = normalize( cameraPosition - pos );\n	vec3 n = inverseTransformDirection( normal, viewMatrix );\n	vec4 transmitted = getIBLVolumeRefraction(\n		n, v, material.roughness, material.diffuseColor, material.specularColor, material.specularF90,\n		pos, modelMatrix, viewMatrix, projectionMatrix, material.dispersion, material.ior, material.thickness,\n		material.attenuationColor, material.attenuationDistance );\n	material.transmissionAlpha = mix( material.transmissionAlpha, transmitted.a, material.transmission );\n	totalDiffuse = mix( totalDiffuse, transmitted.rgb, material.transmission );\n#endif";
var transmission_pars_fragment = "#ifdef USE_TRANSMISSION\n	uniform float transmission;\n	uniform float thickness;\n	uniform float attenuationDistance;\n	uniform vec3 attenuationColor;\n	#ifdef USE_TRANSMISSIONMAP\n		uniform sampler2D transmissionMap;\n	#endif\n	#ifdef USE_THICKNESSMAP\n		uniform sampler2D thicknessMap;\n	#endif\n	uniform vec2 transmissionSamplerSize;\n	uniform sampler2D transmissionSamplerMap;\n	uniform mat4 modelMatrix;\n	uniform mat4 projectionMatrix;\n	varying vec3 vWorldPosition;\n	float w0( float a ) {\n		return ( 1.0 / 6.0 ) * ( a * ( a * ( - a + 3.0 ) - 3.0 ) + 1.0 );\n	}\n	float w1( float a ) {\n		return ( 1.0 / 6.0 ) * ( a *  a * ( 3.0 * a - 6.0 ) + 4.0 );\n	}\n	float w2( float a ){\n		return ( 1.0 / 6.0 ) * ( a * ( a * ( - 3.0 * a + 3.0 ) + 3.0 ) + 1.0 );\n	}\n	float w3( float a ) {\n		return ( 1.0 / 6.0 ) * ( a * a * a );\n	}\n	float g0( float a ) {\n		return w0( a ) + w1( a );\n	}\n	float g1( float a ) {\n		return w2( a ) + w3( a );\n	}\n	float h0( float a ) {\n		return - 1.0 + w1( a ) / ( w0( a ) + w1( a ) );\n	}\n	float h1( float a ) {\n		return 1.0 + w3( a ) / ( w2( a ) + w3( a ) );\n	}\n	vec4 bicubic( sampler2D tex, vec2 uv, vec4 texelSize, float lod ) {\n		uv = uv * texelSize.zw + 0.5;\n		vec2 iuv = floor( uv );\n		vec2 fuv = fract( uv );\n		float g0x = g0( fuv.x );\n		float g1x = g1( fuv.x );\n		float h0x = h0( fuv.x );\n		float h1x = h1( fuv.x );\n		float h0y = h0( fuv.y );\n		float h1y = h1( fuv.y );\n		vec2 p0 = ( vec2( iuv.x + h0x, iuv.y + h0y ) - 0.5 ) * texelSize.xy;\n		vec2 p1 = ( vec2( iuv.x + h1x, iuv.y + h0y ) - 0.5 ) * texelSize.xy;\n		vec2 p2 = ( vec2( iuv.x + h0x, iuv.y + h1y ) - 0.5 ) * texelSize.xy;\n		vec2 p3 = ( vec2( iuv.x + h1x, iuv.y + h1y ) - 0.5 ) * texelSize.xy;\n		return g0( fuv.y ) * ( g0x * textureLod( tex, p0, lod ) + g1x * textureLod( tex, p1, lod ) ) +\n			g1( fuv.y ) * ( g0x * textureLod( tex, p2, lod ) + g1x * textureLod( tex, p3, lod ) );\n	}\n	vec4 textureBicubic( sampler2D sampler, vec2 uv, float lod ) {\n		vec2 fLodSize = vec2( textureSize( sampler, int( lod ) ) );\n		vec2 cLodSize = vec2( textureSize( sampler, int( lod + 1.0 ) ) );\n		vec2 fLodSizeInv = 1.0 / fLodSize;\n		vec2 cLodSizeInv = 1.0 / cLodSize;\n		vec4 fSample = bicubic( sampler, uv, vec4( fLodSizeInv, fLodSize ), floor( lod ) );\n		vec4 cSample = bicubic( sampler, uv, vec4( cLodSizeInv, cLodSize ), ceil( lod ) );\n		return mix( fSample, cSample, fract( lod ) );\n	}\n	vec3 getVolumeTransmissionRay( const in vec3 n, const in vec3 v, const in float thickness, const in float ior, const in mat4 modelMatrix ) {\n		vec3 refractionVector = refract( - v, normalize( n ), 1.0 / ior );\n		vec3 modelScale;\n		modelScale.x = length( vec3( modelMatrix[ 0 ].xyz ) );\n		modelScale.y = length( vec3( modelMatrix[ 1 ].xyz ) );\n		modelScale.z = length( vec3( modelMatrix[ 2 ].xyz ) );\n		return normalize( refractionVector ) * thickness * modelScale;\n	}\n	float applyIorToRoughness( const in float roughness, const in float ior ) {\n		return roughness * clamp( ior * 2.0 - 2.0, 0.0, 1.0 );\n	}\n	vec4 getTransmissionSample( const in vec2 fragCoord, const in float roughness, const in float ior ) {\n		float lod = log2( transmissionSamplerSize.x ) * applyIorToRoughness( roughness, ior );\n		return textureBicubic( transmissionSamplerMap, fragCoord.xy, lod );\n	}\n	vec3 volumeAttenuation( const in float transmissionDistance, const in vec3 attenuationColor, const in float attenuationDistance ) {\n		if ( isinf( attenuationDistance ) ) {\n			return vec3( 1.0 );\n		} else {\n			vec3 attenuationCoefficient = -log( attenuationColor ) / attenuationDistance;\n			vec3 transmittance = exp( - attenuationCoefficient * transmissionDistance );			return transmittance;\n		}\n	}\n	vec4 getIBLVolumeRefraction( const in vec3 n, const in vec3 v, const in float roughness, const in vec3 diffuseColor,\n		const in vec3 specularColor, const in float specularF90, const in vec3 position, const in mat4 modelMatrix,\n		const in mat4 viewMatrix, const in mat4 projMatrix, const in float dispersion, const in float ior, const in float thickness,\n		const in vec3 attenuationColor, const in float attenuationDistance ) {\n		vec4 transmittedLight;\n		vec3 transmittance;\n		#ifdef USE_DISPERSION\n			float halfSpread = ( ior - 1.0 ) * 0.025 * dispersion;\n			vec3 iors = vec3( ior - halfSpread, ior, ior + halfSpread );\n			for ( int i = 0; i < 3; i ++ ) {\n				vec3 transmissionRay = getVolumeTransmissionRay( n, v, thickness, iors[ i ], modelMatrix );\n				vec3 refractedRayExit = position + transmissionRay;\n		\n				vec4 ndcPos = projMatrix * viewMatrix * vec4( refractedRayExit, 1.0 );\n				vec2 refractionCoords = ndcPos.xy / ndcPos.w;\n				refractionCoords += 1.0;\n				refractionCoords /= 2.0;\n		\n				vec4 transmissionSample = getTransmissionSample( refractionCoords, roughness, iors[ i ] );\n				transmittedLight[ i ] = transmissionSample[ i ];\n				transmittedLight.a += transmissionSample.a;\n				transmittance[ i ] = diffuseColor[ i ] * volumeAttenuation( length( transmissionRay ), attenuationColor, attenuationDistance )[ i ];\n			}\n			transmittedLight.a /= 3.0;\n		\n		#else\n		\n			vec3 transmissionRay = getVolumeTransmissionRay( n, v, thickness, ior, modelMatrix );\n			vec3 refractedRayExit = position + transmissionRay;\n			vec4 ndcPos = projMatrix * viewMatrix * vec4( refractedRayExit, 1.0 );\n			vec2 refractionCoords = ndcPos.xy / ndcPos.w;\n			refractionCoords += 1.0;\n			refractionCoords /= 2.0;\n			transmittedLight = getTransmissionSample( refractionCoords, roughness, ior );\n			transmittance = diffuseColor * volumeAttenuation( length( transmissionRay ), attenuationColor, attenuationDistance );\n		\n		#endif\n		vec3 attenuatedColor = transmittance * transmittedLight.rgb;\n		vec3 F = EnvironmentBRDF( n, v, specularColor, specularF90, roughness );\n		float transmittanceFactor = ( transmittance.r + transmittance.g + transmittance.b ) / 3.0;\n		return vec4( ( 1.0 - F ) * attenuatedColor, 1.0 - ( 1.0 - transmittedLight.a ) * transmittanceFactor );\n	}\n#endif";
var uv_pars_fragment = "#if defined( USE_UV ) || defined( USE_ANISOTROPY )\n	varying vec2 vUv;\n#endif\n#ifdef USE_MAP\n	varying vec2 vMapUv;\n#endif\n#ifdef USE_ALPHAMAP\n	varying vec2 vAlphaMapUv;\n#endif\n#ifdef USE_LIGHTMAP\n	varying vec2 vLightMapUv;\n#endif\n#ifdef USE_AOMAP\n	varying vec2 vAoMapUv;\n#endif\n#ifdef USE_BUMPMAP\n	varying vec2 vBumpMapUv;\n#endif\n#ifdef USE_NORMALMAP\n	varying vec2 vNormalMapUv;\n#endif\n#ifdef USE_EMISSIVEMAP\n	varying vec2 vEmissiveMapUv;\n#endif\n#ifdef USE_METALNESSMAP\n	varying vec2 vMetalnessMapUv;\n#endif\n#ifdef USE_ROUGHNESSMAP\n	varying vec2 vRoughnessMapUv;\n#endif\n#ifdef USE_ANISOTROPYMAP\n	varying vec2 vAnisotropyMapUv;\n#endif\n#ifdef USE_CLEARCOATMAP\n	varying vec2 vClearcoatMapUv;\n#endif\n#ifdef USE_CLEARCOAT_NORMALMAP\n	varying vec2 vClearcoatNormalMapUv;\n#endif\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\n	varying vec2 vClearcoatRoughnessMapUv;\n#endif\n#ifdef USE_IRIDESCENCEMAP\n	varying vec2 vIridescenceMapUv;\n#endif\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\n	varying vec2 vIridescenceThicknessMapUv;\n#endif\n#ifdef USE_SHEEN_COLORMAP\n	varying vec2 vSheenColorMapUv;\n#endif\n#ifdef USE_SHEEN_ROUGHNESSMAP\n	varying vec2 vSheenRoughnessMapUv;\n#endif\n#ifdef USE_SPECULARMAP\n	varying vec2 vSpecularMapUv;\n#endif\n#ifdef USE_SPECULAR_COLORMAP\n	varying vec2 vSpecularColorMapUv;\n#endif\n#ifdef USE_SPECULAR_INTENSITYMAP\n	varying vec2 vSpecularIntensityMapUv;\n#endif\n#ifdef USE_TRANSMISSIONMAP\n	uniform mat3 transmissionMapTransform;\n	varying vec2 vTransmissionMapUv;\n#endif\n#ifdef USE_THICKNESSMAP\n	uniform mat3 thicknessMapTransform;\n	varying vec2 vThicknessMapUv;\n#endif";
var uv_pars_vertex = "#if defined( USE_UV ) || defined( USE_ANISOTROPY )\n	varying vec2 vUv;\n#endif\n#ifdef USE_MAP\n	uniform mat3 mapTransform;\n	varying vec2 vMapUv;\n#endif\n#ifdef USE_ALPHAMAP\n	uniform mat3 alphaMapTransform;\n	varying vec2 vAlphaMapUv;\n#endif\n#ifdef USE_LIGHTMAP\n	uniform mat3 lightMapTransform;\n	varying vec2 vLightMapUv;\n#endif\n#ifdef USE_AOMAP\n	uniform mat3 aoMapTransform;\n	varying vec2 vAoMapUv;\n#endif\n#ifdef USE_BUMPMAP\n	uniform mat3 bumpMapTransform;\n	varying vec2 vBumpMapUv;\n#endif\n#ifdef USE_NORMALMAP\n	uniform mat3 normalMapTransform;\n	varying vec2 vNormalMapUv;\n#endif\n#ifdef USE_DISPLACEMENTMAP\n	uniform mat3 displacementMapTransform;\n	varying vec2 vDisplacementMapUv;\n#endif\n#ifdef USE_EMISSIVEMAP\n	uniform mat3 emissiveMapTransform;\n	varying vec2 vEmissiveMapUv;\n#endif\n#ifdef USE_METALNESSMAP\n	uniform mat3 metalnessMapTransform;\n	varying vec2 vMetalnessMapUv;\n#endif\n#ifdef USE_ROUGHNESSMAP\n	uniform mat3 roughnessMapTransform;\n	varying vec2 vRoughnessMapUv;\n#endif\n#ifdef USE_ANISOTROPYMAP\n	uniform mat3 anisotropyMapTransform;\n	varying vec2 vAnisotropyMapUv;\n#endif\n#ifdef USE_CLEARCOATMAP\n	uniform mat3 clearcoatMapTransform;\n	varying vec2 vClearcoatMapUv;\n#endif\n#ifdef USE_CLEARCOAT_NORMALMAP\n	uniform mat3 clearcoatNormalMapTransform;\n	varying vec2 vClearcoatNormalMapUv;\n#endif\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\n	uniform mat3 clearcoatRoughnessMapTransform;\n	varying vec2 vClearcoatRoughnessMapUv;\n#endif\n#ifdef USE_SHEEN_COLORMAP\n	uniform mat3 sheenColorMapTransform;\n	varying vec2 vSheenColorMapUv;\n#endif\n#ifdef USE_SHEEN_ROUGHNESSMAP\n	uniform mat3 sheenRoughnessMapTransform;\n	varying vec2 vSheenRoughnessMapUv;\n#endif\n#ifdef USE_IRIDESCENCEMAP\n	uniform mat3 iridescenceMapTransform;\n	varying vec2 vIridescenceMapUv;\n#endif\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\n	uniform mat3 iridescenceThicknessMapTransform;\n	varying vec2 vIridescenceThicknessMapUv;\n#endif\n#ifdef USE_SPECULARMAP\n	uniform mat3 specularMapTransform;\n	varying vec2 vSpecularMapUv;\n#endif\n#ifdef USE_SPECULAR_COLORMAP\n	uniform mat3 specularColorMapTransform;\n	varying vec2 vSpecularColorMapUv;\n#endif\n#ifdef USE_SPECULAR_INTENSITYMAP\n	uniform mat3 specularIntensityMapTransform;\n	varying vec2 vSpecularIntensityMapUv;\n#endif\n#ifdef USE_TRANSMISSIONMAP\n	uniform mat3 transmissionMapTransform;\n	varying vec2 vTransmissionMapUv;\n#endif\n#ifdef USE_THICKNESSMAP\n	uniform mat3 thicknessMapTransform;\n	varying vec2 vThicknessMapUv;\n#endif";
var uv_vertex = "#if defined( USE_UV ) || defined( USE_ANISOTROPY )\n	vUv = vec3( uv, 1 ).xy;\n#endif\n#ifdef USE_MAP\n	vMapUv = ( mapTransform * vec3( MAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_ALPHAMAP\n	vAlphaMapUv = ( alphaMapTransform * vec3( ALPHAMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_LIGHTMAP\n	vLightMapUv = ( lightMapTransform * vec3( LIGHTMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_AOMAP\n	vAoMapUv = ( aoMapTransform * vec3( AOMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_BUMPMAP\n	vBumpMapUv = ( bumpMapTransform * vec3( BUMPMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_NORMALMAP\n	vNormalMapUv = ( normalMapTransform * vec3( NORMALMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_DISPLACEMENTMAP\n	vDisplacementMapUv = ( displacementMapTransform * vec3( DISPLACEMENTMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_EMISSIVEMAP\n	vEmissiveMapUv = ( emissiveMapTransform * vec3( EMISSIVEMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_METALNESSMAP\n	vMetalnessMapUv = ( metalnessMapTransform * vec3( METALNESSMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_ROUGHNESSMAP\n	vRoughnessMapUv = ( roughnessMapTransform * vec3( ROUGHNESSMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_ANISOTROPYMAP\n	vAnisotropyMapUv = ( anisotropyMapTransform * vec3( ANISOTROPYMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_CLEARCOATMAP\n	vClearcoatMapUv = ( clearcoatMapTransform * vec3( CLEARCOATMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_CLEARCOAT_NORMALMAP\n	vClearcoatNormalMapUv = ( clearcoatNormalMapTransform * vec3( CLEARCOAT_NORMALMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\n	vClearcoatRoughnessMapUv = ( clearcoatRoughnessMapTransform * vec3( CLEARCOAT_ROUGHNESSMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_IRIDESCENCEMAP\n	vIridescenceMapUv = ( iridescenceMapTransform * vec3( IRIDESCENCEMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\n	vIridescenceThicknessMapUv = ( iridescenceThicknessMapTransform * vec3( IRIDESCENCE_THICKNESSMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_SHEEN_COLORMAP\n	vSheenColorMapUv = ( sheenColorMapTransform * vec3( SHEEN_COLORMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_SHEEN_ROUGHNESSMAP\n	vSheenRoughnessMapUv = ( sheenRoughnessMapTransform * vec3( SHEEN_ROUGHNESSMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_SPECULARMAP\n	vSpecularMapUv = ( specularMapTransform * vec3( SPECULARMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_SPECULAR_COLORMAP\n	vSpecularColorMapUv = ( specularColorMapTransform * vec3( SPECULAR_COLORMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_SPECULAR_INTENSITYMAP\n	vSpecularIntensityMapUv = ( specularIntensityMapTransform * vec3( SPECULAR_INTENSITYMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_TRANSMISSIONMAP\n	vTransmissionMapUv = ( transmissionMapTransform * vec3( TRANSMISSIONMAP_UV, 1 ) ).xy;\n#endif\n#ifdef USE_THICKNESSMAP\n	vThicknessMapUv = ( thicknessMapTransform * vec3( THICKNESSMAP_UV, 1 ) ).xy;\n#endif";
var worldpos_vertex = "#if defined( USE_ENVMAP ) || defined( DISTANCE ) || defined ( USE_SHADOWMAP ) || defined ( USE_TRANSMISSION ) || NUM_SPOT_LIGHT_COORDS > 0\n	vec4 worldPosition = vec4( transformed, 1.0 );\n	#ifdef USE_BATCHING\n		worldPosition = batchingMatrix * worldPosition;\n	#endif\n	#ifdef USE_INSTANCING\n		worldPosition = instanceMatrix * worldPosition;\n	#endif\n	worldPosition = modelMatrix * worldPosition;\n#endif";
const vertex$h = "varying vec2 vUv;\nuniform mat3 uvTransform;\nvoid main() {\n	vUv = ( uvTransform * vec3( uv, 1 ) ).xy;\n	gl_Position = vec4( position.xy, 1.0, 1.0 );\n}";
const fragment$h = "uniform sampler2D t2D;\nuniform float backgroundIntensity;\nvarying vec2 vUv;\nvoid main() {\n	vec4 texColor = texture2D( t2D, vUv );\n	#ifdef DECODE_VIDEO_TEXTURE\n		texColor = vec4( mix( pow( texColor.rgb * 0.9478672986 + vec3( 0.0521327014 ), vec3( 2.4 ) ), texColor.rgb * 0.0773993808, vec3( lessThanEqual( texColor.rgb, vec3( 0.04045 ) ) ) ), texColor.w );\n	#endif\n	texColor.rgb *= backgroundIntensity;\n	gl_FragColor = texColor;\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n}";
const vertex$g = "varying vec3 vWorldDirection;\n#include <common>\nvoid main() {\n	vWorldDirection = transformDirection( position, modelMatrix );\n	#include <begin_vertex>\n	#include <project_vertex>\n	gl_Position.z = gl_Position.w;\n}";
const fragment$g = "#ifdef ENVMAP_TYPE_CUBE\n	uniform samplerCube envMap;\n#elif defined( ENVMAP_TYPE_CUBE_UV )\n	uniform sampler2D envMap;\n#endif\nuniform float flipEnvMap;\nuniform float backgroundBlurriness;\nuniform float backgroundIntensity;\nuniform mat3 backgroundRotation;\nvarying vec3 vWorldDirection;\n#include <cube_uv_reflection_fragment>\nvoid main() {\n	#ifdef ENVMAP_TYPE_CUBE\n		vec4 texColor = textureCube( envMap, backgroundRotation * vec3( flipEnvMap * vWorldDirection.x, vWorldDirection.yz ) );\n	#elif defined( ENVMAP_TYPE_CUBE_UV )\n		vec4 texColor = textureCubeUV( envMap, backgroundRotation * vWorldDirection, backgroundBlurriness );\n	#else\n		vec4 texColor = vec4( 0.0, 0.0, 0.0, 1.0 );\n	#endif\n	texColor.rgb *= backgroundIntensity;\n	gl_FragColor = texColor;\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n}";
const vertex$f = "varying vec3 vWorldDirection;\n#include <common>\nvoid main() {\n	vWorldDirection = transformDirection( position, modelMatrix );\n	#include <begin_vertex>\n	#include <project_vertex>\n	gl_Position.z = gl_Position.w;\n}";
const fragment$f = "uniform samplerCube tCube;\nuniform float tFlip;\nuniform float opacity;\nvarying vec3 vWorldDirection;\nvoid main() {\n	vec4 texColor = textureCube( tCube, vec3( tFlip * vWorldDirection.x, vWorldDirection.yz ) );\n	gl_FragColor = texColor;\n	gl_FragColor.a *= opacity;\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n}";
const vertex$e = "#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvarying vec2 vHighPrecisionZW;\nvoid main() {\n	#include <uv_vertex>\n	#include <batching_vertex>\n	#include <skinbase_vertex>\n	#include <morphinstance_vertex>\n	#ifdef USE_DISPLACEMENTMAP\n		#include <beginnormal_vertex>\n		#include <morphnormal_vertex>\n		#include <skinnormal_vertex>\n	#endif\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <skinning_vertex>\n	#include <displacementmap_vertex>\n	#include <project_vertex>\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n	vHighPrecisionZW = gl_Position.zw;\n}";
const fragment$e = "#if DEPTH_PACKING == 3200\n	uniform float opacity;\n#endif\n#include <common>\n#include <packing>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvarying vec2 vHighPrecisionZW;\nvoid main() {\n	vec4 diffuseColor = vec4( 1.0 );\n	#include <clipping_planes_fragment>\n	#if DEPTH_PACKING == 3200\n		diffuseColor.a = opacity;\n	#endif\n	#include <map_fragment>\n	#include <alphamap_fragment>\n	#include <alphatest_fragment>\n	#include <alphahash_fragment>\n	#include <logdepthbuf_fragment>\n	float fragCoordZ = 0.5 * vHighPrecisionZW[0] / vHighPrecisionZW[1] + 0.5;\n	#if DEPTH_PACKING == 3200\n		gl_FragColor = vec4( vec3( 1.0 - fragCoordZ ), opacity );\n	#elif DEPTH_PACKING == 3201\n		gl_FragColor = packDepthToRGBA( fragCoordZ );\n	#endif\n}";
const vertex$d = "#define DISTANCE\nvarying vec3 vWorldPosition;\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n	#include <uv_vertex>\n	#include <batching_vertex>\n	#include <skinbase_vertex>\n	#include <morphinstance_vertex>\n	#ifdef USE_DISPLACEMENTMAP\n		#include <beginnormal_vertex>\n		#include <morphnormal_vertex>\n		#include <skinnormal_vertex>\n	#endif\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <skinning_vertex>\n	#include <displacementmap_vertex>\n	#include <project_vertex>\n	#include <worldpos_vertex>\n	#include <clipping_planes_vertex>\n	vWorldPosition = worldPosition.xyz;\n}";
const fragment$d = "#define DISTANCE\nuniform vec3 referencePosition;\nuniform float nearDistance;\nuniform float farDistance;\nvarying vec3 vWorldPosition;\n#include <common>\n#include <packing>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main () {\n	vec4 diffuseColor = vec4( 1.0 );\n	#include <clipping_planes_fragment>\n	#include <map_fragment>\n	#include <alphamap_fragment>\n	#include <alphatest_fragment>\n	#include <alphahash_fragment>\n	float dist = length( vWorldPosition - referencePosition );\n	dist = ( dist - nearDistance ) / ( farDistance - nearDistance );\n	dist = saturate( dist );\n	gl_FragColor = packDepthToRGBA( dist );\n}";
const vertex$c = "varying vec3 vWorldDirection;\n#include <common>\nvoid main() {\n	vWorldDirection = transformDirection( position, modelMatrix );\n	#include <begin_vertex>\n	#include <project_vertex>\n}";
const fragment$c = "uniform sampler2D tEquirect;\nvarying vec3 vWorldDirection;\n#include <common>\nvoid main() {\n	vec3 direction = normalize( vWorldDirection );\n	vec2 sampleUV = equirectUv( direction );\n	gl_FragColor = texture2D( tEquirect, sampleUV );\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n}";
const vertex$b = "uniform float scale;\nattribute float lineDistance;\nvarying float vLineDistance;\n#include <common>\n#include <uv_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n	vLineDistance = scale * lineDistance;\n	#include <uv_vertex>\n	#include <color_vertex>\n	#include <morphinstance_vertex>\n	#include <morphcolor_vertex>\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <project_vertex>\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n	#include <fog_vertex>\n}";
const fragment$b = "uniform vec3 diffuse;\nuniform float opacity;\nuniform float dashSize;\nuniform float totalSize;\nvarying float vLineDistance;\n#include <common>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <fog_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n	vec4 diffuseColor = vec4( diffuse, opacity );\n	#include <clipping_planes_fragment>\n	if ( mod( vLineDistance, totalSize ) > dashSize ) {\n		discard;\n	}\n	vec3 outgoingLight = vec3( 0.0 );\n	#include <logdepthbuf_fragment>\n	#include <map_fragment>\n	#include <color_fragment>\n	outgoingLight = diffuseColor.rgb;\n	#include <opaque_fragment>\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n	#include <fog_fragment>\n	#include <premultiplied_alpha_fragment>\n}";
const vertex$a = "#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <envmap_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n	#include <uv_vertex>\n	#include <color_vertex>\n	#include <morphinstance_vertex>\n	#include <morphcolor_vertex>\n	#include <batching_vertex>\n	#if defined ( USE_ENVMAP ) || defined ( USE_SKINNING )\n		#include <beginnormal_vertex>\n		#include <morphnormal_vertex>\n		#include <skinbase_vertex>\n		#include <skinnormal_vertex>\n		#include <defaultnormal_vertex>\n	#endif\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <skinning_vertex>\n	#include <project_vertex>\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n	#include <worldpos_vertex>\n	#include <envmap_vertex>\n	#include <fog_vertex>\n}";
const fragment$a = "uniform vec3 diffuse;\nuniform float opacity;\n#ifndef FLAT_SHADED\n	varying vec3 vNormal;\n#endif\n#include <common>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <aomap_pars_fragment>\n#include <lightmap_pars_fragment>\n#include <envmap_common_pars_fragment>\n#include <envmap_pars_fragment>\n#include <fog_pars_fragment>\n#include <specularmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n	vec4 diffuseColor = vec4( diffuse, opacity );\n	#include <clipping_planes_fragment>\n	#include <logdepthbuf_fragment>\n	#include <map_fragment>\n	#include <color_fragment>\n	#include <alphamap_fragment>\n	#include <alphatest_fragment>\n	#include <alphahash_fragment>\n	#include <specularmap_fragment>\n	ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\n	#ifdef USE_LIGHTMAP\n		vec4 lightMapTexel = texture2D( lightMap, vLightMapUv );\n		reflectedLight.indirectDiffuse += lightMapTexel.rgb * lightMapIntensity * RECIPROCAL_PI;\n	#else\n		reflectedLight.indirectDiffuse += vec3( 1.0 );\n	#endif\n	#include <aomap_fragment>\n	reflectedLight.indirectDiffuse *= diffuseColor.rgb;\n	vec3 outgoingLight = reflectedLight.indirectDiffuse;\n	#include <envmap_fragment>\n	#include <opaque_fragment>\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n	#include <fog_fragment>\n	#include <premultiplied_alpha_fragment>\n	#include <dithering_fragment>\n}";
const vertex$9 = "#define LAMBERT\nvarying vec3 vViewPosition;\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <envmap_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <shadowmap_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n	#include <uv_vertex>\n	#include <color_vertex>\n	#include <morphinstance_vertex>\n	#include <morphcolor_vertex>\n	#include <batching_vertex>\n	#include <beginnormal_vertex>\n	#include <morphnormal_vertex>\n	#include <skinbase_vertex>\n	#include <skinnormal_vertex>\n	#include <defaultnormal_vertex>\n	#include <normal_vertex>\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <skinning_vertex>\n	#include <displacementmap_vertex>\n	#include <project_vertex>\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n	vViewPosition = - mvPosition.xyz;\n	#include <worldpos_vertex>\n	#include <envmap_vertex>\n	#include <shadowmap_vertex>\n	#include <fog_vertex>\n}";
const fragment$9 = "#define LAMBERT\nuniform vec3 diffuse;\nuniform vec3 emissive;\nuniform float opacity;\n#include <common>\n#include <packing>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <aomap_pars_fragment>\n#include <lightmap_pars_fragment>\n#include <emissivemap_pars_fragment>\n#include <envmap_common_pars_fragment>\n#include <envmap_pars_fragment>\n#include <fog_pars_fragment>\n#include <bsdfs>\n#include <lights_pars_begin>\n#include <normal_pars_fragment>\n#include <lights_lambert_pars_fragment>\n#include <shadowmap_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <specularmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n	vec4 diffuseColor = vec4( diffuse, opacity );\n	#include <clipping_planes_fragment>\n	ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\n	vec3 totalEmissiveRadiance = emissive;\n	#include <logdepthbuf_fragment>\n	#include <map_fragment>\n	#include <color_fragment>\n	#include <alphamap_fragment>\n	#include <alphatest_fragment>\n	#include <alphahash_fragment>\n	#include <specularmap_fragment>\n	#include <normal_fragment_begin>\n	#include <normal_fragment_maps>\n	#include <emissivemap_fragment>\n	#include <lights_lambert_fragment>\n	#include <lights_fragment_begin>\n	#include <lights_fragment_maps>\n	#include <lights_fragment_end>\n	#include <aomap_fragment>\n	vec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + totalEmissiveRadiance;\n	#include <envmap_fragment>\n	#include <opaque_fragment>\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n	#include <fog_fragment>\n	#include <premultiplied_alpha_fragment>\n	#include <dithering_fragment>\n}";
const vertex$8 = "#define MATCAP\nvarying vec3 vViewPosition;\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <color_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <fog_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n	#include <uv_vertex>\n	#include <color_vertex>\n	#include <morphinstance_vertex>\n	#include <morphcolor_vertex>\n	#include <batching_vertex>\n	#include <beginnormal_vertex>\n	#include <morphnormal_vertex>\n	#include <skinbase_vertex>\n	#include <skinnormal_vertex>\n	#include <defaultnormal_vertex>\n	#include <normal_vertex>\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <skinning_vertex>\n	#include <displacementmap_vertex>\n	#include <project_vertex>\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n	#include <fog_vertex>\n	vViewPosition = - mvPosition.xyz;\n}";
const fragment$8 = "#define MATCAP\nuniform vec3 diffuse;\nuniform float opacity;\nuniform sampler2D matcap;\nvarying vec3 vViewPosition;\n#include <common>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <fog_pars_fragment>\n#include <normal_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n	vec4 diffuseColor = vec4( diffuse, opacity );\n	#include <clipping_planes_fragment>\n	#include <logdepthbuf_fragment>\n	#include <map_fragment>\n	#include <color_fragment>\n	#include <alphamap_fragment>\n	#include <alphatest_fragment>\n	#include <alphahash_fragment>\n	#include <normal_fragment_begin>\n	#include <normal_fragment_maps>\n	vec3 viewDir = normalize( vViewPosition );\n	vec3 x = normalize( vec3( viewDir.z, 0.0, - viewDir.x ) );\n	vec3 y = cross( viewDir, x );\n	vec2 uv = vec2( dot( x, normal ), dot( y, normal ) ) * 0.495 + 0.5;\n	#ifdef USE_MATCAP\n		vec4 matcapColor = texture2D( matcap, uv );\n	#else\n		vec4 matcapColor = vec4( vec3( mix( 0.2, 0.8, uv.y ) ), 1.0 );\n	#endif\n	vec3 outgoingLight = diffuseColor.rgb * matcapColor.rgb;\n	#include <opaque_fragment>\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n	#include <fog_fragment>\n	#include <premultiplied_alpha_fragment>\n	#include <dithering_fragment>\n}";
const vertex$7 = "#define NORMAL\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( USE_NORMALMAP_TANGENTSPACE )\n	varying vec3 vViewPosition;\n#endif\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n	#include <uv_vertex>\n	#include <batching_vertex>\n	#include <beginnormal_vertex>\n	#include <morphinstance_vertex>\n	#include <morphnormal_vertex>\n	#include <skinbase_vertex>\n	#include <skinnormal_vertex>\n	#include <defaultnormal_vertex>\n	#include <normal_vertex>\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <skinning_vertex>\n	#include <displacementmap_vertex>\n	#include <project_vertex>\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( USE_NORMALMAP_TANGENTSPACE )\n	vViewPosition = - mvPosition.xyz;\n#endif\n}";
const fragment$7 = "#define NORMAL\nuniform float opacity;\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( USE_NORMALMAP_TANGENTSPACE )\n	varying vec3 vViewPosition;\n#endif\n#include <packing>\n#include <uv_pars_fragment>\n#include <normal_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n	vec4 diffuseColor = vec4( 0.0, 0.0, 0.0, opacity );\n	#include <clipping_planes_fragment>\n	#include <logdepthbuf_fragment>\n	#include <normal_fragment_begin>\n	#include <normal_fragment_maps>\n	gl_FragColor = vec4( packNormalToRGB( normal ), diffuseColor.a );\n	#ifdef OPAQUE\n		gl_FragColor.a = 1.0;\n	#endif\n}";
const vertex$6 = "#define PHONG\nvarying vec3 vViewPosition;\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <envmap_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <shadowmap_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n	#include <uv_vertex>\n	#include <color_vertex>\n	#include <morphcolor_vertex>\n	#include <batching_vertex>\n	#include <beginnormal_vertex>\n	#include <morphinstance_vertex>\n	#include <morphnormal_vertex>\n	#include <skinbase_vertex>\n	#include <skinnormal_vertex>\n	#include <defaultnormal_vertex>\n	#include <normal_vertex>\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <skinning_vertex>\n	#include <displacementmap_vertex>\n	#include <project_vertex>\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n	vViewPosition = - mvPosition.xyz;\n	#include <worldpos_vertex>\n	#include <envmap_vertex>\n	#include <shadowmap_vertex>\n	#include <fog_vertex>\n}";
const fragment$6 = "#define PHONG\nuniform vec3 diffuse;\nuniform vec3 emissive;\nuniform vec3 specular;\nuniform float shininess;\nuniform float opacity;\n#include <common>\n#include <packing>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <aomap_pars_fragment>\n#include <lightmap_pars_fragment>\n#include <emissivemap_pars_fragment>\n#include <envmap_common_pars_fragment>\n#include <envmap_pars_fragment>\n#include <fog_pars_fragment>\n#include <bsdfs>\n#include <lights_pars_begin>\n#include <normal_pars_fragment>\n#include <lights_phong_pars_fragment>\n#include <shadowmap_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <specularmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n	vec4 diffuseColor = vec4( diffuse, opacity );\n	#include <clipping_planes_fragment>\n	ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\n	vec3 totalEmissiveRadiance = emissive;\n	#include <logdepthbuf_fragment>\n	#include <map_fragment>\n	#include <color_fragment>\n	#include <alphamap_fragment>\n	#include <alphatest_fragment>\n	#include <alphahash_fragment>\n	#include <specularmap_fragment>\n	#include <normal_fragment_begin>\n	#include <normal_fragment_maps>\n	#include <emissivemap_fragment>\n	#include <lights_phong_fragment>\n	#include <lights_fragment_begin>\n	#include <lights_fragment_maps>\n	#include <lights_fragment_end>\n	#include <aomap_fragment>\n	vec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + reflectedLight.directSpecular + reflectedLight.indirectSpecular + totalEmissiveRadiance;\n	#include <envmap_fragment>\n	#include <opaque_fragment>\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n	#include <fog_fragment>\n	#include <premultiplied_alpha_fragment>\n	#include <dithering_fragment>\n}";
const vertex$5 = "#define STANDARD\nvarying vec3 vViewPosition;\n#ifdef USE_TRANSMISSION\n	varying vec3 vWorldPosition;\n#endif\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <shadowmap_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n	#include <uv_vertex>\n	#include <color_vertex>\n	#include <morphinstance_vertex>\n	#include <morphcolor_vertex>\n	#include <batching_vertex>\n	#include <beginnormal_vertex>\n	#include <morphnormal_vertex>\n	#include <skinbase_vertex>\n	#include <skinnormal_vertex>\n	#include <defaultnormal_vertex>\n	#include <normal_vertex>\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <skinning_vertex>\n	#include <displacementmap_vertex>\n	#include <project_vertex>\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n	vViewPosition = - mvPosition.xyz;\n	#include <worldpos_vertex>\n	#include <shadowmap_vertex>\n	#include <fog_vertex>\n#ifdef USE_TRANSMISSION\n	vWorldPosition = worldPosition.xyz;\n#endif\n}";
const fragment$5 = "#define STANDARD\n#ifdef PHYSICAL\n	#define IOR\n	#define USE_SPECULAR\n#endif\nuniform vec3 diffuse;\nuniform vec3 emissive;\nuniform float roughness;\nuniform float metalness;\nuniform float opacity;\n#ifdef IOR\n	uniform float ior;\n#endif\n#ifdef USE_SPECULAR\n	uniform float specularIntensity;\n	uniform vec3 specularColor;\n	#ifdef USE_SPECULAR_COLORMAP\n		uniform sampler2D specularColorMap;\n	#endif\n	#ifdef USE_SPECULAR_INTENSITYMAP\n		uniform sampler2D specularIntensityMap;\n	#endif\n#endif\n#ifdef USE_CLEARCOAT\n	uniform float clearcoat;\n	uniform float clearcoatRoughness;\n#endif\n#ifdef USE_DISPERSION\n	uniform float dispersion;\n#endif\n#ifdef USE_IRIDESCENCE\n	uniform float iridescence;\n	uniform float iridescenceIOR;\n	uniform float iridescenceThicknessMinimum;\n	uniform float iridescenceThicknessMaximum;\n#endif\n#ifdef USE_SHEEN\n	uniform vec3 sheenColor;\n	uniform float sheenRoughness;\n	#ifdef USE_SHEEN_COLORMAP\n		uniform sampler2D sheenColorMap;\n	#endif\n	#ifdef USE_SHEEN_ROUGHNESSMAP\n		uniform sampler2D sheenRoughnessMap;\n	#endif\n#endif\n#ifdef USE_ANISOTROPY\n	uniform vec2 anisotropyVector;\n	#ifdef USE_ANISOTROPYMAP\n		uniform sampler2D anisotropyMap;\n	#endif\n#endif\nvarying vec3 vViewPosition;\n#include <common>\n#include <packing>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <aomap_pars_fragment>\n#include <lightmap_pars_fragment>\n#include <emissivemap_pars_fragment>\n#include <iridescence_fragment>\n#include <cube_uv_reflection_fragment>\n#include <envmap_common_pars_fragment>\n#include <envmap_physical_pars_fragment>\n#include <fog_pars_fragment>\n#include <lights_pars_begin>\n#include <normal_pars_fragment>\n#include <lights_physical_pars_fragment>\n#include <transmission_pars_fragment>\n#include <shadowmap_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <clearcoat_pars_fragment>\n#include <iridescence_pars_fragment>\n#include <roughnessmap_pars_fragment>\n#include <metalnessmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n	vec4 diffuseColor = vec4( diffuse, opacity );\n	#include <clipping_planes_fragment>\n	ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\n	vec3 totalEmissiveRadiance = emissive;\n	#include <logdepthbuf_fragment>\n	#include <map_fragment>\n	#include <color_fragment>\n	#include <alphamap_fragment>\n	#include <alphatest_fragment>\n	#include <alphahash_fragment>\n	#include <roughnessmap_fragment>\n	#include <metalnessmap_fragment>\n	#include <normal_fragment_begin>\n	#include <normal_fragment_maps>\n	#include <clearcoat_normal_fragment_begin>\n	#include <clearcoat_normal_fragment_maps>\n	#include <emissivemap_fragment>\n	#include <lights_physical_fragment>\n	#include <lights_fragment_begin>\n	#include <lights_fragment_maps>\n	#include <lights_fragment_end>\n	#include <aomap_fragment>\n	vec3 totalDiffuse = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse;\n	vec3 totalSpecular = reflectedLight.directSpecular + reflectedLight.indirectSpecular;\n	#include <transmission_fragment>\n	vec3 outgoingLight = totalDiffuse + totalSpecular + totalEmissiveRadiance;\n	#ifdef USE_SHEEN\n		float sheenEnergyComp = 1.0 - 0.157 * max3( material.sheenColor );\n		outgoingLight = outgoingLight * sheenEnergyComp + sheenSpecularDirect + sheenSpecularIndirect;\n	#endif\n	#ifdef USE_CLEARCOAT\n		float dotNVcc = saturate( dot( geometryClearcoatNormal, geometryViewDir ) );\n		vec3 Fcc = F_Schlick( material.clearcoatF0, material.clearcoatF90, dotNVcc );\n		outgoingLight = outgoingLight * ( 1.0 - material.clearcoat * Fcc ) + ( clearcoatSpecularDirect + clearcoatSpecularIndirect ) * material.clearcoat;\n	#endif\n	#include <opaque_fragment>\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n	#include <fog_fragment>\n	#include <premultiplied_alpha_fragment>\n	#include <dithering_fragment>\n}";
const vertex$4 = "#define TOON\nvarying vec3 vViewPosition;\n#include <common>\n#include <batching_pars_vertex>\n#include <uv_pars_vertex>\n#include <displacementmap_pars_vertex>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <shadowmap_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n	#include <uv_vertex>\n	#include <color_vertex>\n	#include <morphinstance_vertex>\n	#include <morphcolor_vertex>\n	#include <batching_vertex>\n	#include <beginnormal_vertex>\n	#include <morphnormal_vertex>\n	#include <skinbase_vertex>\n	#include <skinnormal_vertex>\n	#include <defaultnormal_vertex>\n	#include <normal_vertex>\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <skinning_vertex>\n	#include <displacementmap_vertex>\n	#include <project_vertex>\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n	vViewPosition = - mvPosition.xyz;\n	#include <worldpos_vertex>\n	#include <shadowmap_vertex>\n	#include <fog_vertex>\n}";
const fragment$4 = "#define TOON\nuniform vec3 diffuse;\nuniform vec3 emissive;\nuniform float opacity;\n#include <common>\n#include <packing>\n#include <dithering_pars_fragment>\n#include <color_pars_fragment>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <aomap_pars_fragment>\n#include <lightmap_pars_fragment>\n#include <emissivemap_pars_fragment>\n#include <gradientmap_pars_fragment>\n#include <fog_pars_fragment>\n#include <bsdfs>\n#include <lights_pars_begin>\n#include <normal_pars_fragment>\n#include <lights_toon_pars_fragment>\n#include <shadowmap_pars_fragment>\n#include <bumpmap_pars_fragment>\n#include <normalmap_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n	vec4 diffuseColor = vec4( diffuse, opacity );\n	#include <clipping_planes_fragment>\n	ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\n	vec3 totalEmissiveRadiance = emissive;\n	#include <logdepthbuf_fragment>\n	#include <map_fragment>\n	#include <color_fragment>\n	#include <alphamap_fragment>\n	#include <alphatest_fragment>\n	#include <alphahash_fragment>\n	#include <normal_fragment_begin>\n	#include <normal_fragment_maps>\n	#include <emissivemap_fragment>\n	#include <lights_toon_fragment>\n	#include <lights_fragment_begin>\n	#include <lights_fragment_maps>\n	#include <lights_fragment_end>\n	#include <aomap_fragment>\n	vec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + totalEmissiveRadiance;\n	#include <opaque_fragment>\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n	#include <fog_fragment>\n	#include <premultiplied_alpha_fragment>\n	#include <dithering_fragment>\n}";
const vertex$3 = "uniform float size;\nuniform float scale;\n#include <common>\n#include <color_pars_vertex>\n#include <fog_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\n#ifdef USE_POINTS_UV\n	varying vec2 vUv;\n	uniform mat3 uvTransform;\n#endif\nvoid main() {\n	#ifdef USE_POINTS_UV\n		vUv = ( uvTransform * vec3( uv, 1 ) ).xy;\n	#endif\n	#include <color_vertex>\n	#include <morphinstance_vertex>\n	#include <morphcolor_vertex>\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <project_vertex>\n	gl_PointSize = size;\n	#ifdef USE_SIZEATTENUATION\n		bool isPerspective = isPerspectiveMatrix( projectionMatrix );\n		if ( isPerspective ) gl_PointSize *= ( scale / - mvPosition.z );\n	#endif\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n	#include <worldpos_vertex>\n	#include <fog_vertex>\n}";
const fragment$3 = "uniform vec3 diffuse;\nuniform float opacity;\n#include <common>\n#include <color_pars_fragment>\n#include <map_particle_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <fog_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n	vec4 diffuseColor = vec4( diffuse, opacity );\n	#include <clipping_planes_fragment>\n	vec3 outgoingLight = vec3( 0.0 );\n	#include <logdepthbuf_fragment>\n	#include <map_particle_fragment>\n	#include <color_fragment>\n	#include <alphatest_fragment>\n	#include <alphahash_fragment>\n	outgoingLight = diffuseColor.rgb;\n	#include <opaque_fragment>\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n	#include <fog_fragment>\n	#include <premultiplied_alpha_fragment>\n}";
const vertex$2 = "#include <common>\n#include <batching_pars_vertex>\n#include <fog_pars_vertex>\n#include <morphtarget_pars_vertex>\n#include <skinning_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <shadowmap_pars_vertex>\nvoid main() {\n	#include <batching_vertex>\n	#include <beginnormal_vertex>\n	#include <morphinstance_vertex>\n	#include <morphnormal_vertex>\n	#include <skinbase_vertex>\n	#include <skinnormal_vertex>\n	#include <defaultnormal_vertex>\n	#include <begin_vertex>\n	#include <morphtarget_vertex>\n	#include <skinning_vertex>\n	#include <project_vertex>\n	#include <logdepthbuf_vertex>\n	#include <worldpos_vertex>\n	#include <shadowmap_vertex>\n	#include <fog_vertex>\n}";
const fragment$2 = "uniform vec3 color;\nuniform float opacity;\n#include <common>\n#include <packing>\n#include <fog_pars_fragment>\n#include <bsdfs>\n#include <lights_pars_begin>\n#include <logdepthbuf_pars_fragment>\n#include <shadowmap_pars_fragment>\n#include <shadowmask_pars_fragment>\nvoid main() {\n	#include <logdepthbuf_fragment>\n	gl_FragColor = vec4( color, opacity * ( 1.0 - getShadowMask() ) );\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n	#include <fog_fragment>\n}";
const vertex$1 = "uniform float rotation;\nuniform vec2 center;\n#include <common>\n#include <uv_pars_vertex>\n#include <fog_pars_vertex>\n#include <logdepthbuf_pars_vertex>\n#include <clipping_planes_pars_vertex>\nvoid main() {\n	#include <uv_vertex>\n	vec4 mvPosition = modelViewMatrix * vec4( 0.0, 0.0, 0.0, 1.0 );\n	vec2 scale;\n	scale.x = length( vec3( modelMatrix[ 0 ].x, modelMatrix[ 0 ].y, modelMatrix[ 0 ].z ) );\n	scale.y = length( vec3( modelMatrix[ 1 ].x, modelMatrix[ 1 ].y, modelMatrix[ 1 ].z ) );\n	#ifndef USE_SIZEATTENUATION\n		bool isPerspective = isPerspectiveMatrix( projectionMatrix );\n		if ( isPerspective ) scale *= - mvPosition.z;\n	#endif\n	vec2 alignedPosition = ( position.xy - ( center - vec2( 0.5 ) ) ) * scale;\n	vec2 rotatedPosition;\n	rotatedPosition.x = cos( rotation ) * alignedPosition.x - sin( rotation ) * alignedPosition.y;\n	rotatedPosition.y = sin( rotation ) * alignedPosition.x + cos( rotation ) * alignedPosition.y;\n	mvPosition.xy += rotatedPosition;\n	gl_Position = projectionMatrix * mvPosition;\n	#include <logdepthbuf_vertex>\n	#include <clipping_planes_vertex>\n	#include <fog_vertex>\n}";
const fragment$1 = "uniform vec3 diffuse;\nuniform float opacity;\n#include <common>\n#include <uv_pars_fragment>\n#include <map_pars_fragment>\n#include <alphamap_pars_fragment>\n#include <alphatest_pars_fragment>\n#include <alphahash_pars_fragment>\n#include <fog_pars_fragment>\n#include <logdepthbuf_pars_fragment>\n#include <clipping_planes_pars_fragment>\nvoid main() {\n	vec4 diffuseColor = vec4( diffuse, opacity );\n	#include <clipping_planes_fragment>\n	vec3 outgoingLight = vec3( 0.0 );\n	#include <logdepthbuf_fragment>\n	#include <map_fragment>\n	#include <alphamap_fragment>\n	#include <alphatest_fragment>\n	#include <alphahash_fragment>\n	outgoingLight = diffuseColor.rgb;\n	#include <opaque_fragment>\n	#include <tonemapping_fragment>\n	#include <colorspace_fragment>\n	#include <fog_fragment>\n}";
const ShaderChunk = {
    alphahash_fragment: alphahash_fragment,
    alphahash_pars_fragment: alphahash_pars_fragment,
    alphamap_fragment: alphamap_fragment,
    alphamap_pars_fragment: alphamap_pars_fragment,
    alphatest_fragment: alphatest_fragment,
    alphatest_pars_fragment: alphatest_pars_fragment,
    aomap_fragment: aomap_fragment,
    aomap_pars_fragment: aomap_pars_fragment,
    batching_pars_vertex: batching_pars_vertex,
    batching_vertex: batching_vertex,
    begin_vertex: begin_vertex,
    beginnormal_vertex: beginnormal_vertex,
    bsdfs: bsdfs,
    iridescence_fragment: iridescence_fragment,
    bumpmap_pars_fragment: bumpmap_pars_fragment,
    clipping_planes_fragment: clipping_planes_fragment,
    clipping_planes_pars_fragment: clipping_planes_pars_fragment,
    clipping_planes_pars_vertex: clipping_planes_pars_vertex,
    clipping_planes_vertex: clipping_planes_vertex,
    color_fragment: color_fragment,
    color_pars_fragment: color_pars_fragment,
    color_pars_vertex: color_pars_vertex,
    color_vertex: color_vertex,
    common: common,
    cube_uv_reflection_fragment: cube_uv_reflection_fragment,
    defaultnormal_vertex: defaultnormal_vertex,
    displacementmap_pars_vertex: displacementmap_pars_vertex,
    displacementmap_vertex: displacementmap_vertex,
    emissivemap_fragment: emissivemap_fragment,
    emissivemap_pars_fragment: emissivemap_pars_fragment,
    colorspace_fragment: colorspace_fragment,
    colorspace_pars_fragment: colorspace_pars_fragment,
    envmap_fragment: envmap_fragment,
    envmap_common_pars_fragment: envmap_common_pars_fragment,
    envmap_pars_fragment: envmap_pars_fragment,
    envmap_pars_vertex: envmap_pars_vertex,
    envmap_physical_pars_fragment: envmap_physical_pars_fragment,
    envmap_vertex: envmap_vertex,
    fog_vertex: fog_vertex,
    fog_pars_vertex: fog_pars_vertex,
    fog_fragment: fog_fragment,
    fog_pars_fragment: fog_pars_fragment,
    gradientmap_pars_fragment: gradientmap_pars_fragment,
    lightmap_pars_fragment: lightmap_pars_fragment,
    lights_lambert_fragment: lights_lambert_fragment,
    lights_lambert_pars_fragment: lights_lambert_pars_fragment,
    lights_pars_begin: lights_pars_begin,
    lights_toon_fragment: lights_toon_fragment,
    lights_toon_pars_fragment: lights_toon_pars_fragment,
    lights_phong_fragment: lights_phong_fragment,
    lights_phong_pars_fragment: lights_phong_pars_fragment,
    lights_physical_fragment: lights_physical_fragment,
    lights_physical_pars_fragment: lights_physical_pars_fragment,
    lights_fragment_begin: lights_fragment_begin,
    lights_fragment_maps: lights_fragment_maps,
    lights_fragment_end: lights_fragment_end,
    logdepthbuf_fragment: logdepthbuf_fragment,
    logdepthbuf_pars_fragment: logdepthbuf_pars_fragment,
    logdepthbuf_pars_vertex: logdepthbuf_pars_vertex,
    logdepthbuf_vertex: logdepthbuf_vertex,
    map_fragment: map_fragment,
    map_pars_fragment: map_pars_fragment,
    map_particle_fragment: map_particle_fragment,
    map_particle_pars_fragment: map_particle_pars_fragment,
    metalnessmap_fragment: metalnessmap_fragment,
    metalnessmap_pars_fragment: metalnessmap_pars_fragment,
    morphinstance_vertex: morphinstance_vertex,
    morphcolor_vertex: morphcolor_vertex,
    morphnormal_vertex: morphnormal_vertex,
    morphtarget_pars_vertex: morphtarget_pars_vertex,
    morphtarget_vertex: morphtarget_vertex,
    normal_fragment_begin: normal_fragment_begin,
    normal_fragment_maps: normal_fragment_maps,
    normal_pars_fragment: normal_pars_fragment,
    normal_pars_vertex: normal_pars_vertex,
    normal_vertex: normal_vertex,
    normalmap_pars_fragment: normalmap_pars_fragment,
    clearcoat_normal_fragment_begin: clearcoat_normal_fragment_begin,
    clearcoat_normal_fragment_maps: clearcoat_normal_fragment_maps,
    clearcoat_pars_fragment: clearcoat_pars_fragment,
    iridescence_pars_fragment: iridescence_pars_fragment,
    opaque_fragment: opaque_fragment,
    packing: packing,
    premultiplied_alpha_fragment: premultiplied_alpha_fragment,
    project_vertex: project_vertex,
    dithering_fragment: dithering_fragment,
    dithering_pars_fragment: dithering_pars_fragment,
    roughnessmap_fragment: roughnessmap_fragment,
    roughnessmap_pars_fragment: roughnessmap_pars_fragment,
    shadowmap_pars_fragment: shadowmap_pars_fragment,
    shadowmap_pars_vertex: shadowmap_pars_vertex,
    shadowmap_vertex: shadowmap_vertex,
    shadowmask_pars_fragment: shadowmask_pars_fragment,
    skinbase_vertex: skinbase_vertex,
    skinning_pars_vertex: skinning_pars_vertex,
    skinning_vertex: skinning_vertex,
    skinnormal_vertex: skinnormal_vertex,
    specularmap_fragment: specularmap_fragment,
    specularmap_pars_fragment: specularmap_pars_fragment,
    tonemapping_fragment: tonemapping_fragment,
    tonemapping_pars_fragment: tonemapping_pars_fragment,
    transmission_fragment: transmission_fragment,
    transmission_pars_fragment: transmission_pars_fragment,
    uv_pars_fragment: uv_pars_fragment,
    uv_pars_vertex: uv_pars_vertex,
    uv_vertex: uv_vertex,
    worldpos_vertex: worldpos_vertex,
    background_vert: vertex$h,
    background_frag: fragment$h,
    backgroundCube_vert: vertex$g,
    backgroundCube_frag: fragment$g,
    cube_vert: vertex$f,
    cube_frag: fragment$f,
    depth_vert: vertex$e,
    depth_frag: fragment$e,
    distanceRGBA_vert: vertex$d,
    distanceRGBA_frag: fragment$d,
    equirect_vert: vertex$c,
    equirect_frag: fragment$c,
    linedashed_vert: vertex$b,
    linedashed_frag: fragment$b,
    meshbasic_vert: vertex$a,
    meshbasic_frag: fragment$a,
    meshlambert_vert: vertex$9,
    meshlambert_frag: fragment$9,
    meshmatcap_vert: vertex$8,
    meshmatcap_frag: fragment$8,
    meshnormal_vert: vertex$7,
    meshnormal_frag: fragment$7,
    meshphong_vert: vertex$6,
    meshphong_frag: fragment$6,
    meshphysical_vert: vertex$5,
    meshphysical_frag: fragment$5,
    meshtoon_vert: vertex$4,
    meshtoon_frag: fragment$4,
    points_vert: vertex$3,
    points_frag: fragment$3,
    shadow_vert: vertex$2,
    shadow_frag: fragment$2,
    sprite_vert: vertex$1,
    sprite_frag: fragment$1
};
/**
 * Uniforms library for shared webgl shaders
 */ const UniformsLib = {
    common: {
        diffuse: {
            value: /*@__PURE__*/ new Color(0xffffff)
        },
        opacity: {
            value: 1.0
        },
        map: {
            value: null
        },
        mapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        },
        alphaMap: {
            value: null
        },
        alphaMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        },
        alphaTest: {
            value: 0
        }
    },
    specularmap: {
        specularMap: {
            value: null
        },
        specularMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        }
    },
    envmap: {
        envMap: {
            value: null
        },
        envMapRotation: {
            value: /*@__PURE__*/ new Matrix3()
        },
        flipEnvMap: {
            value: -1
        },
        reflectivity: {
            value: 1.0
        },
        ior: {
            value: 1.5
        },
        refractionRatio: {
            value: 0.98
        }
    },
    aomap: {
        aoMap: {
            value: null
        },
        aoMapIntensity: {
            value: 1
        },
        aoMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        }
    },
    lightmap: {
        lightMap: {
            value: null
        },
        lightMapIntensity: {
            value: 1
        },
        lightMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        }
    },
    bumpmap: {
        bumpMap: {
            value: null
        },
        bumpMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        },
        bumpScale: {
            value: 1
        }
    },
    normalmap: {
        normalMap: {
            value: null
        },
        normalMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        },
        normalScale: {
            value: /*@__PURE__*/ new Vector2(1, 1)
        }
    },
    displacementmap: {
        displacementMap: {
            value: null
        },
        displacementMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        },
        displacementScale: {
            value: 1
        },
        displacementBias: {
            value: 0
        }
    },
    emissivemap: {
        emissiveMap: {
            value: null
        },
        emissiveMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        }
    },
    metalnessmap: {
        metalnessMap: {
            value: null
        },
        metalnessMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        }
    },
    roughnessmap: {
        roughnessMap: {
            value: null
        },
        roughnessMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        }
    },
    gradientmap: {
        gradientMap: {
            value: null
        }
    },
    fog: {
        fogDensity: {
            value: 0.00025
        },
        fogNear: {
            value: 1
        },
        fogFar: {
            value: 2000
        },
        fogColor: {
            value: /*@__PURE__*/ new Color(0xffffff)
        }
    },
    lights: {
        ambientLightColor: {
            value: []
        },
        lightProbe: {
            value: []
        },
        directionalLights: {
            value: [],
            properties: {
                direction: {},
                color: {}
            }
        },
        directionalLightShadows: {
            value: [],
            properties: {
                shadowIntensity: 1,
                shadowBias: {},
                shadowNormalBias: {},
                shadowRadius: {},
                shadowMapSize: {}
            }
        },
        directionalShadowMap: {
            value: []
        },
        directionalShadowMatrix: {
            value: []
        },
        spotLights: {
            value: [],
            properties: {
                color: {},
                position: {},
                direction: {},
                distance: {},
                coneCos: {},
                penumbraCos: {},
                decay: {}
            }
        },
        spotLightShadows: {
            value: [],
            properties: {
                shadowIntensity: 1,
                shadowBias: {},
                shadowNormalBias: {},
                shadowRadius: {},
                shadowMapSize: {}
            }
        },
        spotLightMap: {
            value: []
        },
        spotShadowMap: {
            value: []
        },
        spotLightMatrix: {
            value: []
        },
        pointLights: {
            value: [],
            properties: {
                color: {},
                position: {},
                decay: {},
                distance: {}
            }
        },
        pointLightShadows: {
            value: [],
            properties: {
                shadowIntensity: 1,
                shadowBias: {},
                shadowNormalBias: {},
                shadowRadius: {},
                shadowMapSize: {},
                shadowCameraNear: {},
                shadowCameraFar: {}
            }
        },
        pointShadowMap: {
            value: []
        },
        pointShadowMatrix: {
            value: []
        },
        hemisphereLights: {
            value: [],
            properties: {
                direction: {},
                skyColor: {},
                groundColor: {}
            }
        },
        // TODO (abelnation): RectAreaLight BRDF data needs to be moved from example to main src
        rectAreaLights: {
            value: [],
            properties: {
                color: {},
                position: {},
                width: {},
                height: {}
            }
        },
        ltc_1: {
            value: null
        },
        ltc_2: {
            value: null
        }
    },
    points: {
        diffuse: {
            value: /*@__PURE__*/ new Color(0xffffff)
        },
        opacity: {
            value: 1.0
        },
        size: {
            value: 1.0
        },
        scale: {
            value: 1.0
        },
        map: {
            value: null
        },
        alphaMap: {
            value: null
        },
        alphaMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        },
        alphaTest: {
            value: 0
        },
        uvTransform: {
            value: /*@__PURE__*/ new Matrix3()
        }
    },
    sprite: {
        diffuse: {
            value: /*@__PURE__*/ new Color(0xffffff)
        },
        opacity: {
            value: 1.0
        },
        center: {
            value: /*@__PURE__*/ new Vector2(0.5, 0.5)
        },
        rotation: {
            value: 0.0
        },
        map: {
            value: null
        },
        mapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        },
        alphaMap: {
            value: null
        },
        alphaMapTransform: {
            value: /*@__PURE__*/ new Matrix3()
        },
        alphaTest: {
            value: 0
        }
    }
};
const ShaderLib = {
    basic: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.common,
            UniformsLib.specularmap,
            UniformsLib.envmap,
            UniformsLib.aomap,
            UniformsLib.lightmap,
            UniformsLib.fog
        ]),
        vertexShader: ShaderChunk.meshbasic_vert,
        fragmentShader: ShaderChunk.meshbasic_frag
    },
    lambert: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.common,
            UniformsLib.specularmap,
            UniformsLib.envmap,
            UniformsLib.aomap,
            UniformsLib.lightmap,
            UniformsLib.emissivemap,
            UniformsLib.bumpmap,
            UniformsLib.normalmap,
            UniformsLib.displacementmap,
            UniformsLib.fog,
            UniformsLib.lights,
            {
                emissive: {
                    value: /*@__PURE__*/ new Color(0x000000)
                }
            }
        ]),
        vertexShader: ShaderChunk.meshlambert_vert,
        fragmentShader: ShaderChunk.meshlambert_frag
    },
    phong: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.common,
            UniformsLib.specularmap,
            UniformsLib.envmap,
            UniformsLib.aomap,
            UniformsLib.lightmap,
            UniformsLib.emissivemap,
            UniformsLib.bumpmap,
            UniformsLib.normalmap,
            UniformsLib.displacementmap,
            UniformsLib.fog,
            UniformsLib.lights,
            {
                emissive: {
                    value: /*@__PURE__*/ new Color(0x000000)
                },
                specular: {
                    value: /*@__PURE__*/ new Color(0x111111)
                },
                shininess: {
                    value: 30
                }
            }
        ]),
        vertexShader: ShaderChunk.meshphong_vert,
        fragmentShader: ShaderChunk.meshphong_frag
    },
    standard: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.common,
            UniformsLib.envmap,
            UniformsLib.aomap,
            UniformsLib.lightmap,
            UniformsLib.emissivemap,
            UniformsLib.bumpmap,
            UniformsLib.normalmap,
            UniformsLib.displacementmap,
            UniformsLib.roughnessmap,
            UniformsLib.metalnessmap,
            UniformsLib.fog,
            UniformsLib.lights,
            {
                emissive: {
                    value: /*@__PURE__*/ new Color(0x000000)
                },
                roughness: {
                    value: 1.0
                },
                metalness: {
                    value: 0.0
                },
                envMapIntensity: {
                    value: 1
                }
            }
        ]),
        vertexShader: ShaderChunk.meshphysical_vert,
        fragmentShader: ShaderChunk.meshphysical_frag
    },
    toon: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.common,
            UniformsLib.aomap,
            UniformsLib.lightmap,
            UniformsLib.emissivemap,
            UniformsLib.bumpmap,
            UniformsLib.normalmap,
            UniformsLib.displacementmap,
            UniformsLib.gradientmap,
            UniformsLib.fog,
            UniformsLib.lights,
            {
                emissive: {
                    value: /*@__PURE__*/ new Color(0x000000)
                }
            }
        ]),
        vertexShader: ShaderChunk.meshtoon_vert,
        fragmentShader: ShaderChunk.meshtoon_frag
    },
    matcap: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.common,
            UniformsLib.bumpmap,
            UniformsLib.normalmap,
            UniformsLib.displacementmap,
            UniformsLib.fog,
            {
                matcap: {
                    value: null
                }
            }
        ]),
        vertexShader: ShaderChunk.meshmatcap_vert,
        fragmentShader: ShaderChunk.meshmatcap_frag
    },
    points: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.points,
            UniformsLib.fog
        ]),
        vertexShader: ShaderChunk.points_vert,
        fragmentShader: ShaderChunk.points_frag
    },
    dashed: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.common,
            UniformsLib.fog,
            {
                scale: {
                    value: 1
                },
                dashSize: {
                    value: 1
                },
                totalSize: {
                    value: 2
                }
            }
        ]),
        vertexShader: ShaderChunk.linedashed_vert,
        fragmentShader: ShaderChunk.linedashed_frag
    },
    depth: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.common,
            UniformsLib.displacementmap
        ]),
        vertexShader: ShaderChunk.depth_vert,
        fragmentShader: ShaderChunk.depth_frag
    },
    normal: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.common,
            UniformsLib.bumpmap,
            UniformsLib.normalmap,
            UniformsLib.displacementmap,
            {
                opacity: {
                    value: 1.0
                }
            }
        ]),
        vertexShader: ShaderChunk.meshnormal_vert,
        fragmentShader: ShaderChunk.meshnormal_frag
    },
    sprite: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.sprite,
            UniformsLib.fog
        ]),
        vertexShader: ShaderChunk.sprite_vert,
        fragmentShader: ShaderChunk.sprite_frag
    },
    background: {
        uniforms: {
            uvTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            t2D: {
                value: null
            },
            backgroundIntensity: {
                value: 1
            }
        },
        vertexShader: ShaderChunk.background_vert,
        fragmentShader: ShaderChunk.background_frag
    },
    backgroundCube: {
        uniforms: {
            envMap: {
                value: null
            },
            flipEnvMap: {
                value: -1
            },
            backgroundBlurriness: {
                value: 0
            },
            backgroundIntensity: {
                value: 1
            },
            backgroundRotation: {
                value: /*@__PURE__*/ new Matrix3()
            }
        },
        vertexShader: ShaderChunk.backgroundCube_vert,
        fragmentShader: ShaderChunk.backgroundCube_frag
    },
    cube: {
        uniforms: {
            tCube: {
                value: null
            },
            tFlip: {
                value: -1
            },
            opacity: {
                value: 1.0
            }
        },
        vertexShader: ShaderChunk.cube_vert,
        fragmentShader: ShaderChunk.cube_frag
    },
    equirect: {
        uniforms: {
            tEquirect: {
                value: null
            }
        },
        vertexShader: ShaderChunk.equirect_vert,
        fragmentShader: ShaderChunk.equirect_frag
    },
    distanceRGBA: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.common,
            UniformsLib.displacementmap,
            {
                referencePosition: {
                    value: /*@__PURE__*/ new Vector3()
                },
                nearDistance: {
                    value: 1
                },
                farDistance: {
                    value: 1000
                }
            }
        ]),
        vertexShader: ShaderChunk.distanceRGBA_vert,
        fragmentShader: ShaderChunk.distanceRGBA_frag
    },
    shadow: {
        uniforms: /*@__PURE__*/ mergeUniforms([
            UniformsLib.lights,
            UniformsLib.fog,
            {
                color: {
                    value: /*@__PURE__*/ new Color(0x00000)
                },
                opacity: {
                    value: 1.0
                }
            }
        ]),
        vertexShader: ShaderChunk.shadow_vert,
        fragmentShader: ShaderChunk.shadow_frag
    }
};
ShaderLib.physical = {
    uniforms: /*@__PURE__*/ mergeUniforms([
        ShaderLib.standard.uniforms,
        {
            clearcoat: {
                value: 0
            },
            clearcoatMap: {
                value: null
            },
            clearcoatMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            clearcoatNormalMap: {
                value: null
            },
            clearcoatNormalMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            clearcoatNormalScale: {
                value: /*@__PURE__*/ new Vector2(1, 1)
            },
            clearcoatRoughness: {
                value: 0
            },
            clearcoatRoughnessMap: {
                value: null
            },
            clearcoatRoughnessMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            dispersion: {
                value: 0
            },
            iridescence: {
                value: 0
            },
            iridescenceMap: {
                value: null
            },
            iridescenceMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            iridescenceIOR: {
                value: 1.3
            },
            iridescenceThicknessMinimum: {
                value: 100
            },
            iridescenceThicknessMaximum: {
                value: 400
            },
            iridescenceThicknessMap: {
                value: null
            },
            iridescenceThicknessMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            sheen: {
                value: 0
            },
            sheenColor: {
                value: /*@__PURE__*/ new Color(0x000000)
            },
            sheenColorMap: {
                value: null
            },
            sheenColorMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            sheenRoughness: {
                value: 1
            },
            sheenRoughnessMap: {
                value: null
            },
            sheenRoughnessMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            transmission: {
                value: 0
            },
            transmissionMap: {
                value: null
            },
            transmissionMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            transmissionSamplerSize: {
                value: /*@__PURE__*/ new Vector2()
            },
            transmissionSamplerMap: {
                value: null
            },
            thickness: {
                value: 0
            },
            thicknessMap: {
                value: null
            },
            thicknessMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            attenuationDistance: {
                value: 0
            },
            attenuationColor: {
                value: /*@__PURE__*/ new Color(0x000000)
            },
            specularColor: {
                value: /*@__PURE__*/ new Color(1, 1, 1)
            },
            specularColorMap: {
                value: null
            },
            specularColorMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            specularIntensity: {
                value: 1
            },
            specularIntensityMap: {
                value: null
            },
            specularIntensityMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            },
            anisotropyVector: {
                value: /*@__PURE__*/ new Vector2()
            },
            anisotropyMap: {
                value: null
            },
            anisotropyMapTransform: {
                value: /*@__PURE__*/ new Matrix3()
            }
        }
    ]),
    vertexShader: ShaderChunk.meshphysical_vert,
    fragmentShader: ShaderChunk.meshphysical_frag
};
const _rgb = {
    r: 0,
    b: 0,
    g: 0
};
const _e1$1 = /*@__PURE__*/ new Euler();
const _m1$1 = /*@__PURE__*/ new Matrix4();
function WebGLBackground(renderer, cubemaps, cubeuvmaps, state, objects, alpha, premultipliedAlpha) {
    const clearColor = new Color(0x000000);
    let clearAlpha = alpha === true ? 0 : 1;
    let planeMesh;
    let boxMesh;
    let currentBackground = null;
    let currentBackgroundVersion = 0;
    let currentTonemapping = null;
    function getBackground(scene) {
        let background = scene.isScene === true ? scene.background : null;
        if (background && background.isTexture) {
            const usePMREM = scene.backgroundBlurriness > 0; // use PMREM if the user wants to blur the background
            background = (usePMREM ? cubeuvmaps : cubemaps).get(background);
        }
        return background;
    }
    function render(scene) {
        let forceClear = false;
        const background = getBackground(scene);
        if (background === null) setClear(clearColor, clearAlpha);
        else if (background && background.isColor) {
            setClear(background, 1);
            forceClear = true;
        }
        const environmentBlendMode = renderer.xr.getEnvironmentBlendMode();
        if (environmentBlendMode === "additive") state.buffers.color.setClear(0, 0, 0, 1, premultipliedAlpha);
        else if (environmentBlendMode === "alpha-blend") state.buffers.color.setClear(0, 0, 0, 0, premultipliedAlpha);
        if (renderer.autoClear || forceClear) {
            // buffers might not be writable which is required to ensure a correct clear
            state.buffers.depth.setTest(true);
            state.buffers.depth.setMask(true);
            state.buffers.color.setMask(true);
            renderer.clear(renderer.autoClearColor, renderer.autoClearDepth, renderer.autoClearStencil);
        }
    }
    function addToRenderList(renderList, scene) {
        const background = getBackground(scene);
        if (background && (background.isCubeTexture || background.mapping === CubeUVReflectionMapping)) {
            if (boxMesh === undefined) {
                boxMesh = new Mesh(new BoxGeometry(1, 1, 1), new ShaderMaterial({
                    name: "BackgroundCubeMaterial",
                    uniforms: cloneUniforms(ShaderLib.backgroundCube.uniforms),
                    vertexShader: ShaderLib.backgroundCube.vertexShader,
                    fragmentShader: ShaderLib.backgroundCube.fragmentShader,
                    side: BackSide,
                    depthTest: false,
                    depthWrite: false,
                    fog: false
                }));
                boxMesh.geometry.deleteAttribute("normal");
                boxMesh.geometry.deleteAttribute("uv");
                boxMesh.onBeforeRender = function(renderer, scene, camera) {
                    this.matrixWorld.copyPosition(camera.matrixWorld);
                };
                // add "envMap" material property so the renderer can evaluate it like for built-in materials
                Object.defineProperty(boxMesh.material, "envMap", {
                    get: function() {
                        return this.uniforms.envMap.value;
                    }
                });
                objects.update(boxMesh);
            }
            _e1$1.copy(scene.backgroundRotation);
            // accommodate left-handed frame
            _e1$1.x *= -1;
            _e1$1.y *= -1;
            _e1$1.z *= -1;
            if (background.isCubeTexture && background.isRenderTargetTexture === false) {
                // environment maps which are not cube render targets or PMREMs follow a different convention
                _e1$1.y *= -1;
                _e1$1.z *= -1;
            }
            boxMesh.material.uniforms.envMap.value = background;
            boxMesh.material.uniforms.flipEnvMap.value = background.isCubeTexture && background.isRenderTargetTexture === false ? -1 : 1;
            boxMesh.material.uniforms.backgroundBlurriness.value = scene.backgroundBlurriness;
            boxMesh.material.uniforms.backgroundIntensity.value = scene.backgroundIntensity;
            boxMesh.material.uniforms.backgroundRotation.value.setFromMatrix4(_m1$1.makeRotationFromEuler(_e1$1));
            boxMesh.material.toneMapped = ColorManagement.getTransfer(background.colorSpace) !== SRGBTransfer;
            if (currentBackground !== background || currentBackgroundVersion !== background.version || currentTonemapping !== renderer.toneMapping) {
                boxMesh.material.needsUpdate = true;
                currentBackground = background;
                currentBackgroundVersion = background.version;
                currentTonemapping = renderer.toneMapping;
            }
            boxMesh.layers.enableAll();
            // push to the pre-sorted opaque render list
            renderList.unshift(boxMesh, boxMesh.geometry, boxMesh.material, 0, 0, null);
        } else if (background && background.isTexture) {
            if (planeMesh === undefined) {
                planeMesh = new Mesh(new PlaneGeometry(2, 2), new ShaderMaterial({
                    name: "BackgroundMaterial",
                    uniforms: cloneUniforms(ShaderLib.background.uniforms),
                    vertexShader: ShaderLib.background.vertexShader,
                    fragmentShader: ShaderLib.background.fragmentShader,
                    side: FrontSide,
                    depthTest: false,
                    depthWrite: false,
                    fog: false
                }));
                planeMesh.geometry.deleteAttribute("normal");
                // add "map" material property so the renderer can evaluate it like for built-in materials
                Object.defineProperty(planeMesh.material, "map", {
                    get: function() {
                        return this.uniforms.t2D.value;
                    }
                });
                objects.update(planeMesh);
            }
            planeMesh.material.uniforms.t2D.value = background;
            planeMesh.material.uniforms.backgroundIntensity.value = scene.backgroundIntensity;
            planeMesh.material.toneMapped = ColorManagement.getTransfer(background.colorSpace) !== SRGBTransfer;
            if (background.matrixAutoUpdate === true) background.updateMatrix();
            planeMesh.material.uniforms.uvTransform.value.copy(background.matrix);
            if (currentBackground !== background || currentBackgroundVersion !== background.version || currentTonemapping !== renderer.toneMapping) {
                planeMesh.material.needsUpdate = true;
                currentBackground = background;
                currentBackgroundVersion = background.version;
                currentTonemapping = renderer.toneMapping;
            }
            planeMesh.layers.enableAll();
            // push to the pre-sorted opaque render list
            renderList.unshift(planeMesh, planeMesh.geometry, planeMesh.material, 0, 0, null);
        }
    }
    function setClear(color, alpha) {
        color.getRGB(_rgb, getUnlitUniformColorSpace(renderer));
        state.buffers.color.setClear(_rgb.r, _rgb.g, _rgb.b, alpha, premultipliedAlpha);
    }
    return {
        getClearColor: function() {
            return clearColor;
        },
        setClearColor: function(color, alpha = 1) {
            clearColor.set(color);
            clearAlpha = alpha;
            setClear(clearColor, clearAlpha);
        },
        getClearAlpha: function() {
            return clearAlpha;
        },
        setClearAlpha: function(alpha) {
            clearAlpha = alpha;
            setClear(clearColor, clearAlpha);
        },
        render: render,
        addToRenderList: addToRenderList
    };
}
function WebGLBindingStates(gl, attributes) {
    const maxVertexAttributes = gl.getParameter(gl.MAX_VERTEX_ATTRIBS);
    const bindingStates = {};
    const defaultState = createBindingState(null);
    let currentState = defaultState;
    let forceUpdate = false;
    function setup(object, material, program, geometry, index) {
        let updateBuffers = false;
        const state = getBindingState(geometry, program, material);
        if (currentState !== state) {
            currentState = state;
            bindVertexArrayObject(currentState.object);
        }
        updateBuffers = needsUpdate(object, geometry, program, index);
        if (updateBuffers) saveCache(object, geometry, program, index);
        if (index !== null) attributes.update(index, gl.ELEMENT_ARRAY_BUFFER);
        if (updateBuffers || forceUpdate) {
            forceUpdate = false;
            setupVertexAttributes(object, material, program, geometry);
            if (index !== null) gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, attributes.get(index).buffer);
        }
    }
    function createVertexArrayObject() {
        return gl.createVertexArray();
    }
    function bindVertexArrayObject(vao) {
        return gl.bindVertexArray(vao);
    }
    function deleteVertexArrayObject(vao) {
        return gl.deleteVertexArray(vao);
    }
    function getBindingState(geometry, program, material) {
        const wireframe = material.wireframe === true;
        let programMap = bindingStates[geometry.id];
        if (programMap === undefined) {
            programMap = {};
            bindingStates[geometry.id] = programMap;
        }
        let stateMap = programMap[program.id];
        if (stateMap === undefined) {
            stateMap = {};
            programMap[program.id] = stateMap;
        }
        let state = stateMap[wireframe];
        if (state === undefined) {
            state = createBindingState(createVertexArrayObject());
            stateMap[wireframe] = state;
        }
        return state;
    }
    function createBindingState(vao) {
        const newAttributes = [];
        const enabledAttributes = [];
        const attributeDivisors = [];
        for(let i = 0; i < maxVertexAttributes; i++){
            newAttributes[i] = 0;
            enabledAttributes[i] = 0;
            attributeDivisors[i] = 0;
        }
        return {
            // for backward compatibility on non-VAO support browser
            geometry: null,
            program: null,
            wireframe: false,
            newAttributes: newAttributes,
            enabledAttributes: enabledAttributes,
            attributeDivisors: attributeDivisors,
            object: vao,
            attributes: {},
            index: null
        };
    }
    function needsUpdate(object, geometry, program, index) {
        const cachedAttributes = currentState.attributes;
        const geometryAttributes = geometry.attributes;
        let attributesNum = 0;
        const programAttributes = program.getAttributes();
        for(const name in programAttributes){
            const programAttribute = programAttributes[name];
            if (programAttribute.location >= 0) {
                const cachedAttribute = cachedAttributes[name];
                let geometryAttribute = geometryAttributes[name];
                if (geometryAttribute === undefined) {
                    if (name === "instanceMatrix" && object.instanceMatrix) geometryAttribute = object.instanceMatrix;
                    if (name === "instanceColor" && object.instanceColor) geometryAttribute = object.instanceColor;
                }
                if (cachedAttribute === undefined) return true;
                if (cachedAttribute.attribute !== geometryAttribute) return true;
                if (geometryAttribute && cachedAttribute.data !== geometryAttribute.data) return true;
                attributesNum++;
            }
        }
        if (currentState.attributesNum !== attributesNum) return true;
        if (currentState.index !== index) return true;
        return false;
    }
    function saveCache(object, geometry, program, index) {
        const cache = {};
        const attributes = geometry.attributes;
        let attributesNum = 0;
        const programAttributes = program.getAttributes();
        for(const name in programAttributes){
            const programAttribute = programAttributes[name];
            if (programAttribute.location >= 0) {
                let attribute = attributes[name];
                if (attribute === undefined) {
                    if (name === "instanceMatrix" && object.instanceMatrix) attribute = object.instanceMatrix;
                    if (name === "instanceColor" && object.instanceColor) attribute = object.instanceColor;
                }
                const data = {};
                data.attribute = attribute;
                if (attribute && attribute.data) data.data = attribute.data;
                cache[name] = data;
                attributesNum++;
            }
        }
        currentState.attributes = cache;
        currentState.attributesNum = attributesNum;
        currentState.index = index;
    }
    function initAttributes() {
        const newAttributes = currentState.newAttributes;
        for(let i = 0, il = newAttributes.length; i < il; i++)newAttributes[i] = 0;
    }
    function enableAttribute(attribute) {
        enableAttributeAndDivisor(attribute, 0);
    }
    function enableAttributeAndDivisor(attribute, meshPerAttribute) {
        const newAttributes = currentState.newAttributes;
        const enabledAttributes = currentState.enabledAttributes;
        const attributeDivisors = currentState.attributeDivisors;
        newAttributes[attribute] = 1;
        if (enabledAttributes[attribute] === 0) {
            gl.enableVertexAttribArray(attribute);
            enabledAttributes[attribute] = 1;
        }
        if (attributeDivisors[attribute] !== meshPerAttribute) {
            gl.vertexAttribDivisor(attribute, meshPerAttribute);
            attributeDivisors[attribute] = meshPerAttribute;
        }
    }
    function disableUnusedAttributes() {
        const newAttributes = currentState.newAttributes;
        const enabledAttributes = currentState.enabledAttributes;
        for(let i = 0, il = enabledAttributes.length; i < il; i++)if (enabledAttributes[i] !== newAttributes[i]) {
            gl.disableVertexAttribArray(i);
            enabledAttributes[i] = 0;
        }
    }
    function vertexAttribPointer(index, size, type, normalized, stride, offset, integer) {
        if (integer === true) gl.vertexAttribIPointer(index, size, type, stride, offset);
        else gl.vertexAttribPointer(index, size, type, normalized, stride, offset);
    }
    function setupVertexAttributes(object, material, program, geometry) {
        initAttributes();
        const geometryAttributes = geometry.attributes;
        const programAttributes = program.getAttributes();
        const materialDefaultAttributeValues = material.defaultAttributeValues;
        for(const name in programAttributes){
            const programAttribute = programAttributes[name];
            if (programAttribute.location >= 0) {
                let geometryAttribute = geometryAttributes[name];
                if (geometryAttribute === undefined) {
                    if (name === "instanceMatrix" && object.instanceMatrix) geometryAttribute = object.instanceMatrix;
                    if (name === "instanceColor" && object.instanceColor) geometryAttribute = object.instanceColor;
                }
                if (geometryAttribute !== undefined) {
                    const normalized = geometryAttribute.normalized;
                    const size = geometryAttribute.itemSize;
                    const attribute = attributes.get(geometryAttribute);
                    // TODO Attribute may not be available on context restore
                    if (attribute === undefined) continue;
                    const buffer = attribute.buffer;
                    const type = attribute.type;
                    const bytesPerElement = attribute.bytesPerElement;
                    // check for integer attributes
                    const integer = type === gl.INT || type === gl.UNSIGNED_INT || geometryAttribute.gpuType === IntType;
                    if (geometryAttribute.isInterleavedBufferAttribute) {
                        const data = geometryAttribute.data;
                        const stride = data.stride;
                        const offset = geometryAttribute.offset;
                        if (data.isInstancedInterleavedBuffer) {
                            for(let i = 0; i < programAttribute.locationSize; i++)enableAttributeAndDivisor(programAttribute.location + i, data.meshPerAttribute);
                            if (object.isInstancedMesh !== true && geometry._maxInstanceCount === undefined) geometry._maxInstanceCount = data.meshPerAttribute * data.count;
                        } else for(let i = 0; i < programAttribute.locationSize; i++)enableAttribute(programAttribute.location + i);
                        gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
                        for(let i = 0; i < programAttribute.locationSize; i++)vertexAttribPointer(programAttribute.location + i, size / programAttribute.locationSize, type, normalized, stride * bytesPerElement, (offset + size / programAttribute.locationSize * i) * bytesPerElement, integer);
                    } else {
                        if (geometryAttribute.isInstancedBufferAttribute) {
                            for(let i = 0; i < programAttribute.locationSize; i++)enableAttributeAndDivisor(programAttribute.location + i, geometryAttribute.meshPerAttribute);
                            if (object.isInstancedMesh !== true && geometry._maxInstanceCount === undefined) geometry._maxInstanceCount = geometryAttribute.meshPerAttribute * geometryAttribute.count;
                        } else for(let i = 0; i < programAttribute.locationSize; i++)enableAttribute(programAttribute.location + i);
                        gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
                        for(let i = 0; i < programAttribute.locationSize; i++)vertexAttribPointer(programAttribute.location + i, size / programAttribute.locationSize, type, normalized, size * bytesPerElement, size / programAttribute.locationSize * i * bytesPerElement, integer);
                    }
                } else if (materialDefaultAttributeValues !== undefined) {
                    const value = materialDefaultAttributeValues[name];
                    if (value !== undefined) switch(value.length){
                        case 2:
                            gl.vertexAttrib2fv(programAttribute.location, value);
                            break;
                        case 3:
                            gl.vertexAttrib3fv(programAttribute.location, value);
                            break;
                        case 4:
                            gl.vertexAttrib4fv(programAttribute.location, value);
                            break;
                        default:
                            gl.vertexAttrib1fv(programAttribute.location, value);
                    }
                }
            }
        }
        disableUnusedAttributes();
    }
    function dispose() {
        reset();
        for(const geometryId in bindingStates){
            const programMap = bindingStates[geometryId];
            for(const programId in programMap){
                const stateMap = programMap[programId];
                for(const wireframe in stateMap){
                    deleteVertexArrayObject(stateMap[wireframe].object);
                    delete stateMap[wireframe];
                }
                delete programMap[programId];
            }
            delete bindingStates[geometryId];
        }
    }
    function releaseStatesOfGeometry(geometry) {
        if (bindingStates[geometry.id] === undefined) return;
        const programMap = bindingStates[geometry.id];
        for(const programId in programMap){
            const stateMap = programMap[programId];
            for(const wireframe in stateMap){
                deleteVertexArrayObject(stateMap[wireframe].object);
                delete stateMap[wireframe];
            }
            delete programMap[programId];
        }
        delete bindingStates[geometry.id];
    }
    function releaseStatesOfProgram(program) {
        for(const geometryId in bindingStates){
            const programMap = bindingStates[geometryId];
            if (programMap[program.id] === undefined) continue;
            const stateMap = programMap[program.id];
            for(const wireframe in stateMap){
                deleteVertexArrayObject(stateMap[wireframe].object);
                delete stateMap[wireframe];
            }
            delete programMap[program.id];
        }
    }
    function reset() {
        resetDefaultState();
        forceUpdate = true;
        if (currentState === defaultState) return;
        currentState = defaultState;
        bindVertexArrayObject(currentState.object);
    }
    // for backward-compatibility
    function resetDefaultState() {
        defaultState.geometry = null;
        defaultState.program = null;
        defaultState.wireframe = false;
    }
    return {
        setup: setup,
        reset: reset,
        resetDefaultState: resetDefaultState,
        dispose: dispose,
        releaseStatesOfGeometry: releaseStatesOfGeometry,
        releaseStatesOfProgram: releaseStatesOfProgram,
        initAttributes: initAttributes,
        enableAttribute: enableAttribute,
        disableUnusedAttributes: disableUnusedAttributes
    };
}
function WebGLBufferRenderer(gl, extensions, info) {
    let mode;
    function setMode(value) {
        mode = value;
    }
    function render(start, count) {
        gl.drawArrays(mode, start, count);
        info.update(count, mode, 1);
    }
    function renderInstances(start, count, primcount) {
        if (primcount === 0) return;
        gl.drawArraysInstanced(mode, start, count, primcount);
        info.update(count, mode, primcount);
    }
    function renderMultiDraw(starts, counts, drawCount) {
        if (drawCount === 0) return;
        const extension = extensions.get("WEBGL_multi_draw");
        extension.multiDrawArraysWEBGL(mode, starts, 0, counts, 0, drawCount);
        let elementCount = 0;
        for(let i = 0; i < drawCount; i++)elementCount += counts[i];
        info.update(elementCount, mode, 1);
    }
    function renderMultiDrawInstances(starts, counts, drawCount, primcount) {
        if (drawCount === 0) return;
        const extension = extensions.get("WEBGL_multi_draw");
        if (extension === null) for(let i = 0; i < starts.length; i++)renderInstances(starts[i], counts[i], primcount[i]);
        else {
            extension.multiDrawArraysInstancedWEBGL(mode, starts, 0, counts, 0, primcount, 0, drawCount);
            let elementCount = 0;
            for(let i = 0; i < drawCount; i++)elementCount += counts[i];
            for(let i = 0; i < primcount.length; i++)info.update(elementCount, mode, primcount[i]);
        }
    }
    //
    this.setMode = setMode;
    this.render = render;
    this.renderInstances = renderInstances;
    this.renderMultiDraw = renderMultiDraw;
    this.renderMultiDrawInstances = renderMultiDrawInstances;
}
function WebGLCapabilities(gl, extensions, parameters, utils) {
    let maxAnisotropy;
    function getMaxAnisotropy() {
        if (maxAnisotropy !== undefined) return maxAnisotropy;
        if (extensions.has("EXT_texture_filter_anisotropic") === true) {
            const extension = extensions.get("EXT_texture_filter_anisotropic");
            maxAnisotropy = gl.getParameter(extension.MAX_TEXTURE_MAX_ANISOTROPY_EXT);
        } else maxAnisotropy = 0;
        return maxAnisotropy;
    }
    function textureFormatReadable(textureFormat) {
        if (textureFormat !== RGBAFormat && utils.convert(textureFormat) !== gl.getParameter(gl.IMPLEMENTATION_COLOR_READ_FORMAT)) return false;
        return true;
    }
    function textureTypeReadable(textureType) {
        const halfFloatSupportedByExt = textureType === HalfFloatType && (extensions.has("EXT_color_buffer_half_float") || extensions.has("EXT_color_buffer_float"));
        if (textureType !== UnsignedByteType && utils.convert(textureType) !== gl.getParameter(gl.IMPLEMENTATION_COLOR_READ_TYPE) && // Edge and Chrome Mac < 52 (#9513)
        textureType !== FloatType && !halfFloatSupportedByExt) return false;
        return true;
    }
    function getMaxPrecision(precision) {
        if (precision === "highp") {
            if (gl.getShaderPrecisionFormat(gl.VERTEX_SHADER, gl.HIGH_FLOAT).precision > 0 && gl.getShaderPrecisionFormat(gl.FRAGMENT_SHADER, gl.HIGH_FLOAT).precision > 0) return "highp";
            precision = "mediump";
        }
        if (precision === "mediump") {
            if (gl.getShaderPrecisionFormat(gl.VERTEX_SHADER, gl.MEDIUM_FLOAT).precision > 0 && gl.getShaderPrecisionFormat(gl.FRAGMENT_SHADER, gl.MEDIUM_FLOAT).precision > 0) return "mediump";
        }
        return "lowp";
    }
    let precision = parameters.precision !== undefined ? parameters.precision : "highp";
    const maxPrecision = getMaxPrecision(precision);
    if (maxPrecision !== precision) {
        console.warn("THREE.WebGLRenderer:", precision, "not supported, using", maxPrecision, "instead.");
        precision = maxPrecision;
    }
    const logarithmicDepthBuffer = parameters.logarithmicDepthBuffer === true;
    const maxTextures = gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS);
    const maxVertexTextures = gl.getParameter(gl.MAX_VERTEX_TEXTURE_IMAGE_UNITS);
    const maxTextureSize = gl.getParameter(gl.MAX_TEXTURE_SIZE);
    const maxCubemapSize = gl.getParameter(gl.MAX_CUBE_MAP_TEXTURE_SIZE);
    const maxAttributes = gl.getParameter(gl.MAX_VERTEX_ATTRIBS);
    const maxVertexUniforms = gl.getParameter(gl.MAX_VERTEX_UNIFORM_VECTORS);
    const maxVaryings = gl.getParameter(gl.MAX_VARYING_VECTORS);
    const maxFragmentUniforms = gl.getParameter(gl.MAX_FRAGMENT_UNIFORM_VECTORS);
    const vertexTextures = maxVertexTextures > 0;
    const maxSamples = gl.getParameter(gl.MAX_SAMPLES);
    return {
        isWebGL2: true,
        getMaxAnisotropy: getMaxAnisotropy,
        getMaxPrecision: getMaxPrecision,
        textureFormatReadable: textureFormatReadable,
        textureTypeReadable: textureTypeReadable,
        precision: precision,
        logarithmicDepthBuffer: logarithmicDepthBuffer,
        maxTextures: maxTextures,
        maxVertexTextures: maxVertexTextures,
        maxTextureSize: maxTextureSize,
        maxCubemapSize: maxCubemapSize,
        maxAttributes: maxAttributes,
        maxVertexUniforms: maxVertexUniforms,
        maxVaryings: maxVaryings,
        maxFragmentUniforms: maxFragmentUniforms,
        vertexTextures: vertexTextures,
        maxSamples: maxSamples
    };
}
function WebGLClipping(properties) {
    const scope = this;
    let globalState = null, numGlobalPlanes = 0, localClippingEnabled = false, renderingShadows = false;
    const plane = new Plane(), viewNormalMatrix = new Matrix3(), uniform = {
        value: null,
        needsUpdate: false
    };
    this.uniform = uniform;
    this.numPlanes = 0;
    this.numIntersection = 0;
    this.init = function(planes, enableLocalClipping) {
        const enabled = planes.length !== 0 || enableLocalClipping || // enable state of previous frame - the clipping code has to
        // run another frame in order to reset the state:
        numGlobalPlanes !== 0 || localClippingEnabled;
        localClippingEnabled = enableLocalClipping;
        numGlobalPlanes = planes.length;
        return enabled;
    };
    this.beginShadows = function() {
        renderingShadows = true;
        projectPlanes(null);
    };
    this.endShadows = function() {
        renderingShadows = false;
    };
    this.setGlobalState = function(planes, camera) {
        globalState = projectPlanes(planes, camera, 0);
    };
    this.setState = function(material, camera, useCache) {
        const planes = material.clippingPlanes, clipIntersection = material.clipIntersection, clipShadows = material.clipShadows;
        const materialProperties = properties.get(material);
        if (!localClippingEnabled || planes === null || planes.length === 0 || renderingShadows && !clipShadows) {
            // there's no local clipping
            if (renderingShadows) // there's no global clipping
            projectPlanes(null);
            else resetGlobalState();
        } else {
            const nGlobal = renderingShadows ? 0 : numGlobalPlanes, lGlobal = nGlobal * 4;
            let dstArray = materialProperties.clippingState || null;
            uniform.value = dstArray; // ensure unique state
            dstArray = projectPlanes(planes, camera, lGlobal, useCache);
            for(let i = 0; i !== lGlobal; ++i)dstArray[i] = globalState[i];
            materialProperties.clippingState = dstArray;
            this.numIntersection = clipIntersection ? this.numPlanes : 0;
            this.numPlanes += nGlobal;
        }
    };
    function resetGlobalState() {
        if (uniform.value !== globalState) {
            uniform.value = globalState;
            uniform.needsUpdate = numGlobalPlanes > 0;
        }
        scope.numPlanes = numGlobalPlanes;
        scope.numIntersection = 0;
    }
    function projectPlanes(planes, camera, dstOffset, skipTransform) {
        const nPlanes = planes !== null ? planes.length : 0;
        let dstArray = null;
        if (nPlanes !== 0) {
            dstArray = uniform.value;
            if (skipTransform !== true || dstArray === null) {
                const flatSize = dstOffset + nPlanes * 4, viewMatrix = camera.matrixWorldInverse;
                viewNormalMatrix.getNormalMatrix(viewMatrix);
                if (dstArray === null || dstArray.length < flatSize) dstArray = new Float32Array(flatSize);
                for(let i = 0, i4 = dstOffset; i !== nPlanes; ++i, i4 += 4){
                    plane.copy(planes[i]).applyMatrix4(viewMatrix, viewNormalMatrix);
                    plane.normal.toArray(dstArray, i4);
                    dstArray[i4 + 3] = plane.constant;
                }
            }
            uniform.value = dstArray;
            uniform.needsUpdate = true;
        }
        scope.numPlanes = nPlanes;
        scope.numIntersection = 0;
        return dstArray;
    }
}
function WebGLCubeMaps(renderer) {
    let cubemaps = new WeakMap();
    function mapTextureMapping(texture, mapping) {
        if (mapping === EquirectangularReflectionMapping) texture.mapping = CubeReflectionMapping;
        else if (mapping === EquirectangularRefractionMapping) texture.mapping = CubeRefractionMapping;
        return texture;
    }
    function get(texture) {
        if (texture && texture.isTexture) {
            const mapping = texture.mapping;
            if (mapping === EquirectangularReflectionMapping || mapping === EquirectangularRefractionMapping) {
                if (cubemaps.has(texture)) {
                    const cubemap = cubemaps.get(texture).texture;
                    return mapTextureMapping(cubemap, texture.mapping);
                } else {
                    const image = texture.image;
                    if (image && image.height > 0) {
                        const renderTarget = new WebGLCubeRenderTarget(image.height);
                        renderTarget.fromEquirectangularTexture(renderer, texture);
                        cubemaps.set(texture, renderTarget);
                        texture.addEventListener("dispose", onTextureDispose);
                        return mapTextureMapping(renderTarget.texture, texture.mapping);
                    } else // image not yet ready. try the conversion next frame
                    return null;
                }
            }
        }
        return texture;
    }
    function onTextureDispose(event) {
        const texture = event.target;
        texture.removeEventListener("dispose", onTextureDispose);
        const cubemap = cubemaps.get(texture);
        if (cubemap !== undefined) {
            cubemaps.delete(texture);
            cubemap.dispose();
        }
    }
    function dispose() {
        cubemaps = new WeakMap();
    }
    return {
        get: get,
        dispose: dispose
    };
}
class OrthographicCamera extends Camera {
    constructor(left = -1, right = 1, top = 1, bottom = -1, near = 0.1, far = 2000){
        super();
        this.isOrthographicCamera = true;
        this.type = "OrthographicCamera";
        this.zoom = 1;
        this.view = null;
        this.left = left;
        this.right = right;
        this.top = top;
        this.bottom = bottom;
        this.near = near;
        this.far = far;
        this.updateProjectionMatrix();
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.left = source.left;
        this.right = source.right;
        this.top = source.top;
        this.bottom = source.bottom;
        this.near = source.near;
        this.far = source.far;
        this.zoom = source.zoom;
        this.view = source.view === null ? null : Object.assign({}, source.view);
        return this;
    }
    setViewOffset(fullWidth, fullHeight, x, y, width, height) {
        if (this.view === null) this.view = {
            enabled: true,
            fullWidth: 1,
            fullHeight: 1,
            offsetX: 0,
            offsetY: 0,
            width: 1,
            height: 1
        };
        this.view.enabled = true;
        this.view.fullWidth = fullWidth;
        this.view.fullHeight = fullHeight;
        this.view.offsetX = x;
        this.view.offsetY = y;
        this.view.width = width;
        this.view.height = height;
        this.updateProjectionMatrix();
    }
    clearViewOffset() {
        if (this.view !== null) this.view.enabled = false;
        this.updateProjectionMatrix();
    }
    updateProjectionMatrix() {
        const dx = (this.right - this.left) / (2 * this.zoom);
        const dy = (this.top - this.bottom) / (2 * this.zoom);
        const cx = (this.right + this.left) / 2;
        const cy = (this.top + this.bottom) / 2;
        let left = cx - dx;
        let right = cx + dx;
        let top = cy + dy;
        let bottom = cy - dy;
        if (this.view !== null && this.view.enabled) {
            const scaleW = (this.right - this.left) / this.view.fullWidth / this.zoom;
            const scaleH = (this.top - this.bottom) / this.view.fullHeight / this.zoom;
            left += scaleW * this.view.offsetX;
            right = left + scaleW * this.view.width;
            top -= scaleH * this.view.offsetY;
            bottom = top - scaleH * this.view.height;
        }
        this.projectionMatrix.makeOrthographic(left, right, top, bottom, this.near, this.far, this.coordinateSystem);
        this.projectionMatrixInverse.copy(this.projectionMatrix).invert();
    }
    toJSON(meta) {
        const data = super.toJSON(meta);
        data.object.zoom = this.zoom;
        data.object.left = this.left;
        data.object.right = this.right;
        data.object.top = this.top;
        data.object.bottom = this.bottom;
        data.object.near = this.near;
        data.object.far = this.far;
        if (this.view !== null) data.object.view = Object.assign({}, this.view);
        return data;
    }
}
const LOD_MIN = 4;
// The standard deviations (radians) associated with the extra mips. These are
// chosen to approximate a Trowbridge-Reitz distribution function times the
// geometric shadowing function. These sigma values squared must match the
// variance #defines in cube_uv_reflection_fragment.glsl.js.
const EXTRA_LOD_SIGMA = [
    0.125,
    0.215,
    0.35,
    0.446,
    0.526,
    0.582
];
// The maximum length of the blur for loop. Smaller sigmas will use fewer
// samples and exit early, but not recompile the shader.
const MAX_SAMPLES = 20;
const _flatCamera = /*@__PURE__*/ new OrthographicCamera();
const _clearColor = /*@__PURE__*/ new Color();
let _oldTarget = null;
let _oldActiveCubeFace = 0;
let _oldActiveMipmapLevel = 0;
let _oldXrEnabled = false;
// Golden Ratio
const PHI = (1 + Math.sqrt(5)) / 2;
const INV_PHI = 1 / PHI;
// Vertices of a dodecahedron (except the opposites, which represent the
// same axis), used as axis directions evenly spread on a sphere.
const _axisDirections = [
    /*@__PURE__*/ new Vector3(-PHI, INV_PHI, 0),
    /*@__PURE__*/ new Vector3(PHI, INV_PHI, 0),
    /*@__PURE__*/ new Vector3(-INV_PHI, 0, PHI),
    /*@__PURE__*/ new Vector3(INV_PHI, 0, PHI),
    /*@__PURE__*/ new Vector3(0, PHI, -INV_PHI),
    /*@__PURE__*/ new Vector3(0, PHI, INV_PHI),
    /*@__PURE__*/ new Vector3(-1, 1, -1),
    /*@__PURE__*/ new Vector3(1, 1, -1),
    /*@__PURE__*/ new Vector3(-1, 1, 1),
    /*@__PURE__*/ new Vector3(1, 1, 1)
];
/**
 * This class generates a Prefiltered, Mipmapped Radiance Environment Map
 * (PMREM) from a cubeMap environment texture. This allows different levels of
 * blur to be quickly accessed based on material roughness. It is packed into a
 * special CubeUV format that allows us to perform custom interpolation so that
 * we can support nonlinear formats such as RGBE. Unlike a traditional mipmap
 * chain, it only goes down to the LOD_MIN level (above), and then creates extra
 * even more filtered 'mips' at the same LOD_MIN resolution, associated with
 * higher roughness levels. In this way we maintain resolution to smoothly
 * interpolate diffuse lighting while limiting sampling computation.
 *
 * Paper: Fast, Accurate Image-Based Lighting
 * https://drive.google.com/file/d/15y8r_UpKlU9SvV4ILb0C3qCPecS8pvLz/view
*/ class PMREMGenerator {
    constructor(renderer){
        this._renderer = renderer;
        this._pingPongRenderTarget = null;
        this._lodMax = 0;
        this._cubeSize = 0;
        this._lodPlanes = [];
        this._sizeLods = [];
        this._sigmas = [];
        this._blurMaterial = null;
        this._cubemapMaterial = null;
        this._equirectMaterial = null;
        this._compileMaterial(this._blurMaterial);
    }
    /**
	 * Generates a PMREM from a supplied Scene, which can be faster than using an
	 * image if networking bandwidth is low. Optional sigma specifies a blur radius
	 * in radians to be applied to the scene before PMREM generation. Optional near
	 * and far planes ensure the scene is rendered in its entirety (the cubeCamera
	 * is placed at the origin).
	 */ fromScene(scene, sigma = 0, near = 0.1, far = 100) {
        _oldTarget = this._renderer.getRenderTarget();
        _oldActiveCubeFace = this._renderer.getActiveCubeFace();
        _oldActiveMipmapLevel = this._renderer.getActiveMipmapLevel();
        _oldXrEnabled = this._renderer.xr.enabled;
        this._renderer.xr.enabled = false;
        this._setSize(256);
        const cubeUVRenderTarget = this._allocateTargets();
        cubeUVRenderTarget.depthBuffer = true;
        this._sceneToCubeUV(scene, near, far, cubeUVRenderTarget);
        if (sigma > 0) this._blur(cubeUVRenderTarget, 0, 0, sigma);
        this._applyPMREM(cubeUVRenderTarget);
        this._cleanup(cubeUVRenderTarget);
        return cubeUVRenderTarget;
    }
    /**
	 * Generates a PMREM from an equirectangular texture, which can be either LDR
	 * or HDR. The ideal input image size is 1k (1024 x 512),
	 * as this matches best with the 256 x 256 cubemap output.
	 * The smallest supported equirectangular image size is 64 x 32.
	 */ fromEquirectangular(equirectangular, renderTarget = null) {
        return this._fromTexture(equirectangular, renderTarget);
    }
    /**
	 * Generates a PMREM from an cubemap texture, which can be either LDR
	 * or HDR. The ideal input cube size is 256 x 256,
	 * as this matches best with the 256 x 256 cubemap output.
	 * The smallest supported cube size is 16 x 16.
	 */ fromCubemap(cubemap, renderTarget = null) {
        return this._fromTexture(cubemap, renderTarget);
    }
    /**
	 * Pre-compiles the cubemap shader. You can get faster start-up by invoking this method during
	 * your texture's network fetch for increased concurrency.
	 */ compileCubemapShader() {
        if (this._cubemapMaterial === null) {
            this._cubemapMaterial = _getCubemapMaterial();
            this._compileMaterial(this._cubemapMaterial);
        }
    }
    /**
	 * Pre-compiles the equirectangular shader. You can get faster start-up by invoking this method during
	 * your texture's network fetch for increased concurrency.
	 */ compileEquirectangularShader() {
        if (this._equirectMaterial === null) {
            this._equirectMaterial = _getEquirectMaterial();
            this._compileMaterial(this._equirectMaterial);
        }
    }
    /**
	 * Disposes of the PMREMGenerator's internal memory. Note that PMREMGenerator is a static class,
	 * so you should not need more than one PMREMGenerator object. If you do, calling dispose() on
	 * one of them will cause any others to also become unusable.
	 */ dispose() {
        this._dispose();
        if (this._cubemapMaterial !== null) this._cubemapMaterial.dispose();
        if (this._equirectMaterial !== null) this._equirectMaterial.dispose();
    }
    // private interface
    _setSize(cubeSize) {
        this._lodMax = Math.floor(Math.log2(cubeSize));
        this._cubeSize = Math.pow(2, this._lodMax);
    }
    _dispose() {
        if (this._blurMaterial !== null) this._blurMaterial.dispose();
        if (this._pingPongRenderTarget !== null) this._pingPongRenderTarget.dispose();
        for(let i = 0; i < this._lodPlanes.length; i++)this._lodPlanes[i].dispose();
    }
    _cleanup(outputTarget) {
        this._renderer.setRenderTarget(_oldTarget, _oldActiveCubeFace, _oldActiveMipmapLevel);
        this._renderer.xr.enabled = _oldXrEnabled;
        outputTarget.scissorTest = false;
        _setViewport(outputTarget, 0, 0, outputTarget.width, outputTarget.height);
    }
    _fromTexture(texture, renderTarget) {
        if (texture.mapping === CubeReflectionMapping || texture.mapping === CubeRefractionMapping) this._setSize(texture.image.length === 0 ? 16 : texture.image[0].width || texture.image[0].image.width);
        else this._setSize(texture.image.width / 4);
        _oldTarget = this._renderer.getRenderTarget();
        _oldActiveCubeFace = this._renderer.getActiveCubeFace();
        _oldActiveMipmapLevel = this._renderer.getActiveMipmapLevel();
        _oldXrEnabled = this._renderer.xr.enabled;
        this._renderer.xr.enabled = false;
        const cubeUVRenderTarget = renderTarget || this._allocateTargets();
        this._textureToCubeUV(texture, cubeUVRenderTarget);
        this._applyPMREM(cubeUVRenderTarget);
        this._cleanup(cubeUVRenderTarget);
        return cubeUVRenderTarget;
    }
    _allocateTargets() {
        const width = 3 * Math.max(this._cubeSize, 112);
        const height = 4 * this._cubeSize;
        const params = {
            magFilter: LinearFilter,
            minFilter: LinearFilter,
            generateMipmaps: false,
            type: HalfFloatType,
            format: RGBAFormat,
            colorSpace: LinearSRGBColorSpace,
            depthBuffer: false
        };
        const cubeUVRenderTarget = _createRenderTarget(width, height, params);
        if (this._pingPongRenderTarget === null || this._pingPongRenderTarget.width !== width || this._pingPongRenderTarget.height !== height) {
            if (this._pingPongRenderTarget !== null) this._dispose();
            this._pingPongRenderTarget = _createRenderTarget(width, height, params);
            const { _lodMax } = this;
            ({ sizeLods: this._sizeLods, lodPlanes: this._lodPlanes, sigmas: this._sigmas } = _createPlanes(_lodMax));
            this._blurMaterial = _getBlurShader(_lodMax, width, height);
        }
        return cubeUVRenderTarget;
    }
    _compileMaterial(material) {
        const tmpMesh = new Mesh(this._lodPlanes[0], material);
        this._renderer.compile(tmpMesh, _flatCamera);
    }
    _sceneToCubeUV(scene, near, far, cubeUVRenderTarget) {
        const fov = 90;
        const aspect = 1;
        const cubeCamera = new PerspectiveCamera(fov, aspect, near, far);
        const upSign = [
            1,
            -1,
            1,
            1,
            1,
            1
        ];
        const forwardSign = [
            1,
            1,
            1,
            -1,
            -1,
            -1
        ];
        const renderer = this._renderer;
        const originalAutoClear = renderer.autoClear;
        const toneMapping = renderer.toneMapping;
        renderer.getClearColor(_clearColor);
        renderer.toneMapping = NoToneMapping;
        renderer.autoClear = false;
        const backgroundMaterial = new MeshBasicMaterial({
            name: "PMREM.Background",
            side: BackSide,
            depthWrite: false,
            depthTest: false
        });
        const backgroundBox = new Mesh(new BoxGeometry(), backgroundMaterial);
        let useSolidColor = false;
        const background = scene.background;
        if (background) {
            if (background.isColor) {
                backgroundMaterial.color.copy(background);
                scene.background = null;
                useSolidColor = true;
            }
        } else {
            backgroundMaterial.color.copy(_clearColor);
            useSolidColor = true;
        }
        for(let i = 0; i < 6; i++){
            const col = i % 3;
            if (col === 0) {
                cubeCamera.up.set(0, upSign[i], 0);
                cubeCamera.lookAt(forwardSign[i], 0, 0);
            } else if (col === 1) {
                cubeCamera.up.set(0, 0, upSign[i]);
                cubeCamera.lookAt(0, forwardSign[i], 0);
            } else {
                cubeCamera.up.set(0, upSign[i], 0);
                cubeCamera.lookAt(0, 0, forwardSign[i]);
            }
            const size = this._cubeSize;
            _setViewport(cubeUVRenderTarget, col * size, i > 2 ? size : 0, size, size);
            renderer.setRenderTarget(cubeUVRenderTarget);
            if (useSolidColor) renderer.render(backgroundBox, cubeCamera);
            renderer.render(scene, cubeCamera);
        }
        backgroundBox.geometry.dispose();
        backgroundBox.material.dispose();
        renderer.toneMapping = toneMapping;
        renderer.autoClear = originalAutoClear;
        scene.background = background;
    }
    _textureToCubeUV(texture, cubeUVRenderTarget) {
        const renderer = this._renderer;
        const isCubeTexture = texture.mapping === CubeReflectionMapping || texture.mapping === CubeRefractionMapping;
        if (isCubeTexture) {
            if (this._cubemapMaterial === null) this._cubemapMaterial = _getCubemapMaterial();
            this._cubemapMaterial.uniforms.flipEnvMap.value = texture.isRenderTargetTexture === false ? -1 : 1;
        } else if (this._equirectMaterial === null) this._equirectMaterial = _getEquirectMaterial();
        const material = isCubeTexture ? this._cubemapMaterial : this._equirectMaterial;
        const mesh = new Mesh(this._lodPlanes[0], material);
        const uniforms = material.uniforms;
        uniforms["envMap"].value = texture;
        const size = this._cubeSize;
        _setViewport(cubeUVRenderTarget, 0, 0, 3 * size, 2 * size);
        renderer.setRenderTarget(cubeUVRenderTarget);
        renderer.render(mesh, _flatCamera);
    }
    _applyPMREM(cubeUVRenderTarget) {
        const renderer = this._renderer;
        const autoClear = renderer.autoClear;
        renderer.autoClear = false;
        const n = this._lodPlanes.length;
        for(let i = 1; i < n; i++){
            const sigma = Math.sqrt(this._sigmas[i] * this._sigmas[i] - this._sigmas[i - 1] * this._sigmas[i - 1]);
            const poleAxis = _axisDirections[(n - i - 1) % _axisDirections.length];
            this._blur(cubeUVRenderTarget, i - 1, i, sigma, poleAxis);
        }
        renderer.autoClear = autoClear;
    }
    /**
	 * This is a two-pass Gaussian blur for a cubemap. Normally this is done
	 * vertically and horizontally, but this breaks down on a cube. Here we apply
	 * the blur latitudinally (around the poles), and then longitudinally (towards
	 * the poles) to approximate the orthogonally-separable blur. It is least
	 * accurate at the poles, but still does a decent job.
	 */ _blur(cubeUVRenderTarget, lodIn, lodOut, sigma, poleAxis) {
        const pingPongRenderTarget = this._pingPongRenderTarget;
        this._halfBlur(cubeUVRenderTarget, pingPongRenderTarget, lodIn, lodOut, sigma, "latitudinal", poleAxis);
        this._halfBlur(pingPongRenderTarget, cubeUVRenderTarget, lodOut, lodOut, sigma, "longitudinal", poleAxis);
    }
    _halfBlur(targetIn, targetOut, lodIn, lodOut, sigmaRadians, direction, poleAxis) {
        const renderer = this._renderer;
        const blurMaterial = this._blurMaterial;
        if (direction !== "latitudinal" && direction !== "longitudinal") console.error("blur direction must be either latitudinal or longitudinal!");
        // Number of standard deviations at which to cut off the discrete approximation.
        const STANDARD_DEVIATIONS = 3;
        const blurMesh = new Mesh(this._lodPlanes[lodOut], blurMaterial);
        const blurUniforms = blurMaterial.uniforms;
        const pixels = this._sizeLods[lodIn] - 1;
        const radiansPerPixel = isFinite(sigmaRadians) ? Math.PI / (2 * pixels) : 2 * Math.PI / (2 * MAX_SAMPLES - 1);
        const sigmaPixels = sigmaRadians / radiansPerPixel;
        const samples = isFinite(sigmaRadians) ? 1 + Math.floor(STANDARD_DEVIATIONS * sigmaPixels) : MAX_SAMPLES;
        if (samples > MAX_SAMPLES) console.warn(`sigmaRadians, ${sigmaRadians}, is too large and will clip, as it requested ${samples} samples when the maximum is set to ${MAX_SAMPLES}`);
        const weights = [];
        let sum = 0;
        for(let i = 0; i < MAX_SAMPLES; ++i){
            const x = i / sigmaPixels;
            const weight = Math.exp(-x * x / 2);
            weights.push(weight);
            if (i === 0) sum += weight;
            else if (i < samples) sum += 2 * weight;
        }
        for(let i = 0; i < weights.length; i++)weights[i] = weights[i] / sum;
        blurUniforms["envMap"].value = targetIn.texture;
        blurUniforms["samples"].value = samples;
        blurUniforms["weights"].value = weights;
        blurUniforms["latitudinal"].value = direction === "latitudinal";
        if (poleAxis) blurUniforms["poleAxis"].value = poleAxis;
        const { _lodMax } = this;
        blurUniforms["dTheta"].value = radiansPerPixel;
        blurUniforms["mipInt"].value = _lodMax - lodIn;
        const outputSize = this._sizeLods[lodOut];
        const x = 3 * outputSize * (lodOut > _lodMax - LOD_MIN ? lodOut - _lodMax + LOD_MIN : 0);
        const y = 4 * (this._cubeSize - outputSize);
        _setViewport(targetOut, x, y, 3 * outputSize, 2 * outputSize);
        renderer.setRenderTarget(targetOut);
        renderer.render(blurMesh, _flatCamera);
    }
}
function _createPlanes(lodMax) {
    const lodPlanes = [];
    const sizeLods = [];
    const sigmas = [];
    let lod = lodMax;
    const totalLods = lodMax - LOD_MIN + 1 + EXTRA_LOD_SIGMA.length;
    for(let i = 0; i < totalLods; i++){
        const sizeLod = Math.pow(2, lod);
        sizeLods.push(sizeLod);
        let sigma = 1.0 / sizeLod;
        if (i > lodMax - LOD_MIN) sigma = EXTRA_LOD_SIGMA[i - lodMax + LOD_MIN - 1];
        else if (i === 0) sigma = 0;
        sigmas.push(sigma);
        const texelSize = 1.0 / (sizeLod - 2);
        const min = -texelSize;
        const max = 1 + texelSize;
        const uv1 = [
            min,
            min,
            max,
            min,
            max,
            max,
            min,
            min,
            max,
            max,
            min,
            max
        ];
        const cubeFaces = 6;
        const vertices = 6;
        const positionSize = 3;
        const uvSize = 2;
        const faceIndexSize = 1;
        const position = new Float32Array(positionSize * vertices * cubeFaces);
        const uv = new Float32Array(uvSize * vertices * cubeFaces);
        const faceIndex = new Float32Array(faceIndexSize * vertices * cubeFaces);
        for(let face = 0; face < cubeFaces; face++){
            const x = face % 3 * 2 / 3 - 1;
            const y = face > 2 ? 0 : -1;
            const coordinates = [
                x,
                y,
                0,
                x + 2 / 3,
                y,
                0,
                x + 2 / 3,
                y + 1,
                0,
                x,
                y,
                0,
                x + 2 / 3,
                y + 1,
                0,
                x,
                y + 1,
                0
            ];
            position.set(coordinates, positionSize * vertices * face);
            uv.set(uv1, uvSize * vertices * face);
            const fill = [
                face,
                face,
                face,
                face,
                face,
                face
            ];
            faceIndex.set(fill, faceIndexSize * vertices * face);
        }
        const planes = new BufferGeometry();
        planes.setAttribute("position", new BufferAttribute(position, positionSize));
        planes.setAttribute("uv", new BufferAttribute(uv, uvSize));
        planes.setAttribute("faceIndex", new BufferAttribute(faceIndex, faceIndexSize));
        lodPlanes.push(planes);
        if (lod > LOD_MIN) lod--;
    }
    return {
        lodPlanes,
        sizeLods,
        sigmas
    };
}
function _createRenderTarget(width, height, params) {
    const cubeUVRenderTarget = new WebGLRenderTarget(width, height, params);
    cubeUVRenderTarget.texture.mapping = CubeUVReflectionMapping;
    cubeUVRenderTarget.texture.name = "PMREM.cubeUv";
    cubeUVRenderTarget.scissorTest = true;
    return cubeUVRenderTarget;
}
function _setViewport(target, x, y, width, height) {
    target.viewport.set(x, y, width, height);
    target.scissor.set(x, y, width, height);
}
function _getBlurShader(lodMax, width, height) {
    const weights = new Float32Array(MAX_SAMPLES);
    const poleAxis = new Vector3(0, 1, 0);
    const shaderMaterial = new ShaderMaterial({
        name: "SphericalGaussianBlur",
        defines: {
            "n": MAX_SAMPLES,
            "CUBEUV_TEXEL_WIDTH": 1.0 / width,
            "CUBEUV_TEXEL_HEIGHT": 1.0 / height,
            "CUBEUV_MAX_MIP": `${lodMax}.0`
        },
        uniforms: {
            "envMap": {
                value: null
            },
            "samples": {
                value: 1
            },
            "weights": {
                value: weights
            },
            "latitudinal": {
                value: false
            },
            "dTheta": {
                value: 0
            },
            "mipInt": {
                value: 0
            },
            "poleAxis": {
                value: poleAxis
            }
        },
        vertexShader: _getCommonVertexShader(),
        fragmentShader: /* glsl */ `

			precision mediump float;
			precision mediump int;

			varying vec3 vOutputDirection;

			uniform sampler2D envMap;
			uniform int samples;
			uniform float weights[ n ];
			uniform bool latitudinal;
			uniform float dTheta;
			uniform float mipInt;
			uniform vec3 poleAxis;

			#define ENVMAP_TYPE_CUBE_UV
			#include <cube_uv_reflection_fragment>

			vec3 getSample( float theta, vec3 axis ) {

				float cosTheta = cos( theta );
				// Rodrigues' axis-angle rotation
				vec3 sampleDirection = vOutputDirection * cosTheta
					+ cross( axis, vOutputDirection ) * sin( theta )
					+ axis * dot( axis, vOutputDirection ) * ( 1.0 - cosTheta );

				return bilinearCubeUV( envMap, sampleDirection, mipInt );

			}

			void main() {

				vec3 axis = latitudinal ? poleAxis : cross( poleAxis, vOutputDirection );

				if ( all( equal( axis, vec3( 0.0 ) ) ) ) {

					axis = vec3( vOutputDirection.z, 0.0, - vOutputDirection.x );

				}

				axis = normalize( axis );

				gl_FragColor = vec4( 0.0, 0.0, 0.0, 1.0 );
				gl_FragColor.rgb += weights[ 0 ] * getSample( 0.0, axis );

				for ( int i = 1; i < n; i++ ) {

					if ( i >= samples ) {

						break;

					}

					float theta = dTheta * float( i );
					gl_FragColor.rgb += weights[ i ] * getSample( -1.0 * theta, axis );
					gl_FragColor.rgb += weights[ i ] * getSample( theta, axis );

				}

			}
		`,
        blending: NoBlending,
        depthTest: false,
        depthWrite: false
    });
    return shaderMaterial;
}
function _getEquirectMaterial() {
    return new ShaderMaterial({
        name: "EquirectangularToCubeUV",
        uniforms: {
            "envMap": {
                value: null
            }
        },
        vertexShader: _getCommonVertexShader(),
        fragmentShader: /* glsl */ `

			precision mediump float;
			precision mediump int;

			varying vec3 vOutputDirection;

			uniform sampler2D envMap;

			#include <common>

			void main() {

				vec3 outputDirection = normalize( vOutputDirection );
				vec2 uv = equirectUv( outputDirection );

				gl_FragColor = vec4( texture2D ( envMap, uv ).rgb, 1.0 );

			}
		`,
        blending: NoBlending,
        depthTest: false,
        depthWrite: false
    });
}
function _getCubemapMaterial() {
    return new ShaderMaterial({
        name: "CubemapToCubeUV",
        uniforms: {
            "envMap": {
                value: null
            },
            "flipEnvMap": {
                value: -1
            }
        },
        vertexShader: _getCommonVertexShader(),
        fragmentShader: /* glsl */ `

			precision mediump float;
			precision mediump int;

			uniform float flipEnvMap;

			varying vec3 vOutputDirection;

			uniform samplerCube envMap;

			void main() {

				gl_FragColor = textureCube( envMap, vec3( flipEnvMap * vOutputDirection.x, vOutputDirection.yz ) );

			}
		`,
        blending: NoBlending,
        depthTest: false,
        depthWrite: false
    });
}
function _getCommonVertexShader() {
    return /* glsl */ `

		precision mediump float;
		precision mediump int;

		attribute float faceIndex;

		varying vec3 vOutputDirection;

		// RH coordinate system; PMREM face-indexing convention
		vec3 getDirection( vec2 uv, float face ) {

			uv = 2.0 * uv - 1.0;

			vec3 direction = vec3( uv, 1.0 );

			if ( face == 0.0 ) {

				direction = direction.zyx; // ( 1, v, u ) pos x

			} else if ( face == 1.0 ) {

				direction = direction.xzy;
				direction.xz *= -1.0; // ( -u, 1, -v ) pos y

			} else if ( face == 2.0 ) {

				direction.x *= -1.0; // ( -u, v, 1 ) pos z

			} else if ( face == 3.0 ) {

				direction = direction.zyx;
				direction.xz *= -1.0; // ( -1, v, -u ) neg x

			} else if ( face == 4.0 ) {

				direction = direction.xzy;
				direction.xy *= -1.0; // ( -u, -1, v ) neg y

			} else if ( face == 5.0 ) {

				direction.z *= -1.0; // ( u, v, -1 ) neg z

			}

			return direction;

		}

		void main() {

			vOutputDirection = getDirection( uv, faceIndex );
			gl_Position = vec4( position, 1.0 );

		}
	`;
}
function WebGLCubeUVMaps(renderer) {
    let cubeUVmaps = new WeakMap();
    let pmremGenerator = null;
    function get(texture) {
        if (texture && texture.isTexture) {
            const mapping = texture.mapping;
            const isEquirectMap = mapping === EquirectangularReflectionMapping || mapping === EquirectangularRefractionMapping;
            const isCubeMap = mapping === CubeReflectionMapping || mapping === CubeRefractionMapping;
            // equirect/cube map to cubeUV conversion
            if (isEquirectMap || isCubeMap) {
                let renderTarget = cubeUVmaps.get(texture);
                const currentPMREMVersion = renderTarget !== undefined ? renderTarget.texture.pmremVersion : 0;
                if (texture.isRenderTargetTexture && texture.pmremVersion !== currentPMREMVersion) {
                    if (pmremGenerator === null) pmremGenerator = new PMREMGenerator(renderer);
                    renderTarget = isEquirectMap ? pmremGenerator.fromEquirectangular(texture, renderTarget) : pmremGenerator.fromCubemap(texture, renderTarget);
                    renderTarget.texture.pmremVersion = texture.pmremVersion;
                    cubeUVmaps.set(texture, renderTarget);
                    return renderTarget.texture;
                } else {
                    if (renderTarget !== undefined) return renderTarget.texture;
                    else {
                        const image = texture.image;
                        if (isEquirectMap && image && image.height > 0 || isCubeMap && image && isCubeTextureComplete(image)) {
                            if (pmremGenerator === null) pmremGenerator = new PMREMGenerator(renderer);
                            renderTarget = isEquirectMap ? pmremGenerator.fromEquirectangular(texture) : pmremGenerator.fromCubemap(texture);
                            renderTarget.texture.pmremVersion = texture.pmremVersion;
                            cubeUVmaps.set(texture, renderTarget);
                            texture.addEventListener("dispose", onTextureDispose);
                            return renderTarget.texture;
                        } else // image not yet ready. try the conversion next frame
                        return null;
                    }
                }
            }
        }
        return texture;
    }
    function isCubeTextureComplete(image) {
        let count = 0;
        const length = 6;
        for(let i = 0; i < length; i++)if (image[i] !== undefined) count++;
        return count === length;
    }
    function onTextureDispose(event) {
        const texture = event.target;
        texture.removeEventListener("dispose", onTextureDispose);
        const cubemapUV = cubeUVmaps.get(texture);
        if (cubemapUV !== undefined) {
            cubeUVmaps.delete(texture);
            cubemapUV.dispose();
        }
    }
    function dispose() {
        cubeUVmaps = new WeakMap();
        if (pmremGenerator !== null) {
            pmremGenerator.dispose();
            pmremGenerator = null;
        }
    }
    return {
        get: get,
        dispose: dispose
    };
}
function WebGLExtensions(gl) {
    const extensions = {};
    function getExtension(name) {
        if (extensions[name] !== undefined) return extensions[name];
        let extension;
        switch(name){
            case "WEBGL_depth_texture":
                extension = gl.getExtension("WEBGL_depth_texture") || gl.getExtension("MOZ_WEBGL_depth_texture") || gl.getExtension("WEBKIT_WEBGL_depth_texture");
                break;
            case "EXT_texture_filter_anisotropic":
                extension = gl.getExtension("EXT_texture_filter_anisotropic") || gl.getExtension("MOZ_EXT_texture_filter_anisotropic") || gl.getExtension("WEBKIT_EXT_texture_filter_anisotropic");
                break;
            case "WEBGL_compressed_texture_s3tc":
                extension = gl.getExtension("WEBGL_compressed_texture_s3tc") || gl.getExtension("MOZ_WEBGL_compressed_texture_s3tc") || gl.getExtension("WEBKIT_WEBGL_compressed_texture_s3tc");
                break;
            case "WEBGL_compressed_texture_pvrtc":
                extension = gl.getExtension("WEBGL_compressed_texture_pvrtc") || gl.getExtension("WEBKIT_WEBGL_compressed_texture_pvrtc");
                break;
            default:
                extension = gl.getExtension(name);
        }
        extensions[name] = extension;
        return extension;
    }
    return {
        has: function(name) {
            return getExtension(name) !== null;
        },
        init: function() {
            getExtension("EXT_color_buffer_float");
            getExtension("WEBGL_clip_cull_distance");
            getExtension("OES_texture_float_linear");
            getExtension("EXT_color_buffer_half_float");
            getExtension("WEBGL_multisampled_render_to_texture");
            getExtension("WEBGL_render_shared_exponent");
        },
        get: function(name) {
            const extension = getExtension(name);
            if (extension === null) warnOnce("THREE.WebGLRenderer: " + name + " extension not supported.");
            return extension;
        }
    };
}
function WebGLGeometries(gl, attributes, info, bindingStates) {
    const geometries = {};
    const wireframeAttributes = new WeakMap();
    function onGeometryDispose(event) {
        const geometry = event.target;
        if (geometry.index !== null) attributes.remove(geometry.index);
        for(const name in geometry.attributes)attributes.remove(geometry.attributes[name]);
        for(const name in geometry.morphAttributes){
            const array = geometry.morphAttributes[name];
            for(let i = 0, l = array.length; i < l; i++)attributes.remove(array[i]);
        }
        geometry.removeEventListener("dispose", onGeometryDispose);
        delete geometries[geometry.id];
        const attribute = wireframeAttributes.get(geometry);
        if (attribute) {
            attributes.remove(attribute);
            wireframeAttributes.delete(geometry);
        }
        bindingStates.releaseStatesOfGeometry(geometry);
        if (geometry.isInstancedBufferGeometry === true) delete geometry._maxInstanceCount;
        //
        info.memory.geometries--;
    }
    function get(object, geometry) {
        if (geometries[geometry.id] === true) return geometry;
        geometry.addEventListener("dispose", onGeometryDispose);
        geometries[geometry.id] = true;
        info.memory.geometries++;
        return geometry;
    }
    function update(geometry) {
        const geometryAttributes = geometry.attributes;
        // Updating index buffer in VAO now. See WebGLBindingStates.
        for(const name in geometryAttributes)attributes.update(geometryAttributes[name], gl.ARRAY_BUFFER);
        // morph targets
        const morphAttributes = geometry.morphAttributes;
        for(const name in morphAttributes){
            const array = morphAttributes[name];
            for(let i = 0, l = array.length; i < l; i++)attributes.update(array[i], gl.ARRAY_BUFFER);
        }
    }
    function updateWireframeAttribute(geometry) {
        const indices = [];
        const geometryIndex = geometry.index;
        const geometryPosition = geometry.attributes.position;
        let version = 0;
        if (geometryIndex !== null) {
            const array = geometryIndex.array;
            version = geometryIndex.version;
            for(let i = 0, l = array.length; i < l; i += 3){
                const a = array[i + 0];
                const b = array[i + 1];
                const c = array[i + 2];
                indices.push(a, b, b, c, c, a);
            }
        } else if (geometryPosition !== undefined) {
            const array = geometryPosition.array;
            version = geometryPosition.version;
            for(let i = 0, l = array.length / 3 - 1; i < l; i += 3){
                const a = i + 0;
                const b = i + 1;
                const c = i + 2;
                indices.push(a, b, b, c, c, a);
            }
        } else return;
        const attribute = new (arrayNeedsUint32(indices) ? Uint32BufferAttribute : Uint16BufferAttribute)(indices, 1);
        attribute.version = version;
        // Updating index buffer in VAO now. See WebGLBindingStates
        //
        const previousAttribute = wireframeAttributes.get(geometry);
        if (previousAttribute) attributes.remove(previousAttribute);
        //
        wireframeAttributes.set(geometry, attribute);
    }
    function getWireframeAttribute(geometry) {
        const currentAttribute = wireframeAttributes.get(geometry);
        if (currentAttribute) {
            const geometryIndex = geometry.index;
            if (geometryIndex !== null) // if the attribute is obsolete, create a new one
            {
                if (currentAttribute.version < geometryIndex.version) updateWireframeAttribute(geometry);
            }
        } else updateWireframeAttribute(geometry);
        return wireframeAttributes.get(geometry);
    }
    return {
        get: get,
        update: update,
        getWireframeAttribute: getWireframeAttribute
    };
}
function WebGLIndexedBufferRenderer(gl, extensions, info) {
    let mode;
    function setMode(value) {
        mode = value;
    }
    let type, bytesPerElement;
    function setIndex(value) {
        type = value.type;
        bytesPerElement = value.bytesPerElement;
    }
    function render(start, count) {
        gl.drawElements(mode, count, type, start * bytesPerElement);
        info.update(count, mode, 1);
    }
    function renderInstances(start, count, primcount) {
        if (primcount === 0) return;
        gl.drawElementsInstanced(mode, count, type, start * bytesPerElement, primcount);
        info.update(count, mode, primcount);
    }
    function renderMultiDraw(starts, counts, drawCount) {
        if (drawCount === 0) return;
        const extension = extensions.get("WEBGL_multi_draw");
        extension.multiDrawElementsWEBGL(mode, counts, 0, type, starts, 0, drawCount);
        let elementCount = 0;
        for(let i = 0; i < drawCount; i++)elementCount += counts[i];
        info.update(elementCount, mode, 1);
    }
    function renderMultiDrawInstances(starts, counts, drawCount, primcount) {
        if (drawCount === 0) return;
        const extension = extensions.get("WEBGL_multi_draw");
        if (extension === null) for(let i = 0; i < starts.length; i++)renderInstances(starts[i] / bytesPerElement, counts[i], primcount[i]);
        else {
            extension.multiDrawElementsInstancedWEBGL(mode, counts, 0, type, starts, 0, primcount, 0, drawCount);
            let elementCount = 0;
            for(let i = 0; i < drawCount; i++)elementCount += counts[i];
            for(let i = 0; i < primcount.length; i++)info.update(elementCount, mode, primcount[i]);
        }
    }
    //
    this.setMode = setMode;
    this.setIndex = setIndex;
    this.render = render;
    this.renderInstances = renderInstances;
    this.renderMultiDraw = renderMultiDraw;
    this.renderMultiDrawInstances = renderMultiDrawInstances;
}
function WebGLInfo(gl) {
    const memory = {
        geometries: 0,
        textures: 0
    };
    const render = {
        frame: 0,
        calls: 0,
        triangles: 0,
        points: 0,
        lines: 0
    };
    function update(count, mode, instanceCount) {
        render.calls++;
        switch(mode){
            case gl.TRIANGLES:
                render.triangles += instanceCount * (count / 3);
                break;
            case gl.LINES:
                render.lines += instanceCount * (count / 2);
                break;
            case gl.LINE_STRIP:
                render.lines += instanceCount * (count - 1);
                break;
            case gl.LINE_LOOP:
                render.lines += instanceCount * count;
                break;
            case gl.POINTS:
                render.points += instanceCount * count;
                break;
            default:
                console.error("THREE.WebGLInfo: Unknown draw mode:", mode);
                break;
        }
    }
    function reset() {
        render.calls = 0;
        render.triangles = 0;
        render.points = 0;
        render.lines = 0;
    }
    return {
        memory: memory,
        render: render,
        programs: null,
        autoReset: true,
        reset: reset,
        update: update
    };
}
function WebGLMorphtargets(gl, capabilities, textures) {
    const morphTextures = new WeakMap();
    const morph = new Vector4();
    function update(object, geometry, program) {
        const objectInfluences = object.morphTargetInfluences;
        // the following encodes morph targets into an array of data textures. Each layer represents a single morph target.
        const morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;
        const morphTargetsCount = morphAttribute !== undefined ? morphAttribute.length : 0;
        let entry = morphTextures.get(geometry);
        if (entry === undefined || entry.count !== morphTargetsCount) {
            if (entry !== undefined) entry.texture.dispose();
            const hasMorphPosition = geometry.morphAttributes.position !== undefined;
            const hasMorphNormals = geometry.morphAttributes.normal !== undefined;
            const hasMorphColors = geometry.morphAttributes.color !== undefined;
            const morphTargets = geometry.morphAttributes.position || [];
            const morphNormals = geometry.morphAttributes.normal || [];
            const morphColors = geometry.morphAttributes.color || [];
            let vertexDataCount = 0;
            if (hasMorphPosition === true) vertexDataCount = 1;
            if (hasMorphNormals === true) vertexDataCount = 2;
            if (hasMorphColors === true) vertexDataCount = 3;
            let width = geometry.attributes.position.count * vertexDataCount;
            let height = 1;
            if (width > capabilities.maxTextureSize) {
                height = Math.ceil(width / capabilities.maxTextureSize);
                width = capabilities.maxTextureSize;
            }
            const buffer = new Float32Array(width * height * 4 * morphTargetsCount);
            const texture = new DataArrayTexture(buffer, width, height, morphTargetsCount);
            texture.type = FloatType;
            texture.needsUpdate = true;
            // fill buffer
            const vertexDataStride = vertexDataCount * 4;
            for(let i = 0; i < morphTargetsCount; i++){
                const morphTarget = morphTargets[i];
                const morphNormal = morphNormals[i];
                const morphColor = morphColors[i];
                const offset = width * height * 4 * i;
                for(let j = 0; j < morphTarget.count; j++){
                    const stride = j * vertexDataStride;
                    if (hasMorphPosition === true) {
                        morph.fromBufferAttribute(morphTarget, j);
                        buffer[offset + stride + 0] = morph.x;
                        buffer[offset + stride + 1] = morph.y;
                        buffer[offset + stride + 2] = morph.z;
                        buffer[offset + stride + 3] = 0;
                    }
                    if (hasMorphNormals === true) {
                        morph.fromBufferAttribute(morphNormal, j);
                        buffer[offset + stride + 4] = morph.x;
                        buffer[offset + stride + 5] = morph.y;
                        buffer[offset + stride + 6] = morph.z;
                        buffer[offset + stride + 7] = 0;
                    }
                    if (hasMorphColors === true) {
                        morph.fromBufferAttribute(morphColor, j);
                        buffer[offset + stride + 8] = morph.x;
                        buffer[offset + stride + 9] = morph.y;
                        buffer[offset + stride + 10] = morph.z;
                        buffer[offset + stride + 11] = morphColor.itemSize === 4 ? morph.w : 1;
                    }
                }
            }
            entry = {
                count: morphTargetsCount,
                texture: texture,
                size: new Vector2(width, height)
            };
            morphTextures.set(geometry, entry);
            function disposeTexture() {
                texture.dispose();
                morphTextures.delete(geometry);
                geometry.removeEventListener("dispose", disposeTexture);
            }
            geometry.addEventListener("dispose", disposeTexture);
        }
        //
        if (object.isInstancedMesh === true && object.morphTexture !== null) program.getUniforms().setValue(gl, "morphTexture", object.morphTexture, textures);
        else {
            let morphInfluencesSum = 0;
            for(let i = 0; i < objectInfluences.length; i++)morphInfluencesSum += objectInfluences[i];
            const morphBaseInfluence = geometry.morphTargetsRelative ? 1 : 1 - morphInfluencesSum;
            program.getUniforms().setValue(gl, "morphTargetBaseInfluence", morphBaseInfluence);
            program.getUniforms().setValue(gl, "morphTargetInfluences", objectInfluences);
        }
        program.getUniforms().setValue(gl, "morphTargetsTexture", entry.texture, textures);
        program.getUniforms().setValue(gl, "morphTargetsTextureSize", entry.size);
    }
    return {
        update: update
    };
}
function WebGLObjects(gl, geometries, attributes, info) {
    let updateMap = new WeakMap();
    function update(object) {
        const frame = info.render.frame;
        const geometry = object.geometry;
        const buffergeometry = geometries.get(object, geometry);
        // Update once per frame
        if (updateMap.get(buffergeometry) !== frame) {
            geometries.update(buffergeometry);
            updateMap.set(buffergeometry, frame);
        }
        if (object.isInstancedMesh) {
            if (object.hasEventListener("dispose", onInstancedMeshDispose) === false) object.addEventListener("dispose", onInstancedMeshDispose);
            if (updateMap.get(object) !== frame) {
                attributes.update(object.instanceMatrix, gl.ARRAY_BUFFER);
                if (object.instanceColor !== null) attributes.update(object.instanceColor, gl.ARRAY_BUFFER);
                updateMap.set(object, frame);
            }
        }
        if (object.isSkinnedMesh) {
            const skeleton = object.skeleton;
            if (updateMap.get(skeleton) !== frame) {
                skeleton.update();
                updateMap.set(skeleton, frame);
            }
        }
        return buffergeometry;
    }
    function dispose() {
        updateMap = new WeakMap();
    }
    function onInstancedMeshDispose(event) {
        const instancedMesh = event.target;
        instancedMesh.removeEventListener("dispose", onInstancedMeshDispose);
        attributes.remove(instancedMesh.instanceMatrix);
        if (instancedMesh.instanceColor !== null) attributes.remove(instancedMesh.instanceColor);
    }
    return {
        update: update,
        dispose: dispose
    };
}
class DepthTexture extends Texture {
    constructor(width, height, type, mapping, wrapS, wrapT, magFilter, minFilter, anisotropy, format = DepthFormat){
        if (format !== DepthFormat && format !== DepthStencilFormat) throw new Error("DepthTexture format must be either THREE.DepthFormat or THREE.DepthStencilFormat");
        if (type === undefined && format === DepthFormat) type = UnsignedIntType;
        if (type === undefined && format === DepthStencilFormat) type = UnsignedInt248Type;
        super(null, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy);
        this.isDepthTexture = true;
        this.image = {
            width: width,
            height: height
        };
        this.magFilter = magFilter !== undefined ? magFilter : NearestFilter;
        this.minFilter = minFilter !== undefined ? minFilter : NearestFilter;
        this.flipY = false;
        this.generateMipmaps = false;
        this.compareFunction = null;
    }
    copy(source) {
        super.copy(source);
        this.compareFunction = source.compareFunction;
        return this;
    }
    toJSON(meta) {
        const data = super.toJSON(meta);
        if (this.compareFunction !== null) data.compareFunction = this.compareFunction;
        return data;
    }
}
/**
 * Uniforms of a program.
 * Those form a tree structure with a special top-level container for the root,
 * which you get by calling 'new WebGLUniforms( gl, program )'.
 *
 *
 * Properties of inner nodes including the top-level container:
 *
 * .seq - array of nested uniforms
 * .map - nested uniforms by name
 *
 *
 * Methods of all nodes except the top-level container:
 *
 * .setValue( gl, value, [textures] )
 *
 * 		uploads a uniform value(s)
 *  	the 'textures' parameter is needed for sampler uniforms
 *
 *
 * Static methods of the top-level container (textures factorizations):
 *
 * .upload( gl, seq, values, textures )
 *
 * 		sets uniforms in 'seq' to 'values[id].value'
 *
 * .seqWithValue( seq, values ) : filteredSeq
 *
 * 		filters 'seq' entries with corresponding entry in values
 *
 *
 * Methods of the top-level container (textures factorizations):
 *
 * .setValue( gl, name, value, textures )
 *
 * 		sets uniform with  name 'name' to 'value'
 *
 * .setOptional( gl, obj, prop )
 *
 * 		like .set for an optional property of the object
 *
 */ const emptyTexture = /*@__PURE__*/ new Texture();
const emptyShadowTexture = /*@__PURE__*/ new DepthTexture(1, 1);
const emptyArrayTexture = /*@__PURE__*/ new DataArrayTexture();
const empty3dTexture = /*@__PURE__*/ new Data3DTexture();
const emptyCubeTexture = /*@__PURE__*/ new CubeTexture();
// --- Utilities ---
// Array Caches (provide typed arrays for temporary by size)
const arrayCacheF32 = [];
const arrayCacheI32 = [];
// Float32Array caches used for uploading Matrix uniforms
const mat4array = new Float32Array(16);
const mat3array = new Float32Array(9);
const mat2array = new Float32Array(4);
// Flattening for arrays of vectors and matrices
function flatten(array, nBlocks, blockSize) {
    const firstElem = array[0];
    if (firstElem <= 0 || firstElem > 0) return array;
    // unoptimized: ! isNaN( firstElem )
    // see http://jacksondunstan.com/articles/983
    const n = nBlocks * blockSize;
    let r = arrayCacheF32[n];
    if (r === undefined) {
        r = new Float32Array(n);
        arrayCacheF32[n] = r;
    }
    if (nBlocks !== 0) {
        firstElem.toArray(r, 0);
        for(let i = 1, offset = 0; i !== nBlocks; ++i){
            offset += blockSize;
            array[i].toArray(r, offset);
        }
    }
    return r;
}
function arraysEqual(a, b) {
    if (a.length !== b.length) return false;
    for(let i = 0, l = a.length; i < l; i++){
        if (a[i] !== b[i]) return false;
    }
    return true;
}
function copyArray(a, b) {
    for(let i = 0, l = b.length; i < l; i++)a[i] = b[i];
}
// Texture unit allocation
function allocTexUnits(textures, n) {
    let r = arrayCacheI32[n];
    if (r === undefined) {
        r = new Int32Array(n);
        arrayCacheI32[n] = r;
    }
    for(let i = 0; i !== n; ++i)r[i] = textures.allocateTextureUnit();
    return r;
}
// --- Setters ---
// Note: Defining these methods externally, because they come in a bunch
// and this way their names minify.
// Single scalar
function setValueV1f(gl, v) {
    const cache = this.cache;
    if (cache[0] === v) return;
    gl.uniform1f(this.addr, v);
    cache[0] = v;
}
// Single float vector (from flat array or THREE.VectorN)
function setValueV2f(gl, v) {
    const cache = this.cache;
    if (v.x !== undefined) {
        if (cache[0] !== v.x || cache[1] !== v.y) {
            gl.uniform2f(this.addr, v.x, v.y);
            cache[0] = v.x;
            cache[1] = v.y;
        }
    } else {
        if (arraysEqual(cache, v)) return;
        gl.uniform2fv(this.addr, v);
        copyArray(cache, v);
    }
}
function setValueV3f(gl, v) {
    const cache = this.cache;
    if (v.x !== undefined) {
        if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z) {
            gl.uniform3f(this.addr, v.x, v.y, v.z);
            cache[0] = v.x;
            cache[1] = v.y;
            cache[2] = v.z;
        }
    } else if (v.r !== undefined) {
        if (cache[0] !== v.r || cache[1] !== v.g || cache[2] !== v.b) {
            gl.uniform3f(this.addr, v.r, v.g, v.b);
            cache[0] = v.r;
            cache[1] = v.g;
            cache[2] = v.b;
        }
    } else {
        if (arraysEqual(cache, v)) return;
        gl.uniform3fv(this.addr, v);
        copyArray(cache, v);
    }
}
function setValueV4f(gl, v) {
    const cache = this.cache;
    if (v.x !== undefined) {
        if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z || cache[3] !== v.w) {
            gl.uniform4f(this.addr, v.x, v.y, v.z, v.w);
            cache[0] = v.x;
            cache[1] = v.y;
            cache[2] = v.z;
            cache[3] = v.w;
        }
    } else {
        if (arraysEqual(cache, v)) return;
        gl.uniform4fv(this.addr, v);
        copyArray(cache, v);
    }
}
// Single matrix (from flat array or THREE.MatrixN)
function setValueM2(gl, v) {
    const cache = this.cache;
    const elements = v.elements;
    if (elements === undefined) {
        if (arraysEqual(cache, v)) return;
        gl.uniformMatrix2fv(this.addr, false, v);
        copyArray(cache, v);
    } else {
        if (arraysEqual(cache, elements)) return;
        mat2array.set(elements);
        gl.uniformMatrix2fv(this.addr, false, mat2array);
        copyArray(cache, elements);
    }
}
function setValueM3(gl, v) {
    const cache = this.cache;
    const elements = v.elements;
    if (elements === undefined) {
        if (arraysEqual(cache, v)) return;
        gl.uniformMatrix3fv(this.addr, false, v);
        copyArray(cache, v);
    } else {
        if (arraysEqual(cache, elements)) return;
        mat3array.set(elements);
        gl.uniformMatrix3fv(this.addr, false, mat3array);
        copyArray(cache, elements);
    }
}
function setValueM4(gl, v) {
    const cache = this.cache;
    const elements = v.elements;
    if (elements === undefined) {
        if (arraysEqual(cache, v)) return;
        gl.uniformMatrix4fv(this.addr, false, v);
        copyArray(cache, v);
    } else {
        if (arraysEqual(cache, elements)) return;
        mat4array.set(elements);
        gl.uniformMatrix4fv(this.addr, false, mat4array);
        copyArray(cache, elements);
    }
}
// Single integer / boolean
function setValueV1i(gl, v) {
    const cache = this.cache;
    if (cache[0] === v) return;
    gl.uniform1i(this.addr, v);
    cache[0] = v;
}
// Single integer / boolean vector (from flat array or THREE.VectorN)
function setValueV2i(gl, v) {
    const cache = this.cache;
    if (v.x !== undefined) {
        if (cache[0] !== v.x || cache[1] !== v.y) {
            gl.uniform2i(this.addr, v.x, v.y);
            cache[0] = v.x;
            cache[1] = v.y;
        }
    } else {
        if (arraysEqual(cache, v)) return;
        gl.uniform2iv(this.addr, v);
        copyArray(cache, v);
    }
}
function setValueV3i(gl, v) {
    const cache = this.cache;
    if (v.x !== undefined) {
        if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z) {
            gl.uniform3i(this.addr, v.x, v.y, v.z);
            cache[0] = v.x;
            cache[1] = v.y;
            cache[2] = v.z;
        }
    } else {
        if (arraysEqual(cache, v)) return;
        gl.uniform3iv(this.addr, v);
        copyArray(cache, v);
    }
}
function setValueV4i(gl, v) {
    const cache = this.cache;
    if (v.x !== undefined) {
        if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z || cache[3] !== v.w) {
            gl.uniform4i(this.addr, v.x, v.y, v.z, v.w);
            cache[0] = v.x;
            cache[1] = v.y;
            cache[2] = v.z;
            cache[3] = v.w;
        }
    } else {
        if (arraysEqual(cache, v)) return;
        gl.uniform4iv(this.addr, v);
        copyArray(cache, v);
    }
}
// Single unsigned integer
function setValueV1ui(gl, v) {
    const cache = this.cache;
    if (cache[0] === v) return;
    gl.uniform1ui(this.addr, v);
    cache[0] = v;
}
// Single unsigned integer vector (from flat array or THREE.VectorN)
function setValueV2ui(gl, v) {
    const cache = this.cache;
    if (v.x !== undefined) {
        if (cache[0] !== v.x || cache[1] !== v.y) {
            gl.uniform2ui(this.addr, v.x, v.y);
            cache[0] = v.x;
            cache[1] = v.y;
        }
    } else {
        if (arraysEqual(cache, v)) return;
        gl.uniform2uiv(this.addr, v);
        copyArray(cache, v);
    }
}
function setValueV3ui(gl, v) {
    const cache = this.cache;
    if (v.x !== undefined) {
        if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z) {
            gl.uniform3ui(this.addr, v.x, v.y, v.z);
            cache[0] = v.x;
            cache[1] = v.y;
            cache[2] = v.z;
        }
    } else {
        if (arraysEqual(cache, v)) return;
        gl.uniform3uiv(this.addr, v);
        copyArray(cache, v);
    }
}
function setValueV4ui(gl, v) {
    const cache = this.cache;
    if (v.x !== undefined) {
        if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z || cache[3] !== v.w) {
            gl.uniform4ui(this.addr, v.x, v.y, v.z, v.w);
            cache[0] = v.x;
            cache[1] = v.y;
            cache[2] = v.z;
            cache[3] = v.w;
        }
    } else {
        if (arraysEqual(cache, v)) return;
        gl.uniform4uiv(this.addr, v);
        copyArray(cache, v);
    }
}
// Single texture (2D / Cube)
function setValueT1(gl, v, textures) {
    const cache = this.cache;
    const unit = textures.allocateTextureUnit();
    if (cache[0] !== unit) {
        gl.uniform1i(this.addr, unit);
        cache[0] = unit;
    }
    let emptyTexture2D;
    if (this.type === gl.SAMPLER_2D_SHADOW) {
        emptyShadowTexture.compareFunction = LessEqualCompare; // #28670
        emptyTexture2D = emptyShadowTexture;
    } else emptyTexture2D = emptyTexture;
    textures.setTexture2D(v || emptyTexture2D, unit);
}
function setValueT3D1(gl, v, textures) {
    const cache = this.cache;
    const unit = textures.allocateTextureUnit();
    if (cache[0] !== unit) {
        gl.uniform1i(this.addr, unit);
        cache[0] = unit;
    }
    textures.setTexture3D(v || empty3dTexture, unit);
}
function setValueT6(gl, v, textures) {
    const cache = this.cache;
    const unit = textures.allocateTextureUnit();
    if (cache[0] !== unit) {
        gl.uniform1i(this.addr, unit);
        cache[0] = unit;
    }
    textures.setTextureCube(v || emptyCubeTexture, unit);
}
function setValueT2DArray1(gl, v, textures) {
    const cache = this.cache;
    const unit = textures.allocateTextureUnit();
    if (cache[0] !== unit) {
        gl.uniform1i(this.addr, unit);
        cache[0] = unit;
    }
    textures.setTexture2DArray(v || emptyArrayTexture, unit);
}
// Helper to pick the right setter for the singular case
function getSingularSetter(type) {
    switch(type){
        case 0x1406:
            return setValueV1f; // FLOAT
        case 0x8b50:
            return setValueV2f; // _VEC2
        case 0x8b51:
            return setValueV3f; // _VEC3
        case 0x8b52:
            return setValueV4f; // _VEC4
        case 0x8b5a:
            return setValueM2; // _MAT2
        case 0x8b5b:
            return setValueM3; // _MAT3
        case 0x8b5c:
            return setValueM4; // _MAT4
        case 0x1404:
        case 0x8b56:
            return setValueV1i; // INT, BOOL
        case 0x8b53:
        case 0x8b57:
            return setValueV2i; // _VEC2
        case 0x8b54:
        case 0x8b58:
            return setValueV3i; // _VEC3
        case 0x8b55:
        case 0x8b59:
            return setValueV4i; // _VEC4
        case 0x1405:
            return setValueV1ui; // UINT
        case 0x8dc6:
            return setValueV2ui; // _VEC2
        case 0x8dc7:
            return setValueV3ui; // _VEC3
        case 0x8dc8:
            return setValueV4ui; // _VEC4
        case 0x8b5e:
        case 0x8d66:
        case 0x8dca:
        case 0x8dd2:
        case 0x8b62:
            return setValueT1;
        case 0x8b5f:
        case 0x8dcb:
        case 0x8dd3:
            return setValueT3D1;
        case 0x8b60:
        case 0x8dcc:
        case 0x8dd4:
        case 0x8dc5:
            return setValueT6;
        case 0x8dc1:
        case 0x8dcf:
        case 0x8dd7:
        case 0x8dc4:
            return setValueT2DArray1;
    }
}
// Array of scalars
function setValueV1fArray(gl, v) {
    gl.uniform1fv(this.addr, v);
}
// Array of vectors (from flat array or array of THREE.VectorN)
function setValueV2fArray(gl, v) {
    const data = flatten(v, this.size, 2);
    gl.uniform2fv(this.addr, data);
}
function setValueV3fArray(gl, v) {
    const data = flatten(v, this.size, 3);
    gl.uniform3fv(this.addr, data);
}
function setValueV4fArray(gl, v) {
    const data = flatten(v, this.size, 4);
    gl.uniform4fv(this.addr, data);
}
// Array of matrices (from flat array or array of THREE.MatrixN)
function setValueM2Array(gl, v) {
    const data = flatten(v, this.size, 4);
    gl.uniformMatrix2fv(this.addr, false, data);
}
function setValueM3Array(gl, v) {
    const data = flatten(v, this.size, 9);
    gl.uniformMatrix3fv(this.addr, false, data);
}
function setValueM4Array(gl, v) {
    const data = flatten(v, this.size, 16);
    gl.uniformMatrix4fv(this.addr, false, data);
}
// Array of integer / boolean
function setValueV1iArray(gl, v) {
    gl.uniform1iv(this.addr, v);
}
// Array of integer / boolean vectors (from flat array)
function setValueV2iArray(gl, v) {
    gl.uniform2iv(this.addr, v);
}
function setValueV3iArray(gl, v) {
    gl.uniform3iv(this.addr, v);
}
function setValueV4iArray(gl, v) {
    gl.uniform4iv(this.addr, v);
}
// Array of unsigned integer
function setValueV1uiArray(gl, v) {
    gl.uniform1uiv(this.addr, v);
}
// Array of unsigned integer vectors (from flat array)
function setValueV2uiArray(gl, v) {
    gl.uniform2uiv(this.addr, v);
}
function setValueV3uiArray(gl, v) {
    gl.uniform3uiv(this.addr, v);
}
function setValueV4uiArray(gl, v) {
    gl.uniform4uiv(this.addr, v);
}
// Array of textures (2D / 3D / Cube / 2DArray)
function setValueT1Array(gl, v, textures) {
    const cache = this.cache;
    const n = v.length;
    const units = allocTexUnits(textures, n);
    if (!arraysEqual(cache, units)) {
        gl.uniform1iv(this.addr, units);
        copyArray(cache, units);
    }
    for(let i = 0; i !== n; ++i)textures.setTexture2D(v[i] || emptyTexture, units[i]);
}
function setValueT3DArray(gl, v, textures) {
    const cache = this.cache;
    const n = v.length;
    const units = allocTexUnits(textures, n);
    if (!arraysEqual(cache, units)) {
        gl.uniform1iv(this.addr, units);
        copyArray(cache, units);
    }
    for(let i = 0; i !== n; ++i)textures.setTexture3D(v[i] || empty3dTexture, units[i]);
}
function setValueT6Array(gl, v, textures) {
    const cache = this.cache;
    const n = v.length;
    const units = allocTexUnits(textures, n);
    if (!arraysEqual(cache, units)) {
        gl.uniform1iv(this.addr, units);
        copyArray(cache, units);
    }
    for(let i = 0; i !== n; ++i)textures.setTextureCube(v[i] || emptyCubeTexture, units[i]);
}
function setValueT2DArrayArray(gl, v, textures) {
    const cache = this.cache;
    const n = v.length;
    const units = allocTexUnits(textures, n);
    if (!arraysEqual(cache, units)) {
        gl.uniform1iv(this.addr, units);
        copyArray(cache, units);
    }
    for(let i = 0; i !== n; ++i)textures.setTexture2DArray(v[i] || emptyArrayTexture, units[i]);
}
// Helper to pick the right setter for a pure (bottom-level) array
function getPureArraySetter(type) {
    switch(type){
        case 0x1406:
            return setValueV1fArray; // FLOAT
        case 0x8b50:
            return setValueV2fArray; // _VEC2
        case 0x8b51:
            return setValueV3fArray; // _VEC3
        case 0x8b52:
            return setValueV4fArray; // _VEC4
        case 0x8b5a:
            return setValueM2Array; // _MAT2
        case 0x8b5b:
            return setValueM3Array; // _MAT3
        case 0x8b5c:
            return setValueM4Array; // _MAT4
        case 0x1404:
        case 0x8b56:
            return setValueV1iArray; // INT, BOOL
        case 0x8b53:
        case 0x8b57:
            return setValueV2iArray; // _VEC2
        case 0x8b54:
        case 0x8b58:
            return setValueV3iArray; // _VEC3
        case 0x8b55:
        case 0x8b59:
            return setValueV4iArray; // _VEC4
        case 0x1405:
            return setValueV1uiArray; // UINT
        case 0x8dc6:
            return setValueV2uiArray; // _VEC2
        case 0x8dc7:
            return setValueV3uiArray; // _VEC3
        case 0x8dc8:
            return setValueV4uiArray; // _VEC4
        case 0x8b5e:
        case 0x8d66:
        case 0x8dca:
        case 0x8dd2:
        case 0x8b62:
            return setValueT1Array;
        case 0x8b5f:
        case 0x8dcb:
        case 0x8dd3:
            return setValueT3DArray;
        case 0x8b60:
        case 0x8dcc:
        case 0x8dd4:
        case 0x8dc5:
            return setValueT6Array;
        case 0x8dc1:
        case 0x8dcf:
        case 0x8dd7:
        case 0x8dc4:
            return setValueT2DArrayArray;
    }
}
// --- Uniform Classes ---
class SingleUniform {
    constructor(id, activeInfo, addr){
        this.id = id;
        this.addr = addr;
        this.cache = [];
        this.type = activeInfo.type;
        this.setValue = getSingularSetter(activeInfo.type);
    // this.path = activeInfo.name; // DEBUG
    }
}
class PureArrayUniform {
    constructor(id, activeInfo, addr){
        this.id = id;
        this.addr = addr;
        this.cache = [];
        this.type = activeInfo.type;
        this.size = activeInfo.size;
        this.setValue = getPureArraySetter(activeInfo.type);
    // this.path = activeInfo.name; // DEBUG
    }
}
class StructuredUniform {
    constructor(id){
        this.id = id;
        this.seq = [];
        this.map = {};
    }
    setValue(gl, value, textures) {
        const seq = this.seq;
        for(let i = 0, n = seq.length; i !== n; ++i){
            const u = seq[i];
            u.setValue(gl, value[u.id], textures);
        }
    }
}
// --- Top-level ---
// Parser - builds up the property tree from the path strings
const RePathPart = /(\w+)(\])?(\[|\.)?/g;
// extracts
// 	- the identifier (member name or array index)
//  - followed by an optional right bracket (found when array index)
//  - followed by an optional left bracket or dot (type of subscript)
//
// Note: These portions can be read in a non-overlapping fashion and
// allow straightforward parsing of the hierarchy that WebGL encodes
// in the uniform names.
function addUniform(container, uniformObject) {
    container.seq.push(uniformObject);
    container.map[uniformObject.id] = uniformObject;
}
function parseUniform(activeInfo, addr, container) {
    const path = activeInfo.name, pathLength = path.length;
    // reset RegExp object, because of the early exit of a previous run
    RePathPart.lastIndex = 0;
    while(true){
        const match = RePathPart.exec(path), matchEnd = RePathPart.lastIndex;
        let id = match[1];
        const idIsIndex = match[2] === "]", subscript = match[3];
        if (idIsIndex) id = id | 0; // convert to integer
        if (subscript === undefined || subscript === "[" && matchEnd + 2 === pathLength) {
            // bare name or "pure" bottom-level array "[0]" suffix
            addUniform(container, subscript === undefined ? new SingleUniform(id, activeInfo, addr) : new PureArrayUniform(id, activeInfo, addr));
            break;
        } else {
            // step into inner node / create it in case it doesn't exist
            const map = container.map;
            let next = map[id];
            if (next === undefined) {
                next = new StructuredUniform(id);
                addUniform(container, next);
            }
            container = next;
        }
    }
}
// Root Container
class WebGLUniforms {
    constructor(gl, program){
        this.seq = [];
        this.map = {};
        const n = gl.getProgramParameter(program, gl.ACTIVE_UNIFORMS);
        for(let i = 0; i < n; ++i){
            const info = gl.getActiveUniform(program, i), addr = gl.getUniformLocation(program, info.name);
            parseUniform(info, addr, this);
        }
    }
    setValue(gl, name, value, textures) {
        const u = this.map[name];
        if (u !== undefined) u.setValue(gl, value, textures);
    }
    setOptional(gl, object, name) {
        const v = object[name];
        if (v !== undefined) this.setValue(gl, name, v);
    }
    static upload(gl, seq, values, textures) {
        for(let i = 0, n = seq.length; i !== n; ++i){
            const u = seq[i], v = values[u.id];
            if (v.needsUpdate !== false) // note: always updating when .needsUpdate is undefined
            u.setValue(gl, v.value, textures);
        }
    }
    static seqWithValue(seq, values) {
        const r = [];
        for(let i = 0, n = seq.length; i !== n; ++i){
            const u = seq[i];
            if (u.id in values) r.push(u);
        }
        return r;
    }
}
function WebGLShader(gl, type, string) {
    const shader = gl.createShader(type);
    gl.shaderSource(shader, string);
    gl.compileShader(shader);
    return shader;
}
// From https://www.khronos.org/registry/webgl/extensions/KHR_parallel_shader_compile/
const COMPLETION_STATUS_KHR = 0x91B1;
let programIdCount = 0;
function handleSource(string, errorLine) {
    const lines = string.split("\n");
    const lines2 = [];
    const from = Math.max(errorLine - 6, 0);
    const to = Math.min(errorLine + 6, lines.length);
    for(let i = from; i < to; i++){
        const line = i + 1;
        lines2.push(`${line === errorLine ? ">" : " "} ${line}: ${lines[i]}`);
    }
    return lines2.join("\n");
}
function getEncodingComponents(colorSpace1) {
    const workingPrimaries = ColorManagement.getPrimaries(ColorManagement.workingColorSpace);
    const encodingPrimaries = ColorManagement.getPrimaries(colorSpace1);
    let gamutMapping;
    if (workingPrimaries === encodingPrimaries) gamutMapping = "";
    else if (workingPrimaries === P3Primaries && encodingPrimaries === Rec709Primaries) gamutMapping = "LinearDisplayP3ToLinearSRGB";
    else if (workingPrimaries === Rec709Primaries && encodingPrimaries === P3Primaries) gamutMapping = "LinearSRGBToLinearDisplayP3";
    switch(colorSpace1){
        case LinearSRGBColorSpace:
        case LinearDisplayP3ColorSpace:
            return [
                gamutMapping,
                "LinearTransferOETF"
            ];
        case SRGBColorSpace:
        case DisplayP3ColorSpace:
            return [
                gamutMapping,
                "sRGBTransferOETF"
            ];
        default:
            console.warn("THREE.WebGLProgram: Unsupported color space:", colorSpace1);
            return [
                gamutMapping,
                "LinearTransferOETF"
            ];
    }
}
function getShaderErrors(gl, shader, type) {
    const status = gl.getShaderParameter(shader, gl.COMPILE_STATUS);
    const errors = gl.getShaderInfoLog(shader).trim();
    if (status && errors === "") return "";
    const errorMatches = /ERROR: 0:(\d+)/.exec(errors);
    if (errorMatches) {
        // --enable-privileged-webgl-extension
        // console.log( '**' + type + '**', gl.getExtension( 'WEBGL_debug_shaders' ).getTranslatedShaderSource( shader ) );
        const errorLine = parseInt(errorMatches[1]);
        return type.toUpperCase() + "\n\n" + errors + "\n\n" + handleSource(gl.getShaderSource(shader), errorLine);
    } else return errors;
}
function getTexelEncodingFunction(functionName, colorSpace1) {
    const components = getEncodingComponents(colorSpace1);
    return `vec4 ${functionName}( vec4 value ) { return ${components[0]}( ${components[1]}( value ) ); }`;
}
function getToneMappingFunction(functionName, toneMapping) {
    let toneMappingName;
    switch(toneMapping){
        case LinearToneMapping:
            toneMappingName = "Linear";
            break;
        case ReinhardToneMapping:
            toneMappingName = "Reinhard";
            break;
        case CineonToneMapping:
            toneMappingName = "OptimizedCineon";
            break;
        case ACESFilmicToneMapping:
            toneMappingName = "ACESFilmic";
            break;
        case AgXToneMapping:
            toneMappingName = "AgX";
            break;
        case NeutralToneMapping:
            toneMappingName = "Neutral";
            break;
        case CustomToneMapping:
            toneMappingName = "Custom";
            break;
        default:
            console.warn("THREE.WebGLProgram: Unsupported toneMapping:", toneMapping);
            toneMappingName = "Linear";
    }
    return "vec3 " + functionName + "( vec3 color ) { return " + toneMappingName + "ToneMapping( color ); }";
}
function generateVertexExtensions(parameters) {
    const chunks = [
        parameters.extensionClipCullDistance ? "#extension GL_ANGLE_clip_cull_distance : require" : "",
        parameters.extensionMultiDraw ? "#extension GL_ANGLE_multi_draw : require" : ""
    ];
    return chunks.filter(filterEmptyLine).join("\n");
}
function generateDefines(defines) {
    const chunks = [];
    for(const name in defines){
        const value = defines[name];
        if (value === false) continue;
        chunks.push("#define " + name + " " + value);
    }
    return chunks.join("\n");
}
function fetchAttributeLocations(gl, program) {
    const attributes = {};
    const n = gl.getProgramParameter(program, gl.ACTIVE_ATTRIBUTES);
    for(let i = 0; i < n; i++){
        const info = gl.getActiveAttrib(program, i);
        const name = info.name;
        let locationSize = 1;
        if (info.type === gl.FLOAT_MAT2) locationSize = 2;
        if (info.type === gl.FLOAT_MAT3) locationSize = 3;
        if (info.type === gl.FLOAT_MAT4) locationSize = 4;
        // console.log( 'THREE.WebGLProgram: ACTIVE VERTEX ATTRIBUTE:', name, i );
        attributes[name] = {
            type: info.type,
            location: gl.getAttribLocation(program, name),
            locationSize: locationSize
        };
    }
    return attributes;
}
function filterEmptyLine(string) {
    return string !== "";
}
function replaceLightNums(string, parameters) {
    const numSpotLightCoords = parameters.numSpotLightShadows + parameters.numSpotLightMaps - parameters.numSpotLightShadowsWithMaps;
    return string.replace(/NUM_DIR_LIGHTS/g, parameters.numDirLights).replace(/NUM_SPOT_LIGHTS/g, parameters.numSpotLights).replace(/NUM_SPOT_LIGHT_MAPS/g, parameters.numSpotLightMaps).replace(/NUM_SPOT_LIGHT_COORDS/g, numSpotLightCoords).replace(/NUM_RECT_AREA_LIGHTS/g, parameters.numRectAreaLights).replace(/NUM_POINT_LIGHTS/g, parameters.numPointLights).replace(/NUM_HEMI_LIGHTS/g, parameters.numHemiLights).replace(/NUM_DIR_LIGHT_SHADOWS/g, parameters.numDirLightShadows).replace(/NUM_SPOT_LIGHT_SHADOWS_WITH_MAPS/g, parameters.numSpotLightShadowsWithMaps).replace(/NUM_SPOT_LIGHT_SHADOWS/g, parameters.numSpotLightShadows).replace(/NUM_POINT_LIGHT_SHADOWS/g, parameters.numPointLightShadows);
}
function replaceClippingPlaneNums(string, parameters) {
    return string.replace(/NUM_CLIPPING_PLANES/g, parameters.numClippingPlanes).replace(/UNION_CLIPPING_PLANES/g, parameters.numClippingPlanes - parameters.numClipIntersection);
}
// Resolve Includes
const includePattern = /^[ \t]*#include +<([\w\d./]+)>/gm;
function resolveIncludes(string) {
    return string.replace(includePattern, includeReplacer);
}
const shaderChunkMap = new Map();
function includeReplacer(match, include) {
    let string = ShaderChunk[include];
    if (string === undefined) {
        const newInclude = shaderChunkMap.get(include);
        if (newInclude !== undefined) {
            string = ShaderChunk[newInclude];
            console.warn('THREE.WebGLRenderer: Shader chunk "%s" has been deprecated. Use "%s" instead.', include, newInclude);
        } else throw new Error("Can not resolve #include <" + include + ">");
    }
    return resolveIncludes(string);
}
// Unroll Loops
const unrollLoopPattern = /#pragma unroll_loop_start\s+for\s*\(\s*int\s+i\s*=\s*(\d+)\s*;\s*i\s*<\s*(\d+)\s*;\s*i\s*\+\+\s*\)\s*{([\s\S]+?)}\s+#pragma unroll_loop_end/g;
function unrollLoops(string) {
    return string.replace(unrollLoopPattern, loopReplacer);
}
function loopReplacer(match, start, end, snippet) {
    let string = "";
    for(let i = parseInt(start); i < parseInt(end); i++)string += snippet.replace(/\[\s*i\s*\]/g, "[ " + i + " ]").replace(/UNROLLED_LOOP_INDEX/g, i);
    return string;
}
//
function generatePrecision(parameters) {
    let precisionstring = `precision ${parameters.precision} float;
	precision ${parameters.precision} int;
	precision ${parameters.precision} sampler2D;
	precision ${parameters.precision} samplerCube;
	precision ${parameters.precision} sampler3D;
	precision ${parameters.precision} sampler2DArray;
	precision ${parameters.precision} sampler2DShadow;
	precision ${parameters.precision} samplerCubeShadow;
	precision ${parameters.precision} sampler2DArrayShadow;
	precision ${parameters.precision} isampler2D;
	precision ${parameters.precision} isampler3D;
	precision ${parameters.precision} isamplerCube;
	precision ${parameters.precision} isampler2DArray;
	precision ${parameters.precision} usampler2D;
	precision ${parameters.precision} usampler3D;
	precision ${parameters.precision} usamplerCube;
	precision ${parameters.precision} usampler2DArray;
	`;
    if (parameters.precision === "highp") precisionstring += "\n#define HIGH_PRECISION";
    else if (parameters.precision === "mediump") precisionstring += "\n#define MEDIUM_PRECISION";
    else if (parameters.precision === "lowp") precisionstring += "\n#define LOW_PRECISION";
    return precisionstring;
}
function generateShadowMapTypeDefine(parameters) {
    let shadowMapTypeDefine = "SHADOWMAP_TYPE_BASIC";
    if (parameters.shadowMapType === PCFShadowMap) shadowMapTypeDefine = "SHADOWMAP_TYPE_PCF";
    else if (parameters.shadowMapType === PCFSoftShadowMap) shadowMapTypeDefine = "SHADOWMAP_TYPE_PCF_SOFT";
    else if (parameters.shadowMapType === VSMShadowMap) shadowMapTypeDefine = "SHADOWMAP_TYPE_VSM";
    return shadowMapTypeDefine;
}
function generateEnvMapTypeDefine(parameters) {
    let envMapTypeDefine = "ENVMAP_TYPE_CUBE";
    if (parameters.envMap) switch(parameters.envMapMode){
        case CubeReflectionMapping:
        case CubeRefractionMapping:
            envMapTypeDefine = "ENVMAP_TYPE_CUBE";
            break;
        case CubeUVReflectionMapping:
            envMapTypeDefine = "ENVMAP_TYPE_CUBE_UV";
            break;
    }
    return envMapTypeDefine;
}
function generateEnvMapModeDefine(parameters) {
    let envMapModeDefine = "ENVMAP_MODE_REFLECTION";
    if (parameters.envMap) switch(parameters.envMapMode){
        case CubeRefractionMapping:
            envMapModeDefine = "ENVMAP_MODE_REFRACTION";
            break;
    }
    return envMapModeDefine;
}
function generateEnvMapBlendingDefine(parameters) {
    let envMapBlendingDefine = "ENVMAP_BLENDING_NONE";
    if (parameters.envMap) switch(parameters.combine){
        case MultiplyOperation:
            envMapBlendingDefine = "ENVMAP_BLENDING_MULTIPLY";
            break;
        case MixOperation:
            envMapBlendingDefine = "ENVMAP_BLENDING_MIX";
            break;
        case AddOperation:
            envMapBlendingDefine = "ENVMAP_BLENDING_ADD";
            break;
    }
    return envMapBlendingDefine;
}
function generateCubeUVSize(parameters) {
    const imageHeight = parameters.envMapCubeUVHeight;
    if (imageHeight === null) return null;
    const maxMip = Math.log2(imageHeight) - 2;
    const texelHeight = 1.0 / imageHeight;
    const texelWidth = 1.0 / (3 * Math.max(Math.pow(2, maxMip), 112));
    return {
        texelWidth,
        texelHeight,
        maxMip
    };
}
function WebGLProgram(renderer, cacheKey, parameters, bindingStates) {
    // TODO Send this event to Three.js DevTools
    // console.log( 'WebGLProgram', cacheKey );
    const gl = renderer.getContext();
    const defines = parameters.defines;
    let vertexShader = parameters.vertexShader;
    let fragmentShader = parameters.fragmentShader;
    const shadowMapTypeDefine = generateShadowMapTypeDefine(parameters);
    const envMapTypeDefine = generateEnvMapTypeDefine(parameters);
    const envMapModeDefine = generateEnvMapModeDefine(parameters);
    const envMapBlendingDefine = generateEnvMapBlendingDefine(parameters);
    const envMapCubeUVSize = generateCubeUVSize(parameters);
    const customVertexExtensions = generateVertexExtensions(parameters);
    const customDefines = generateDefines(defines);
    const program = gl.createProgram();
    let prefixVertex, prefixFragment;
    let versionString = parameters.glslVersion ? "#version " + parameters.glslVersion + "\n" : "";
    if (parameters.isRawShaderMaterial) {
        prefixVertex = [
            "#define SHADER_TYPE " + parameters.shaderType,
            "#define SHADER_NAME " + parameters.shaderName,
            customDefines
        ].filter(filterEmptyLine).join("\n");
        if (prefixVertex.length > 0) prefixVertex += "\n";
        prefixFragment = [
            "#define SHADER_TYPE " + parameters.shaderType,
            "#define SHADER_NAME " + parameters.shaderName,
            customDefines
        ].filter(filterEmptyLine).join("\n");
        if (prefixFragment.length > 0) prefixFragment += "\n";
    } else {
        prefixVertex = [
            generatePrecision(parameters),
            "#define SHADER_TYPE " + parameters.shaderType,
            "#define SHADER_NAME " + parameters.shaderName,
            customDefines,
            parameters.extensionClipCullDistance ? "#define USE_CLIP_DISTANCE" : "",
            parameters.batching ? "#define USE_BATCHING" : "",
            parameters.batchingColor ? "#define USE_BATCHING_COLOR" : "",
            parameters.instancing ? "#define USE_INSTANCING" : "",
            parameters.instancingColor ? "#define USE_INSTANCING_COLOR" : "",
            parameters.instancingMorph ? "#define USE_INSTANCING_MORPH" : "",
            parameters.useFog && parameters.fog ? "#define USE_FOG" : "",
            parameters.useFog && parameters.fogExp2 ? "#define FOG_EXP2" : "",
            parameters.map ? "#define USE_MAP" : "",
            parameters.envMap ? "#define USE_ENVMAP" : "",
            parameters.envMap ? "#define " + envMapModeDefine : "",
            parameters.lightMap ? "#define USE_LIGHTMAP" : "",
            parameters.aoMap ? "#define USE_AOMAP" : "",
            parameters.bumpMap ? "#define USE_BUMPMAP" : "",
            parameters.normalMap ? "#define USE_NORMALMAP" : "",
            parameters.normalMapObjectSpace ? "#define USE_NORMALMAP_OBJECTSPACE" : "",
            parameters.normalMapTangentSpace ? "#define USE_NORMALMAP_TANGENTSPACE" : "",
            parameters.displacementMap ? "#define USE_DISPLACEMENTMAP" : "",
            parameters.emissiveMap ? "#define USE_EMISSIVEMAP" : "",
            parameters.anisotropy ? "#define USE_ANISOTROPY" : "",
            parameters.anisotropyMap ? "#define USE_ANISOTROPYMAP" : "",
            parameters.clearcoatMap ? "#define USE_CLEARCOATMAP" : "",
            parameters.clearcoatRoughnessMap ? "#define USE_CLEARCOAT_ROUGHNESSMAP" : "",
            parameters.clearcoatNormalMap ? "#define USE_CLEARCOAT_NORMALMAP" : "",
            parameters.iridescenceMap ? "#define USE_IRIDESCENCEMAP" : "",
            parameters.iridescenceThicknessMap ? "#define USE_IRIDESCENCE_THICKNESSMAP" : "",
            parameters.specularMap ? "#define USE_SPECULARMAP" : "",
            parameters.specularColorMap ? "#define USE_SPECULAR_COLORMAP" : "",
            parameters.specularIntensityMap ? "#define USE_SPECULAR_INTENSITYMAP" : "",
            parameters.roughnessMap ? "#define USE_ROUGHNESSMAP" : "",
            parameters.metalnessMap ? "#define USE_METALNESSMAP" : "",
            parameters.alphaMap ? "#define USE_ALPHAMAP" : "",
            parameters.alphaHash ? "#define USE_ALPHAHASH" : "",
            parameters.transmission ? "#define USE_TRANSMISSION" : "",
            parameters.transmissionMap ? "#define USE_TRANSMISSIONMAP" : "",
            parameters.thicknessMap ? "#define USE_THICKNESSMAP" : "",
            parameters.sheenColorMap ? "#define USE_SHEEN_COLORMAP" : "",
            parameters.sheenRoughnessMap ? "#define USE_SHEEN_ROUGHNESSMAP" : "",
            //
            parameters.mapUv ? "#define MAP_UV " + parameters.mapUv : "",
            parameters.alphaMapUv ? "#define ALPHAMAP_UV " + parameters.alphaMapUv : "",
            parameters.lightMapUv ? "#define LIGHTMAP_UV " + parameters.lightMapUv : "",
            parameters.aoMapUv ? "#define AOMAP_UV " + parameters.aoMapUv : "",
            parameters.emissiveMapUv ? "#define EMISSIVEMAP_UV " + parameters.emissiveMapUv : "",
            parameters.bumpMapUv ? "#define BUMPMAP_UV " + parameters.bumpMapUv : "",
            parameters.normalMapUv ? "#define NORMALMAP_UV " + parameters.normalMapUv : "",
            parameters.displacementMapUv ? "#define DISPLACEMENTMAP_UV " + parameters.displacementMapUv : "",
            parameters.metalnessMapUv ? "#define METALNESSMAP_UV " + parameters.metalnessMapUv : "",
            parameters.roughnessMapUv ? "#define ROUGHNESSMAP_UV " + parameters.roughnessMapUv : "",
            parameters.anisotropyMapUv ? "#define ANISOTROPYMAP_UV " + parameters.anisotropyMapUv : "",
            parameters.clearcoatMapUv ? "#define CLEARCOATMAP_UV " + parameters.clearcoatMapUv : "",
            parameters.clearcoatNormalMapUv ? "#define CLEARCOAT_NORMALMAP_UV " + parameters.clearcoatNormalMapUv : "",
            parameters.clearcoatRoughnessMapUv ? "#define CLEARCOAT_ROUGHNESSMAP_UV " + parameters.clearcoatRoughnessMapUv : "",
            parameters.iridescenceMapUv ? "#define IRIDESCENCEMAP_UV " + parameters.iridescenceMapUv : "",
            parameters.iridescenceThicknessMapUv ? "#define IRIDESCENCE_THICKNESSMAP_UV " + parameters.iridescenceThicknessMapUv : "",
            parameters.sheenColorMapUv ? "#define SHEEN_COLORMAP_UV " + parameters.sheenColorMapUv : "",
            parameters.sheenRoughnessMapUv ? "#define SHEEN_ROUGHNESSMAP_UV " + parameters.sheenRoughnessMapUv : "",
            parameters.specularMapUv ? "#define SPECULARMAP_UV " + parameters.specularMapUv : "",
            parameters.specularColorMapUv ? "#define SPECULAR_COLORMAP_UV " + parameters.specularColorMapUv : "",
            parameters.specularIntensityMapUv ? "#define SPECULAR_INTENSITYMAP_UV " + parameters.specularIntensityMapUv : "",
            parameters.transmissionMapUv ? "#define TRANSMISSIONMAP_UV " + parameters.transmissionMapUv : "",
            parameters.thicknessMapUv ? "#define THICKNESSMAP_UV " + parameters.thicknessMapUv : "",
            //
            parameters.vertexTangents && parameters.flatShading === false ? "#define USE_TANGENT" : "",
            parameters.vertexColors ? "#define USE_COLOR" : "",
            parameters.vertexAlphas ? "#define USE_COLOR_ALPHA" : "",
            parameters.vertexUv1s ? "#define USE_UV1" : "",
            parameters.vertexUv2s ? "#define USE_UV2" : "",
            parameters.vertexUv3s ? "#define USE_UV3" : "",
            parameters.pointsUvs ? "#define USE_POINTS_UV" : "",
            parameters.flatShading ? "#define FLAT_SHADED" : "",
            parameters.skinning ? "#define USE_SKINNING" : "",
            parameters.morphTargets ? "#define USE_MORPHTARGETS" : "",
            parameters.morphNormals && parameters.flatShading === false ? "#define USE_MORPHNORMALS" : "",
            parameters.morphColors ? "#define USE_MORPHCOLORS" : "",
            parameters.morphTargetsCount > 0 ? "#define MORPHTARGETS_TEXTURE_STRIDE " + parameters.morphTextureStride : "",
            parameters.morphTargetsCount > 0 ? "#define MORPHTARGETS_COUNT " + parameters.morphTargetsCount : "",
            parameters.doubleSided ? "#define DOUBLE_SIDED" : "",
            parameters.flipSided ? "#define FLIP_SIDED" : "",
            parameters.shadowMapEnabled ? "#define USE_SHADOWMAP" : "",
            parameters.shadowMapEnabled ? "#define " + shadowMapTypeDefine : "",
            parameters.sizeAttenuation ? "#define USE_SIZEATTENUATION" : "",
            parameters.numLightProbes > 0 ? "#define USE_LIGHT_PROBES" : "",
            parameters.logarithmicDepthBuffer ? "#define USE_LOGDEPTHBUF" : "",
            "uniform mat4 modelMatrix;",
            "uniform mat4 modelViewMatrix;",
            "uniform mat4 projectionMatrix;",
            "uniform mat4 viewMatrix;",
            "uniform mat3 normalMatrix;",
            "uniform vec3 cameraPosition;",
            "uniform bool isOrthographic;",
            "#ifdef USE_INSTANCING",
            "	attribute mat4 instanceMatrix;",
            "#endif",
            "#ifdef USE_INSTANCING_COLOR",
            "	attribute vec3 instanceColor;",
            "#endif",
            "#ifdef USE_INSTANCING_MORPH",
            "	uniform sampler2D morphTexture;",
            "#endif",
            "attribute vec3 position;",
            "attribute vec3 normal;",
            "attribute vec2 uv;",
            "#ifdef USE_UV1",
            "	attribute vec2 uv1;",
            "#endif",
            "#ifdef USE_UV2",
            "	attribute vec2 uv2;",
            "#endif",
            "#ifdef USE_UV3",
            "	attribute vec2 uv3;",
            "#endif",
            "#ifdef USE_TANGENT",
            "	attribute vec4 tangent;",
            "#endif",
            "#if defined( USE_COLOR_ALPHA )",
            "	attribute vec4 color;",
            "#elif defined( USE_COLOR )",
            "	attribute vec3 color;",
            "#endif",
            "#ifdef USE_SKINNING",
            "	attribute vec4 skinIndex;",
            "	attribute vec4 skinWeight;",
            "#endif",
            "\n"
        ].filter(filterEmptyLine).join("\n");
        prefixFragment = [
            generatePrecision(parameters),
            "#define SHADER_TYPE " + parameters.shaderType,
            "#define SHADER_NAME " + parameters.shaderName,
            customDefines,
            parameters.useFog && parameters.fog ? "#define USE_FOG" : "",
            parameters.useFog && parameters.fogExp2 ? "#define FOG_EXP2" : "",
            parameters.alphaToCoverage ? "#define ALPHA_TO_COVERAGE" : "",
            parameters.map ? "#define USE_MAP" : "",
            parameters.matcap ? "#define USE_MATCAP" : "",
            parameters.envMap ? "#define USE_ENVMAP" : "",
            parameters.envMap ? "#define " + envMapTypeDefine : "",
            parameters.envMap ? "#define " + envMapModeDefine : "",
            parameters.envMap ? "#define " + envMapBlendingDefine : "",
            envMapCubeUVSize ? "#define CUBEUV_TEXEL_WIDTH " + envMapCubeUVSize.texelWidth : "",
            envMapCubeUVSize ? "#define CUBEUV_TEXEL_HEIGHT " + envMapCubeUVSize.texelHeight : "",
            envMapCubeUVSize ? "#define CUBEUV_MAX_MIP " + envMapCubeUVSize.maxMip + ".0" : "",
            parameters.lightMap ? "#define USE_LIGHTMAP" : "",
            parameters.aoMap ? "#define USE_AOMAP" : "",
            parameters.bumpMap ? "#define USE_BUMPMAP" : "",
            parameters.normalMap ? "#define USE_NORMALMAP" : "",
            parameters.normalMapObjectSpace ? "#define USE_NORMALMAP_OBJECTSPACE" : "",
            parameters.normalMapTangentSpace ? "#define USE_NORMALMAP_TANGENTSPACE" : "",
            parameters.emissiveMap ? "#define USE_EMISSIVEMAP" : "",
            parameters.anisotropy ? "#define USE_ANISOTROPY" : "",
            parameters.anisotropyMap ? "#define USE_ANISOTROPYMAP" : "",
            parameters.clearcoat ? "#define USE_CLEARCOAT" : "",
            parameters.clearcoatMap ? "#define USE_CLEARCOATMAP" : "",
            parameters.clearcoatRoughnessMap ? "#define USE_CLEARCOAT_ROUGHNESSMAP" : "",
            parameters.clearcoatNormalMap ? "#define USE_CLEARCOAT_NORMALMAP" : "",
            parameters.dispersion ? "#define USE_DISPERSION" : "",
            parameters.iridescence ? "#define USE_IRIDESCENCE" : "",
            parameters.iridescenceMap ? "#define USE_IRIDESCENCEMAP" : "",
            parameters.iridescenceThicknessMap ? "#define USE_IRIDESCENCE_THICKNESSMAP" : "",
            parameters.specularMap ? "#define USE_SPECULARMAP" : "",
            parameters.specularColorMap ? "#define USE_SPECULAR_COLORMAP" : "",
            parameters.specularIntensityMap ? "#define USE_SPECULAR_INTENSITYMAP" : "",
            parameters.roughnessMap ? "#define USE_ROUGHNESSMAP" : "",
            parameters.metalnessMap ? "#define USE_METALNESSMAP" : "",
            parameters.alphaMap ? "#define USE_ALPHAMAP" : "",
            parameters.alphaTest ? "#define USE_ALPHATEST" : "",
            parameters.alphaHash ? "#define USE_ALPHAHASH" : "",
            parameters.sheen ? "#define USE_SHEEN" : "",
            parameters.sheenColorMap ? "#define USE_SHEEN_COLORMAP" : "",
            parameters.sheenRoughnessMap ? "#define USE_SHEEN_ROUGHNESSMAP" : "",
            parameters.transmission ? "#define USE_TRANSMISSION" : "",
            parameters.transmissionMap ? "#define USE_TRANSMISSIONMAP" : "",
            parameters.thicknessMap ? "#define USE_THICKNESSMAP" : "",
            parameters.vertexTangents && parameters.flatShading === false ? "#define USE_TANGENT" : "",
            parameters.vertexColors || parameters.instancingColor || parameters.batchingColor ? "#define USE_COLOR" : "",
            parameters.vertexAlphas ? "#define USE_COLOR_ALPHA" : "",
            parameters.vertexUv1s ? "#define USE_UV1" : "",
            parameters.vertexUv2s ? "#define USE_UV2" : "",
            parameters.vertexUv3s ? "#define USE_UV3" : "",
            parameters.pointsUvs ? "#define USE_POINTS_UV" : "",
            parameters.gradientMap ? "#define USE_GRADIENTMAP" : "",
            parameters.flatShading ? "#define FLAT_SHADED" : "",
            parameters.doubleSided ? "#define DOUBLE_SIDED" : "",
            parameters.flipSided ? "#define FLIP_SIDED" : "",
            parameters.shadowMapEnabled ? "#define USE_SHADOWMAP" : "",
            parameters.shadowMapEnabled ? "#define " + shadowMapTypeDefine : "",
            parameters.premultipliedAlpha ? "#define PREMULTIPLIED_ALPHA" : "",
            parameters.numLightProbes > 0 ? "#define USE_LIGHT_PROBES" : "",
            parameters.decodeVideoTexture ? "#define DECODE_VIDEO_TEXTURE" : "",
            parameters.logarithmicDepthBuffer ? "#define USE_LOGDEPTHBUF" : "",
            "uniform mat4 viewMatrix;",
            "uniform vec3 cameraPosition;",
            "uniform bool isOrthographic;",
            parameters.toneMapping !== NoToneMapping ? "#define TONE_MAPPING" : "",
            parameters.toneMapping !== NoToneMapping ? ShaderChunk["tonemapping_pars_fragment"] : "",
            parameters.toneMapping !== NoToneMapping ? getToneMappingFunction("toneMapping", parameters.toneMapping) : "",
            parameters.dithering ? "#define DITHERING" : "",
            parameters.opaque ? "#define OPAQUE" : "",
            ShaderChunk["colorspace_pars_fragment"],
            getTexelEncodingFunction("linearToOutputTexel", parameters.outputColorSpace),
            parameters.useDepthPacking ? "#define DEPTH_PACKING " + parameters.depthPacking : "",
            "\n"
        ].filter(filterEmptyLine).join("\n");
    }
    vertexShader = resolveIncludes(vertexShader);
    vertexShader = replaceLightNums(vertexShader, parameters);
    vertexShader = replaceClippingPlaneNums(vertexShader, parameters);
    fragmentShader = resolveIncludes(fragmentShader);
    fragmentShader = replaceLightNums(fragmentShader, parameters);
    fragmentShader = replaceClippingPlaneNums(fragmentShader, parameters);
    vertexShader = unrollLoops(vertexShader);
    fragmentShader = unrollLoops(fragmentShader);
    if (parameters.isRawShaderMaterial !== true) {
        // GLSL 3.0 conversion for built-in materials and ShaderMaterial
        versionString = "#version 300 es\n";
        prefixVertex = [
            customVertexExtensions,
            "#define attribute in",
            "#define varying out",
            "#define texture2D texture"
        ].join("\n") + "\n" + prefixVertex;
        prefixFragment = [
            "#define varying in",
            parameters.glslVersion === GLSL3 ? "" : "layout(location = 0) out highp vec4 pc_fragColor;",
            parameters.glslVersion === GLSL3 ? "" : "#define gl_FragColor pc_fragColor",
            "#define gl_FragDepthEXT gl_FragDepth",
            "#define texture2D texture",
            "#define textureCube texture",
            "#define texture2DProj textureProj",
            "#define texture2DLodEXT textureLod",
            "#define texture2DProjLodEXT textureProjLod",
            "#define textureCubeLodEXT textureLod",
            "#define texture2DGradEXT textureGrad",
            "#define texture2DProjGradEXT textureProjGrad",
            "#define textureCubeGradEXT textureGrad"
        ].join("\n") + "\n" + prefixFragment;
    }
    const vertexGlsl = versionString + prefixVertex + vertexShader;
    const fragmentGlsl = versionString + prefixFragment + fragmentShader;
    // console.log( '*VERTEX*', vertexGlsl );
    // console.log( '*FRAGMENT*', fragmentGlsl );
    const glVertexShader = WebGLShader(gl, gl.VERTEX_SHADER, vertexGlsl);
    const glFragmentShader = WebGLShader(gl, gl.FRAGMENT_SHADER, fragmentGlsl);
    gl.attachShader(program, glVertexShader);
    gl.attachShader(program, glFragmentShader);
    // Force a particular attribute to index 0.
    if (parameters.index0AttributeName !== undefined) gl.bindAttribLocation(program, 0, parameters.index0AttributeName);
    else if (parameters.morphTargets === true) // programs with morphTargets displace position out of attribute 0
    gl.bindAttribLocation(program, 0, "position");
    gl.linkProgram(program);
    function onFirstUse(self1) {
        // check for link errors
        if (renderer.debug.checkShaderErrors) {
            const programLog = gl.getProgramInfoLog(program).trim();
            const vertexLog = gl.getShaderInfoLog(glVertexShader).trim();
            const fragmentLog = gl.getShaderInfoLog(glFragmentShader).trim();
            let runnable = true;
            let haveDiagnostics = true;
            if (gl.getProgramParameter(program, gl.LINK_STATUS) === false) {
                runnable = false;
                if (typeof renderer.debug.onShaderError === "function") renderer.debug.onShaderError(gl, program, glVertexShader, glFragmentShader);
                else {
                    // default error reporting
                    const vertexErrors = getShaderErrors(gl, glVertexShader, "vertex");
                    const fragmentErrors = getShaderErrors(gl, glFragmentShader, "fragment");
                    console.error("THREE.WebGLProgram: Shader Error " + gl.getError() + " - " + "VALIDATE_STATUS " + gl.getProgramParameter(program, gl.VALIDATE_STATUS) + "\n\n" + "Material Name: " + self1.name + "\n" + "Material Type: " + self1.type + "\n\n" + "Program Info Log: " + programLog + "\n" + vertexErrors + "\n" + fragmentErrors);
                }
            } else if (programLog !== "") console.warn("THREE.WebGLProgram: Program Info Log:", programLog);
            else if (vertexLog === "" || fragmentLog === "") haveDiagnostics = false;
            if (haveDiagnostics) self1.diagnostics = {
                runnable: runnable,
                programLog: programLog,
                vertexShader: {
                    log: vertexLog,
                    prefix: prefixVertex
                },
                fragmentShader: {
                    log: fragmentLog,
                    prefix: prefixFragment
                }
            };
        }
        // Clean up
        // Crashes in iOS9 and iOS10. #18402
        // gl.detachShader( program, glVertexShader );
        // gl.detachShader( program, glFragmentShader );
        gl.deleteShader(glVertexShader);
        gl.deleteShader(glFragmentShader);
        cachedUniforms = new WebGLUniforms(gl, program);
        cachedAttributes = fetchAttributeLocations(gl, program);
    }
    // set up caching for uniform locations
    let cachedUniforms;
    this.getUniforms = function() {
        if (cachedUniforms === undefined) // Populates cachedUniforms and cachedAttributes
        onFirstUse(this);
        return cachedUniforms;
    };
    // set up caching for attribute locations
    let cachedAttributes;
    this.getAttributes = function() {
        if (cachedAttributes === undefined) // Populates cachedAttributes and cachedUniforms
        onFirstUse(this);
        return cachedAttributes;
    };
    // indicate when the program is ready to be used. if the KHR_parallel_shader_compile extension isn't supported,
    // flag the program as ready immediately. It may cause a stall when it's first used.
    let programReady = parameters.rendererExtensionParallelShaderCompile === false;
    this.isReady = function() {
        if (programReady === false) programReady = gl.getProgramParameter(program, COMPLETION_STATUS_KHR);
        return programReady;
    };
    // free resource
    this.destroy = function() {
        bindingStates.releaseStatesOfProgram(this);
        gl.deleteProgram(program);
        this.program = undefined;
    };
    //
    this.type = parameters.shaderType;
    this.name = parameters.shaderName;
    this.id = programIdCount++;
    this.cacheKey = cacheKey;
    this.usedTimes = 1;
    this.program = program;
    this.vertexShader = glVertexShader;
    this.fragmentShader = glFragmentShader;
    return this;
}
let _id$1 = 0;
class WebGLShaderCache {
    constructor(){
        this.shaderCache = new Map();
        this.materialCache = new Map();
    }
    update(material) {
        const vertexShader = material.vertexShader;
        const fragmentShader = material.fragmentShader;
        const vertexShaderStage = this._getShaderStage(vertexShader);
        const fragmentShaderStage = this._getShaderStage(fragmentShader);
        const materialShaders = this._getShaderCacheForMaterial(material);
        if (materialShaders.has(vertexShaderStage) === false) {
            materialShaders.add(vertexShaderStage);
            vertexShaderStage.usedTimes++;
        }
        if (materialShaders.has(fragmentShaderStage) === false) {
            materialShaders.add(fragmentShaderStage);
            fragmentShaderStage.usedTimes++;
        }
        return this;
    }
    remove(material) {
        const materialShaders = this.materialCache.get(material);
        for (const shaderStage of materialShaders){
            shaderStage.usedTimes--;
            if (shaderStage.usedTimes === 0) this.shaderCache.delete(shaderStage.code);
        }
        this.materialCache.delete(material);
        return this;
    }
    getVertexShaderID(material) {
        return this._getShaderStage(material.vertexShader).id;
    }
    getFragmentShaderID(material) {
        return this._getShaderStage(material.fragmentShader).id;
    }
    dispose() {
        this.shaderCache.clear();
        this.materialCache.clear();
    }
    _getShaderCacheForMaterial(material) {
        const cache = this.materialCache;
        let set = cache.get(material);
        if (set === undefined) {
            set = new Set();
            cache.set(material, set);
        }
        return set;
    }
    _getShaderStage(code) {
        const cache = this.shaderCache;
        let stage = cache.get(code);
        if (stage === undefined) {
            stage = new WebGLShaderStage(code);
            cache.set(code, stage);
        }
        return stage;
    }
}
class WebGLShaderStage {
    constructor(code){
        this.id = _id$1++;
        this.code = code;
        this.usedTimes = 0;
    }
}
function WebGLPrograms(renderer, cubemaps, cubeuvmaps, extensions, capabilities, bindingStates, clipping) {
    const _programLayers = new Layers();
    const _customShaders = new WebGLShaderCache();
    const _activeChannels = new Set();
    const programs = [];
    const logarithmicDepthBuffer = capabilities.logarithmicDepthBuffer;
    const SUPPORTS_VERTEX_TEXTURES = capabilities.vertexTextures;
    let precision = capabilities.precision;
    const shaderIDs = {
        MeshDepthMaterial: "depth",
        MeshDistanceMaterial: "distanceRGBA",
        MeshNormalMaterial: "normal",
        MeshBasicMaterial: "basic",
        MeshLambertMaterial: "lambert",
        MeshPhongMaterial: "phong",
        MeshToonMaterial: "toon",
        MeshStandardMaterial: "physical",
        MeshPhysicalMaterial: "physical",
        MeshMatcapMaterial: "matcap",
        LineBasicMaterial: "basic",
        LineDashedMaterial: "dashed",
        PointsMaterial: "points",
        ShadowMaterial: "shadow",
        SpriteMaterial: "sprite"
    };
    function getChannel(value) {
        _activeChannels.add(value);
        if (value === 0) return "uv";
        return `uv${value}`;
    }
    function getParameters(material, lights, shadows, scene, object) {
        const fog = scene.fog;
        const geometry = object.geometry;
        const environment = material.isMeshStandardMaterial ? scene.environment : null;
        const envMap = (material.isMeshStandardMaterial ? cubeuvmaps : cubemaps).get(material.envMap || environment);
        const envMapCubeUVHeight = !!envMap && envMap.mapping === CubeUVReflectionMapping ? envMap.image.height : null;
        const shaderID = shaderIDs[material.type];
        // heuristics to create shader parameters according to lights in the scene
        // (not to blow over maxLights budget)
        if (material.precision !== null) {
            precision = capabilities.getMaxPrecision(material.precision);
            if (precision !== material.precision) console.warn("THREE.WebGLProgram.getParameters:", material.precision, "not supported, using", precision, "instead.");
        }
        //
        const morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;
        const morphTargetsCount = morphAttribute !== undefined ? morphAttribute.length : 0;
        let morphTextureStride = 0;
        if (geometry.morphAttributes.position !== undefined) morphTextureStride = 1;
        if (geometry.morphAttributes.normal !== undefined) morphTextureStride = 2;
        if (geometry.morphAttributes.color !== undefined) morphTextureStride = 3;
        //
        let vertexShader, fragmentShader;
        let customVertexShaderID, customFragmentShaderID;
        if (shaderID) {
            const shader = ShaderLib[shaderID];
            vertexShader = shader.vertexShader;
            fragmentShader = shader.fragmentShader;
        } else {
            vertexShader = material.vertexShader;
            fragmentShader = material.fragmentShader;
            _customShaders.update(material);
            customVertexShaderID = _customShaders.getVertexShaderID(material);
            customFragmentShaderID = _customShaders.getFragmentShaderID(material);
        }
        const currentRenderTarget = renderer.getRenderTarget();
        const IS_INSTANCEDMESH = object.isInstancedMesh === true;
        const IS_BATCHEDMESH = object.isBatchedMesh === true;
        const HAS_MAP = !!material.map;
        const HAS_MATCAP = !!material.matcap;
        const HAS_ENVMAP = !!envMap;
        const HAS_AOMAP = !!material.aoMap;
        const HAS_LIGHTMAP = !!material.lightMap;
        const HAS_BUMPMAP = !!material.bumpMap;
        const HAS_NORMALMAP = !!material.normalMap;
        const HAS_DISPLACEMENTMAP = !!material.displacementMap;
        const HAS_EMISSIVEMAP = !!material.emissiveMap;
        const HAS_METALNESSMAP = !!material.metalnessMap;
        const HAS_ROUGHNESSMAP = !!material.roughnessMap;
        const HAS_ANISOTROPY = material.anisotropy > 0;
        const HAS_CLEARCOAT = material.clearcoat > 0;
        const HAS_DISPERSION = material.dispersion > 0;
        const HAS_IRIDESCENCE = material.iridescence > 0;
        const HAS_SHEEN = material.sheen > 0;
        const HAS_TRANSMISSION = material.transmission > 0;
        const HAS_ANISOTROPYMAP = HAS_ANISOTROPY && !!material.anisotropyMap;
        const HAS_CLEARCOATMAP = HAS_CLEARCOAT && !!material.clearcoatMap;
        const HAS_CLEARCOAT_NORMALMAP = HAS_CLEARCOAT && !!material.clearcoatNormalMap;
        const HAS_CLEARCOAT_ROUGHNESSMAP = HAS_CLEARCOAT && !!material.clearcoatRoughnessMap;
        const HAS_IRIDESCENCEMAP = HAS_IRIDESCENCE && !!material.iridescenceMap;
        const HAS_IRIDESCENCE_THICKNESSMAP = HAS_IRIDESCENCE && !!material.iridescenceThicknessMap;
        const HAS_SHEEN_COLORMAP = HAS_SHEEN && !!material.sheenColorMap;
        const HAS_SHEEN_ROUGHNESSMAP = HAS_SHEEN && !!material.sheenRoughnessMap;
        const HAS_SPECULARMAP = !!material.specularMap;
        const HAS_SPECULAR_COLORMAP = !!material.specularColorMap;
        const HAS_SPECULAR_INTENSITYMAP = !!material.specularIntensityMap;
        const HAS_TRANSMISSIONMAP = HAS_TRANSMISSION && !!material.transmissionMap;
        const HAS_THICKNESSMAP = HAS_TRANSMISSION && !!material.thicknessMap;
        const HAS_GRADIENTMAP = !!material.gradientMap;
        const HAS_ALPHAMAP = !!material.alphaMap;
        const HAS_ALPHATEST = material.alphaTest > 0;
        const HAS_ALPHAHASH = !!material.alphaHash;
        const HAS_EXTENSIONS = !!material.extensions;
        let toneMapping = NoToneMapping;
        if (material.toneMapped) {
            if (currentRenderTarget === null || currentRenderTarget.isXRRenderTarget === true) toneMapping = renderer.toneMapping;
        }
        const parameters = {
            shaderID: shaderID,
            shaderType: material.type,
            shaderName: material.name,
            vertexShader: vertexShader,
            fragmentShader: fragmentShader,
            defines: material.defines,
            customVertexShaderID: customVertexShaderID,
            customFragmentShaderID: customFragmentShaderID,
            isRawShaderMaterial: material.isRawShaderMaterial === true,
            glslVersion: material.glslVersion,
            precision: precision,
            batching: IS_BATCHEDMESH,
            batchingColor: IS_BATCHEDMESH && object._colorsTexture !== null,
            instancing: IS_INSTANCEDMESH,
            instancingColor: IS_INSTANCEDMESH && object.instanceColor !== null,
            instancingMorph: IS_INSTANCEDMESH && object.morphTexture !== null,
            supportsVertexTextures: SUPPORTS_VERTEX_TEXTURES,
            outputColorSpace: currentRenderTarget === null ? renderer.outputColorSpace : currentRenderTarget.isXRRenderTarget === true ? currentRenderTarget.texture.colorSpace : LinearSRGBColorSpace,
            alphaToCoverage: !!material.alphaToCoverage,
            map: HAS_MAP,
            matcap: HAS_MATCAP,
            envMap: HAS_ENVMAP,
            envMapMode: HAS_ENVMAP && envMap.mapping,
            envMapCubeUVHeight: envMapCubeUVHeight,
            aoMap: HAS_AOMAP,
            lightMap: HAS_LIGHTMAP,
            bumpMap: HAS_BUMPMAP,
            normalMap: HAS_NORMALMAP,
            displacementMap: SUPPORTS_VERTEX_TEXTURES && HAS_DISPLACEMENTMAP,
            emissiveMap: HAS_EMISSIVEMAP,
            normalMapObjectSpace: HAS_NORMALMAP && material.normalMapType === ObjectSpaceNormalMap,
            normalMapTangentSpace: HAS_NORMALMAP && material.normalMapType === TangentSpaceNormalMap,
            metalnessMap: HAS_METALNESSMAP,
            roughnessMap: HAS_ROUGHNESSMAP,
            anisotropy: HAS_ANISOTROPY,
            anisotropyMap: HAS_ANISOTROPYMAP,
            clearcoat: HAS_CLEARCOAT,
            clearcoatMap: HAS_CLEARCOATMAP,
            clearcoatNormalMap: HAS_CLEARCOAT_NORMALMAP,
            clearcoatRoughnessMap: HAS_CLEARCOAT_ROUGHNESSMAP,
            dispersion: HAS_DISPERSION,
            iridescence: HAS_IRIDESCENCE,
            iridescenceMap: HAS_IRIDESCENCEMAP,
            iridescenceThicknessMap: HAS_IRIDESCENCE_THICKNESSMAP,
            sheen: HAS_SHEEN,
            sheenColorMap: HAS_SHEEN_COLORMAP,
            sheenRoughnessMap: HAS_SHEEN_ROUGHNESSMAP,
            specularMap: HAS_SPECULARMAP,
            specularColorMap: HAS_SPECULAR_COLORMAP,
            specularIntensityMap: HAS_SPECULAR_INTENSITYMAP,
            transmission: HAS_TRANSMISSION,
            transmissionMap: HAS_TRANSMISSIONMAP,
            thicknessMap: HAS_THICKNESSMAP,
            gradientMap: HAS_GRADIENTMAP,
            opaque: material.transparent === false && material.blending === NormalBlending && material.alphaToCoverage === false,
            alphaMap: HAS_ALPHAMAP,
            alphaTest: HAS_ALPHATEST,
            alphaHash: HAS_ALPHAHASH,
            combine: material.combine,
            //
            mapUv: HAS_MAP && getChannel(material.map.channel),
            aoMapUv: HAS_AOMAP && getChannel(material.aoMap.channel),
            lightMapUv: HAS_LIGHTMAP && getChannel(material.lightMap.channel),
            bumpMapUv: HAS_BUMPMAP && getChannel(material.bumpMap.channel),
            normalMapUv: HAS_NORMALMAP && getChannel(material.normalMap.channel),
            displacementMapUv: HAS_DISPLACEMENTMAP && getChannel(material.displacementMap.channel),
            emissiveMapUv: HAS_EMISSIVEMAP && getChannel(material.emissiveMap.channel),
            metalnessMapUv: HAS_METALNESSMAP && getChannel(material.metalnessMap.channel),
            roughnessMapUv: HAS_ROUGHNESSMAP && getChannel(material.roughnessMap.channel),
            anisotropyMapUv: HAS_ANISOTROPYMAP && getChannel(material.anisotropyMap.channel),
            clearcoatMapUv: HAS_CLEARCOATMAP && getChannel(material.clearcoatMap.channel),
            clearcoatNormalMapUv: HAS_CLEARCOAT_NORMALMAP && getChannel(material.clearcoatNormalMap.channel),
            clearcoatRoughnessMapUv: HAS_CLEARCOAT_ROUGHNESSMAP && getChannel(material.clearcoatRoughnessMap.channel),
            iridescenceMapUv: HAS_IRIDESCENCEMAP && getChannel(material.iridescenceMap.channel),
            iridescenceThicknessMapUv: HAS_IRIDESCENCE_THICKNESSMAP && getChannel(material.iridescenceThicknessMap.channel),
            sheenColorMapUv: HAS_SHEEN_COLORMAP && getChannel(material.sheenColorMap.channel),
            sheenRoughnessMapUv: HAS_SHEEN_ROUGHNESSMAP && getChannel(material.sheenRoughnessMap.channel),
            specularMapUv: HAS_SPECULARMAP && getChannel(material.specularMap.channel),
            specularColorMapUv: HAS_SPECULAR_COLORMAP && getChannel(material.specularColorMap.channel),
            specularIntensityMapUv: HAS_SPECULAR_INTENSITYMAP && getChannel(material.specularIntensityMap.channel),
            transmissionMapUv: HAS_TRANSMISSIONMAP && getChannel(material.transmissionMap.channel),
            thicknessMapUv: HAS_THICKNESSMAP && getChannel(material.thicknessMap.channel),
            alphaMapUv: HAS_ALPHAMAP && getChannel(material.alphaMap.channel),
            //
            vertexTangents: !!geometry.attributes.tangent && (HAS_NORMALMAP || HAS_ANISOTROPY),
            vertexColors: material.vertexColors,
            vertexAlphas: material.vertexColors === true && !!geometry.attributes.color && geometry.attributes.color.itemSize === 4,
            pointsUvs: object.isPoints === true && !!geometry.attributes.uv && (HAS_MAP || HAS_ALPHAMAP),
            fog: !!fog,
            useFog: material.fog === true,
            fogExp2: !!fog && fog.isFogExp2,
            flatShading: material.flatShading === true,
            sizeAttenuation: material.sizeAttenuation === true,
            logarithmicDepthBuffer: logarithmicDepthBuffer,
            skinning: object.isSkinnedMesh === true,
            morphTargets: geometry.morphAttributes.position !== undefined,
            morphNormals: geometry.morphAttributes.normal !== undefined,
            morphColors: geometry.morphAttributes.color !== undefined,
            morphTargetsCount: morphTargetsCount,
            morphTextureStride: morphTextureStride,
            numDirLights: lights.directional.length,
            numPointLights: lights.point.length,
            numSpotLights: lights.spot.length,
            numSpotLightMaps: lights.spotLightMap.length,
            numRectAreaLights: lights.rectArea.length,
            numHemiLights: lights.hemi.length,
            numDirLightShadows: lights.directionalShadowMap.length,
            numPointLightShadows: lights.pointShadowMap.length,
            numSpotLightShadows: lights.spotShadowMap.length,
            numSpotLightShadowsWithMaps: lights.numSpotLightShadowsWithMaps,
            numLightProbes: lights.numLightProbes,
            numClippingPlanes: clipping.numPlanes,
            numClipIntersection: clipping.numIntersection,
            dithering: material.dithering,
            shadowMapEnabled: renderer.shadowMap.enabled && shadows.length > 0,
            shadowMapType: renderer.shadowMap.type,
            toneMapping: toneMapping,
            decodeVideoTexture: HAS_MAP && material.map.isVideoTexture === true && ColorManagement.getTransfer(material.map.colorSpace) === SRGBTransfer,
            premultipliedAlpha: material.premultipliedAlpha,
            doubleSided: material.side === DoubleSide,
            flipSided: material.side === BackSide,
            useDepthPacking: material.depthPacking >= 0,
            depthPacking: material.depthPacking || 0,
            index0AttributeName: material.index0AttributeName,
            extensionClipCullDistance: HAS_EXTENSIONS && material.extensions.clipCullDistance === true && extensions.has("WEBGL_clip_cull_distance"),
            extensionMultiDraw: (HAS_EXTENSIONS && material.extensions.multiDraw === true || IS_BATCHEDMESH) && extensions.has("WEBGL_multi_draw"),
            rendererExtensionParallelShaderCompile: extensions.has("KHR_parallel_shader_compile"),
            customProgramCacheKey: material.customProgramCacheKey()
        };
        // the usage of getChannel() determines the active texture channels for this shader
        parameters.vertexUv1s = _activeChannels.has(1);
        parameters.vertexUv2s = _activeChannels.has(2);
        parameters.vertexUv3s = _activeChannels.has(3);
        _activeChannels.clear();
        return parameters;
    }
    function getProgramCacheKey(parameters) {
        const array = [];
        if (parameters.shaderID) array.push(parameters.shaderID);
        else {
            array.push(parameters.customVertexShaderID);
            array.push(parameters.customFragmentShaderID);
        }
        if (parameters.defines !== undefined) for(const name in parameters.defines){
            array.push(name);
            array.push(parameters.defines[name]);
        }
        if (parameters.isRawShaderMaterial === false) {
            getProgramCacheKeyParameters(array, parameters);
            getProgramCacheKeyBooleans(array, parameters);
            array.push(renderer.outputColorSpace);
        }
        array.push(parameters.customProgramCacheKey);
        return array.join();
    }
    function getProgramCacheKeyParameters(array, parameters) {
        array.push(parameters.precision);
        array.push(parameters.outputColorSpace);
        array.push(parameters.envMapMode);
        array.push(parameters.envMapCubeUVHeight);
        array.push(parameters.mapUv);
        array.push(parameters.alphaMapUv);
        array.push(parameters.lightMapUv);
        array.push(parameters.aoMapUv);
        array.push(parameters.bumpMapUv);
        array.push(parameters.normalMapUv);
        array.push(parameters.displacementMapUv);
        array.push(parameters.emissiveMapUv);
        array.push(parameters.metalnessMapUv);
        array.push(parameters.roughnessMapUv);
        array.push(parameters.anisotropyMapUv);
        array.push(parameters.clearcoatMapUv);
        array.push(parameters.clearcoatNormalMapUv);
        array.push(parameters.clearcoatRoughnessMapUv);
        array.push(parameters.iridescenceMapUv);
        array.push(parameters.iridescenceThicknessMapUv);
        array.push(parameters.sheenColorMapUv);
        array.push(parameters.sheenRoughnessMapUv);
        array.push(parameters.specularMapUv);
        array.push(parameters.specularColorMapUv);
        array.push(parameters.specularIntensityMapUv);
        array.push(parameters.transmissionMapUv);
        array.push(parameters.thicknessMapUv);
        array.push(parameters.combine);
        array.push(parameters.fogExp2);
        array.push(parameters.sizeAttenuation);
        array.push(parameters.morphTargetsCount);
        array.push(parameters.morphAttributeCount);
        array.push(parameters.numDirLights);
        array.push(parameters.numPointLights);
        array.push(parameters.numSpotLights);
        array.push(parameters.numSpotLightMaps);
        array.push(parameters.numHemiLights);
        array.push(parameters.numRectAreaLights);
        array.push(parameters.numDirLightShadows);
        array.push(parameters.numPointLightShadows);
        array.push(parameters.numSpotLightShadows);
        array.push(parameters.numSpotLightShadowsWithMaps);
        array.push(parameters.numLightProbes);
        array.push(parameters.shadowMapType);
        array.push(parameters.toneMapping);
        array.push(parameters.numClippingPlanes);
        array.push(parameters.numClipIntersection);
        array.push(parameters.depthPacking);
    }
    function getProgramCacheKeyBooleans(array, parameters) {
        _programLayers.disableAll();
        if (parameters.supportsVertexTextures) _programLayers.enable(0);
        if (parameters.instancing) _programLayers.enable(1);
        if (parameters.instancingColor) _programLayers.enable(2);
        if (parameters.instancingMorph) _programLayers.enable(3);
        if (parameters.matcap) _programLayers.enable(4);
        if (parameters.envMap) _programLayers.enable(5);
        if (parameters.normalMapObjectSpace) _programLayers.enable(6);
        if (parameters.normalMapTangentSpace) _programLayers.enable(7);
        if (parameters.clearcoat) _programLayers.enable(8);
        if (parameters.iridescence) _programLayers.enable(9);
        if (parameters.alphaTest) _programLayers.enable(10);
        if (parameters.vertexColors) _programLayers.enable(11);
        if (parameters.vertexAlphas) _programLayers.enable(12);
        if (parameters.vertexUv1s) _programLayers.enable(13);
        if (parameters.vertexUv2s) _programLayers.enable(14);
        if (parameters.vertexUv3s) _programLayers.enable(15);
        if (parameters.vertexTangents) _programLayers.enable(16);
        if (parameters.anisotropy) _programLayers.enable(17);
        if (parameters.alphaHash) _programLayers.enable(18);
        if (parameters.batching) _programLayers.enable(19);
        if (parameters.dispersion) _programLayers.enable(20);
        if (parameters.batchingColor) _programLayers.enable(21);
        array.push(_programLayers.mask);
        _programLayers.disableAll();
        if (parameters.fog) _programLayers.enable(0);
        if (parameters.useFog) _programLayers.enable(1);
        if (parameters.flatShading) _programLayers.enable(2);
        if (parameters.logarithmicDepthBuffer) _programLayers.enable(3);
        if (parameters.skinning) _programLayers.enable(4);
        if (parameters.morphTargets) _programLayers.enable(5);
        if (parameters.morphNormals) _programLayers.enable(6);
        if (parameters.morphColors) _programLayers.enable(7);
        if (parameters.premultipliedAlpha) _programLayers.enable(8);
        if (parameters.shadowMapEnabled) _programLayers.enable(9);
        if (parameters.doubleSided) _programLayers.enable(10);
        if (parameters.flipSided) _programLayers.enable(11);
        if (parameters.useDepthPacking) _programLayers.enable(12);
        if (parameters.dithering) _programLayers.enable(13);
        if (parameters.transmission) _programLayers.enable(14);
        if (parameters.sheen) _programLayers.enable(15);
        if (parameters.opaque) _programLayers.enable(16);
        if (parameters.pointsUvs) _programLayers.enable(17);
        if (parameters.decodeVideoTexture) _programLayers.enable(18);
        if (parameters.alphaToCoverage) _programLayers.enable(19);
        array.push(_programLayers.mask);
    }
    function getUniforms(material) {
        const shaderID = shaderIDs[material.type];
        let uniforms;
        if (shaderID) {
            const shader = ShaderLib[shaderID];
            uniforms = UniformsUtils.clone(shader.uniforms);
        } else uniforms = material.uniforms;
        return uniforms;
    }
    function acquireProgram(parameters, cacheKey) {
        let program;
        // Check if code has been already compiled
        for(let p = 0, pl = programs.length; p < pl; p++){
            const preexistingProgram = programs[p];
            if (preexistingProgram.cacheKey === cacheKey) {
                program = preexistingProgram;
                ++program.usedTimes;
                break;
            }
        }
        if (program === undefined) {
            program = new WebGLProgram(renderer, cacheKey, parameters, bindingStates);
            programs.push(program);
        }
        return program;
    }
    function releaseProgram(program) {
        if (--program.usedTimes === 0) {
            // Remove from unordered set
            const i = programs.indexOf(program);
            programs[i] = programs[programs.length - 1];
            programs.pop();
            // Free WebGL resources
            program.destroy();
        }
    }
    function releaseShaderCache(material) {
        _customShaders.remove(material);
    }
    function dispose() {
        _customShaders.dispose();
    }
    return {
        getParameters: getParameters,
        getProgramCacheKey: getProgramCacheKey,
        getUniforms: getUniforms,
        acquireProgram: acquireProgram,
        releaseProgram: releaseProgram,
        releaseShaderCache: releaseShaderCache,
        // Exposed for resource monitoring & error feedback via renderer.info:
        programs: programs,
        dispose: dispose
    };
}
function WebGLProperties() {
    let properties = new WeakMap();
    function get(object) {
        let map = properties.get(object);
        if (map === undefined) {
            map = {};
            properties.set(object, map);
        }
        return map;
    }
    function remove(object) {
        properties.delete(object);
    }
    function update(object, key, value) {
        properties.get(object)[key] = value;
    }
    function dispose() {
        properties = new WeakMap();
    }
    return {
        get: get,
        remove: remove,
        update: update,
        dispose: dispose
    };
}
function painterSortStable(a, b) {
    if (a.groupOrder !== b.groupOrder) return a.groupOrder - b.groupOrder;
    else if (a.renderOrder !== b.renderOrder) return a.renderOrder - b.renderOrder;
    else if (a.material.id !== b.material.id) return a.material.id - b.material.id;
    else if (a.z !== b.z) return a.z - b.z;
    else return a.id - b.id;
}
function reversePainterSortStable(a, b) {
    if (a.groupOrder !== b.groupOrder) return a.groupOrder - b.groupOrder;
    else if (a.renderOrder !== b.renderOrder) return a.renderOrder - b.renderOrder;
    else if (a.z !== b.z) return b.z - a.z;
    else return a.id - b.id;
}
function WebGLRenderList() {
    const renderItems = [];
    let renderItemsIndex = 0;
    const opaque = [];
    const transmissive = [];
    const transparent = [];
    function init() {
        renderItemsIndex = 0;
        opaque.length = 0;
        transmissive.length = 0;
        transparent.length = 0;
    }
    function getNextRenderItem(object, geometry, material, groupOrder, z, group) {
        let renderItem = renderItems[renderItemsIndex];
        if (renderItem === undefined) {
            renderItem = {
                id: object.id,
                object: object,
                geometry: geometry,
                material: material,
                groupOrder: groupOrder,
                renderOrder: object.renderOrder,
                z: z,
                group: group
            };
            renderItems[renderItemsIndex] = renderItem;
        } else {
            renderItem.id = object.id;
            renderItem.object = object;
            renderItem.geometry = geometry;
            renderItem.material = material;
            renderItem.groupOrder = groupOrder;
            renderItem.renderOrder = object.renderOrder;
            renderItem.z = z;
            renderItem.group = group;
        }
        renderItemsIndex++;
        return renderItem;
    }
    function push(object, geometry, material, groupOrder, z, group) {
        const renderItem = getNextRenderItem(object, geometry, material, groupOrder, z, group);
        if (material.transmission > 0.0) transmissive.push(renderItem);
        else if (material.transparent === true) transparent.push(renderItem);
        else opaque.push(renderItem);
    }
    function unshift(object, geometry, material, groupOrder, z, group) {
        const renderItem = getNextRenderItem(object, geometry, material, groupOrder, z, group);
        if (material.transmission > 0.0) transmissive.unshift(renderItem);
        else if (material.transparent === true) transparent.unshift(renderItem);
        else opaque.unshift(renderItem);
    }
    function sort(customOpaqueSort, customTransparentSort) {
        if (opaque.length > 1) opaque.sort(customOpaqueSort || painterSortStable);
        if (transmissive.length > 1) transmissive.sort(customTransparentSort || reversePainterSortStable);
        if (transparent.length > 1) transparent.sort(customTransparentSort || reversePainterSortStable);
    }
    function finish() {
        // Clear references from inactive renderItems in the list
        for(let i = renderItemsIndex, il = renderItems.length; i < il; i++){
            const renderItem = renderItems[i];
            if (renderItem.id === null) break;
            renderItem.id = null;
            renderItem.object = null;
            renderItem.geometry = null;
            renderItem.material = null;
            renderItem.group = null;
        }
    }
    return {
        opaque: opaque,
        transmissive: transmissive,
        transparent: transparent,
        init: init,
        push: push,
        unshift: unshift,
        finish: finish,
        sort: sort
    };
}
function WebGLRenderLists() {
    let lists = new WeakMap();
    function get(scene, renderCallDepth) {
        const listArray = lists.get(scene);
        let list;
        if (listArray === undefined) {
            list = new WebGLRenderList();
            lists.set(scene, [
                list
            ]);
        } else if (renderCallDepth >= listArray.length) {
            list = new WebGLRenderList();
            listArray.push(list);
        } else list = listArray[renderCallDepth];
        return list;
    }
    function dispose() {
        lists = new WeakMap();
    }
    return {
        get: get,
        dispose: dispose
    };
}
function UniformsCache() {
    const lights = {};
    return {
        get: function(light) {
            if (lights[light.id] !== undefined) return lights[light.id];
            let uniforms;
            switch(light.type){
                case "DirectionalLight":
                    uniforms = {
                        direction: new Vector3(),
                        color: new Color()
                    };
                    break;
                case "SpotLight":
                    uniforms = {
                        position: new Vector3(),
                        direction: new Vector3(),
                        color: new Color(),
                        distance: 0,
                        coneCos: 0,
                        penumbraCos: 0,
                        decay: 0
                    };
                    break;
                case "PointLight":
                    uniforms = {
                        position: new Vector3(),
                        color: new Color(),
                        distance: 0,
                        decay: 0
                    };
                    break;
                case "HemisphereLight":
                    uniforms = {
                        direction: new Vector3(),
                        skyColor: new Color(),
                        groundColor: new Color()
                    };
                    break;
                case "RectAreaLight":
                    uniforms = {
                        color: new Color(),
                        position: new Vector3(),
                        halfWidth: new Vector3(),
                        halfHeight: new Vector3()
                    };
                    break;
            }
            lights[light.id] = uniforms;
            return uniforms;
        }
    };
}
function ShadowUniformsCache() {
    const lights = {};
    return {
        get: function(light) {
            if (lights[light.id] !== undefined) return lights[light.id];
            let uniforms;
            switch(light.type){
                case "DirectionalLight":
                    uniforms = {
                        shadowIntensity: 1,
                        shadowBias: 0,
                        shadowNormalBias: 0,
                        shadowRadius: 1,
                        shadowMapSize: new Vector2()
                    };
                    break;
                case "SpotLight":
                    uniforms = {
                        shadowIntensity: 1,
                        shadowBias: 0,
                        shadowNormalBias: 0,
                        shadowRadius: 1,
                        shadowMapSize: new Vector2()
                    };
                    break;
                case "PointLight":
                    uniforms = {
                        shadowIntensity: 1,
                        shadowBias: 0,
                        shadowNormalBias: 0,
                        shadowRadius: 1,
                        shadowMapSize: new Vector2(),
                        shadowCameraNear: 1,
                        shadowCameraFar: 1000
                    };
                    break;
            }
            lights[light.id] = uniforms;
            return uniforms;
        }
    };
}
let nextVersion = 0;
function shadowCastingAndTexturingLightsFirst(lightA, lightB) {
    return (lightB.castShadow ? 2 : 0) - (lightA.castShadow ? 2 : 0) + (lightB.map ? 1 : 0) - (lightA.map ? 1 : 0);
}
function WebGLLights(extensions) {
    const cache = new UniformsCache();
    const shadowCache = ShadowUniformsCache();
    const state = {
        version: 0,
        hash: {
            directionalLength: -1,
            pointLength: -1,
            spotLength: -1,
            rectAreaLength: -1,
            hemiLength: -1,
            numDirectionalShadows: -1,
            numPointShadows: -1,
            numSpotShadows: -1,
            numSpotMaps: -1,
            numLightProbes: -1
        },
        ambient: [
            0,
            0,
            0
        ],
        probe: [],
        directional: [],
        directionalShadow: [],
        directionalShadowMap: [],
        directionalShadowMatrix: [],
        spot: [],
        spotLightMap: [],
        spotShadow: [],
        spotShadowMap: [],
        spotLightMatrix: [],
        rectArea: [],
        rectAreaLTC1: null,
        rectAreaLTC2: null,
        point: [],
        pointShadow: [],
        pointShadowMap: [],
        pointShadowMatrix: [],
        hemi: [],
        numSpotLightShadowsWithMaps: 0,
        numLightProbes: 0
    };
    for(let i = 0; i < 9; i++)state.probe.push(new Vector3());
    const vector3 = new Vector3();
    const matrix4 = new Matrix4();
    const matrix42 = new Matrix4();
    function setup(lights) {
        let r = 0, g = 0, b = 0;
        for(let i = 0; i < 9; i++)state.probe[i].set(0, 0, 0);
        let directionalLength = 0;
        let pointLength = 0;
        let spotLength = 0;
        let rectAreaLength = 0;
        let hemiLength = 0;
        let numDirectionalShadows = 0;
        let numPointShadows = 0;
        let numSpotShadows = 0;
        let numSpotMaps = 0;
        let numSpotShadowsWithMaps = 0;
        let numLightProbes = 0;
        // ordering : [shadow casting + map texturing, map texturing, shadow casting, none ]
        lights.sort(shadowCastingAndTexturingLightsFirst);
        for(let i = 0, l = lights.length; i < l; i++){
            const light = lights[i];
            const color = light.color;
            const intensity = light.intensity;
            const distance = light.distance;
            const shadowMap = light.shadow && light.shadow.map ? light.shadow.map.texture : null;
            if (light.isAmbientLight) {
                r += color.r * intensity;
                g += color.g * intensity;
                b += color.b * intensity;
            } else if (light.isLightProbe) {
                for(let j = 0; j < 9; j++)state.probe[j].addScaledVector(light.sh.coefficients[j], intensity);
                numLightProbes++;
            } else if (light.isDirectionalLight) {
                const uniforms = cache.get(light);
                uniforms.color.copy(light.color).multiplyScalar(light.intensity);
                if (light.castShadow) {
                    const shadow = light.shadow;
                    const shadowUniforms = shadowCache.get(light);
                    shadowUniforms.shadowIntensity = shadow.intensity;
                    shadowUniforms.shadowBias = shadow.bias;
                    shadowUniforms.shadowNormalBias = shadow.normalBias;
                    shadowUniforms.shadowRadius = shadow.radius;
                    shadowUniforms.shadowMapSize = shadow.mapSize;
                    state.directionalShadow[directionalLength] = shadowUniforms;
                    state.directionalShadowMap[directionalLength] = shadowMap;
                    state.directionalShadowMatrix[directionalLength] = light.shadow.matrix;
                    numDirectionalShadows++;
                }
                state.directional[directionalLength] = uniforms;
                directionalLength++;
            } else if (light.isSpotLight) {
                const uniforms = cache.get(light);
                uniforms.position.setFromMatrixPosition(light.matrixWorld);
                uniforms.color.copy(color).multiplyScalar(intensity);
                uniforms.distance = distance;
                uniforms.coneCos = Math.cos(light.angle);
                uniforms.penumbraCos = Math.cos(light.angle * (1 - light.penumbra));
                uniforms.decay = light.decay;
                state.spot[spotLength] = uniforms;
                const shadow = light.shadow;
                if (light.map) {
                    state.spotLightMap[numSpotMaps] = light.map;
                    numSpotMaps++;
                    // make sure the lightMatrix is up to date
                    // TODO : do it if required only
                    shadow.updateMatrices(light);
                    if (light.castShadow) numSpotShadowsWithMaps++;
                }
                state.spotLightMatrix[spotLength] = shadow.matrix;
                if (light.castShadow) {
                    const shadowUniforms = shadowCache.get(light);
                    shadowUniforms.shadowIntensity = shadow.intensity;
                    shadowUniforms.shadowBias = shadow.bias;
                    shadowUniforms.shadowNormalBias = shadow.normalBias;
                    shadowUniforms.shadowRadius = shadow.radius;
                    shadowUniforms.shadowMapSize = shadow.mapSize;
                    state.spotShadow[spotLength] = shadowUniforms;
                    state.spotShadowMap[spotLength] = shadowMap;
                    numSpotShadows++;
                }
                spotLength++;
            } else if (light.isRectAreaLight) {
                const uniforms = cache.get(light);
                uniforms.color.copy(color).multiplyScalar(intensity);
                uniforms.halfWidth.set(light.width * 0.5, 0.0, 0.0);
                uniforms.halfHeight.set(0.0, light.height * 0.5, 0.0);
                state.rectArea[rectAreaLength] = uniforms;
                rectAreaLength++;
            } else if (light.isPointLight) {
                const uniforms = cache.get(light);
                uniforms.color.copy(light.color).multiplyScalar(light.intensity);
                uniforms.distance = light.distance;
                uniforms.decay = light.decay;
                if (light.castShadow) {
                    const shadow = light.shadow;
                    const shadowUniforms = shadowCache.get(light);
                    shadowUniforms.shadowIntensity = shadow.intensity;
                    shadowUniforms.shadowBias = shadow.bias;
                    shadowUniforms.shadowNormalBias = shadow.normalBias;
                    shadowUniforms.shadowRadius = shadow.radius;
                    shadowUniforms.shadowMapSize = shadow.mapSize;
                    shadowUniforms.shadowCameraNear = shadow.camera.near;
                    shadowUniforms.shadowCameraFar = shadow.camera.far;
                    state.pointShadow[pointLength] = shadowUniforms;
                    state.pointShadowMap[pointLength] = shadowMap;
                    state.pointShadowMatrix[pointLength] = light.shadow.matrix;
                    numPointShadows++;
                }
                state.point[pointLength] = uniforms;
                pointLength++;
            } else if (light.isHemisphereLight) {
                const uniforms = cache.get(light);
                uniforms.skyColor.copy(light.color).multiplyScalar(intensity);
                uniforms.groundColor.copy(light.groundColor).multiplyScalar(intensity);
                state.hemi[hemiLength] = uniforms;
                hemiLength++;
            }
        }
        if (rectAreaLength > 0) {
            if (extensions.has("OES_texture_float_linear") === true) {
                state.rectAreaLTC1 = UniformsLib.LTC_FLOAT_1;
                state.rectAreaLTC2 = UniformsLib.LTC_FLOAT_2;
            } else {
                state.rectAreaLTC1 = UniformsLib.LTC_HALF_1;
                state.rectAreaLTC2 = UniformsLib.LTC_HALF_2;
            }
        }
        state.ambient[0] = r;
        state.ambient[1] = g;
        state.ambient[2] = b;
        const hash = state.hash;
        if (hash.directionalLength !== directionalLength || hash.pointLength !== pointLength || hash.spotLength !== spotLength || hash.rectAreaLength !== rectAreaLength || hash.hemiLength !== hemiLength || hash.numDirectionalShadows !== numDirectionalShadows || hash.numPointShadows !== numPointShadows || hash.numSpotShadows !== numSpotShadows || hash.numSpotMaps !== numSpotMaps || hash.numLightProbes !== numLightProbes) {
            state.directional.length = directionalLength;
            state.spot.length = spotLength;
            state.rectArea.length = rectAreaLength;
            state.point.length = pointLength;
            state.hemi.length = hemiLength;
            state.directionalShadow.length = numDirectionalShadows;
            state.directionalShadowMap.length = numDirectionalShadows;
            state.pointShadow.length = numPointShadows;
            state.pointShadowMap.length = numPointShadows;
            state.spotShadow.length = numSpotShadows;
            state.spotShadowMap.length = numSpotShadows;
            state.directionalShadowMatrix.length = numDirectionalShadows;
            state.pointShadowMatrix.length = numPointShadows;
            state.spotLightMatrix.length = numSpotShadows + numSpotMaps - numSpotShadowsWithMaps;
            state.spotLightMap.length = numSpotMaps;
            state.numSpotLightShadowsWithMaps = numSpotShadowsWithMaps;
            state.numLightProbes = numLightProbes;
            hash.directionalLength = directionalLength;
            hash.pointLength = pointLength;
            hash.spotLength = spotLength;
            hash.rectAreaLength = rectAreaLength;
            hash.hemiLength = hemiLength;
            hash.numDirectionalShadows = numDirectionalShadows;
            hash.numPointShadows = numPointShadows;
            hash.numSpotShadows = numSpotShadows;
            hash.numSpotMaps = numSpotMaps;
            hash.numLightProbes = numLightProbes;
            state.version = nextVersion++;
        }
    }
    function setupView(lights, camera) {
        let directionalLength = 0;
        let pointLength = 0;
        let spotLength = 0;
        let rectAreaLength = 0;
        let hemiLength = 0;
        const viewMatrix = camera.matrixWorldInverse;
        for(let i = 0, l = lights.length; i < l; i++){
            const light = lights[i];
            if (light.isDirectionalLight) {
                const uniforms = state.directional[directionalLength];
                uniforms.direction.setFromMatrixPosition(light.matrixWorld);
                vector3.setFromMatrixPosition(light.target.matrixWorld);
                uniforms.direction.sub(vector3);
                uniforms.direction.transformDirection(viewMatrix);
                directionalLength++;
            } else if (light.isSpotLight) {
                const uniforms = state.spot[spotLength];
                uniforms.position.setFromMatrixPosition(light.matrixWorld);
                uniforms.position.applyMatrix4(viewMatrix);
                uniforms.direction.setFromMatrixPosition(light.matrixWorld);
                vector3.setFromMatrixPosition(light.target.matrixWorld);
                uniforms.direction.sub(vector3);
                uniforms.direction.transformDirection(viewMatrix);
                spotLength++;
            } else if (light.isRectAreaLight) {
                const uniforms = state.rectArea[rectAreaLength];
                uniforms.position.setFromMatrixPosition(light.matrixWorld);
                uniforms.position.applyMatrix4(viewMatrix);
                // extract local rotation of light to derive width/height half vectors
                matrix42.identity();
                matrix4.copy(light.matrixWorld);
                matrix4.premultiply(viewMatrix);
                matrix42.extractRotation(matrix4);
                uniforms.halfWidth.set(light.width * 0.5, 0.0, 0.0);
                uniforms.halfHeight.set(0.0, light.height * 0.5, 0.0);
                uniforms.halfWidth.applyMatrix4(matrix42);
                uniforms.halfHeight.applyMatrix4(matrix42);
                rectAreaLength++;
            } else if (light.isPointLight) {
                const uniforms = state.point[pointLength];
                uniforms.position.setFromMatrixPosition(light.matrixWorld);
                uniforms.position.applyMatrix4(viewMatrix);
                pointLength++;
            } else if (light.isHemisphereLight) {
                const uniforms = state.hemi[hemiLength];
                uniforms.direction.setFromMatrixPosition(light.matrixWorld);
                uniforms.direction.transformDirection(viewMatrix);
                hemiLength++;
            }
        }
    }
    return {
        setup: setup,
        setupView: setupView,
        state: state
    };
}
function WebGLRenderState(extensions) {
    const lights = new WebGLLights(extensions);
    const lightsArray = [];
    const shadowsArray = [];
    function init(camera) {
        state.camera = camera;
        lightsArray.length = 0;
        shadowsArray.length = 0;
    }
    function pushLight(light) {
        lightsArray.push(light);
    }
    function pushShadow(shadowLight) {
        shadowsArray.push(shadowLight);
    }
    function setupLights() {
        lights.setup(lightsArray);
    }
    function setupLightsView(camera) {
        lights.setupView(lightsArray, camera);
    }
    const state = {
        lightsArray: lightsArray,
        shadowsArray: shadowsArray,
        camera: null,
        lights: lights,
        transmissionRenderTarget: {}
    };
    return {
        init: init,
        state: state,
        setupLights: setupLights,
        setupLightsView: setupLightsView,
        pushLight: pushLight,
        pushShadow: pushShadow
    };
}
function WebGLRenderStates(extensions) {
    let renderStates = new WeakMap();
    function get(scene, renderCallDepth = 0) {
        const renderStateArray = renderStates.get(scene);
        let renderState;
        if (renderStateArray === undefined) {
            renderState = new WebGLRenderState(extensions);
            renderStates.set(scene, [
                renderState
            ]);
        } else if (renderCallDepth >= renderStateArray.length) {
            renderState = new WebGLRenderState(extensions);
            renderStateArray.push(renderState);
        } else renderState = renderStateArray[renderCallDepth];
        return renderState;
    }
    function dispose() {
        renderStates = new WeakMap();
    }
    return {
        get: get,
        dispose: dispose
    };
}
class MeshDepthMaterial extends Material {
    constructor(parameters){
        super();
        this.isMeshDepthMaterial = true;
        this.type = "MeshDepthMaterial";
        this.depthPacking = BasicDepthPacking;
        this.map = null;
        this.alphaMap = null;
        this.displacementMap = null;
        this.displacementScale = 1;
        this.displacementBias = 0;
        this.wireframe = false;
        this.wireframeLinewidth = 1;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.depthPacking = source.depthPacking;
        this.map = source.map;
        this.alphaMap = source.alphaMap;
        this.displacementMap = source.displacementMap;
        this.displacementScale = source.displacementScale;
        this.displacementBias = source.displacementBias;
        this.wireframe = source.wireframe;
        this.wireframeLinewidth = source.wireframeLinewidth;
        return this;
    }
}
class MeshDistanceMaterial extends Material {
    constructor(parameters){
        super();
        this.isMeshDistanceMaterial = true;
        this.type = "MeshDistanceMaterial";
        this.map = null;
        this.alphaMap = null;
        this.displacementMap = null;
        this.displacementScale = 1;
        this.displacementBias = 0;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.map = source.map;
        this.alphaMap = source.alphaMap;
        this.displacementMap = source.displacementMap;
        this.displacementScale = source.displacementScale;
        this.displacementBias = source.displacementBias;
        return this;
    }
}
const vertex = "void main() {\n	gl_Position = vec4( position, 1.0 );\n}";
const fragment = "uniform sampler2D shadow_pass;\nuniform vec2 resolution;\nuniform float radius;\n#include <packing>\nvoid main() {\n	const float samples = float( VSM_SAMPLES );\n	float mean = 0.0;\n	float squared_mean = 0.0;\n	float uvStride = samples <= 1.0 ? 0.0 : 2.0 / ( samples - 1.0 );\n	float uvStart = samples <= 1.0 ? 0.0 : - 1.0;\n	for ( float i = 0.0; i < samples; i ++ ) {\n		float uvOffset = uvStart + i * uvStride;\n		#ifdef HORIZONTAL_PASS\n			vec2 distribution = unpackRGBATo2Half( texture2D( shadow_pass, ( gl_FragCoord.xy + vec2( uvOffset, 0.0 ) * radius ) / resolution ) );\n			mean += distribution.x;\n			squared_mean += distribution.y * distribution.y + distribution.x * distribution.x;\n		#else\n			float depth = unpackRGBAToDepth( texture2D( shadow_pass, ( gl_FragCoord.xy + vec2( 0.0, uvOffset ) * radius ) / resolution ) );\n			mean += depth;\n			squared_mean += depth * depth;\n		#endif\n	}\n	mean = mean / samples;\n	squared_mean = squared_mean / samples;\n	float std_dev = sqrt( squared_mean - mean * mean );\n	gl_FragColor = pack2HalfToRGBA( vec2( mean, std_dev ) );\n}";
function WebGLShadowMap(renderer, objects, capabilities) {
    let _frustum = new Frustum();
    const _shadowMapSize = new Vector2(), _viewportSize = new Vector2(), _viewport = new Vector4(), _depthMaterial = new MeshDepthMaterial({
        depthPacking: RGBADepthPacking
    }), _distanceMaterial = new MeshDistanceMaterial(), _materialCache = {}, _maxTextureSize = capabilities.maxTextureSize;
    const shadowSide = {
        [FrontSide]: BackSide,
        [BackSide]: FrontSide,
        [DoubleSide]: DoubleSide
    };
    const shadowMaterialVertical = new ShaderMaterial({
        defines: {
            VSM_SAMPLES: 8
        },
        uniforms: {
            shadow_pass: {
                value: null
            },
            resolution: {
                value: new Vector2()
            },
            radius: {
                value: 4.0
            }
        },
        vertexShader: vertex,
        fragmentShader: fragment
    });
    const shadowMaterialHorizontal = shadowMaterialVertical.clone();
    shadowMaterialHorizontal.defines.HORIZONTAL_PASS = 1;
    const fullScreenTri = new BufferGeometry();
    fullScreenTri.setAttribute("position", new BufferAttribute(new Float32Array([
        -1,
        -1,
        0.5,
        3,
        -1,
        0.5,
        -1,
        3,
        0.5
    ]), 3));
    const fullScreenMesh = new Mesh(fullScreenTri, shadowMaterialVertical);
    const scope = this;
    this.enabled = false;
    this.autoUpdate = true;
    this.needsUpdate = false;
    this.type = PCFShadowMap;
    let _previousType = this.type;
    this.render = function(lights, scene, camera) {
        if (scope.enabled === false) return;
        if (scope.autoUpdate === false && scope.needsUpdate === false) return;
        if (lights.length === 0) return;
        const currentRenderTarget = renderer.getRenderTarget();
        const activeCubeFace = renderer.getActiveCubeFace();
        const activeMipmapLevel = renderer.getActiveMipmapLevel();
        const _state = renderer.state;
        // Set GL state for depth map.
        _state.setBlending(NoBlending);
        _state.buffers.color.setClear(1, 1, 1, 1);
        _state.buffers.depth.setTest(true);
        _state.setScissorTest(false);
        // check for shadow map type changes
        const toVSM = _previousType !== VSMShadowMap && this.type === VSMShadowMap;
        const fromVSM = _previousType === VSMShadowMap && this.type !== VSMShadowMap;
        // render depth map
        for(let i = 0, il = lights.length; i < il; i++){
            const light = lights[i];
            const shadow = light.shadow;
            if (shadow === undefined) {
                console.warn("THREE.WebGLShadowMap:", light, "has no shadow.");
                continue;
            }
            if (shadow.autoUpdate === false && shadow.needsUpdate === false) continue;
            _shadowMapSize.copy(shadow.mapSize);
            const shadowFrameExtents = shadow.getFrameExtents();
            _shadowMapSize.multiply(shadowFrameExtents);
            _viewportSize.copy(shadow.mapSize);
            if (_shadowMapSize.x > _maxTextureSize || _shadowMapSize.y > _maxTextureSize) {
                if (_shadowMapSize.x > _maxTextureSize) {
                    _viewportSize.x = Math.floor(_maxTextureSize / shadowFrameExtents.x);
                    _shadowMapSize.x = _viewportSize.x * shadowFrameExtents.x;
                    shadow.mapSize.x = _viewportSize.x;
                }
                if (_shadowMapSize.y > _maxTextureSize) {
                    _viewportSize.y = Math.floor(_maxTextureSize / shadowFrameExtents.y);
                    _shadowMapSize.y = _viewportSize.y * shadowFrameExtents.y;
                    shadow.mapSize.y = _viewportSize.y;
                }
            }
            if (shadow.map === null || toVSM === true || fromVSM === true) {
                const pars = this.type !== VSMShadowMap ? {
                    minFilter: NearestFilter,
                    magFilter: NearestFilter
                } : {};
                if (shadow.map !== null) shadow.map.dispose();
                shadow.map = new WebGLRenderTarget(_shadowMapSize.x, _shadowMapSize.y, pars);
                shadow.map.texture.name = light.name + ".shadowMap";
                shadow.camera.updateProjectionMatrix();
            }
            renderer.setRenderTarget(shadow.map);
            renderer.clear();
            const viewportCount = shadow.getViewportCount();
            for(let vp = 0; vp < viewportCount; vp++){
                const viewport = shadow.getViewport(vp);
                _viewport.set(_viewportSize.x * viewport.x, _viewportSize.y * viewport.y, _viewportSize.x * viewport.z, _viewportSize.y * viewport.w);
                _state.viewport(_viewport);
                shadow.updateMatrices(light, vp);
                _frustum = shadow.getFrustum();
                renderObject(scene, camera, shadow.camera, light, this.type);
            }
            // do blur pass for VSM
            if (shadow.isPointLightShadow !== true && this.type === VSMShadowMap) VSMPass(shadow, camera);
            shadow.needsUpdate = false;
        }
        _previousType = this.type;
        scope.needsUpdate = false;
        renderer.setRenderTarget(currentRenderTarget, activeCubeFace, activeMipmapLevel);
    };
    function VSMPass(shadow, camera) {
        const geometry = objects.update(fullScreenMesh);
        if (shadowMaterialVertical.defines.VSM_SAMPLES !== shadow.blurSamples) {
            shadowMaterialVertical.defines.VSM_SAMPLES = shadow.blurSamples;
            shadowMaterialHorizontal.defines.VSM_SAMPLES = shadow.blurSamples;
            shadowMaterialVertical.needsUpdate = true;
            shadowMaterialHorizontal.needsUpdate = true;
        }
        if (shadow.mapPass === null) shadow.mapPass = new WebGLRenderTarget(_shadowMapSize.x, _shadowMapSize.y);
        // vertical pass
        shadowMaterialVertical.uniforms.shadow_pass.value = shadow.map.texture;
        shadowMaterialVertical.uniforms.resolution.value = shadow.mapSize;
        shadowMaterialVertical.uniforms.radius.value = shadow.radius;
        renderer.setRenderTarget(shadow.mapPass);
        renderer.clear();
        renderer.renderBufferDirect(camera, null, geometry, shadowMaterialVertical, fullScreenMesh, null);
        // horizontal pass
        shadowMaterialHorizontal.uniforms.shadow_pass.value = shadow.mapPass.texture;
        shadowMaterialHorizontal.uniforms.resolution.value = shadow.mapSize;
        shadowMaterialHorizontal.uniforms.radius.value = shadow.radius;
        renderer.setRenderTarget(shadow.map);
        renderer.clear();
        renderer.renderBufferDirect(camera, null, geometry, shadowMaterialHorizontal, fullScreenMesh, null);
    }
    function getDepthMaterial(object, material, light, type) {
        let result = null;
        const customMaterial = light.isPointLight === true ? object.customDistanceMaterial : object.customDepthMaterial;
        if (customMaterial !== undefined) result = customMaterial;
        else {
            result = light.isPointLight === true ? _distanceMaterial : _depthMaterial;
            if (renderer.localClippingEnabled && material.clipShadows === true && Array.isArray(material.clippingPlanes) && material.clippingPlanes.length !== 0 || material.displacementMap && material.displacementScale !== 0 || material.alphaMap && material.alphaTest > 0 || material.map && material.alphaTest > 0) {
                // in this case we need a unique material instance reflecting the
                // appropriate state
                const keyA = result.uuid, keyB = material.uuid;
                let materialsForVariant = _materialCache[keyA];
                if (materialsForVariant === undefined) {
                    materialsForVariant = {};
                    _materialCache[keyA] = materialsForVariant;
                }
                let cachedMaterial = materialsForVariant[keyB];
                if (cachedMaterial === undefined) {
                    cachedMaterial = result.clone();
                    materialsForVariant[keyB] = cachedMaterial;
                    material.addEventListener("dispose", onMaterialDispose);
                }
                result = cachedMaterial;
            }
        }
        result.visible = material.visible;
        result.wireframe = material.wireframe;
        if (type === VSMShadowMap) result.side = material.shadowSide !== null ? material.shadowSide : material.side;
        else result.side = material.shadowSide !== null ? material.shadowSide : shadowSide[material.side];
        result.alphaMap = material.alphaMap;
        result.alphaTest = material.alphaTest;
        result.map = material.map;
        result.clipShadows = material.clipShadows;
        result.clippingPlanes = material.clippingPlanes;
        result.clipIntersection = material.clipIntersection;
        result.displacementMap = material.displacementMap;
        result.displacementScale = material.displacementScale;
        result.displacementBias = material.displacementBias;
        result.wireframeLinewidth = material.wireframeLinewidth;
        result.linewidth = material.linewidth;
        if (light.isPointLight === true && result.isMeshDistanceMaterial === true) {
            const materialProperties = renderer.properties.get(result);
            materialProperties.light = light;
        }
        return result;
    }
    function renderObject(object, camera, shadowCamera, light, type) {
        if (object.visible === false) return;
        const visible = object.layers.test(camera.layers);
        if (visible && (object.isMesh || object.isLine || object.isPoints)) {
            if ((object.castShadow || object.receiveShadow && type === VSMShadowMap) && (!object.frustumCulled || _frustum.intersectsObject(object))) {
                object.modelViewMatrix.multiplyMatrices(shadowCamera.matrixWorldInverse, object.matrixWorld);
                const geometry = objects.update(object);
                const material = object.material;
                if (Array.isArray(material)) {
                    const groups = geometry.groups;
                    for(let k = 0, kl = groups.length; k < kl; k++){
                        const group = groups[k];
                        const groupMaterial = material[group.materialIndex];
                        if (groupMaterial && groupMaterial.visible) {
                            const depthMaterial = getDepthMaterial(object, groupMaterial, light, type);
                            object.onBeforeShadow(renderer, object, camera, shadowCamera, geometry, depthMaterial, group);
                            renderer.renderBufferDirect(shadowCamera, null, geometry, depthMaterial, object, group);
                            object.onAfterShadow(renderer, object, camera, shadowCamera, geometry, depthMaterial, group);
                        }
                    }
                } else if (material.visible) {
                    const depthMaterial = getDepthMaterial(object, material, light, type);
                    object.onBeforeShadow(renderer, object, camera, shadowCamera, geometry, depthMaterial, null);
                    renderer.renderBufferDirect(shadowCamera, null, geometry, depthMaterial, object, null);
                    object.onAfterShadow(renderer, object, camera, shadowCamera, geometry, depthMaterial, null);
                }
            }
        }
        const children = object.children;
        for(let i = 0, l = children.length; i < l; i++)renderObject(children[i], camera, shadowCamera, light, type);
    }
    function onMaterialDispose(event) {
        const material = event.target;
        material.removeEventListener("dispose", onMaterialDispose);
        // make sure to remove the unique distance/depth materials used for shadow map rendering
        for(const id in _materialCache){
            const cache = _materialCache[id];
            const uuid = event.target.uuid;
            if (uuid in cache) {
                const shadowMaterial = cache[uuid];
                shadowMaterial.dispose();
                delete cache[uuid];
            }
        }
    }
}
function WebGLState(gl) {
    function ColorBuffer() {
        let locked = false;
        const color = new Vector4();
        let currentColorMask = null;
        const currentColorClear = new Vector4(0, 0, 0, 0);
        return {
            setMask: function(colorMask) {
                if (currentColorMask !== colorMask && !locked) {
                    gl.colorMask(colorMask, colorMask, colorMask, colorMask);
                    currentColorMask = colorMask;
                }
            },
            setLocked: function(lock) {
                locked = lock;
            },
            setClear: function(r, g, b, a, premultipliedAlpha) {
                if (premultipliedAlpha === true) {
                    r *= a;
                    g *= a;
                    b *= a;
                }
                color.set(r, g, b, a);
                if (currentColorClear.equals(color) === false) {
                    gl.clearColor(r, g, b, a);
                    currentColorClear.copy(color);
                }
            },
            reset: function() {
                locked = false;
                currentColorMask = null;
                currentColorClear.set(-1, 0, 0, 0); // set to invalid state
            }
        };
    }
    function DepthBuffer() {
        let locked = false;
        let currentDepthMask = null;
        let currentDepthFunc = null;
        let currentDepthClear = null;
        return {
            setTest: function(depthTest) {
                if (depthTest) enable(gl.DEPTH_TEST);
                else disable(gl.DEPTH_TEST);
            },
            setMask: function(depthMask) {
                if (currentDepthMask !== depthMask && !locked) {
                    gl.depthMask(depthMask);
                    currentDepthMask = depthMask;
                }
            },
            setFunc: function(depthFunc) {
                if (currentDepthFunc !== depthFunc) {
                    switch(depthFunc){
                        case NeverDepth:
                            gl.depthFunc(gl.NEVER);
                            break;
                        case AlwaysDepth:
                            gl.depthFunc(gl.ALWAYS);
                            break;
                        case LessDepth:
                            gl.depthFunc(gl.LESS);
                            break;
                        case LessEqualDepth:
                            gl.depthFunc(gl.LEQUAL);
                            break;
                        case EqualDepth:
                            gl.depthFunc(gl.EQUAL);
                            break;
                        case GreaterEqualDepth:
                            gl.depthFunc(gl.GEQUAL);
                            break;
                        case GreaterDepth:
                            gl.depthFunc(gl.GREATER);
                            break;
                        case NotEqualDepth:
                            gl.depthFunc(gl.NOTEQUAL);
                            break;
                        default:
                            gl.depthFunc(gl.LEQUAL);
                    }
                    currentDepthFunc = depthFunc;
                }
            },
            setLocked: function(lock) {
                locked = lock;
            },
            setClear: function(depth) {
                if (currentDepthClear !== depth) {
                    gl.clearDepth(depth);
                    currentDepthClear = depth;
                }
            },
            reset: function() {
                locked = false;
                currentDepthMask = null;
                currentDepthFunc = null;
                currentDepthClear = null;
            }
        };
    }
    function StencilBuffer() {
        let locked = false;
        let currentStencilMask = null;
        let currentStencilFunc = null;
        let currentStencilRef = null;
        let currentStencilFuncMask = null;
        let currentStencilFail = null;
        let currentStencilZFail = null;
        let currentStencilZPass = null;
        let currentStencilClear = null;
        return {
            setTest: function(stencilTest) {
                if (!locked) {
                    if (stencilTest) enable(gl.STENCIL_TEST);
                    else disable(gl.STENCIL_TEST);
                }
            },
            setMask: function(stencilMask) {
                if (currentStencilMask !== stencilMask && !locked) {
                    gl.stencilMask(stencilMask);
                    currentStencilMask = stencilMask;
                }
            },
            setFunc: function(stencilFunc, stencilRef, stencilMask) {
                if (currentStencilFunc !== stencilFunc || currentStencilRef !== stencilRef || currentStencilFuncMask !== stencilMask) {
                    gl.stencilFunc(stencilFunc, stencilRef, stencilMask);
                    currentStencilFunc = stencilFunc;
                    currentStencilRef = stencilRef;
                    currentStencilFuncMask = stencilMask;
                }
            },
            setOp: function(stencilFail, stencilZFail, stencilZPass) {
                if (currentStencilFail !== stencilFail || currentStencilZFail !== stencilZFail || currentStencilZPass !== stencilZPass) {
                    gl.stencilOp(stencilFail, stencilZFail, stencilZPass);
                    currentStencilFail = stencilFail;
                    currentStencilZFail = stencilZFail;
                    currentStencilZPass = stencilZPass;
                }
            },
            setLocked: function(lock) {
                locked = lock;
            },
            setClear: function(stencil) {
                if (currentStencilClear !== stencil) {
                    gl.clearStencil(stencil);
                    currentStencilClear = stencil;
                }
            },
            reset: function() {
                locked = false;
                currentStencilMask = null;
                currentStencilFunc = null;
                currentStencilRef = null;
                currentStencilFuncMask = null;
                currentStencilFail = null;
                currentStencilZFail = null;
                currentStencilZPass = null;
                currentStencilClear = null;
            }
        };
    }
    //
    const colorBuffer = new ColorBuffer();
    const depthBuffer = new DepthBuffer();
    const stencilBuffer = new StencilBuffer();
    const uboBindings = new WeakMap();
    const uboProgramMap = new WeakMap();
    let enabledCapabilities = {};
    let currentBoundFramebuffers = {};
    let currentDrawbuffers = new WeakMap();
    let defaultDrawbuffers = [];
    let currentProgram = null;
    let currentBlendingEnabled = false;
    let currentBlending = null;
    let currentBlendEquation = null;
    let currentBlendSrc = null;
    let currentBlendDst = null;
    let currentBlendEquationAlpha = null;
    let currentBlendSrcAlpha = null;
    let currentBlendDstAlpha = null;
    let currentBlendColor = new Color(0, 0, 0);
    let currentBlendAlpha = 0;
    let currentPremultipledAlpha = false;
    let currentFlipSided = null;
    let currentCullFace = null;
    let currentLineWidth = null;
    let currentPolygonOffsetFactor = null;
    let currentPolygonOffsetUnits = null;
    const maxTextures = gl.getParameter(gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS);
    let lineWidthAvailable = false;
    let version = 0;
    const glVersion = gl.getParameter(gl.VERSION);
    if (glVersion.indexOf("WebGL") !== -1) {
        version = parseFloat(/^WebGL (\d)/.exec(glVersion)[1]);
        lineWidthAvailable = version >= 1.0;
    } else if (glVersion.indexOf("OpenGL ES") !== -1) {
        version = parseFloat(/^OpenGL ES (\d)/.exec(glVersion)[1]);
        lineWidthAvailable = version >= 2.0;
    }
    let currentTextureSlot = null;
    let currentBoundTextures = {};
    const scissorParam = gl.getParameter(gl.SCISSOR_BOX);
    const viewportParam = gl.getParameter(gl.VIEWPORT);
    const currentScissor = new Vector4().fromArray(scissorParam);
    const currentViewport = new Vector4().fromArray(viewportParam);
    function createTexture(type, target, count, dimensions) {
        const data = new Uint8Array(4); // 4 is required to match default unpack alignment of 4.
        const texture = gl.createTexture();
        gl.bindTexture(type, texture);
        gl.texParameteri(type, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
        gl.texParameteri(type, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
        for(let i = 0; i < count; i++)if (type === gl.TEXTURE_3D || type === gl.TEXTURE_2D_ARRAY) gl.texImage3D(target, 0, gl.RGBA, 1, 1, dimensions, 0, gl.RGBA, gl.UNSIGNED_BYTE, data);
        else gl.texImage2D(target + i, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, data);
        return texture;
    }
    const emptyTextures = {};
    emptyTextures[gl.TEXTURE_2D] = createTexture(gl.TEXTURE_2D, gl.TEXTURE_2D, 1);
    emptyTextures[gl.TEXTURE_CUBE_MAP] = createTexture(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_CUBE_MAP_POSITIVE_X, 6);
    emptyTextures[gl.TEXTURE_2D_ARRAY] = createTexture(gl.TEXTURE_2D_ARRAY, gl.TEXTURE_2D_ARRAY, 1, 1);
    emptyTextures[gl.TEXTURE_3D] = createTexture(gl.TEXTURE_3D, gl.TEXTURE_3D, 1, 1);
    // init
    colorBuffer.setClear(0, 0, 0, 1);
    depthBuffer.setClear(1);
    stencilBuffer.setClear(0);
    enable(gl.DEPTH_TEST);
    depthBuffer.setFunc(LessEqualDepth);
    setFlipSided(false);
    setCullFace(CullFaceBack);
    enable(gl.CULL_FACE);
    setBlending(NoBlending);
    //
    function enable(id) {
        if (enabledCapabilities[id] !== true) {
            gl.enable(id);
            enabledCapabilities[id] = true;
        }
    }
    function disable(id) {
        if (enabledCapabilities[id] !== false) {
            gl.disable(id);
            enabledCapabilities[id] = false;
        }
    }
    function bindFramebuffer(target, framebuffer) {
        if (currentBoundFramebuffers[target] !== framebuffer) {
            gl.bindFramebuffer(target, framebuffer);
            currentBoundFramebuffers[target] = framebuffer;
            // gl.DRAW_FRAMEBUFFER is equivalent to gl.FRAMEBUFFER
            if (target === gl.DRAW_FRAMEBUFFER) currentBoundFramebuffers[gl.FRAMEBUFFER] = framebuffer;
            if (target === gl.FRAMEBUFFER) currentBoundFramebuffers[gl.DRAW_FRAMEBUFFER] = framebuffer;
            return true;
        }
        return false;
    }
    function drawBuffers(renderTarget, framebuffer) {
        let drawBuffers = defaultDrawbuffers;
        let needsUpdate = false;
        if (renderTarget) {
            drawBuffers = currentDrawbuffers.get(framebuffer);
            if (drawBuffers === undefined) {
                drawBuffers = [];
                currentDrawbuffers.set(framebuffer, drawBuffers);
            }
            const textures = renderTarget.textures;
            if (drawBuffers.length !== textures.length || drawBuffers[0] !== gl.COLOR_ATTACHMENT0) {
                for(let i = 0, il = textures.length; i < il; i++)drawBuffers[i] = gl.COLOR_ATTACHMENT0 + i;
                drawBuffers.length = textures.length;
                needsUpdate = true;
            }
        } else if (drawBuffers[0] !== gl.BACK) {
            drawBuffers[0] = gl.BACK;
            needsUpdate = true;
        }
        if (needsUpdate) gl.drawBuffers(drawBuffers);
    }
    function useProgram(program) {
        if (currentProgram !== program) {
            gl.useProgram(program);
            currentProgram = program;
            return true;
        }
        return false;
    }
    const equationToGL = {
        [AddEquation]: gl.FUNC_ADD,
        [SubtractEquation]: gl.FUNC_SUBTRACT,
        [ReverseSubtractEquation]: gl.FUNC_REVERSE_SUBTRACT
    };
    equationToGL[MinEquation] = gl.MIN;
    equationToGL[MaxEquation] = gl.MAX;
    const factorToGL = {
        [ZeroFactor]: gl.ZERO,
        [OneFactor]: gl.ONE,
        [SrcColorFactor]: gl.SRC_COLOR,
        [SrcAlphaFactor]: gl.SRC_ALPHA,
        [SrcAlphaSaturateFactor]: gl.SRC_ALPHA_SATURATE,
        [DstColorFactor]: gl.DST_COLOR,
        [DstAlphaFactor]: gl.DST_ALPHA,
        [OneMinusSrcColorFactor]: gl.ONE_MINUS_SRC_COLOR,
        [OneMinusSrcAlphaFactor]: gl.ONE_MINUS_SRC_ALPHA,
        [OneMinusDstColorFactor]: gl.ONE_MINUS_DST_COLOR,
        [OneMinusDstAlphaFactor]: gl.ONE_MINUS_DST_ALPHA,
        [ConstantColorFactor]: gl.CONSTANT_COLOR,
        [OneMinusConstantColorFactor]: gl.ONE_MINUS_CONSTANT_COLOR,
        [ConstantAlphaFactor]: gl.CONSTANT_ALPHA,
        [OneMinusConstantAlphaFactor]: gl.ONE_MINUS_CONSTANT_ALPHA
    };
    function setBlending(blending, blendEquation, blendSrc, blendDst, blendEquationAlpha, blendSrcAlpha, blendDstAlpha, blendColor, blendAlpha, premultipliedAlpha) {
        if (blending === NoBlending) {
            if (currentBlendingEnabled === true) {
                disable(gl.BLEND);
                currentBlendingEnabled = false;
            }
            return;
        }
        if (currentBlendingEnabled === false) {
            enable(gl.BLEND);
            currentBlendingEnabled = true;
        }
        if (blending !== CustomBlending) {
            if (blending !== currentBlending || premultipliedAlpha !== currentPremultipledAlpha) {
                if (currentBlendEquation !== AddEquation || currentBlendEquationAlpha !== AddEquation) {
                    gl.blendEquation(gl.FUNC_ADD);
                    currentBlendEquation = AddEquation;
                    currentBlendEquationAlpha = AddEquation;
                }
                if (premultipliedAlpha) switch(blending){
                    case NormalBlending:
                        gl.blendFuncSeparate(gl.ONE, gl.ONE_MINUS_SRC_ALPHA, gl.ONE, gl.ONE_MINUS_SRC_ALPHA);
                        break;
                    case AdditiveBlending:
                        gl.blendFunc(gl.ONE, gl.ONE);
                        break;
                    case SubtractiveBlending:
                        gl.blendFuncSeparate(gl.ZERO, gl.ONE_MINUS_SRC_COLOR, gl.ZERO, gl.ONE);
                        break;
                    case MultiplyBlending:
                        gl.blendFuncSeparate(gl.ZERO, gl.SRC_COLOR, gl.ZERO, gl.SRC_ALPHA);
                        break;
                    default:
                        console.error("THREE.WebGLState: Invalid blending: ", blending);
                        break;
                }
                else switch(blending){
                    case NormalBlending:
                        gl.blendFuncSeparate(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA, gl.ONE, gl.ONE_MINUS_SRC_ALPHA);
                        break;
                    case AdditiveBlending:
                        gl.blendFunc(gl.SRC_ALPHA, gl.ONE);
                        break;
                    case SubtractiveBlending:
                        gl.blendFuncSeparate(gl.ZERO, gl.ONE_MINUS_SRC_COLOR, gl.ZERO, gl.ONE);
                        break;
                    case MultiplyBlending:
                        gl.blendFunc(gl.ZERO, gl.SRC_COLOR);
                        break;
                    default:
                        console.error("THREE.WebGLState: Invalid blending: ", blending);
                        break;
                }
                currentBlendSrc = null;
                currentBlendDst = null;
                currentBlendSrcAlpha = null;
                currentBlendDstAlpha = null;
                currentBlendColor.set(0, 0, 0);
                currentBlendAlpha = 0;
                currentBlending = blending;
                currentPremultipledAlpha = premultipliedAlpha;
            }
            return;
        }
        // custom blending
        blendEquationAlpha = blendEquationAlpha || blendEquation;
        blendSrcAlpha = blendSrcAlpha || blendSrc;
        blendDstAlpha = blendDstAlpha || blendDst;
        if (blendEquation !== currentBlendEquation || blendEquationAlpha !== currentBlendEquationAlpha) {
            gl.blendEquationSeparate(equationToGL[blendEquation], equationToGL[blendEquationAlpha]);
            currentBlendEquation = blendEquation;
            currentBlendEquationAlpha = blendEquationAlpha;
        }
        if (blendSrc !== currentBlendSrc || blendDst !== currentBlendDst || blendSrcAlpha !== currentBlendSrcAlpha || blendDstAlpha !== currentBlendDstAlpha) {
            gl.blendFuncSeparate(factorToGL[blendSrc], factorToGL[blendDst], factorToGL[blendSrcAlpha], factorToGL[blendDstAlpha]);
            currentBlendSrc = blendSrc;
            currentBlendDst = blendDst;
            currentBlendSrcAlpha = blendSrcAlpha;
            currentBlendDstAlpha = blendDstAlpha;
        }
        if (blendColor.equals(currentBlendColor) === false || blendAlpha !== currentBlendAlpha) {
            gl.blendColor(blendColor.r, blendColor.g, blendColor.b, blendAlpha);
            currentBlendColor.copy(blendColor);
            currentBlendAlpha = blendAlpha;
        }
        currentBlending = blending;
        currentPremultipledAlpha = false;
    }
    function setMaterial(material, frontFaceCW) {
        material.side === DoubleSide ? disable(gl.CULL_FACE) : enable(gl.CULL_FACE);
        let flipSided = material.side === BackSide;
        if (frontFaceCW) flipSided = !flipSided;
        setFlipSided(flipSided);
        material.blending === NormalBlending && material.transparent === false ? setBlending(NoBlending) : setBlending(material.blending, material.blendEquation, material.blendSrc, material.blendDst, material.blendEquationAlpha, material.blendSrcAlpha, material.blendDstAlpha, material.blendColor, material.blendAlpha, material.premultipliedAlpha);
        depthBuffer.setFunc(material.depthFunc);
        depthBuffer.setTest(material.depthTest);
        depthBuffer.setMask(material.depthWrite);
        colorBuffer.setMask(material.colorWrite);
        const stencilWrite = material.stencilWrite;
        stencilBuffer.setTest(stencilWrite);
        if (stencilWrite) {
            stencilBuffer.setMask(material.stencilWriteMask);
            stencilBuffer.setFunc(material.stencilFunc, material.stencilRef, material.stencilFuncMask);
            stencilBuffer.setOp(material.stencilFail, material.stencilZFail, material.stencilZPass);
        }
        setPolygonOffset(material.polygonOffset, material.polygonOffsetFactor, material.polygonOffsetUnits);
        material.alphaToCoverage === true ? enable(gl.SAMPLE_ALPHA_TO_COVERAGE) : disable(gl.SAMPLE_ALPHA_TO_COVERAGE);
    }
    //
    function setFlipSided(flipSided) {
        if (currentFlipSided !== flipSided) {
            if (flipSided) gl.frontFace(gl.CW);
            else gl.frontFace(gl.CCW);
            currentFlipSided = flipSided;
        }
    }
    function setCullFace(cullFace) {
        if (cullFace !== CullFaceNone) {
            enable(gl.CULL_FACE);
            if (cullFace !== currentCullFace) {
                if (cullFace === CullFaceBack) gl.cullFace(gl.BACK);
                else if (cullFace === CullFaceFront) gl.cullFace(gl.FRONT);
                else gl.cullFace(gl.FRONT_AND_BACK);
            }
        } else disable(gl.CULL_FACE);
        currentCullFace = cullFace;
    }
    function setLineWidth(width) {
        if (width !== currentLineWidth) {
            if (lineWidthAvailable) gl.lineWidth(width);
            currentLineWidth = width;
        }
    }
    function setPolygonOffset(polygonOffset, factor, units) {
        if (polygonOffset) {
            enable(gl.POLYGON_OFFSET_FILL);
            if (currentPolygonOffsetFactor !== factor || currentPolygonOffsetUnits !== units) {
                gl.polygonOffset(factor, units);
                currentPolygonOffsetFactor = factor;
                currentPolygonOffsetUnits = units;
            }
        } else disable(gl.POLYGON_OFFSET_FILL);
    }
    function setScissorTest(scissorTest) {
        if (scissorTest) enable(gl.SCISSOR_TEST);
        else disable(gl.SCISSOR_TEST);
    }
    // texture
    function activeTexture(webglSlot) {
        if (webglSlot === undefined) webglSlot = gl.TEXTURE0 + maxTextures - 1;
        if (currentTextureSlot !== webglSlot) {
            gl.activeTexture(webglSlot);
            currentTextureSlot = webglSlot;
        }
    }
    function bindTexture(webglType, webglTexture, webglSlot) {
        if (webglSlot === undefined) {
            if (currentTextureSlot === null) webglSlot = gl.TEXTURE0 + maxTextures - 1;
            else webglSlot = currentTextureSlot;
        }
        let boundTexture = currentBoundTextures[webglSlot];
        if (boundTexture === undefined) {
            boundTexture = {
                type: undefined,
                texture: undefined
            };
            currentBoundTextures[webglSlot] = boundTexture;
        }
        if (boundTexture.type !== webglType || boundTexture.texture !== webglTexture) {
            if (currentTextureSlot !== webglSlot) {
                gl.activeTexture(webglSlot);
                currentTextureSlot = webglSlot;
            }
            gl.bindTexture(webglType, webglTexture || emptyTextures[webglType]);
            boundTexture.type = webglType;
            boundTexture.texture = webglTexture;
        }
    }
    function unbindTexture() {
        const boundTexture = currentBoundTextures[currentTextureSlot];
        if (boundTexture !== undefined && boundTexture.type !== undefined) {
            gl.bindTexture(boundTexture.type, null);
            boundTexture.type = undefined;
            boundTexture.texture = undefined;
        }
    }
    function compressedTexImage2D() {
        try {
            gl.compressedTexImage2D.apply(gl, arguments);
        } catch (error) {
            console.error("THREE.WebGLState:", error);
        }
    }
    function compressedTexImage3D() {
        try {
            gl.compressedTexImage3D.apply(gl, arguments);
        } catch (error) {
            console.error("THREE.WebGLState:", error);
        }
    }
    function texSubImage2D() {
        try {
            gl.texSubImage2D.apply(gl, arguments);
        } catch (error) {
            console.error("THREE.WebGLState:", error);
        }
    }
    function texSubImage3D() {
        try {
            gl.texSubImage3D.apply(gl, arguments);
        } catch (error) {
            console.error("THREE.WebGLState:", error);
        }
    }
    function compressedTexSubImage2D() {
        try {
            gl.compressedTexSubImage2D.apply(gl, arguments);
        } catch (error) {
            console.error("THREE.WebGLState:", error);
        }
    }
    function compressedTexSubImage3D() {
        try {
            gl.compressedTexSubImage3D.apply(gl, arguments);
        } catch (error) {
            console.error("THREE.WebGLState:", error);
        }
    }
    function texStorage2D() {
        try {
            gl.texStorage2D.apply(gl, arguments);
        } catch (error) {
            console.error("THREE.WebGLState:", error);
        }
    }
    function texStorage3D() {
        try {
            gl.texStorage3D.apply(gl, arguments);
        } catch (error) {
            console.error("THREE.WebGLState:", error);
        }
    }
    function texImage2D() {
        try {
            gl.texImage2D.apply(gl, arguments);
        } catch (error) {
            console.error("THREE.WebGLState:", error);
        }
    }
    function texImage3D() {
        try {
            gl.texImage3D.apply(gl, arguments);
        } catch (error) {
            console.error("THREE.WebGLState:", error);
        }
    }
    //
    function scissor(scissor) {
        if (currentScissor.equals(scissor) === false) {
            gl.scissor(scissor.x, scissor.y, scissor.z, scissor.w);
            currentScissor.copy(scissor);
        }
    }
    function viewport(viewport) {
        if (currentViewport.equals(viewport) === false) {
            gl.viewport(viewport.x, viewport.y, viewport.z, viewport.w);
            currentViewport.copy(viewport);
        }
    }
    function updateUBOMapping(uniformsGroup, program) {
        let mapping = uboProgramMap.get(program);
        if (mapping === undefined) {
            mapping = new WeakMap();
            uboProgramMap.set(program, mapping);
        }
        let blockIndex = mapping.get(uniformsGroup);
        if (blockIndex === undefined) {
            blockIndex = gl.getUniformBlockIndex(program, uniformsGroup.name);
            mapping.set(uniformsGroup, blockIndex);
        }
    }
    function uniformBlockBinding(uniformsGroup, program) {
        const mapping = uboProgramMap.get(program);
        const blockIndex = mapping.get(uniformsGroup);
        if (uboBindings.get(program) !== blockIndex) {
            // bind shader specific block index to global block point
            gl.uniformBlockBinding(program, blockIndex, uniformsGroup.__bindingPointIndex);
            uboBindings.set(program, blockIndex);
        }
    }
    //
    function reset() {
        // reset state
        gl.disable(gl.BLEND);
        gl.disable(gl.CULL_FACE);
        gl.disable(gl.DEPTH_TEST);
        gl.disable(gl.POLYGON_OFFSET_FILL);
        gl.disable(gl.SCISSOR_TEST);
        gl.disable(gl.STENCIL_TEST);
        gl.disable(gl.SAMPLE_ALPHA_TO_COVERAGE);
        gl.blendEquation(gl.FUNC_ADD);
        gl.blendFunc(gl.ONE, gl.ZERO);
        gl.blendFuncSeparate(gl.ONE, gl.ZERO, gl.ONE, gl.ZERO);
        gl.blendColor(0, 0, 0, 0);
        gl.colorMask(true, true, true, true);
        gl.clearColor(0, 0, 0, 0);
        gl.depthMask(true);
        gl.depthFunc(gl.LESS);
        gl.clearDepth(1);
        gl.stencilMask(0xffffffff);
        gl.stencilFunc(gl.ALWAYS, 0, 0xffffffff);
        gl.stencilOp(gl.KEEP, gl.KEEP, gl.KEEP);
        gl.clearStencil(0);
        gl.cullFace(gl.BACK);
        gl.frontFace(gl.CCW);
        gl.polygonOffset(0, 0);
        gl.activeTexture(gl.TEXTURE0);
        gl.bindFramebuffer(gl.FRAMEBUFFER, null);
        gl.bindFramebuffer(gl.DRAW_FRAMEBUFFER, null);
        gl.bindFramebuffer(gl.READ_FRAMEBUFFER, null);
        gl.useProgram(null);
        gl.lineWidth(1);
        gl.scissor(0, 0, gl.canvas.width, gl.canvas.height);
        gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
        // reset internals
        enabledCapabilities = {};
        currentTextureSlot = null;
        currentBoundTextures = {};
        currentBoundFramebuffers = {};
        currentDrawbuffers = new WeakMap();
        defaultDrawbuffers = [];
        currentProgram = null;
        currentBlendingEnabled = false;
        currentBlending = null;
        currentBlendEquation = null;
        currentBlendSrc = null;
        currentBlendDst = null;
        currentBlendEquationAlpha = null;
        currentBlendSrcAlpha = null;
        currentBlendDstAlpha = null;
        currentBlendColor = new Color(0, 0, 0);
        currentBlendAlpha = 0;
        currentPremultipledAlpha = false;
        currentFlipSided = null;
        currentCullFace = null;
        currentLineWidth = null;
        currentPolygonOffsetFactor = null;
        currentPolygonOffsetUnits = null;
        currentScissor.set(0, 0, gl.canvas.width, gl.canvas.height);
        currentViewport.set(0, 0, gl.canvas.width, gl.canvas.height);
        colorBuffer.reset();
        depthBuffer.reset();
        stencilBuffer.reset();
    }
    return {
        buffers: {
            color: colorBuffer,
            depth: depthBuffer,
            stencil: stencilBuffer
        },
        enable: enable,
        disable: disable,
        bindFramebuffer: bindFramebuffer,
        drawBuffers: drawBuffers,
        useProgram: useProgram,
        setBlending: setBlending,
        setMaterial: setMaterial,
        setFlipSided: setFlipSided,
        setCullFace: setCullFace,
        setLineWidth: setLineWidth,
        setPolygonOffset: setPolygonOffset,
        setScissorTest: setScissorTest,
        activeTexture: activeTexture,
        bindTexture: bindTexture,
        unbindTexture: unbindTexture,
        compressedTexImage2D: compressedTexImage2D,
        compressedTexImage3D: compressedTexImage3D,
        texImage2D: texImage2D,
        texImage3D: texImage3D,
        updateUBOMapping: updateUBOMapping,
        uniformBlockBinding: uniformBlockBinding,
        texStorage2D: texStorage2D,
        texStorage3D: texStorage3D,
        texSubImage2D: texSubImage2D,
        texSubImage3D: texSubImage3D,
        compressedTexSubImage2D: compressedTexSubImage2D,
        compressedTexSubImage3D: compressedTexSubImage3D,
        scissor: scissor,
        viewport: viewport,
        reset: reset
    };
}
function contain(texture, aspect) {
    const imageAspect = texture.image && texture.image.width ? texture.image.width / texture.image.height : 1;
    if (imageAspect > aspect) {
        texture.repeat.x = 1;
        texture.repeat.y = imageAspect / aspect;
        texture.offset.x = 0;
        texture.offset.y = (1 - texture.repeat.y) / 2;
    } else {
        texture.repeat.x = aspect / imageAspect;
        texture.repeat.y = 1;
        texture.offset.x = (1 - texture.repeat.x) / 2;
        texture.offset.y = 0;
    }
    return texture;
}
function cover(texture, aspect) {
    const imageAspect = texture.image && texture.image.width ? texture.image.width / texture.image.height : 1;
    if (imageAspect > aspect) {
        texture.repeat.x = aspect / imageAspect;
        texture.repeat.y = 1;
        texture.offset.x = (1 - texture.repeat.x) / 2;
        texture.offset.y = 0;
    } else {
        texture.repeat.x = 1;
        texture.repeat.y = imageAspect / aspect;
        texture.offset.x = 0;
        texture.offset.y = (1 - texture.repeat.y) / 2;
    }
    return texture;
}
function fill(texture) {
    texture.repeat.x = 1;
    texture.repeat.y = 1;
    texture.offset.x = 0;
    texture.offset.y = 0;
    return texture;
}
/**
 * Given the width, height, format, and type of a texture. Determines how many
 * bytes must be used to represent the texture.
 */ function getByteLength(width, height, format, type) {
    const typeByteLength = getTextureTypeByteLength(type);
    switch(format){
        // https://registry.khronos.org/OpenGL-Refpages/es3.0/html/glTexImage2D.xhtml
        case AlphaFormat:
            return width * height;
        case LuminanceFormat:
            return width * height;
        case LuminanceAlphaFormat:
            return width * height * 2;
        case RedFormat:
            return width * height / typeByteLength.components * typeByteLength.byteLength;
        case RedIntegerFormat:
            return width * height / typeByteLength.components * typeByteLength.byteLength;
        case RGFormat:
            return width * height * 2 / typeByteLength.components * typeByteLength.byteLength;
        case RGIntegerFormat:
            return width * height * 2 / typeByteLength.components * typeByteLength.byteLength;
        case RGBFormat:
            return width * height * 3 / typeByteLength.components * typeByteLength.byteLength;
        case RGBAFormat:
            return width * height * 4 / typeByteLength.components * typeByteLength.byteLength;
        case RGBAIntegerFormat:
            return width * height * 4 / typeByteLength.components * typeByteLength.byteLength;
        // https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_s3tc_srgb/
        case RGB_S3TC_DXT1_Format:
        case RGBA_S3TC_DXT1_Format:
            return Math.floor((width + 3) / 4) * Math.floor((height + 3) / 4) * 8;
        case RGBA_S3TC_DXT3_Format:
        case RGBA_S3TC_DXT5_Format:
            return Math.floor((width + 3) / 4) * Math.floor((height + 3) / 4) * 16;
        // https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_pvrtc/
        case RGB_PVRTC_2BPPV1_Format:
        case RGBA_PVRTC_2BPPV1_Format:
            return Math.max(width, 16) * Math.max(height, 8) / 4;
        case RGB_PVRTC_4BPPV1_Format:
        case RGBA_PVRTC_4BPPV1_Format:
            return Math.max(width, 8) * Math.max(height, 8) / 2;
        // https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_etc/
        case RGB_ETC1_Format:
        case RGB_ETC2_Format:
            return Math.floor((width + 3) / 4) * Math.floor((height + 3) / 4) * 8;
        case RGBA_ETC2_EAC_Format:
            return Math.floor((width + 3) / 4) * Math.floor((height + 3) / 4) * 16;
        // https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_astc/
        case RGBA_ASTC_4x4_Format:
            return Math.floor((width + 3) / 4) * Math.floor((height + 3) / 4) * 16;
        case RGBA_ASTC_5x4_Format:
            return Math.floor((width + 4) / 5) * Math.floor((height + 3) / 4) * 16;
        case RGBA_ASTC_5x5_Format:
            return Math.floor((width + 4) / 5) * Math.floor((height + 4) / 5) * 16;
        case RGBA_ASTC_6x5_Format:
            return Math.floor((width + 5) / 6) * Math.floor((height + 4) / 5) * 16;
        case RGBA_ASTC_6x6_Format:
            return Math.floor((width + 5) / 6) * Math.floor((height + 5) / 6) * 16;
        case RGBA_ASTC_8x5_Format:
            return Math.floor((width + 7) / 8) * Math.floor((height + 4) / 5) * 16;
        case RGBA_ASTC_8x6_Format:
            return Math.floor((width + 7) / 8) * Math.floor((height + 5) / 6) * 16;
        case RGBA_ASTC_8x8_Format:
            return Math.floor((width + 7) / 8) * Math.floor((height + 7) / 8) * 16;
        case RGBA_ASTC_10x5_Format:
            return Math.floor((width + 9) / 10) * Math.floor((height + 4) / 5) * 16;
        case RGBA_ASTC_10x6_Format:
            return Math.floor((width + 9) / 10) * Math.floor((height + 5) / 6) * 16;
        case RGBA_ASTC_10x8_Format:
            return Math.floor((width + 9) / 10) * Math.floor((height + 7) / 8) * 16;
        case RGBA_ASTC_10x10_Format:
            return Math.floor((width + 9) / 10) * Math.floor((height + 9) / 10) * 16;
        case RGBA_ASTC_12x10_Format:
            return Math.floor((width + 11) / 12) * Math.floor((height + 9) / 10) * 16;
        case RGBA_ASTC_12x12_Format:
            return Math.floor((width + 11) / 12) * Math.floor((height + 11) / 12) * 16;
        // https://registry.khronos.org/webgl/extensions/EXT_texture_compression_bptc/
        case RGBA_BPTC_Format:
        case RGB_BPTC_SIGNED_Format:
        case RGB_BPTC_UNSIGNED_Format:
            return Math.ceil(width / 4) * Math.ceil(height / 4) * 16;
        // https://registry.khronos.org/webgl/extensions/EXT_texture_compression_rgtc/
        case RED_RGTC1_Format:
        case SIGNED_RED_RGTC1_Format:
            return Math.ceil(width / 4) * Math.ceil(height / 4) * 8;
        case RED_GREEN_RGTC2_Format:
        case SIGNED_RED_GREEN_RGTC2_Format:
            return Math.ceil(width / 4) * Math.ceil(height / 4) * 16;
    }
    throw new Error(`Unable to determine texture byte length for ${format} format.`);
}
function getTextureTypeByteLength(type) {
    switch(type){
        case UnsignedByteType:
        case ByteType:
            return {
                byteLength: 1,
                components: 1
            };
        case UnsignedShortType:
        case ShortType:
        case HalfFloatType:
            return {
                byteLength: 2,
                components: 1
            };
        case UnsignedShort4444Type:
        case UnsignedShort5551Type:
            return {
                byteLength: 2,
                components: 4
            };
        case UnsignedIntType:
        case IntType:
        case FloatType:
            return {
                byteLength: 4,
                components: 1
            };
        case UnsignedInt5999Type:
            return {
                byteLength: 4,
                components: 3
            };
    }
    throw new Error(`Unknown texture type ${type}.`);
}
const TextureUtils = {
    contain,
    cover,
    fill,
    getByteLength
};
function WebGLTextures(_gl, extensions, state, properties, capabilities, utils, info) {
    const multisampledRTTExt = extensions.has("WEBGL_multisampled_render_to_texture") ? extensions.get("WEBGL_multisampled_render_to_texture") : null;
    const supportsInvalidateFramebuffer = typeof navigator === "undefined" ? false : /OculusBrowser/g.test(navigator.userAgent);
    const _imageDimensions = new Vector2();
    const _videoTextures = new WeakMap();
    let _canvas;
    const _sources = new WeakMap(); // maps WebglTexture objects to instances of Source
    // cordova iOS (as of 5.0) still uses UIWebView, which provides OffscreenCanvas,
    // also OffscreenCanvas.getContext("webgl"), but not OffscreenCanvas.getContext("2d")!
    // Some implementations may only implement OffscreenCanvas partially (e.g. lacking 2d).
    let useOffscreenCanvas = false;
    try {
        useOffscreenCanvas = typeof OffscreenCanvas !== "undefined" && new OffscreenCanvas(1, 1).getContext("2d") !== null;
    } catch (err) {
    // Ignore any errors
    }
    function createCanvas(width, height) {
        // Use OffscreenCanvas when available. Specially needed in web workers
        return useOffscreenCanvas ? // eslint-disable-next-line compat/compat
        new OffscreenCanvas(width, height) : createElementNS("canvas");
    }
    function resizeImage(image, needsNewCanvas, maxSize) {
        let scale = 1;
        const dimensions = getDimensions(image);
        // handle case if texture exceeds max size
        if (dimensions.width > maxSize || dimensions.height > maxSize) scale = maxSize / Math.max(dimensions.width, dimensions.height);
        // only perform resize if necessary
        if (scale < 1) {
            // only perform resize for certain image types
            if (typeof HTMLImageElement !== "undefined" && image instanceof HTMLImageElement || typeof HTMLCanvasElement !== "undefined" && image instanceof HTMLCanvasElement || typeof ImageBitmap !== "undefined" && image instanceof ImageBitmap || typeof VideoFrame !== "undefined" && image instanceof VideoFrame) {
                const width = Math.floor(scale * dimensions.width);
                const height = Math.floor(scale * dimensions.height);
                if (_canvas === undefined) _canvas = createCanvas(width, height);
                // cube textures can't reuse the same canvas
                const canvas = needsNewCanvas ? createCanvas(width, height) : _canvas;
                canvas.width = width;
                canvas.height = height;
                const context = canvas.getContext("2d");
                context.drawImage(image, 0, 0, width, height);
                console.warn("THREE.WebGLRenderer: Texture has been resized from (" + dimensions.width + "x" + dimensions.height + ") to (" + width + "x" + height + ").");
                return canvas;
            } else {
                if ("data" in image) console.warn("THREE.WebGLRenderer: Image in DataTexture is too big (" + dimensions.width + "x" + dimensions.height + ").");
                return image;
            }
        }
        return image;
    }
    function textureNeedsGenerateMipmaps(texture) {
        return texture.generateMipmaps && texture.minFilter !== NearestFilter && texture.minFilter !== LinearFilter;
    }
    function generateMipmap(target) {
        _gl.generateMipmap(target);
    }
    function getInternalFormat(internalFormatName, glFormat, glType, colorSpace1, forceLinearTransfer = false) {
        if (internalFormatName !== null) {
            if (_gl[internalFormatName] !== undefined) return _gl[internalFormatName];
            console.warn("THREE.WebGLRenderer: Attempt to use non-existing WebGL internal format '" + internalFormatName + "'");
        }
        let internalFormat = glFormat;
        if (glFormat === _gl.RED) {
            if (glType === _gl.FLOAT) internalFormat = _gl.R32F;
            if (glType === _gl.HALF_FLOAT) internalFormat = _gl.R16F;
            if (glType === _gl.UNSIGNED_BYTE) internalFormat = _gl.R8;
        }
        if (glFormat === _gl.RED_INTEGER) {
            if (glType === _gl.UNSIGNED_BYTE) internalFormat = _gl.R8UI;
            if (glType === _gl.UNSIGNED_SHORT) internalFormat = _gl.R16UI;
            if (glType === _gl.UNSIGNED_INT) internalFormat = _gl.R32UI;
            if (glType === _gl.BYTE) internalFormat = _gl.R8I;
            if (glType === _gl.SHORT) internalFormat = _gl.R16I;
            if (glType === _gl.INT) internalFormat = _gl.R32I;
        }
        if (glFormat === _gl.RG) {
            if (glType === _gl.FLOAT) internalFormat = _gl.RG32F;
            if (glType === _gl.HALF_FLOAT) internalFormat = _gl.RG16F;
            if (glType === _gl.UNSIGNED_BYTE) internalFormat = _gl.RG8;
        }
        if (glFormat === _gl.RG_INTEGER) {
            if (glType === _gl.UNSIGNED_BYTE) internalFormat = _gl.RG8UI;
            if (glType === _gl.UNSIGNED_SHORT) internalFormat = _gl.RG16UI;
            if (glType === _gl.UNSIGNED_INT) internalFormat = _gl.RG32UI;
            if (glType === _gl.BYTE) internalFormat = _gl.RG8I;
            if (glType === _gl.SHORT) internalFormat = _gl.RG16I;
            if (glType === _gl.INT) internalFormat = _gl.RG32I;
        }
        if (glFormat === _gl.RGB) {
            if (glType === _gl.UNSIGNED_INT_5_9_9_9_REV) internalFormat = _gl.RGB9_E5;
        }
        if (glFormat === _gl.RGBA) {
            const transfer = forceLinearTransfer ? LinearTransfer : ColorManagement.getTransfer(colorSpace1);
            if (glType === _gl.FLOAT) internalFormat = _gl.RGBA32F;
            if (glType === _gl.HALF_FLOAT) internalFormat = _gl.RGBA16F;
            if (glType === _gl.UNSIGNED_BYTE) internalFormat = transfer === SRGBTransfer ? _gl.SRGB8_ALPHA8 : _gl.RGBA8;
            if (glType === _gl.UNSIGNED_SHORT_4_4_4_4) internalFormat = _gl.RGBA4;
            if (glType === _gl.UNSIGNED_SHORT_5_5_5_1) internalFormat = _gl.RGB5_A1;
        }
        if (internalFormat === _gl.R16F || internalFormat === _gl.R32F || internalFormat === _gl.RG16F || internalFormat === _gl.RG32F || internalFormat === _gl.RGBA16F || internalFormat === _gl.RGBA32F) extensions.get("EXT_color_buffer_float");
        return internalFormat;
    }
    function getInternalDepthFormat(useStencil, depthType) {
        let glInternalFormat;
        if (useStencil) {
            if (depthType === null || depthType === UnsignedIntType || depthType === UnsignedInt248Type) glInternalFormat = _gl.DEPTH24_STENCIL8;
            else if (depthType === FloatType) glInternalFormat = _gl.DEPTH32F_STENCIL8;
            else if (depthType === UnsignedShortType) {
                glInternalFormat = _gl.DEPTH24_STENCIL8;
                console.warn("DepthTexture: 16 bit depth attachment is not supported with stencil. Using 24-bit attachment.");
            }
        } else {
            if (depthType === null || depthType === UnsignedIntType || depthType === UnsignedInt248Type) glInternalFormat = _gl.DEPTH_COMPONENT24;
            else if (depthType === FloatType) glInternalFormat = _gl.DEPTH_COMPONENT32F;
            else if (depthType === UnsignedShortType) glInternalFormat = _gl.DEPTH_COMPONENT16;
        }
        return glInternalFormat;
    }
    function getMipLevels(texture, image) {
        if (textureNeedsGenerateMipmaps(texture) === true || texture.isFramebufferTexture && texture.minFilter !== NearestFilter && texture.minFilter !== LinearFilter) return Math.log2(Math.max(image.width, image.height)) + 1;
        else if (texture.mipmaps !== undefined && texture.mipmaps.length > 0) // user-defined mipmaps
        return texture.mipmaps.length;
        else if (texture.isCompressedTexture && Array.isArray(texture.image)) return image.mipmaps.length;
        else // texture without mipmaps (only base level)
        return 1;
    }
    //
    function onTextureDispose(event) {
        const texture = event.target;
        texture.removeEventListener("dispose", onTextureDispose);
        deallocateTexture(texture);
        if (texture.isVideoTexture) _videoTextures.delete(texture);
    }
    function onRenderTargetDispose(event) {
        const renderTarget = event.target;
        renderTarget.removeEventListener("dispose", onRenderTargetDispose);
        deallocateRenderTarget(renderTarget);
    }
    //
    function deallocateTexture(texture) {
        const textureProperties = properties.get(texture);
        if (textureProperties.__webglInit === undefined) return;
        // check if it's necessary to remove the WebGLTexture object
        const source = texture.source;
        const webglTextures = _sources.get(source);
        if (webglTextures) {
            const webglTexture = webglTextures[textureProperties.__cacheKey];
            webglTexture.usedTimes--;
            // the WebGLTexture object is not used anymore, remove it
            if (webglTexture.usedTimes === 0) deleteTexture(texture);
            // remove the weak map entry if no WebGLTexture uses the source anymore
            if (Object.keys(webglTextures).length === 0) _sources.delete(source);
        }
        properties.remove(texture);
    }
    function deleteTexture(texture) {
        const textureProperties = properties.get(texture);
        _gl.deleteTexture(textureProperties.__webglTexture);
        const source = texture.source;
        const webglTextures = _sources.get(source);
        delete webglTextures[textureProperties.__cacheKey];
        info.memory.textures--;
    }
    function deallocateRenderTarget(renderTarget) {
        const renderTargetProperties = properties.get(renderTarget);
        if (renderTarget.depthTexture) renderTarget.depthTexture.dispose();
        if (renderTarget.isWebGLCubeRenderTarget) for(let i = 0; i < 6; i++){
            if (Array.isArray(renderTargetProperties.__webglFramebuffer[i])) for(let level = 0; level < renderTargetProperties.__webglFramebuffer[i].length; level++)_gl.deleteFramebuffer(renderTargetProperties.__webglFramebuffer[i][level]);
            else _gl.deleteFramebuffer(renderTargetProperties.__webglFramebuffer[i]);
            if (renderTargetProperties.__webglDepthbuffer) _gl.deleteRenderbuffer(renderTargetProperties.__webglDepthbuffer[i]);
        }
        else {
            if (Array.isArray(renderTargetProperties.__webglFramebuffer)) for(let level = 0; level < renderTargetProperties.__webglFramebuffer.length; level++)_gl.deleteFramebuffer(renderTargetProperties.__webglFramebuffer[level]);
            else _gl.deleteFramebuffer(renderTargetProperties.__webglFramebuffer);
            if (renderTargetProperties.__webglDepthbuffer) _gl.deleteRenderbuffer(renderTargetProperties.__webglDepthbuffer);
            if (renderTargetProperties.__webglMultisampledFramebuffer) _gl.deleteFramebuffer(renderTargetProperties.__webglMultisampledFramebuffer);
            if (renderTargetProperties.__webglColorRenderbuffer) {
                for(let i = 0; i < renderTargetProperties.__webglColorRenderbuffer.length; i++)if (renderTargetProperties.__webglColorRenderbuffer[i]) _gl.deleteRenderbuffer(renderTargetProperties.__webglColorRenderbuffer[i]);
            }
            if (renderTargetProperties.__webglDepthRenderbuffer) _gl.deleteRenderbuffer(renderTargetProperties.__webglDepthRenderbuffer);
        }
        const textures = renderTarget.textures;
        for(let i = 0, il = textures.length; i < il; i++){
            const attachmentProperties = properties.get(textures[i]);
            if (attachmentProperties.__webglTexture) {
                _gl.deleteTexture(attachmentProperties.__webglTexture);
                info.memory.textures--;
            }
            properties.remove(textures[i]);
        }
        properties.remove(renderTarget);
    }
    //
    let textureUnits = 0;
    function resetTextureUnits() {
        textureUnits = 0;
    }
    function allocateTextureUnit() {
        const textureUnit = textureUnits;
        if (textureUnit >= capabilities.maxTextures) console.warn("THREE.WebGLTextures: Trying to use " + textureUnit + " texture units while this GPU supports only " + capabilities.maxTextures);
        textureUnits += 1;
        return textureUnit;
    }
    function getTextureCacheKey(texture) {
        const array = [];
        array.push(texture.wrapS);
        array.push(texture.wrapT);
        array.push(texture.wrapR || 0);
        array.push(texture.magFilter);
        array.push(texture.minFilter);
        array.push(texture.anisotropy);
        array.push(texture.internalFormat);
        array.push(texture.format);
        array.push(texture.type);
        array.push(texture.generateMipmaps);
        array.push(texture.premultiplyAlpha);
        array.push(texture.flipY);
        array.push(texture.unpackAlignment);
        array.push(texture.colorSpace);
        return array.join();
    }
    //
    function setTexture2D(texture, slot) {
        const textureProperties = properties.get(texture);
        if (texture.isVideoTexture) updateVideoTexture(texture);
        if (texture.isRenderTargetTexture === false && texture.version > 0 && textureProperties.__version !== texture.version) {
            const image = texture.image;
            if (image === null) console.warn("THREE.WebGLRenderer: Texture marked for update but no image data found.");
            else if (image.complete === false) console.warn("THREE.WebGLRenderer: Texture marked for update but image is incomplete");
            else {
                uploadTexture(textureProperties, texture, slot);
                return;
            }
        }
        state.bindTexture(_gl.TEXTURE_2D, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);
    }
    function setTexture2DArray(texture, slot) {
        const textureProperties = properties.get(texture);
        if (texture.version > 0 && textureProperties.__version !== texture.version) {
            uploadTexture(textureProperties, texture, slot);
            return;
        }
        state.bindTexture(_gl.TEXTURE_2D_ARRAY, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);
    }
    function setTexture3D(texture, slot) {
        const textureProperties = properties.get(texture);
        if (texture.version > 0 && textureProperties.__version !== texture.version) {
            uploadTexture(textureProperties, texture, slot);
            return;
        }
        state.bindTexture(_gl.TEXTURE_3D, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);
    }
    function setTextureCube(texture, slot) {
        const textureProperties = properties.get(texture);
        if (texture.version > 0 && textureProperties.__version !== texture.version) {
            uploadCubeTexture(textureProperties, texture, slot);
            return;
        }
        state.bindTexture(_gl.TEXTURE_CUBE_MAP, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);
    }
    const wrappingToGL = {
        [RepeatWrapping]: _gl.REPEAT,
        [ClampToEdgeWrapping]: _gl.CLAMP_TO_EDGE,
        [MirroredRepeatWrapping]: _gl.MIRRORED_REPEAT
    };
    const filterToGL = {
        [NearestFilter]: _gl.NEAREST,
        [NearestMipmapNearestFilter]: _gl.NEAREST_MIPMAP_NEAREST,
        [NearestMipmapLinearFilter]: _gl.NEAREST_MIPMAP_LINEAR,
        [LinearFilter]: _gl.LINEAR,
        [LinearMipmapNearestFilter]: _gl.LINEAR_MIPMAP_NEAREST,
        [LinearMipmapLinearFilter]: _gl.LINEAR_MIPMAP_LINEAR
    };
    const compareToGL = {
        [NeverCompare]: _gl.NEVER,
        [AlwaysCompare]: _gl.ALWAYS,
        [LessCompare]: _gl.LESS,
        [LessEqualCompare]: _gl.LEQUAL,
        [EqualCompare]: _gl.EQUAL,
        [GreaterEqualCompare]: _gl.GEQUAL,
        [GreaterCompare]: _gl.GREATER,
        [NotEqualCompare]: _gl.NOTEQUAL
    };
    function setTextureParameters(textureType, texture) {
        if (texture.type === FloatType && extensions.has("OES_texture_float_linear") === false && (texture.magFilter === LinearFilter || texture.magFilter === LinearMipmapNearestFilter || texture.magFilter === NearestMipmapLinearFilter || texture.magFilter === LinearMipmapLinearFilter || texture.minFilter === LinearFilter || texture.minFilter === LinearMipmapNearestFilter || texture.minFilter === NearestMipmapLinearFilter || texture.minFilter === LinearMipmapLinearFilter)) console.warn("THREE.WebGLRenderer: Unable to use linear filtering with floating point textures. OES_texture_float_linear not supported on this device.");
        _gl.texParameteri(textureType, _gl.TEXTURE_WRAP_S, wrappingToGL[texture.wrapS]);
        _gl.texParameteri(textureType, _gl.TEXTURE_WRAP_T, wrappingToGL[texture.wrapT]);
        if (textureType === _gl.TEXTURE_3D || textureType === _gl.TEXTURE_2D_ARRAY) _gl.texParameteri(textureType, _gl.TEXTURE_WRAP_R, wrappingToGL[texture.wrapR]);
        _gl.texParameteri(textureType, _gl.TEXTURE_MAG_FILTER, filterToGL[texture.magFilter]);
        _gl.texParameteri(textureType, _gl.TEXTURE_MIN_FILTER, filterToGL[texture.minFilter]);
        if (texture.compareFunction) {
            _gl.texParameteri(textureType, _gl.TEXTURE_COMPARE_MODE, _gl.COMPARE_REF_TO_TEXTURE);
            _gl.texParameteri(textureType, _gl.TEXTURE_COMPARE_FUNC, compareToGL[texture.compareFunction]);
        }
        if (extensions.has("EXT_texture_filter_anisotropic") === true) {
            if (texture.magFilter === NearestFilter) return;
            if (texture.minFilter !== NearestMipmapLinearFilter && texture.minFilter !== LinearMipmapLinearFilter) return;
            if (texture.type === FloatType && extensions.has("OES_texture_float_linear") === false) return; // verify extension
            if (texture.anisotropy > 1 || properties.get(texture).__currentAnisotropy) {
                const extension = extensions.get("EXT_texture_filter_anisotropic");
                _gl.texParameterf(textureType, extension.TEXTURE_MAX_ANISOTROPY_EXT, Math.min(texture.anisotropy, capabilities.getMaxAnisotropy()));
                properties.get(texture).__currentAnisotropy = texture.anisotropy;
            }
        }
    }
    function initTexture(textureProperties, texture) {
        let forceUpload = false;
        if (textureProperties.__webglInit === undefined) {
            textureProperties.__webglInit = true;
            texture.addEventListener("dispose", onTextureDispose);
        }
        // create Source <-> WebGLTextures mapping if necessary
        const source = texture.source;
        let webglTextures = _sources.get(source);
        if (webglTextures === undefined) {
            webglTextures = {};
            _sources.set(source, webglTextures);
        }
        // check if there is already a WebGLTexture object for the given texture parameters
        const textureCacheKey = getTextureCacheKey(texture);
        if (textureCacheKey !== textureProperties.__cacheKey) {
            // if not, create a new instance of WebGLTexture
            if (webglTextures[textureCacheKey] === undefined) {
                // create new entry
                webglTextures[textureCacheKey] = {
                    texture: _gl.createTexture(),
                    usedTimes: 0
                };
                info.memory.textures++;
                // when a new instance of WebGLTexture was created, a texture upload is required
                // even if the image contents are identical
                forceUpload = true;
            }
            webglTextures[textureCacheKey].usedTimes++;
            // every time the texture cache key changes, it's necessary to check if an instance of
            // WebGLTexture can be deleted in order to avoid a memory leak.
            const webglTexture = webglTextures[textureProperties.__cacheKey];
            if (webglTexture !== undefined) {
                webglTextures[textureProperties.__cacheKey].usedTimes--;
                if (webglTexture.usedTimes === 0) deleteTexture(texture);
            }
            // store references to cache key and WebGLTexture object
            textureProperties.__cacheKey = textureCacheKey;
            textureProperties.__webglTexture = webglTextures[textureCacheKey].texture;
        }
        return forceUpload;
    }
    function uploadTexture(textureProperties, texture, slot) {
        let textureType = _gl.TEXTURE_2D;
        if (texture.isDataArrayTexture || texture.isCompressedArrayTexture) textureType = _gl.TEXTURE_2D_ARRAY;
        if (texture.isData3DTexture) textureType = _gl.TEXTURE_3D;
        const forceUpload = initTexture(textureProperties, texture);
        const source = texture.source;
        state.bindTexture(textureType, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);
        const sourceProperties = properties.get(source);
        if (source.version !== sourceProperties.__version || forceUpload === true) {
            state.activeTexture(_gl.TEXTURE0 + slot);
            const workingPrimaries = ColorManagement.getPrimaries(ColorManagement.workingColorSpace);
            const texturePrimaries = texture.colorSpace === NoColorSpace ? null : ColorManagement.getPrimaries(texture.colorSpace);
            const unpackConversion = texture.colorSpace === NoColorSpace || workingPrimaries === texturePrimaries ? _gl.NONE : _gl.BROWSER_DEFAULT_WEBGL;
            _gl.pixelStorei(_gl.UNPACK_FLIP_Y_WEBGL, texture.flipY);
            _gl.pixelStorei(_gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, texture.premultiplyAlpha);
            _gl.pixelStorei(_gl.UNPACK_ALIGNMENT, texture.unpackAlignment);
            _gl.pixelStorei(_gl.UNPACK_COLORSPACE_CONVERSION_WEBGL, unpackConversion);
            let image = resizeImage(texture.image, false, capabilities.maxTextureSize);
            image = verifyColorSpace(texture, image);
            const glFormat = utils.convert(texture.format, texture.colorSpace);
            const glType = utils.convert(texture.type);
            let glInternalFormat = getInternalFormat(texture.internalFormat, glFormat, glType, texture.colorSpace, texture.isVideoTexture);
            setTextureParameters(textureType, texture);
            let mipmap;
            const mipmaps = texture.mipmaps;
            const useTexStorage = texture.isVideoTexture !== true;
            const allocateMemory = sourceProperties.__version === undefined || forceUpload === true;
            const dataReady = source.dataReady;
            const levels = getMipLevels(texture, image);
            if (texture.isDepthTexture) {
                glInternalFormat = getInternalDepthFormat(texture.format === DepthStencilFormat, texture.type);
                //
                if (allocateMemory) {
                    if (useTexStorage) state.texStorage2D(_gl.TEXTURE_2D, 1, glInternalFormat, image.width, image.height);
                    else state.texImage2D(_gl.TEXTURE_2D, 0, glInternalFormat, image.width, image.height, 0, glFormat, glType, null);
                }
            } else if (texture.isDataTexture) {
                // use manually created mipmaps if available
                // if there are no manual mipmaps
                // set 0 level mipmap and then use GL to generate other mipmap levels
                if (mipmaps.length > 0) {
                    if (useTexStorage && allocateMemory) state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, mipmaps[0].width, mipmaps[0].height);
                    for(let i = 0, il = mipmaps.length; i < il; i++){
                        mipmap = mipmaps[i];
                        if (useTexStorage) {
                            if (dataReady) state.texSubImage2D(_gl.TEXTURE_2D, i, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data);
                        } else state.texImage2D(_gl.TEXTURE_2D, i, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data);
                    }
                    texture.generateMipmaps = false;
                } else if (useTexStorage) {
                    if (allocateMemory) state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, image.width, image.height);
                    if (dataReady) state.texSubImage2D(_gl.TEXTURE_2D, 0, 0, 0, image.width, image.height, glFormat, glType, image.data);
                } else state.texImage2D(_gl.TEXTURE_2D, 0, glInternalFormat, image.width, image.height, 0, glFormat, glType, image.data);
            } else if (texture.isCompressedTexture) {
                if (texture.isCompressedArrayTexture) {
                    if (useTexStorage && allocateMemory) state.texStorage3D(_gl.TEXTURE_2D_ARRAY, levels, glInternalFormat, mipmaps[0].width, mipmaps[0].height, image.depth);
                    for(let i = 0, il = mipmaps.length; i < il; i++){
                        mipmap = mipmaps[i];
                        if (texture.format !== RGBAFormat) {
                            if (glFormat !== null) {
                                if (useTexStorage) {
                                    if (dataReady) {
                                        if (texture.layerUpdates.size > 0) {
                                            const layerByteLength = getByteLength(mipmap.width, mipmap.height, texture.format, texture.type);
                                            for (const layerIndex of texture.layerUpdates){
                                                const layerData = mipmap.data.subarray(layerIndex * layerByteLength / mipmap.data.BYTES_PER_ELEMENT, (layerIndex + 1) * layerByteLength / mipmap.data.BYTES_PER_ELEMENT);
                                                state.compressedTexSubImage3D(_gl.TEXTURE_2D_ARRAY, i, 0, 0, layerIndex, mipmap.width, mipmap.height, 1, glFormat, layerData, 0, 0);
                                            }
                                            texture.clearLayerUpdates();
                                        } else state.compressedTexSubImage3D(_gl.TEXTURE_2D_ARRAY, i, 0, 0, 0, mipmap.width, mipmap.height, image.depth, glFormat, mipmap.data, 0, 0);
                                    }
                                } else state.compressedTexImage3D(_gl.TEXTURE_2D_ARRAY, i, glInternalFormat, mipmap.width, mipmap.height, image.depth, 0, mipmap.data, 0, 0);
                            } else console.warn("THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .uploadTexture()");
                        } else {
                            if (useTexStorage) {
                                if (dataReady) state.texSubImage3D(_gl.TEXTURE_2D_ARRAY, i, 0, 0, 0, mipmap.width, mipmap.height, image.depth, glFormat, glType, mipmap.data);
                            } else state.texImage3D(_gl.TEXTURE_2D_ARRAY, i, glInternalFormat, mipmap.width, mipmap.height, image.depth, 0, glFormat, glType, mipmap.data);
                        }
                    }
                } else {
                    if (useTexStorage && allocateMemory) state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, mipmaps[0].width, mipmaps[0].height);
                    for(let i = 0, il = mipmaps.length; i < il; i++){
                        mipmap = mipmaps[i];
                        if (texture.format !== RGBAFormat) {
                            if (glFormat !== null) {
                                if (useTexStorage) {
                                    if (dataReady) state.compressedTexSubImage2D(_gl.TEXTURE_2D, i, 0, 0, mipmap.width, mipmap.height, glFormat, mipmap.data);
                                } else state.compressedTexImage2D(_gl.TEXTURE_2D, i, glInternalFormat, mipmap.width, mipmap.height, 0, mipmap.data);
                            } else console.warn("THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .uploadTexture()");
                        } else {
                            if (useTexStorage) {
                                if (dataReady) state.texSubImage2D(_gl.TEXTURE_2D, i, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data);
                            } else state.texImage2D(_gl.TEXTURE_2D, i, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data);
                        }
                    }
                }
            } else if (texture.isDataArrayTexture) {
                if (useTexStorage) {
                    if (allocateMemory) state.texStorage3D(_gl.TEXTURE_2D_ARRAY, levels, glInternalFormat, image.width, image.height, image.depth);
                    if (dataReady) {
                        if (texture.layerUpdates.size > 0) {
                            const layerByteLength = getByteLength(image.width, image.height, texture.format, texture.type);
                            for (const layerIndex of texture.layerUpdates){
                                const layerData = image.data.subarray(layerIndex * layerByteLength / image.data.BYTES_PER_ELEMENT, (layerIndex + 1) * layerByteLength / image.data.BYTES_PER_ELEMENT);
                                state.texSubImage3D(_gl.TEXTURE_2D_ARRAY, 0, 0, 0, layerIndex, image.width, image.height, 1, glFormat, glType, layerData);
                            }
                            texture.clearLayerUpdates();
                        } else state.texSubImage3D(_gl.TEXTURE_2D_ARRAY, 0, 0, 0, 0, image.width, image.height, image.depth, glFormat, glType, image.data);
                    }
                } else state.texImage3D(_gl.TEXTURE_2D_ARRAY, 0, glInternalFormat, image.width, image.height, image.depth, 0, glFormat, glType, image.data);
            } else if (texture.isData3DTexture) {
                if (useTexStorage) {
                    if (allocateMemory) state.texStorage3D(_gl.TEXTURE_3D, levels, glInternalFormat, image.width, image.height, image.depth);
                    if (dataReady) state.texSubImage3D(_gl.TEXTURE_3D, 0, 0, 0, 0, image.width, image.height, image.depth, glFormat, glType, image.data);
                } else state.texImage3D(_gl.TEXTURE_3D, 0, glInternalFormat, image.width, image.height, image.depth, 0, glFormat, glType, image.data);
            } else if (texture.isFramebufferTexture) {
                if (allocateMemory) {
                    if (useTexStorage) state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, image.width, image.height);
                    else {
                        let width = image.width, height = image.height;
                        for(let i = 0; i < levels; i++){
                            state.texImage2D(_gl.TEXTURE_2D, i, glInternalFormat, width, height, 0, glFormat, glType, null);
                            width >>= 1;
                            height >>= 1;
                        }
                    }
                }
            } else {
                // regular Texture (image, video, canvas)
                // use manually created mipmaps if available
                // if there are no manual mipmaps
                // set 0 level mipmap and then use GL to generate other mipmap levels
                if (mipmaps.length > 0) {
                    if (useTexStorage && allocateMemory) {
                        const dimensions = getDimensions(mipmaps[0]);
                        state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, dimensions.width, dimensions.height);
                    }
                    for(let i = 0, il = mipmaps.length; i < il; i++){
                        mipmap = mipmaps[i];
                        if (useTexStorage) {
                            if (dataReady) state.texSubImage2D(_gl.TEXTURE_2D, i, 0, 0, glFormat, glType, mipmap);
                        } else state.texImage2D(_gl.TEXTURE_2D, i, glInternalFormat, glFormat, glType, mipmap);
                    }
                    texture.generateMipmaps = false;
                } else if (useTexStorage) {
                    if (allocateMemory) {
                        const dimensions = getDimensions(image);
                        state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, dimensions.width, dimensions.height);
                    }
                    if (dataReady) state.texSubImage2D(_gl.TEXTURE_2D, 0, 0, 0, glFormat, glType, image);
                } else state.texImage2D(_gl.TEXTURE_2D, 0, glInternalFormat, glFormat, glType, image);
            }
            if (textureNeedsGenerateMipmaps(texture)) generateMipmap(textureType);
            sourceProperties.__version = source.version;
            if (texture.onUpdate) texture.onUpdate(texture);
        }
        textureProperties.__version = texture.version;
    }
    function uploadCubeTexture(textureProperties, texture, slot) {
        if (texture.image.length !== 6) return;
        const forceUpload = initTexture(textureProperties, texture);
        const source = texture.source;
        state.bindTexture(_gl.TEXTURE_CUBE_MAP, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);
        const sourceProperties = properties.get(source);
        if (source.version !== sourceProperties.__version || forceUpload === true) {
            state.activeTexture(_gl.TEXTURE0 + slot);
            const workingPrimaries = ColorManagement.getPrimaries(ColorManagement.workingColorSpace);
            const texturePrimaries = texture.colorSpace === NoColorSpace ? null : ColorManagement.getPrimaries(texture.colorSpace);
            const unpackConversion = texture.colorSpace === NoColorSpace || workingPrimaries === texturePrimaries ? _gl.NONE : _gl.BROWSER_DEFAULT_WEBGL;
            _gl.pixelStorei(_gl.UNPACK_FLIP_Y_WEBGL, texture.flipY);
            _gl.pixelStorei(_gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, texture.premultiplyAlpha);
            _gl.pixelStorei(_gl.UNPACK_ALIGNMENT, texture.unpackAlignment);
            _gl.pixelStorei(_gl.UNPACK_COLORSPACE_CONVERSION_WEBGL, unpackConversion);
            const isCompressed = texture.isCompressedTexture || texture.image[0].isCompressedTexture;
            const isDataTexture = texture.image[0] && texture.image[0].isDataTexture;
            const cubeImage = [];
            for(let i = 0; i < 6; i++){
                if (!isCompressed && !isDataTexture) cubeImage[i] = resizeImage(texture.image[i], true, capabilities.maxCubemapSize);
                else cubeImage[i] = isDataTexture ? texture.image[i].image : texture.image[i];
                cubeImage[i] = verifyColorSpace(texture, cubeImage[i]);
            }
            const image = cubeImage[0], glFormat = utils.convert(texture.format, texture.colorSpace), glType = utils.convert(texture.type), glInternalFormat = getInternalFormat(texture.internalFormat, glFormat, glType, texture.colorSpace);
            const useTexStorage = texture.isVideoTexture !== true;
            const allocateMemory = sourceProperties.__version === undefined || forceUpload === true;
            const dataReady = source.dataReady;
            let levels = getMipLevels(texture, image);
            setTextureParameters(_gl.TEXTURE_CUBE_MAP, texture);
            let mipmaps;
            if (isCompressed) {
                if (useTexStorage && allocateMemory) state.texStorage2D(_gl.TEXTURE_CUBE_MAP, levels, glInternalFormat, image.width, image.height);
                for(let i = 0; i < 6; i++){
                    mipmaps = cubeImage[i].mipmaps;
                    for(let j = 0; j < mipmaps.length; j++){
                        const mipmap = mipmaps[j];
                        if (texture.format !== RGBAFormat) {
                            if (glFormat !== null) {
                                if (useTexStorage) {
                                    if (dataReady) state.compressedTexSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, 0, 0, mipmap.width, mipmap.height, glFormat, mipmap.data);
                                } else state.compressedTexImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, glInternalFormat, mipmap.width, mipmap.height, 0, mipmap.data);
                            } else console.warn("THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .setTextureCube()");
                        } else {
                            if (useTexStorage) {
                                if (dataReady) state.texSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data);
                            } else state.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data);
                        }
                    }
                }
            } else {
                mipmaps = texture.mipmaps;
                if (useTexStorage && allocateMemory) {
                    // TODO: Uniformly handle mipmap definitions
                    // Normal textures and compressed cube textures define base level + mips with their mipmap array
                    // Uncompressed cube textures use their mipmap array only for mips (no base level)
                    if (mipmaps.length > 0) levels++;
                    const dimensions = getDimensions(cubeImage[0]);
                    state.texStorage2D(_gl.TEXTURE_CUBE_MAP, levels, glInternalFormat, dimensions.width, dimensions.height);
                }
                for(let i = 0; i < 6; i++)if (isDataTexture) {
                    if (useTexStorage) {
                        if (dataReady) state.texSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, 0, 0, cubeImage[i].width, cubeImage[i].height, glFormat, glType, cubeImage[i].data);
                    } else state.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, glInternalFormat, cubeImage[i].width, cubeImage[i].height, 0, glFormat, glType, cubeImage[i].data);
                    for(let j = 0; j < mipmaps.length; j++){
                        const mipmap = mipmaps[j];
                        const mipmapImage = mipmap.image[i].image;
                        if (useTexStorage) {
                            if (dataReady) state.texSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, 0, 0, mipmapImage.width, mipmapImage.height, glFormat, glType, mipmapImage.data);
                        } else state.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, glInternalFormat, mipmapImage.width, mipmapImage.height, 0, glFormat, glType, mipmapImage.data);
                    }
                } else {
                    if (useTexStorage) {
                        if (dataReady) state.texSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, 0, 0, glFormat, glType, cubeImage[i]);
                    } else state.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, glInternalFormat, glFormat, glType, cubeImage[i]);
                    for(let j = 0; j < mipmaps.length; j++){
                        const mipmap = mipmaps[j];
                        if (useTexStorage) {
                            if (dataReady) state.texSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, 0, 0, glFormat, glType, mipmap.image[i]);
                        } else state.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, glInternalFormat, glFormat, glType, mipmap.image[i]);
                    }
                }
            }
            if (textureNeedsGenerateMipmaps(texture)) // We assume images for cube map have the same size.
            generateMipmap(_gl.TEXTURE_CUBE_MAP);
            sourceProperties.__version = source.version;
            if (texture.onUpdate) texture.onUpdate(texture);
        }
        textureProperties.__version = texture.version;
    }
    // Render targets
    // Setup storage for target texture and bind it to correct framebuffer
    function setupFrameBufferTexture(framebuffer, renderTarget, texture, attachment, textureTarget, level) {
        const glFormat = utils.convert(texture.format, texture.colorSpace);
        const glType = utils.convert(texture.type);
        const glInternalFormat = getInternalFormat(texture.internalFormat, glFormat, glType, texture.colorSpace);
        const renderTargetProperties = properties.get(renderTarget);
        if (!renderTargetProperties.__hasExternalTextures) {
            const width = Math.max(1, renderTarget.width >> level);
            const height = Math.max(1, renderTarget.height >> level);
            if (textureTarget === _gl.TEXTURE_3D || textureTarget === _gl.TEXTURE_2D_ARRAY) state.texImage3D(textureTarget, level, glInternalFormat, width, height, renderTarget.depth, 0, glFormat, glType, null);
            else state.texImage2D(textureTarget, level, glInternalFormat, width, height, 0, glFormat, glType, null);
        }
        state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);
        if (useMultisampledRTT(renderTarget)) multisampledRTTExt.framebufferTexture2DMultisampleEXT(_gl.FRAMEBUFFER, attachment, textureTarget, properties.get(texture).__webglTexture, 0, getRenderTargetSamples(renderTarget));
        else if (textureTarget === _gl.TEXTURE_2D || textureTarget >= _gl.TEXTURE_CUBE_MAP_POSITIVE_X && textureTarget <= _gl.TEXTURE_CUBE_MAP_NEGATIVE_Z) _gl.framebufferTexture2D(_gl.FRAMEBUFFER, attachment, textureTarget, properties.get(texture).__webglTexture, level);
        state.bindFramebuffer(_gl.FRAMEBUFFER, null);
    }
    // Setup storage for internal depth/stencil buffers and bind to correct framebuffer
    function setupRenderBufferStorage(renderbuffer, renderTarget, isMultisample) {
        _gl.bindRenderbuffer(_gl.RENDERBUFFER, renderbuffer);
        if (renderTarget.depthBuffer) {
            // retrieve the depth attachment types
            const depthTexture = renderTarget.depthTexture;
            const depthType = depthTexture && depthTexture.isDepthTexture ? depthTexture.type : null;
            const glInternalFormat = getInternalDepthFormat(renderTarget.stencilBuffer, depthType);
            const glAttachmentType = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;
            // set up the attachment
            const samples = getRenderTargetSamples(renderTarget);
            const isUseMultisampledRTT = useMultisampledRTT(renderTarget);
            if (isUseMultisampledRTT) multisampledRTTExt.renderbufferStorageMultisampleEXT(_gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height);
            else if (isMultisample) _gl.renderbufferStorageMultisample(_gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height);
            else _gl.renderbufferStorage(_gl.RENDERBUFFER, glInternalFormat, renderTarget.width, renderTarget.height);
            _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, glAttachmentType, _gl.RENDERBUFFER, renderbuffer);
        } else {
            const textures = renderTarget.textures;
            for(let i = 0; i < textures.length; i++){
                const texture = textures[i];
                const glFormat = utils.convert(texture.format, texture.colorSpace);
                const glType = utils.convert(texture.type);
                const glInternalFormat = getInternalFormat(texture.internalFormat, glFormat, glType, texture.colorSpace);
                const samples = getRenderTargetSamples(renderTarget);
                if (isMultisample && useMultisampledRTT(renderTarget) === false) _gl.renderbufferStorageMultisample(_gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height);
                else if (useMultisampledRTT(renderTarget)) multisampledRTTExt.renderbufferStorageMultisampleEXT(_gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height);
                else _gl.renderbufferStorage(_gl.RENDERBUFFER, glInternalFormat, renderTarget.width, renderTarget.height);
            }
        }
        _gl.bindRenderbuffer(_gl.RENDERBUFFER, null);
    }
    // Setup resources for a Depth Texture for a FBO (needs an extension)
    function setupDepthTexture(framebuffer, renderTarget) {
        const isCube = renderTarget && renderTarget.isWebGLCubeRenderTarget;
        if (isCube) throw new Error("Depth Texture with cube render targets is not supported");
        state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);
        if (!(renderTarget.depthTexture && renderTarget.depthTexture.isDepthTexture)) throw new Error("renderTarget.depthTexture must be an instance of THREE.DepthTexture");
        // upload an empty depth texture with framebuffer size
        if (!properties.get(renderTarget.depthTexture).__webglTexture || renderTarget.depthTexture.image.width !== renderTarget.width || renderTarget.depthTexture.image.height !== renderTarget.height) {
            renderTarget.depthTexture.image.width = renderTarget.width;
            renderTarget.depthTexture.image.height = renderTarget.height;
            renderTarget.depthTexture.needsUpdate = true;
        }
        setTexture2D(renderTarget.depthTexture, 0);
        const webglDepthTexture = properties.get(renderTarget.depthTexture).__webglTexture;
        const samples = getRenderTargetSamples(renderTarget);
        if (renderTarget.depthTexture.format === DepthFormat) {
            if (useMultisampledRTT(renderTarget)) multisampledRTTExt.framebufferTexture2DMultisampleEXT(_gl.FRAMEBUFFER, _gl.DEPTH_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0, samples);
            else _gl.framebufferTexture2D(_gl.FRAMEBUFFER, _gl.DEPTH_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0);
        } else if (renderTarget.depthTexture.format === DepthStencilFormat) {
            if (useMultisampledRTT(renderTarget)) multisampledRTTExt.framebufferTexture2DMultisampleEXT(_gl.FRAMEBUFFER, _gl.DEPTH_STENCIL_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0, samples);
            else _gl.framebufferTexture2D(_gl.FRAMEBUFFER, _gl.DEPTH_STENCIL_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0);
        } else throw new Error("Unknown depthTexture format");
    }
    // Setup GL resources for a non-texture depth buffer
    function setupDepthRenderbuffer(renderTarget) {
        const renderTargetProperties = properties.get(renderTarget);
        const isCube = renderTarget.isWebGLCubeRenderTarget === true;
        if (renderTarget.depthTexture && !renderTargetProperties.__autoAllocateDepthBuffer) {
            if (isCube) throw new Error("target.depthTexture not supported in Cube render targets");
            setupDepthTexture(renderTargetProperties.__webglFramebuffer, renderTarget);
        } else if (isCube) {
            renderTargetProperties.__webglDepthbuffer = [];
            for(let i = 0; i < 6; i++){
                state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer[i]);
                renderTargetProperties.__webglDepthbuffer[i] = _gl.createRenderbuffer();
                setupRenderBufferStorage(renderTargetProperties.__webglDepthbuffer[i], renderTarget, false);
            }
        } else {
            state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer);
            renderTargetProperties.__webglDepthbuffer = _gl.createRenderbuffer();
            setupRenderBufferStorage(renderTargetProperties.__webglDepthbuffer, renderTarget, false);
        }
        state.bindFramebuffer(_gl.FRAMEBUFFER, null);
    }
    // rebind framebuffer with external textures
    function rebindTextures(renderTarget, colorTexture, depthTexture) {
        const renderTargetProperties = properties.get(renderTarget);
        if (colorTexture !== undefined) setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer, renderTarget, renderTarget.texture, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_2D, 0);
        if (depthTexture !== undefined) setupDepthRenderbuffer(renderTarget);
    }
    // Set up GL resources for the render target
    function setupRenderTarget(renderTarget) {
        const texture = renderTarget.texture;
        const renderTargetProperties = properties.get(renderTarget);
        const textureProperties = properties.get(texture);
        renderTarget.addEventListener("dispose", onRenderTargetDispose);
        const textures = renderTarget.textures;
        const isCube = renderTarget.isWebGLCubeRenderTarget === true;
        const isMultipleRenderTargets = textures.length > 1;
        if (!isMultipleRenderTargets) {
            if (textureProperties.__webglTexture === undefined) textureProperties.__webglTexture = _gl.createTexture();
            textureProperties.__version = texture.version;
            info.memory.textures++;
        }
        // Setup framebuffer
        if (isCube) {
            renderTargetProperties.__webglFramebuffer = [];
            for(let i = 0; i < 6; i++)if (texture.mipmaps && texture.mipmaps.length > 0) {
                renderTargetProperties.__webglFramebuffer[i] = [];
                for(let level = 0; level < texture.mipmaps.length; level++)renderTargetProperties.__webglFramebuffer[i][level] = _gl.createFramebuffer();
            } else renderTargetProperties.__webglFramebuffer[i] = _gl.createFramebuffer();
        } else {
            if (texture.mipmaps && texture.mipmaps.length > 0) {
                renderTargetProperties.__webglFramebuffer = [];
                for(let level = 0; level < texture.mipmaps.length; level++)renderTargetProperties.__webglFramebuffer[level] = _gl.createFramebuffer();
            } else renderTargetProperties.__webglFramebuffer = _gl.createFramebuffer();
            if (isMultipleRenderTargets) for(let i = 0, il = textures.length; i < il; i++){
                const attachmentProperties = properties.get(textures[i]);
                if (attachmentProperties.__webglTexture === undefined) {
                    attachmentProperties.__webglTexture = _gl.createTexture();
                    info.memory.textures++;
                }
            }
            if (renderTarget.samples > 0 && useMultisampledRTT(renderTarget) === false) {
                renderTargetProperties.__webglMultisampledFramebuffer = _gl.createFramebuffer();
                renderTargetProperties.__webglColorRenderbuffer = [];
                state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer);
                for(let i = 0; i < textures.length; i++){
                    const texture = textures[i];
                    renderTargetProperties.__webglColorRenderbuffer[i] = _gl.createRenderbuffer();
                    _gl.bindRenderbuffer(_gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[i]);
                    const glFormat = utils.convert(texture.format, texture.colorSpace);
                    const glType = utils.convert(texture.type);
                    const glInternalFormat = getInternalFormat(texture.internalFormat, glFormat, glType, texture.colorSpace, renderTarget.isXRRenderTarget === true);
                    const samples = getRenderTargetSamples(renderTarget);
                    _gl.renderbufferStorageMultisample(_gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height);
                    _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[i]);
                }
                _gl.bindRenderbuffer(_gl.RENDERBUFFER, null);
                if (renderTarget.depthBuffer) {
                    renderTargetProperties.__webglDepthRenderbuffer = _gl.createRenderbuffer();
                    setupRenderBufferStorage(renderTargetProperties.__webglDepthRenderbuffer, renderTarget, true);
                }
                state.bindFramebuffer(_gl.FRAMEBUFFER, null);
            }
        }
        // Setup color buffer
        if (isCube) {
            state.bindTexture(_gl.TEXTURE_CUBE_MAP, textureProperties.__webglTexture);
            setTextureParameters(_gl.TEXTURE_CUBE_MAP, texture);
            for(let i = 0; i < 6; i++){
                if (texture.mipmaps && texture.mipmaps.length > 0) for(let level = 0; level < texture.mipmaps.length; level++)setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer[i][level], renderTarget, texture, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, level);
                else setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer[i], renderTarget, texture, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0);
            }
            if (textureNeedsGenerateMipmaps(texture)) generateMipmap(_gl.TEXTURE_CUBE_MAP);
            state.unbindTexture();
        } else if (isMultipleRenderTargets) {
            for(let i = 0, il = textures.length; i < il; i++){
                const attachment = textures[i];
                const attachmentProperties = properties.get(attachment);
                state.bindTexture(_gl.TEXTURE_2D, attachmentProperties.__webglTexture);
                setTextureParameters(_gl.TEXTURE_2D, attachment);
                setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer, renderTarget, attachment, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, 0);
                if (textureNeedsGenerateMipmaps(attachment)) generateMipmap(_gl.TEXTURE_2D);
            }
            state.unbindTexture();
        } else {
            let glTextureType = _gl.TEXTURE_2D;
            if (renderTarget.isWebGL3DRenderTarget || renderTarget.isWebGLArrayRenderTarget) glTextureType = renderTarget.isWebGL3DRenderTarget ? _gl.TEXTURE_3D : _gl.TEXTURE_2D_ARRAY;
            state.bindTexture(glTextureType, textureProperties.__webglTexture);
            setTextureParameters(glTextureType, texture);
            if (texture.mipmaps && texture.mipmaps.length > 0) for(let level = 0; level < texture.mipmaps.length; level++)setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer[level], renderTarget, texture, _gl.COLOR_ATTACHMENT0, glTextureType, level);
            else setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer, renderTarget, texture, _gl.COLOR_ATTACHMENT0, glTextureType, 0);
            if (textureNeedsGenerateMipmaps(texture)) generateMipmap(glTextureType);
            state.unbindTexture();
        }
        // Setup depth and stencil buffers
        if (renderTarget.depthBuffer) setupDepthRenderbuffer(renderTarget);
    }
    function updateRenderTargetMipmap(renderTarget) {
        const textures = renderTarget.textures;
        for(let i = 0, il = textures.length; i < il; i++){
            const texture = textures[i];
            if (textureNeedsGenerateMipmaps(texture)) {
                const target = renderTarget.isWebGLCubeRenderTarget ? _gl.TEXTURE_CUBE_MAP : _gl.TEXTURE_2D;
                const webglTexture = properties.get(texture).__webglTexture;
                state.bindTexture(target, webglTexture);
                generateMipmap(target);
                state.unbindTexture();
            }
        }
    }
    const invalidationArrayRead = [];
    const invalidationArrayDraw = [];
    function updateMultisampleRenderTarget(renderTarget) {
        if (renderTarget.samples > 0) {
            if (useMultisampledRTT(renderTarget) === false) {
                const textures = renderTarget.textures;
                const width = renderTarget.width;
                const height = renderTarget.height;
                let mask = _gl.COLOR_BUFFER_BIT;
                const depthStyle = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;
                const renderTargetProperties = properties.get(renderTarget);
                const isMultipleRenderTargets = textures.length > 1;
                // If MRT we need to remove FBO attachments
                if (isMultipleRenderTargets) for(let i = 0; i < textures.length; i++){
                    state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer);
                    _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.RENDERBUFFER, null);
                    state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer);
                    _gl.framebufferTexture2D(_gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, null, 0);
                }
                state.bindFramebuffer(_gl.READ_FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer);
                state.bindFramebuffer(_gl.DRAW_FRAMEBUFFER, renderTargetProperties.__webglFramebuffer);
                for(let i = 0; i < textures.length; i++){
                    if (renderTarget.resolveDepthBuffer) {
                        if (renderTarget.depthBuffer) mask |= _gl.DEPTH_BUFFER_BIT;
                        // resolving stencil is slow with a D3D backend. disable it for all transmission render targets (see #27799)
                        if (renderTarget.stencilBuffer && renderTarget.resolveStencilBuffer) mask |= _gl.STENCIL_BUFFER_BIT;
                    }
                    if (isMultipleRenderTargets) {
                        _gl.framebufferRenderbuffer(_gl.READ_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[i]);
                        const webglTexture = properties.get(textures[i]).__webglTexture;
                        _gl.framebufferTexture2D(_gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_2D, webglTexture, 0);
                    }
                    _gl.blitFramebuffer(0, 0, width, height, 0, 0, width, height, mask, _gl.NEAREST);
                    if (supportsInvalidateFramebuffer === true) {
                        invalidationArrayRead.length = 0;
                        invalidationArrayDraw.length = 0;
                        invalidationArrayRead.push(_gl.COLOR_ATTACHMENT0 + i);
                        if (renderTarget.depthBuffer && renderTarget.resolveDepthBuffer === false) {
                            invalidationArrayRead.push(depthStyle);
                            invalidationArrayDraw.push(depthStyle);
                            _gl.invalidateFramebuffer(_gl.DRAW_FRAMEBUFFER, invalidationArrayDraw);
                        }
                        _gl.invalidateFramebuffer(_gl.READ_FRAMEBUFFER, invalidationArrayRead);
                    }
                }
                state.bindFramebuffer(_gl.READ_FRAMEBUFFER, null);
                state.bindFramebuffer(_gl.DRAW_FRAMEBUFFER, null);
                // If MRT since pre-blit we removed the FBO we need to reconstruct the attachments
                if (isMultipleRenderTargets) for(let i = 0; i < textures.length; i++){
                    state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer);
                    _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[i]);
                    const webglTexture = properties.get(textures[i]).__webglTexture;
                    state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer);
                    _gl.framebufferTexture2D(_gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, webglTexture, 0);
                }
                state.bindFramebuffer(_gl.DRAW_FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer);
            } else if (renderTarget.depthBuffer && renderTarget.resolveDepthBuffer === false && supportsInvalidateFramebuffer) {
                const depthStyle = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;
                _gl.invalidateFramebuffer(_gl.DRAW_FRAMEBUFFER, [
                    depthStyle
                ]);
            }
        }
    }
    function getRenderTargetSamples(renderTarget) {
        return Math.min(capabilities.maxSamples, renderTarget.samples);
    }
    function useMultisampledRTT(renderTarget) {
        const renderTargetProperties = properties.get(renderTarget);
        return renderTarget.samples > 0 && extensions.has("WEBGL_multisampled_render_to_texture") === true && renderTargetProperties.__useRenderToTexture !== false;
    }
    function updateVideoTexture(texture) {
        const frame = info.render.frame;
        // Check the last frame we updated the VideoTexture
        if (_videoTextures.get(texture) !== frame) {
            _videoTextures.set(texture, frame);
            texture.update();
        }
    }
    function verifyColorSpace(texture, image) {
        const colorSpace1 = texture.colorSpace;
        const format = texture.format;
        const type = texture.type;
        if (texture.isCompressedTexture === true || texture.isVideoTexture === true) return image;
        if (colorSpace1 !== LinearSRGBColorSpace && colorSpace1 !== NoColorSpace) {
            // sRGB
            if (ColorManagement.getTransfer(colorSpace1) === SRGBTransfer) // in WebGL 2 uncompressed textures can only be sRGB encoded if they have the RGBA8 format
            {
                if (format !== RGBAFormat || type !== UnsignedByteType) console.warn("THREE.WebGLTextures: sRGB encoded textures have to use RGBAFormat and UnsignedByteType.");
            } else console.error("THREE.WebGLTextures: Unsupported texture color space:", colorSpace1);
        }
        return image;
    }
    function getDimensions(image) {
        if (typeof HTMLImageElement !== "undefined" && image instanceof HTMLImageElement) {
            // if intrinsic data are not available, fallback to width/height
            _imageDimensions.width = image.naturalWidth || image.width;
            _imageDimensions.height = image.naturalHeight || image.height;
        } else if (typeof VideoFrame !== "undefined" && image instanceof VideoFrame) {
            _imageDimensions.width = image.displayWidth;
            _imageDimensions.height = image.displayHeight;
        } else {
            _imageDimensions.width = image.width;
            _imageDimensions.height = image.height;
        }
        return _imageDimensions;
    }
    //
    this.allocateTextureUnit = allocateTextureUnit;
    this.resetTextureUnits = resetTextureUnits;
    this.setTexture2D = setTexture2D;
    this.setTexture2DArray = setTexture2DArray;
    this.setTexture3D = setTexture3D;
    this.setTextureCube = setTextureCube;
    this.rebindTextures = rebindTextures;
    this.setupRenderTarget = setupRenderTarget;
    this.updateRenderTargetMipmap = updateRenderTargetMipmap;
    this.updateMultisampleRenderTarget = updateMultisampleRenderTarget;
    this.setupDepthRenderbuffer = setupDepthRenderbuffer;
    this.setupFrameBufferTexture = setupFrameBufferTexture;
    this.useMultisampledRTT = useMultisampledRTT;
}
function WebGLUtils(gl, extensions) {
    function convert(p, colorSpace1 = NoColorSpace) {
        let extension;
        const transfer = ColorManagement.getTransfer(colorSpace1);
        if (p === UnsignedByteType) return gl.UNSIGNED_BYTE;
        if (p === UnsignedShort4444Type) return gl.UNSIGNED_SHORT_4_4_4_4;
        if (p === UnsignedShort5551Type) return gl.UNSIGNED_SHORT_5_5_5_1;
        if (p === UnsignedInt5999Type) return gl.UNSIGNED_INT_5_9_9_9_REV;
        if (p === ByteType) return gl.BYTE;
        if (p === ShortType) return gl.SHORT;
        if (p === UnsignedShortType) return gl.UNSIGNED_SHORT;
        if (p === IntType) return gl.INT;
        if (p === UnsignedIntType) return gl.UNSIGNED_INT;
        if (p === FloatType) return gl.FLOAT;
        if (p === HalfFloatType) return gl.HALF_FLOAT;
        if (p === AlphaFormat) return gl.ALPHA;
        if (p === RGBFormat) return gl.RGB;
        if (p === RGBAFormat) return gl.RGBA;
        if (p === LuminanceFormat) return gl.LUMINANCE;
        if (p === LuminanceAlphaFormat) return gl.LUMINANCE_ALPHA;
        if (p === DepthFormat) return gl.DEPTH_COMPONENT;
        if (p === DepthStencilFormat) return gl.DEPTH_STENCIL;
        // WebGL2 formats.
        if (p === RedFormat) return gl.RED;
        if (p === RedIntegerFormat) return gl.RED_INTEGER;
        if (p === RGFormat) return gl.RG;
        if (p === RGIntegerFormat) return gl.RG_INTEGER;
        if (p === RGBAIntegerFormat) return gl.RGBA_INTEGER;
        // S3TC
        if (p === RGB_S3TC_DXT1_Format || p === RGBA_S3TC_DXT1_Format || p === RGBA_S3TC_DXT3_Format || p === RGBA_S3TC_DXT5_Format) {
            if (transfer === SRGBTransfer) {
                extension = extensions.get("WEBGL_compressed_texture_s3tc_srgb");
                if (extension !== null) {
                    if (p === RGB_S3TC_DXT1_Format) return extension.COMPRESSED_SRGB_S3TC_DXT1_EXT;
                    if (p === RGBA_S3TC_DXT1_Format) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT;
                    if (p === RGBA_S3TC_DXT3_Format) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT;
                    if (p === RGBA_S3TC_DXT5_Format) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT;
                } else return null;
            } else {
                extension = extensions.get("WEBGL_compressed_texture_s3tc");
                if (extension !== null) {
                    if (p === RGB_S3TC_DXT1_Format) return extension.COMPRESSED_RGB_S3TC_DXT1_EXT;
                    if (p === RGBA_S3TC_DXT1_Format) return extension.COMPRESSED_RGBA_S3TC_DXT1_EXT;
                    if (p === RGBA_S3TC_DXT3_Format) return extension.COMPRESSED_RGBA_S3TC_DXT3_EXT;
                    if (p === RGBA_S3TC_DXT5_Format) return extension.COMPRESSED_RGBA_S3TC_DXT5_EXT;
                } else return null;
            }
        }
        // PVRTC
        if (p === RGB_PVRTC_4BPPV1_Format || p === RGB_PVRTC_2BPPV1_Format || p === RGBA_PVRTC_4BPPV1_Format || p === RGBA_PVRTC_2BPPV1_Format) {
            extension = extensions.get("WEBGL_compressed_texture_pvrtc");
            if (extension !== null) {
                if (p === RGB_PVRTC_4BPPV1_Format) return extension.COMPRESSED_RGB_PVRTC_4BPPV1_IMG;
                if (p === RGB_PVRTC_2BPPV1_Format) return extension.COMPRESSED_RGB_PVRTC_2BPPV1_IMG;
                if (p === RGBA_PVRTC_4BPPV1_Format) return extension.COMPRESSED_RGBA_PVRTC_4BPPV1_IMG;
                if (p === RGBA_PVRTC_2BPPV1_Format) return extension.COMPRESSED_RGBA_PVRTC_2BPPV1_IMG;
            } else return null;
        }
        // ETC
        if (p === RGB_ETC1_Format || p === RGB_ETC2_Format || p === RGBA_ETC2_EAC_Format) {
            extension = extensions.get("WEBGL_compressed_texture_etc");
            if (extension !== null) {
                if (p === RGB_ETC1_Format || p === RGB_ETC2_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ETC2 : extension.COMPRESSED_RGB8_ETC2;
                if (p === RGBA_ETC2_EAC_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ETC2_EAC : extension.COMPRESSED_RGBA8_ETC2_EAC;
            } else return null;
        }
        // ASTC
        if (p === RGBA_ASTC_4x4_Format || p === RGBA_ASTC_5x4_Format || p === RGBA_ASTC_5x5_Format || p === RGBA_ASTC_6x5_Format || p === RGBA_ASTC_6x6_Format || p === RGBA_ASTC_8x5_Format || p === RGBA_ASTC_8x6_Format || p === RGBA_ASTC_8x8_Format || p === RGBA_ASTC_10x5_Format || p === RGBA_ASTC_10x6_Format || p === RGBA_ASTC_10x8_Format || p === RGBA_ASTC_10x10_Format || p === RGBA_ASTC_12x10_Format || p === RGBA_ASTC_12x12_Format) {
            extension = extensions.get("WEBGL_compressed_texture_astc");
            if (extension !== null) {
                if (p === RGBA_ASTC_4x4_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR : extension.COMPRESSED_RGBA_ASTC_4x4_KHR;
                if (p === RGBA_ASTC_5x4_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR : extension.COMPRESSED_RGBA_ASTC_5x4_KHR;
                if (p === RGBA_ASTC_5x5_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR : extension.COMPRESSED_RGBA_ASTC_5x5_KHR;
                if (p === RGBA_ASTC_6x5_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR : extension.COMPRESSED_RGBA_ASTC_6x5_KHR;
                if (p === RGBA_ASTC_6x6_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR : extension.COMPRESSED_RGBA_ASTC_6x6_KHR;
                if (p === RGBA_ASTC_8x5_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR : extension.COMPRESSED_RGBA_ASTC_8x5_KHR;
                if (p === RGBA_ASTC_8x6_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR : extension.COMPRESSED_RGBA_ASTC_8x6_KHR;
                if (p === RGBA_ASTC_8x8_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR : extension.COMPRESSED_RGBA_ASTC_8x8_KHR;
                if (p === RGBA_ASTC_10x5_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR : extension.COMPRESSED_RGBA_ASTC_10x5_KHR;
                if (p === RGBA_ASTC_10x6_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR : extension.COMPRESSED_RGBA_ASTC_10x6_KHR;
                if (p === RGBA_ASTC_10x8_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x8_KHR : extension.COMPRESSED_RGBA_ASTC_10x8_KHR;
                if (p === RGBA_ASTC_10x10_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR : extension.COMPRESSED_RGBA_ASTC_10x10_KHR;
                if (p === RGBA_ASTC_12x10_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR : extension.COMPRESSED_RGBA_ASTC_12x10_KHR;
                if (p === RGBA_ASTC_12x12_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR : extension.COMPRESSED_RGBA_ASTC_12x12_KHR;
            } else return null;
        }
        // BPTC
        if (p === RGBA_BPTC_Format || p === RGB_BPTC_SIGNED_Format || p === RGB_BPTC_UNSIGNED_Format) {
            extension = extensions.get("EXT_texture_compression_bptc");
            if (extension !== null) {
                if (p === RGBA_BPTC_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT : extension.COMPRESSED_RGBA_BPTC_UNORM_EXT;
                if (p === RGB_BPTC_SIGNED_Format) return extension.COMPRESSED_RGB_BPTC_SIGNED_FLOAT_EXT;
                if (p === RGB_BPTC_UNSIGNED_Format) return extension.COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_EXT;
            } else return null;
        }
        // RGTC
        if (p === RED_RGTC1_Format || p === SIGNED_RED_RGTC1_Format || p === RED_GREEN_RGTC2_Format || p === SIGNED_RED_GREEN_RGTC2_Format) {
            extension = extensions.get("EXT_texture_compression_rgtc");
            if (extension !== null) {
                if (p === RGBA_BPTC_Format) return extension.COMPRESSED_RED_RGTC1_EXT;
                if (p === SIGNED_RED_RGTC1_Format) return extension.COMPRESSED_SIGNED_RED_RGTC1_EXT;
                if (p === RED_GREEN_RGTC2_Format) return extension.COMPRESSED_RED_GREEN_RGTC2_EXT;
                if (p === SIGNED_RED_GREEN_RGTC2_Format) return extension.COMPRESSED_SIGNED_RED_GREEN_RGTC2_EXT;
            } else return null;
        }
        //
        if (p === UnsignedInt248Type) return gl.UNSIGNED_INT_24_8;
        // if "p" can't be resolved, assume the user defines a WebGL constant as a string (fallback/workaround for packed RGB formats)
        return gl[p] !== undefined ? gl[p] : null;
    }
    return {
        convert: convert
    };
}
class ArrayCamera extends PerspectiveCamera {
    constructor(array = []){
        super();
        this.isArrayCamera = true;
        this.cameras = array;
    }
}
class Group extends Object3D {
    constructor(){
        super();
        this.isGroup = true;
        this.type = "Group";
    }
}
const _moveEvent = {
    type: "move"
};
class WebXRController {
    constructor(){
        this._targetRay = null;
        this._grip = null;
        this._hand = null;
    }
    getHandSpace() {
        if (this._hand === null) {
            this._hand = new Group();
            this._hand.matrixAutoUpdate = false;
            this._hand.visible = false;
            this._hand.joints = {};
            this._hand.inputState = {
                pinching: false
            };
        }
        return this._hand;
    }
    getTargetRaySpace() {
        if (this._targetRay === null) {
            this._targetRay = new Group();
            this._targetRay.matrixAutoUpdate = false;
            this._targetRay.visible = false;
            this._targetRay.hasLinearVelocity = false;
            this._targetRay.linearVelocity = new Vector3();
            this._targetRay.hasAngularVelocity = false;
            this._targetRay.angularVelocity = new Vector3();
        }
        return this._targetRay;
    }
    getGripSpace() {
        if (this._grip === null) {
            this._grip = new Group();
            this._grip.matrixAutoUpdate = false;
            this._grip.visible = false;
            this._grip.hasLinearVelocity = false;
            this._grip.linearVelocity = new Vector3();
            this._grip.hasAngularVelocity = false;
            this._grip.angularVelocity = new Vector3();
        }
        return this._grip;
    }
    dispatchEvent(event) {
        if (this._targetRay !== null) this._targetRay.dispatchEvent(event);
        if (this._grip !== null) this._grip.dispatchEvent(event);
        if (this._hand !== null) this._hand.dispatchEvent(event);
        return this;
    }
    connect(inputSource) {
        if (inputSource && inputSource.hand) {
            const hand = this._hand;
            if (hand) for (const inputjoint of inputSource.hand.values())// Initialize hand with joints when connected
            this._getHandJoint(hand, inputjoint);
        }
        this.dispatchEvent({
            type: "connected",
            data: inputSource
        });
        return this;
    }
    disconnect(inputSource) {
        this.dispatchEvent({
            type: "disconnected",
            data: inputSource
        });
        if (this._targetRay !== null) this._targetRay.visible = false;
        if (this._grip !== null) this._grip.visible = false;
        if (this._hand !== null) this._hand.visible = false;
        return this;
    }
    update(inputSource, frame, referenceSpace) {
        let inputPose = null;
        let gripPose = null;
        let handPose = null;
        const targetRay = this._targetRay;
        const grip = this._grip;
        const hand = this._hand;
        if (inputSource && frame.session.visibilityState !== "visible-blurred") {
            if (hand && inputSource.hand) {
                handPose = true;
                for (const inputjoint of inputSource.hand.values()){
                    // Update the joints groups with the XRJoint poses
                    const jointPose = frame.getJointPose(inputjoint, referenceSpace);
                    // The transform of this joint will be updated with the joint pose on each frame
                    const joint = this._getHandJoint(hand, inputjoint);
                    if (jointPose !== null) {
                        joint.matrix.fromArray(jointPose.transform.matrix);
                        joint.matrix.decompose(joint.position, joint.rotation, joint.scale);
                        joint.matrixWorldNeedsUpdate = true;
                        joint.jointRadius = jointPose.radius;
                    }
                    joint.visible = jointPose !== null;
                }
                // Custom events
                // Check pinchz
                const indexTip = hand.joints["index-finger-tip"];
                const thumbTip = hand.joints["thumb-tip"];
                const distance = indexTip.position.distanceTo(thumbTip.position);
                const distanceToPinch = 0.02;
                const threshold = 0.005;
                if (hand.inputState.pinching && distance > distanceToPinch + threshold) {
                    hand.inputState.pinching = false;
                    this.dispatchEvent({
                        type: "pinchend",
                        handedness: inputSource.handedness,
                        target: this
                    });
                } else if (!hand.inputState.pinching && distance <= distanceToPinch - threshold) {
                    hand.inputState.pinching = true;
                    this.dispatchEvent({
                        type: "pinchstart",
                        handedness: inputSource.handedness,
                        target: this
                    });
                }
            } else if (grip !== null && inputSource.gripSpace) {
                gripPose = frame.getPose(inputSource.gripSpace, referenceSpace);
                if (gripPose !== null) {
                    grip.matrix.fromArray(gripPose.transform.matrix);
                    grip.matrix.decompose(grip.position, grip.rotation, grip.scale);
                    grip.matrixWorldNeedsUpdate = true;
                    if (gripPose.linearVelocity) {
                        grip.hasLinearVelocity = true;
                        grip.linearVelocity.copy(gripPose.linearVelocity);
                    } else grip.hasLinearVelocity = false;
                    if (gripPose.angularVelocity) {
                        grip.hasAngularVelocity = true;
                        grip.angularVelocity.copy(gripPose.angularVelocity);
                    } else grip.hasAngularVelocity = false;
                }
            }
            if (targetRay !== null) {
                inputPose = frame.getPose(inputSource.targetRaySpace, referenceSpace);
                // Some runtimes (namely Vive Cosmos with Vive OpenXR Runtime) have only grip space and ray space is equal to it
                if (inputPose === null && gripPose !== null) inputPose = gripPose;
                if (inputPose !== null) {
                    targetRay.matrix.fromArray(inputPose.transform.matrix);
                    targetRay.matrix.decompose(targetRay.position, targetRay.rotation, targetRay.scale);
                    targetRay.matrixWorldNeedsUpdate = true;
                    if (inputPose.linearVelocity) {
                        targetRay.hasLinearVelocity = true;
                        targetRay.linearVelocity.copy(inputPose.linearVelocity);
                    } else targetRay.hasLinearVelocity = false;
                    if (inputPose.angularVelocity) {
                        targetRay.hasAngularVelocity = true;
                        targetRay.angularVelocity.copy(inputPose.angularVelocity);
                    } else targetRay.hasAngularVelocity = false;
                    this.dispatchEvent(_moveEvent);
                }
            }
        }
        if (targetRay !== null) targetRay.visible = inputPose !== null;
        if (grip !== null) grip.visible = gripPose !== null;
        if (hand !== null) hand.visible = handPose !== null;
        return this;
    }
    // private method
    _getHandJoint(hand, inputjoint) {
        if (hand.joints[inputjoint.jointName] === undefined) {
            const joint = new Group();
            joint.matrixAutoUpdate = false;
            joint.visible = false;
            hand.joints[inputjoint.jointName] = joint;
            hand.add(joint);
        }
        return hand.joints[inputjoint.jointName];
    }
}
const _occlusion_vertex = `
void main() {

	gl_Position = vec4( position, 1.0 );

}`;
const _occlusion_fragment = `
uniform sampler2DArray depthColor;
uniform float depthWidth;
uniform float depthHeight;

void main() {

	vec2 coord = vec2( gl_FragCoord.x / depthWidth, gl_FragCoord.y / depthHeight );

	if ( coord.x >= 1.0 ) {

		gl_FragDepth = texture( depthColor, vec3( coord.x - 1.0, coord.y, 1 ) ).r;

	} else {

		gl_FragDepth = texture( depthColor, vec3( coord.x, coord.y, 0 ) ).r;

	}

}`;
class WebXRDepthSensing {
    constructor(){
        this.texture = null;
        this.mesh = null;
        this.depthNear = 0;
        this.depthFar = 0;
    }
    init(renderer, depthData, renderState) {
        if (this.texture === null) {
            const texture = new Texture();
            const texProps = renderer.properties.get(texture);
            texProps.__webglTexture = depthData.texture;
            if (depthData.depthNear != renderState.depthNear || depthData.depthFar != renderState.depthFar) {
                this.depthNear = depthData.depthNear;
                this.depthFar = depthData.depthFar;
            }
            this.texture = texture;
        }
    }
    getMesh(cameraXR) {
        if (this.texture !== null) {
            if (this.mesh === null) {
                const viewport = cameraXR.cameras[0].viewport;
                const material = new ShaderMaterial({
                    vertexShader: _occlusion_vertex,
                    fragmentShader: _occlusion_fragment,
                    uniforms: {
                        depthColor: {
                            value: this.texture
                        },
                        depthWidth: {
                            value: viewport.z
                        },
                        depthHeight: {
                            value: viewport.w
                        }
                    }
                });
                this.mesh = new Mesh(new PlaneGeometry(20, 20), material);
            }
        }
        return this.mesh;
    }
    reset() {
        this.texture = null;
        this.mesh = null;
    }
    getDepthTexture() {
        return this.texture;
    }
}
class WebXRManager extends EventDispatcher {
    constructor(renderer, gl){
        super();
        const scope = this;
        let session = null;
        let framebufferScaleFactor = 1.0;
        let referenceSpace = null;
        let referenceSpaceType = "local-floor";
        // Set default foveation to maximum.
        let foveation = 1.0;
        let customReferenceSpace = null;
        let pose = null;
        let glBinding = null;
        let glProjLayer = null;
        let glBaseLayer = null;
        let xrFrame = null;
        const depthSensing = new WebXRDepthSensing();
        const attributes = gl.getContextAttributes();
        let initialRenderTarget = null;
        let newRenderTarget = null;
        const controllers = [];
        const controllerInputSources = [];
        const currentSize = new Vector2();
        let currentPixelRatio = null;
        //
        const cameraL = new PerspectiveCamera();
        cameraL.layers.enable(1);
        cameraL.viewport = new Vector4();
        const cameraR = new PerspectiveCamera();
        cameraR.layers.enable(2);
        cameraR.viewport = new Vector4();
        const cameras = [
            cameraL,
            cameraR
        ];
        const cameraXR = new ArrayCamera();
        cameraXR.layers.enable(1);
        cameraXR.layers.enable(2);
        let _currentDepthNear = null;
        let _currentDepthFar = null;
        //
        this.cameraAutoUpdate = true;
        this.enabled = false;
        this.isPresenting = false;
        this.getController = function(index) {
            let controller = controllers[index];
            if (controller === undefined) {
                controller = new WebXRController();
                controllers[index] = controller;
            }
            return controller.getTargetRaySpace();
        };
        this.getControllerGrip = function(index) {
            let controller = controllers[index];
            if (controller === undefined) {
                controller = new WebXRController();
                controllers[index] = controller;
            }
            return controller.getGripSpace();
        };
        this.getHand = function(index) {
            let controller = controllers[index];
            if (controller === undefined) {
                controller = new WebXRController();
                controllers[index] = controller;
            }
            return controller.getHandSpace();
        };
        //
        function onSessionEvent(event) {
            const controllerIndex = controllerInputSources.indexOf(event.inputSource);
            if (controllerIndex === -1) return;
            const controller = controllers[controllerIndex];
            if (controller !== undefined) {
                controller.update(event.inputSource, event.frame, customReferenceSpace || referenceSpace);
                controller.dispatchEvent({
                    type: event.type,
                    data: event.inputSource
                });
            }
        }
        function onSessionEnd() {
            session.removeEventListener("select", onSessionEvent);
            session.removeEventListener("selectstart", onSessionEvent);
            session.removeEventListener("selectend", onSessionEvent);
            session.removeEventListener("squeeze", onSessionEvent);
            session.removeEventListener("squeezestart", onSessionEvent);
            session.removeEventListener("squeezeend", onSessionEvent);
            session.removeEventListener("end", onSessionEnd);
            session.removeEventListener("inputsourceschange", onInputSourcesChange);
            for(let i = 0; i < controllers.length; i++){
                const inputSource = controllerInputSources[i];
                if (inputSource === null) continue;
                controllerInputSources[i] = null;
                controllers[i].disconnect(inputSource);
            }
            _currentDepthNear = null;
            _currentDepthFar = null;
            depthSensing.reset();
            // restore framebuffer/rendering state
            renderer.setRenderTarget(initialRenderTarget);
            glBaseLayer = null;
            glProjLayer = null;
            glBinding = null;
            session = null;
            newRenderTarget = null;
            //
            animation.stop();
            scope.isPresenting = false;
            renderer.setPixelRatio(currentPixelRatio);
            renderer.setSize(currentSize.width, currentSize.height, false);
            scope.dispatchEvent({
                type: "sessionend"
            });
        }
        this.setFramebufferScaleFactor = function(value) {
            framebufferScaleFactor = value;
            if (scope.isPresenting === true) console.warn("THREE.WebXRManager: Cannot change framebuffer scale while presenting.");
        };
        this.setReferenceSpaceType = function(value) {
            referenceSpaceType = value;
            if (scope.isPresenting === true) console.warn("THREE.WebXRManager: Cannot change reference space type while presenting.");
        };
        this.getReferenceSpace = function() {
            return customReferenceSpace || referenceSpace;
        };
        this.setReferenceSpace = function(space) {
            customReferenceSpace = space;
        };
        this.getBaseLayer = function() {
            return glProjLayer !== null ? glProjLayer : glBaseLayer;
        };
        this.getBinding = function() {
            return glBinding;
        };
        this.getFrame = function() {
            return xrFrame;
        };
        this.getSession = function() {
            return session;
        };
        this.setSession = async function(value) {
            session = value;
            if (session !== null) {
                initialRenderTarget = renderer.getRenderTarget();
                session.addEventListener("select", onSessionEvent);
                session.addEventListener("selectstart", onSessionEvent);
                session.addEventListener("selectend", onSessionEvent);
                session.addEventListener("squeeze", onSessionEvent);
                session.addEventListener("squeezestart", onSessionEvent);
                session.addEventListener("squeezeend", onSessionEvent);
                session.addEventListener("end", onSessionEnd);
                session.addEventListener("inputsourceschange", onInputSourcesChange);
                if (attributes.xrCompatible !== true) await gl.makeXRCompatible();
                currentPixelRatio = renderer.getPixelRatio();
                renderer.getSize(currentSize);
                if (session.renderState.layers === undefined) {
                    const layerInit = {
                        antialias: attributes.antialias,
                        alpha: true,
                        depth: attributes.depth,
                        stencil: attributes.stencil,
                        framebufferScaleFactor: framebufferScaleFactor
                    };
                    glBaseLayer = new XRWebGLLayer(session, gl, layerInit);
                    session.updateRenderState({
                        baseLayer: glBaseLayer
                    });
                    renderer.setPixelRatio(1);
                    renderer.setSize(glBaseLayer.framebufferWidth, glBaseLayer.framebufferHeight, false);
                    newRenderTarget = new WebGLRenderTarget(glBaseLayer.framebufferWidth, glBaseLayer.framebufferHeight, {
                        format: RGBAFormat,
                        type: UnsignedByteType,
                        colorSpace: renderer.outputColorSpace,
                        stencilBuffer: attributes.stencil
                    });
                } else {
                    let depthFormat = null;
                    let depthType = null;
                    let glDepthFormat = null;
                    if (attributes.depth) {
                        glDepthFormat = attributes.stencil ? gl.DEPTH24_STENCIL8 : gl.DEPTH_COMPONENT24;
                        depthFormat = attributes.stencil ? DepthStencilFormat : DepthFormat;
                        depthType = attributes.stencil ? UnsignedInt248Type : UnsignedIntType;
                    }
                    const projectionlayerInit = {
                        colorFormat: gl.RGBA8,
                        depthFormat: glDepthFormat,
                        scaleFactor: framebufferScaleFactor
                    };
                    glBinding = new XRWebGLBinding(session, gl);
                    glProjLayer = glBinding.createProjectionLayer(projectionlayerInit);
                    session.updateRenderState({
                        layers: [
                            glProjLayer
                        ]
                    });
                    renderer.setPixelRatio(1);
                    renderer.setSize(glProjLayer.textureWidth, glProjLayer.textureHeight, false);
                    newRenderTarget = new WebGLRenderTarget(glProjLayer.textureWidth, glProjLayer.textureHeight, {
                        format: RGBAFormat,
                        type: UnsignedByteType,
                        depthTexture: new DepthTexture(glProjLayer.textureWidth, glProjLayer.textureHeight, depthType, undefined, undefined, undefined, undefined, undefined, undefined, depthFormat),
                        stencilBuffer: attributes.stencil,
                        colorSpace: renderer.outputColorSpace,
                        samples: attributes.antialias ? 4 : 0,
                        resolveDepthBuffer: glProjLayer.ignoreDepthValues === false
                    });
                }
                newRenderTarget.isXRRenderTarget = true; // TODO Remove this when possible, see #23278
                this.setFoveation(foveation);
                customReferenceSpace = null;
                referenceSpace = await session.requestReferenceSpace(referenceSpaceType);
                animation.setContext(session);
                animation.start();
                scope.isPresenting = true;
                scope.dispatchEvent({
                    type: "sessionstart"
                });
            }
        };
        this.getEnvironmentBlendMode = function() {
            if (session !== null) return session.environmentBlendMode;
        };
        this.getDepthTexture = function() {
            return depthSensing.getDepthTexture();
        };
        function onInputSourcesChange(event) {
            // Notify disconnected
            for(let i = 0; i < event.removed.length; i++){
                const inputSource = event.removed[i];
                const index = controllerInputSources.indexOf(inputSource);
                if (index >= 0) {
                    controllerInputSources[index] = null;
                    controllers[index].disconnect(inputSource);
                }
            }
            // Notify connected
            for(let i = 0; i < event.added.length; i++){
                const inputSource = event.added[i];
                let controllerIndex = controllerInputSources.indexOf(inputSource);
                if (controllerIndex === -1) {
                    // Assign input source a controller that currently has no input source
                    for(let i = 0; i < controllers.length; i++){
                        if (i >= controllerInputSources.length) {
                            controllerInputSources.push(inputSource);
                            controllerIndex = i;
                            break;
                        } else if (controllerInputSources[i] === null) {
                            controllerInputSources[i] = inputSource;
                            controllerIndex = i;
                            break;
                        }
                    }
                    // If all controllers do currently receive input we ignore new ones
                    if (controllerIndex === -1) break;
                }
                const controller = controllers[controllerIndex];
                if (controller) controller.connect(inputSource);
            }
        }
        //
        const cameraLPos = new Vector3();
        const cameraRPos = new Vector3();
        /**
		 * Assumes 2 cameras that are parallel and share an X-axis, and that
		 * the cameras' projection and world matrices have already been set.
		 * And that near and far planes are identical for both cameras.
		 * Visualization of this technique: https://computergraphics.stackexchange.com/a/4765
		 */ function setProjectionFromUnion(camera, cameraL, cameraR) {
            cameraLPos.setFromMatrixPosition(cameraL.matrixWorld);
            cameraRPos.setFromMatrixPosition(cameraR.matrixWorld);
            const ipd = cameraLPos.distanceTo(cameraRPos);
            const projL = cameraL.projectionMatrix.elements;
            const projR = cameraR.projectionMatrix.elements;
            // VR systems will have identical far and near planes, and
            // most likely identical top and bottom frustum extents.
            // Use the left camera for these values.
            const near = projL[14] / (projL[10] - 1);
            const far = projL[14] / (projL[10] + 1);
            const topFov = (projL[9] + 1) / projL[5];
            const bottomFov = (projL[9] - 1) / projL[5];
            const leftFov = (projL[8] - 1) / projL[0];
            const rightFov = (projR[8] + 1) / projR[0];
            const left = near * leftFov;
            const right = near * rightFov;
            // Calculate the new camera's position offset from the
            // left camera. xOffset should be roughly half `ipd`.
            const zOffset = ipd / (-leftFov + rightFov);
            const xOffset = zOffset * -leftFov;
            // TODO: Better way to apply this offset?
            cameraL.matrixWorld.decompose(camera.position, camera.quaternion, camera.scale);
            camera.translateX(xOffset);
            camera.translateZ(zOffset);
            camera.matrixWorld.compose(camera.position, camera.quaternion, camera.scale);
            camera.matrixWorldInverse.copy(camera.matrixWorld).invert();
            // Find the union of the frustum values of the cameras and scale
            // the values so that the near plane's position does not change in world space,
            // although must now be relative to the new union camera.
            const near2 = near + zOffset;
            const far2 = far + zOffset;
            const left2 = left - xOffset;
            const right2 = right + (ipd - xOffset);
            const top2 = topFov * far / far2 * near2;
            const bottom2 = bottomFov * far / far2 * near2;
            camera.projectionMatrix.makePerspective(left2, right2, top2, bottom2, near2, far2);
            camera.projectionMatrixInverse.copy(camera.projectionMatrix).invert();
        }
        function updateCamera(camera, parent) {
            if (parent === null) camera.matrixWorld.copy(camera.matrix);
            else camera.matrixWorld.multiplyMatrices(parent.matrixWorld, camera.matrix);
            camera.matrixWorldInverse.copy(camera.matrixWorld).invert();
        }
        this.updateCamera = function(camera) {
            if (session === null) return;
            if (depthSensing.texture !== null) {
                camera.near = depthSensing.depthNear;
                camera.far = depthSensing.depthFar;
            }
            cameraXR.near = cameraR.near = cameraL.near = camera.near;
            cameraXR.far = cameraR.far = cameraL.far = camera.far;
            if (_currentDepthNear !== cameraXR.near || _currentDepthFar !== cameraXR.far) {
                // Note that the new renderState won't apply until the next frame. See #18320
                session.updateRenderState({
                    depthNear: cameraXR.near,
                    depthFar: cameraXR.far
                });
                _currentDepthNear = cameraXR.near;
                _currentDepthFar = cameraXR.far;
                cameraL.near = _currentDepthNear;
                cameraL.far = _currentDepthFar;
                cameraR.near = _currentDepthNear;
                cameraR.far = _currentDepthFar;
                cameraL.updateProjectionMatrix();
                cameraR.updateProjectionMatrix();
                camera.updateProjectionMatrix();
            }
            const parent = camera.parent;
            const cameras = cameraXR.cameras;
            updateCamera(cameraXR, parent);
            for(let i = 0; i < cameras.length; i++)updateCamera(cameras[i], parent);
            // update projection matrix for proper view frustum culling
            if (cameras.length === 2) setProjectionFromUnion(cameraXR, cameraL, cameraR);
            else // assume single camera setup (AR)
            cameraXR.projectionMatrix.copy(cameraL.projectionMatrix);
            // update user camera and its children
            updateUserCamera(camera, cameraXR, parent);
        };
        function updateUserCamera(camera, cameraXR, parent) {
            if (parent === null) camera.matrix.copy(cameraXR.matrixWorld);
            else {
                camera.matrix.copy(parent.matrixWorld);
                camera.matrix.invert();
                camera.matrix.multiply(cameraXR.matrixWorld);
            }
            camera.matrix.decompose(camera.position, camera.quaternion, camera.scale);
            camera.updateMatrixWorld(true);
            camera.projectionMatrix.copy(cameraXR.projectionMatrix);
            camera.projectionMatrixInverse.copy(cameraXR.projectionMatrixInverse);
            if (camera.isPerspectiveCamera) {
                camera.fov = RAD2DEG * 2 * Math.atan(1 / camera.projectionMatrix.elements[5]);
                camera.zoom = 1;
            }
        }
        this.getCamera = function() {
            return cameraXR;
        };
        this.getFoveation = function() {
            if (glProjLayer === null && glBaseLayer === null) return undefined;
            return foveation;
        };
        this.setFoveation = function(value) {
            // 0 = no foveation = full resolution
            // 1 = maximum foveation = the edges render at lower resolution
            foveation = value;
            if (glProjLayer !== null) glProjLayer.fixedFoveation = value;
            if (glBaseLayer !== null && glBaseLayer.fixedFoveation !== undefined) glBaseLayer.fixedFoveation = value;
        };
        this.hasDepthSensing = function() {
            return depthSensing.texture !== null;
        };
        this.getDepthSensingMesh = function() {
            return depthSensing.getMesh(cameraXR);
        };
        // Animation Loop
        let onAnimationFrameCallback = null;
        function onAnimationFrame(time, frame) {
            pose = frame.getViewerPose(customReferenceSpace || referenceSpace);
            xrFrame = frame;
            if (pose !== null) {
                const views = pose.views;
                if (glBaseLayer !== null) {
                    renderer.setRenderTargetFramebuffer(newRenderTarget, glBaseLayer.framebuffer);
                    renderer.setRenderTarget(newRenderTarget);
                }
                let cameraXRNeedsUpdate = false;
                // check if it's necessary to rebuild cameraXR's camera list
                if (views.length !== cameraXR.cameras.length) {
                    cameraXR.cameras.length = 0;
                    cameraXRNeedsUpdate = true;
                }
                for(let i = 0; i < views.length; i++){
                    const view = views[i];
                    let viewport = null;
                    if (glBaseLayer !== null) viewport = glBaseLayer.getViewport(view);
                    else {
                        const glSubImage = glBinding.getViewSubImage(glProjLayer, view);
                        viewport = glSubImage.viewport;
                        // For side-by-side projection, we only produce a single texture for both eyes.
                        if (i === 0) {
                            renderer.setRenderTargetTextures(newRenderTarget, glSubImage.colorTexture, glProjLayer.ignoreDepthValues ? undefined : glSubImage.depthStencilTexture);
                            renderer.setRenderTarget(newRenderTarget);
                        }
                    }
                    let camera = cameras[i];
                    if (camera === undefined) {
                        camera = new PerspectiveCamera();
                        camera.layers.enable(i);
                        camera.viewport = new Vector4();
                        cameras[i] = camera;
                    }
                    camera.matrix.fromArray(view.transform.matrix);
                    camera.matrix.decompose(camera.position, camera.quaternion, camera.scale);
                    camera.projectionMatrix.fromArray(view.projectionMatrix);
                    camera.projectionMatrixInverse.copy(camera.projectionMatrix).invert();
                    camera.viewport.set(viewport.x, viewport.y, viewport.width, viewport.height);
                    if (i === 0) {
                        cameraXR.matrix.copy(camera.matrix);
                        cameraXR.matrix.decompose(cameraXR.position, cameraXR.quaternion, cameraXR.scale);
                    }
                    if (cameraXRNeedsUpdate === true) cameraXR.cameras.push(camera);
                }
                //
                const enabledFeatures = session.enabledFeatures;
                if (enabledFeatures && enabledFeatures.includes("depth-sensing")) {
                    const depthData = glBinding.getDepthInformation(views[0]);
                    if (depthData && depthData.isValid && depthData.texture) depthSensing.init(renderer, depthData, session.renderState);
                }
            }
            //
            for(let i = 0; i < controllers.length; i++){
                const inputSource = controllerInputSources[i];
                const controller = controllers[i];
                if (inputSource !== null && controller !== undefined) controller.update(inputSource, frame, customReferenceSpace || referenceSpace);
            }
            if (onAnimationFrameCallback) onAnimationFrameCallback(time, frame);
            if (frame.detectedPlanes) scope.dispatchEvent({
                type: "planesdetected",
                data: frame
            });
            xrFrame = null;
        }
        const animation = new WebGLAnimation();
        animation.setAnimationLoop(onAnimationFrame);
        this.setAnimationLoop = function(callback) {
            onAnimationFrameCallback = callback;
        };
        this.dispose = function() {};
    }
}
const _e1 = /*@__PURE__*/ new Euler();
const _m1 = /*@__PURE__*/ new Matrix4();
function WebGLMaterials(renderer, properties) {
    function refreshTransformUniform(map, uniform) {
        if (map.matrixAutoUpdate === true) map.updateMatrix();
        uniform.value.copy(map.matrix);
    }
    function refreshFogUniforms(uniforms, fog) {
        fog.color.getRGB(uniforms.fogColor.value, getUnlitUniformColorSpace(renderer));
        if (fog.isFog) {
            uniforms.fogNear.value = fog.near;
            uniforms.fogFar.value = fog.far;
        } else if (fog.isFogExp2) uniforms.fogDensity.value = fog.density;
    }
    function refreshMaterialUniforms(uniforms, material, pixelRatio, height, transmissionRenderTarget) {
        if (material.isMeshBasicMaterial) refreshUniformsCommon(uniforms, material);
        else if (material.isMeshLambertMaterial) refreshUniformsCommon(uniforms, material);
        else if (material.isMeshToonMaterial) {
            refreshUniformsCommon(uniforms, material);
            refreshUniformsToon(uniforms, material);
        } else if (material.isMeshPhongMaterial) {
            refreshUniformsCommon(uniforms, material);
            refreshUniformsPhong(uniforms, material);
        } else if (material.isMeshStandardMaterial) {
            refreshUniformsCommon(uniforms, material);
            refreshUniformsStandard(uniforms, material);
            if (material.isMeshPhysicalMaterial) refreshUniformsPhysical(uniforms, material, transmissionRenderTarget);
        } else if (material.isMeshMatcapMaterial) {
            refreshUniformsCommon(uniforms, material);
            refreshUniformsMatcap(uniforms, material);
        } else if (material.isMeshDepthMaterial) refreshUniformsCommon(uniforms, material);
        else if (material.isMeshDistanceMaterial) {
            refreshUniformsCommon(uniforms, material);
            refreshUniformsDistance(uniforms, material);
        } else if (material.isMeshNormalMaterial) refreshUniformsCommon(uniforms, material);
        else if (material.isLineBasicMaterial) {
            refreshUniformsLine(uniforms, material);
            if (material.isLineDashedMaterial) refreshUniformsDash(uniforms, material);
        } else if (material.isPointsMaterial) refreshUniformsPoints(uniforms, material, pixelRatio, height);
        else if (material.isSpriteMaterial) refreshUniformsSprites(uniforms, material);
        else if (material.isShadowMaterial) {
            uniforms.color.value.copy(material.color);
            uniforms.opacity.value = material.opacity;
        } else if (material.isShaderMaterial) material.uniformsNeedUpdate = false; // #15581
    }
    function refreshUniformsCommon(uniforms, material) {
        uniforms.opacity.value = material.opacity;
        if (material.color) uniforms.diffuse.value.copy(material.color);
        if (material.emissive) uniforms.emissive.value.copy(material.emissive).multiplyScalar(material.emissiveIntensity);
        if (material.map) {
            uniforms.map.value = material.map;
            refreshTransformUniform(material.map, uniforms.mapTransform);
        }
        if (material.alphaMap) {
            uniforms.alphaMap.value = material.alphaMap;
            refreshTransformUniform(material.alphaMap, uniforms.alphaMapTransform);
        }
        if (material.bumpMap) {
            uniforms.bumpMap.value = material.bumpMap;
            refreshTransformUniform(material.bumpMap, uniforms.bumpMapTransform);
            uniforms.bumpScale.value = material.bumpScale;
            if (material.side === BackSide) uniforms.bumpScale.value *= -1;
        }
        if (material.normalMap) {
            uniforms.normalMap.value = material.normalMap;
            refreshTransformUniform(material.normalMap, uniforms.normalMapTransform);
            uniforms.normalScale.value.copy(material.normalScale);
            if (material.side === BackSide) uniforms.normalScale.value.negate();
        }
        if (material.displacementMap) {
            uniforms.displacementMap.value = material.displacementMap;
            refreshTransformUniform(material.displacementMap, uniforms.displacementMapTransform);
            uniforms.displacementScale.value = material.displacementScale;
            uniforms.displacementBias.value = material.displacementBias;
        }
        if (material.emissiveMap) {
            uniforms.emissiveMap.value = material.emissiveMap;
            refreshTransformUniform(material.emissiveMap, uniforms.emissiveMapTransform);
        }
        if (material.specularMap) {
            uniforms.specularMap.value = material.specularMap;
            refreshTransformUniform(material.specularMap, uniforms.specularMapTransform);
        }
        if (material.alphaTest > 0) uniforms.alphaTest.value = material.alphaTest;
        const materialProperties = properties.get(material);
        const envMap = materialProperties.envMap;
        const envMapRotation = materialProperties.envMapRotation;
        if (envMap) {
            uniforms.envMap.value = envMap;
            _e1.copy(envMapRotation);
            // accommodate left-handed frame
            _e1.x *= -1;
            _e1.y *= -1;
            _e1.z *= -1;
            if (envMap.isCubeTexture && envMap.isRenderTargetTexture === false) {
                // environment maps which are not cube render targets or PMREMs follow a different convention
                _e1.y *= -1;
                _e1.z *= -1;
            }
            uniforms.envMapRotation.value.setFromMatrix4(_m1.makeRotationFromEuler(_e1));
            uniforms.flipEnvMap.value = envMap.isCubeTexture && envMap.isRenderTargetTexture === false ? -1 : 1;
            uniforms.reflectivity.value = material.reflectivity;
            uniforms.ior.value = material.ior;
            uniforms.refractionRatio.value = material.refractionRatio;
        }
        if (material.lightMap) {
            uniforms.lightMap.value = material.lightMap;
            uniforms.lightMapIntensity.value = material.lightMapIntensity;
            refreshTransformUniform(material.lightMap, uniforms.lightMapTransform);
        }
        if (material.aoMap) {
            uniforms.aoMap.value = material.aoMap;
            uniforms.aoMapIntensity.value = material.aoMapIntensity;
            refreshTransformUniform(material.aoMap, uniforms.aoMapTransform);
        }
    }
    function refreshUniformsLine(uniforms, material) {
        uniforms.diffuse.value.copy(material.color);
        uniforms.opacity.value = material.opacity;
        if (material.map) {
            uniforms.map.value = material.map;
            refreshTransformUniform(material.map, uniforms.mapTransform);
        }
    }
    function refreshUniformsDash(uniforms, material) {
        uniforms.dashSize.value = material.dashSize;
        uniforms.totalSize.value = material.dashSize + material.gapSize;
        uniforms.scale.value = material.scale;
    }
    function refreshUniformsPoints(uniforms, material, pixelRatio, height) {
        uniforms.diffuse.value.copy(material.color);
        uniforms.opacity.value = material.opacity;
        uniforms.size.value = material.size * pixelRatio;
        uniforms.scale.value = height * 0.5;
        if (material.map) {
            uniforms.map.value = material.map;
            refreshTransformUniform(material.map, uniforms.uvTransform);
        }
        if (material.alphaMap) {
            uniforms.alphaMap.value = material.alphaMap;
            refreshTransformUniform(material.alphaMap, uniforms.alphaMapTransform);
        }
        if (material.alphaTest > 0) uniforms.alphaTest.value = material.alphaTest;
    }
    function refreshUniformsSprites(uniforms, material) {
        uniforms.diffuse.value.copy(material.color);
        uniforms.opacity.value = material.opacity;
        uniforms.rotation.value = material.rotation;
        if (material.map) {
            uniforms.map.value = material.map;
            refreshTransformUniform(material.map, uniforms.mapTransform);
        }
        if (material.alphaMap) {
            uniforms.alphaMap.value = material.alphaMap;
            refreshTransformUniform(material.alphaMap, uniforms.alphaMapTransform);
        }
        if (material.alphaTest > 0) uniforms.alphaTest.value = material.alphaTest;
    }
    function refreshUniformsPhong(uniforms, material) {
        uniforms.specular.value.copy(material.specular);
        uniforms.shininess.value = Math.max(material.shininess, 1e-4); // to prevent pow( 0.0, 0.0 )
    }
    function refreshUniformsToon(uniforms, material) {
        if (material.gradientMap) uniforms.gradientMap.value = material.gradientMap;
    }
    function refreshUniformsStandard(uniforms, material) {
        uniforms.metalness.value = material.metalness;
        if (material.metalnessMap) {
            uniforms.metalnessMap.value = material.metalnessMap;
            refreshTransformUniform(material.metalnessMap, uniforms.metalnessMapTransform);
        }
        uniforms.roughness.value = material.roughness;
        if (material.roughnessMap) {
            uniforms.roughnessMap.value = material.roughnessMap;
            refreshTransformUniform(material.roughnessMap, uniforms.roughnessMapTransform);
        }
        if (material.envMap) //uniforms.envMap.value = material.envMap; // part of uniforms common
        uniforms.envMapIntensity.value = material.envMapIntensity;
    }
    function refreshUniformsPhysical(uniforms, material, transmissionRenderTarget) {
        uniforms.ior.value = material.ior; // also part of uniforms common
        if (material.sheen > 0) {
            uniforms.sheenColor.value.copy(material.sheenColor).multiplyScalar(material.sheen);
            uniforms.sheenRoughness.value = material.sheenRoughness;
            if (material.sheenColorMap) {
                uniforms.sheenColorMap.value = material.sheenColorMap;
                refreshTransformUniform(material.sheenColorMap, uniforms.sheenColorMapTransform);
            }
            if (material.sheenRoughnessMap) {
                uniforms.sheenRoughnessMap.value = material.sheenRoughnessMap;
                refreshTransformUniform(material.sheenRoughnessMap, uniforms.sheenRoughnessMapTransform);
            }
        }
        if (material.clearcoat > 0) {
            uniforms.clearcoat.value = material.clearcoat;
            uniforms.clearcoatRoughness.value = material.clearcoatRoughness;
            if (material.clearcoatMap) {
                uniforms.clearcoatMap.value = material.clearcoatMap;
                refreshTransformUniform(material.clearcoatMap, uniforms.clearcoatMapTransform);
            }
            if (material.clearcoatRoughnessMap) {
                uniforms.clearcoatRoughnessMap.value = material.clearcoatRoughnessMap;
                refreshTransformUniform(material.clearcoatRoughnessMap, uniforms.clearcoatRoughnessMapTransform);
            }
            if (material.clearcoatNormalMap) {
                uniforms.clearcoatNormalMap.value = material.clearcoatNormalMap;
                refreshTransformUniform(material.clearcoatNormalMap, uniforms.clearcoatNormalMapTransform);
                uniforms.clearcoatNormalScale.value.copy(material.clearcoatNormalScale);
                if (material.side === BackSide) uniforms.clearcoatNormalScale.value.negate();
            }
        }
        if (material.dispersion > 0) uniforms.dispersion.value = material.dispersion;
        if (material.iridescence > 0) {
            uniforms.iridescence.value = material.iridescence;
            uniforms.iridescenceIOR.value = material.iridescenceIOR;
            uniforms.iridescenceThicknessMinimum.value = material.iridescenceThicknessRange[0];
            uniforms.iridescenceThicknessMaximum.value = material.iridescenceThicknessRange[1];
            if (material.iridescenceMap) {
                uniforms.iridescenceMap.value = material.iridescenceMap;
                refreshTransformUniform(material.iridescenceMap, uniforms.iridescenceMapTransform);
            }
            if (material.iridescenceThicknessMap) {
                uniforms.iridescenceThicknessMap.value = material.iridescenceThicknessMap;
                refreshTransformUniform(material.iridescenceThicknessMap, uniforms.iridescenceThicknessMapTransform);
            }
        }
        if (material.transmission > 0) {
            uniforms.transmission.value = material.transmission;
            uniforms.transmissionSamplerMap.value = transmissionRenderTarget.texture;
            uniforms.transmissionSamplerSize.value.set(transmissionRenderTarget.width, transmissionRenderTarget.height);
            if (material.transmissionMap) {
                uniforms.transmissionMap.value = material.transmissionMap;
                refreshTransformUniform(material.transmissionMap, uniforms.transmissionMapTransform);
            }
            uniforms.thickness.value = material.thickness;
            if (material.thicknessMap) {
                uniforms.thicknessMap.value = material.thicknessMap;
                refreshTransformUniform(material.thicknessMap, uniforms.thicknessMapTransform);
            }
            uniforms.attenuationDistance.value = material.attenuationDistance;
            uniforms.attenuationColor.value.copy(material.attenuationColor);
        }
        if (material.anisotropy > 0) {
            uniforms.anisotropyVector.value.set(material.anisotropy * Math.cos(material.anisotropyRotation), material.anisotropy * Math.sin(material.anisotropyRotation));
            if (material.anisotropyMap) {
                uniforms.anisotropyMap.value = material.anisotropyMap;
                refreshTransformUniform(material.anisotropyMap, uniforms.anisotropyMapTransform);
            }
        }
        uniforms.specularIntensity.value = material.specularIntensity;
        uniforms.specularColor.value.copy(material.specularColor);
        if (material.specularColorMap) {
            uniforms.specularColorMap.value = material.specularColorMap;
            refreshTransformUniform(material.specularColorMap, uniforms.specularColorMapTransform);
        }
        if (material.specularIntensityMap) {
            uniforms.specularIntensityMap.value = material.specularIntensityMap;
            refreshTransformUniform(material.specularIntensityMap, uniforms.specularIntensityMapTransform);
        }
    }
    function refreshUniformsMatcap(uniforms, material) {
        if (material.matcap) uniforms.matcap.value = material.matcap;
    }
    function refreshUniformsDistance(uniforms, material) {
        const light = properties.get(material).light;
        uniforms.referencePosition.value.setFromMatrixPosition(light.matrixWorld);
        uniforms.nearDistance.value = light.shadow.camera.near;
        uniforms.farDistance.value = light.shadow.camera.far;
    }
    return {
        refreshFogUniforms: refreshFogUniforms,
        refreshMaterialUniforms: refreshMaterialUniforms
    };
}
function WebGLUniformsGroups(gl, info, capabilities, state) {
    let buffers = {};
    let updateList = {};
    let allocatedBindingPoints = [];
    const maxBindingPoints = gl.getParameter(gl.MAX_UNIFORM_BUFFER_BINDINGS); // binding points are global whereas block indices are per shader program
    function bind(uniformsGroup, program) {
        const webglProgram = program.program;
        state.uniformBlockBinding(uniformsGroup, webglProgram);
    }
    function update(uniformsGroup, program) {
        let buffer = buffers[uniformsGroup.id];
        if (buffer === undefined) {
            prepareUniformsGroup(uniformsGroup);
            buffer = createBuffer(uniformsGroup);
            buffers[uniformsGroup.id] = buffer;
            uniformsGroup.addEventListener("dispose", onUniformsGroupsDispose);
        }
        // ensure to update the binding points/block indices mapping for this program
        const webglProgram = program.program;
        state.updateUBOMapping(uniformsGroup, webglProgram);
        // update UBO once per frame
        const frame = info.render.frame;
        if (updateList[uniformsGroup.id] !== frame) {
            updateBufferData(uniformsGroup);
            updateList[uniformsGroup.id] = frame;
        }
    }
    function createBuffer(uniformsGroup) {
        // the setup of an UBO is independent of a particular shader program but global
        const bindingPointIndex = allocateBindingPointIndex();
        uniformsGroup.__bindingPointIndex = bindingPointIndex;
        const buffer = gl.createBuffer();
        const size = uniformsGroup.__size;
        const usage = uniformsGroup.usage;
        gl.bindBuffer(gl.UNIFORM_BUFFER, buffer);
        gl.bufferData(gl.UNIFORM_BUFFER, size, usage);
        gl.bindBuffer(gl.UNIFORM_BUFFER, null);
        gl.bindBufferBase(gl.UNIFORM_BUFFER, bindingPointIndex, buffer);
        return buffer;
    }
    function allocateBindingPointIndex() {
        for(let i = 0; i < maxBindingPoints; i++)if (allocatedBindingPoints.indexOf(i) === -1) {
            allocatedBindingPoints.push(i);
            return i;
        }
        console.error("THREE.WebGLRenderer: Maximum number of simultaneously usable uniforms groups reached.");
        return 0;
    }
    function updateBufferData(uniformsGroup) {
        const buffer = buffers[uniformsGroup.id];
        const uniforms = uniformsGroup.uniforms;
        const cache = uniformsGroup.__cache;
        gl.bindBuffer(gl.UNIFORM_BUFFER, buffer);
        for(let i = 0, il = uniforms.length; i < il; i++){
            const uniformArray = Array.isArray(uniforms[i]) ? uniforms[i] : [
                uniforms[i]
            ];
            for(let j = 0, jl = uniformArray.length; j < jl; j++){
                const uniform = uniformArray[j];
                if (hasUniformChanged(uniform, i, j, cache) === true) {
                    const offset = uniform.__offset;
                    const values = Array.isArray(uniform.value) ? uniform.value : [
                        uniform.value
                    ];
                    let arrayOffset = 0;
                    for(let k = 0; k < values.length; k++){
                        const value = values[k];
                        const info = getUniformSize(value);
                        // TODO add integer and struct support
                        if (typeof value === "number" || typeof value === "boolean") {
                            uniform.__data[0] = value;
                            gl.bufferSubData(gl.UNIFORM_BUFFER, offset + arrayOffset, uniform.__data);
                        } else if (value.isMatrix3) {
                            // manually converting 3x3 to 3x4
                            uniform.__data[0] = value.elements[0];
                            uniform.__data[1] = value.elements[1];
                            uniform.__data[2] = value.elements[2];
                            uniform.__data[3] = 0;
                            uniform.__data[4] = value.elements[3];
                            uniform.__data[5] = value.elements[4];
                            uniform.__data[6] = value.elements[5];
                            uniform.__data[7] = 0;
                            uniform.__data[8] = value.elements[6];
                            uniform.__data[9] = value.elements[7];
                            uniform.__data[10] = value.elements[8];
                            uniform.__data[11] = 0;
                        } else {
                            value.toArray(uniform.__data, arrayOffset);
                            arrayOffset += info.storage / Float32Array.BYTES_PER_ELEMENT;
                        }
                    }
                    gl.bufferSubData(gl.UNIFORM_BUFFER, offset, uniform.__data);
                }
            }
        }
        gl.bindBuffer(gl.UNIFORM_BUFFER, null);
    }
    function hasUniformChanged(uniform, index, indexArray, cache) {
        const value = uniform.value;
        const indexString = index + "_" + indexArray;
        if (cache[indexString] === undefined) {
            // cache entry does not exist so far
            if (typeof value === "number" || typeof value === "boolean") cache[indexString] = value;
            else cache[indexString] = value.clone();
            return true;
        } else {
            const cachedObject = cache[indexString];
            // compare current value with cached entry
            if (typeof value === "number" || typeof value === "boolean") {
                if (cachedObject !== value) {
                    cache[indexString] = value;
                    return true;
                }
            } else if (cachedObject.equals(value) === false) {
                cachedObject.copy(value);
                return true;
            }
        }
        return false;
    }
    function prepareUniformsGroup(uniformsGroup) {
        // determine total buffer size according to the STD140 layout
        // Hint: STD140 is the only supported layout in WebGL 2
        const uniforms = uniformsGroup.uniforms;
        let offset = 0; // global buffer offset in bytes
        const chunkSize = 16; // size of a chunk in bytes
        for(let i = 0, l = uniforms.length; i < l; i++){
            const uniformArray = Array.isArray(uniforms[i]) ? uniforms[i] : [
                uniforms[i]
            ];
            for(let j = 0, jl = uniformArray.length; j < jl; j++){
                const uniform = uniformArray[j];
                const values = Array.isArray(uniform.value) ? uniform.value : [
                    uniform.value
                ];
                for(let k = 0, kl = values.length; k < kl; k++){
                    const value = values[k];
                    const info = getUniformSize(value);
                    // Calculate the chunk offset
                    const chunkOffsetUniform = offset % chunkSize;
                    // Check for chunk overflow
                    if (chunkOffsetUniform !== 0 && chunkSize - chunkOffsetUniform < info.boundary) // Add padding and adjust offset
                    offset += chunkSize - chunkOffsetUniform;
                    // the following two properties will be used for partial buffer updates
                    uniform.__data = new Float32Array(info.storage / Float32Array.BYTES_PER_ELEMENT);
                    uniform.__offset = offset;
                    // Update the global offset
                    offset += info.storage;
                }
            }
        }
        // ensure correct final padding
        const chunkOffset = offset % chunkSize;
        if (chunkOffset > 0) offset += chunkSize - chunkOffset;
        //
        uniformsGroup.__size = offset;
        uniformsGroup.__cache = {};
        return this;
    }
    function getUniformSize(value) {
        const info = {
            boundary: 0,
            storage: 0 // bytes
        };
        // determine sizes according to STD140
        if (typeof value === "number" || typeof value === "boolean") {
            // float/int/bool
            info.boundary = 4;
            info.storage = 4;
        } else if (value.isVector2) {
            // vec2
            info.boundary = 8;
            info.storage = 8;
        } else if (value.isVector3 || value.isColor) {
            // vec3
            info.boundary = 16;
            info.storage = 12; // evil: vec3 must start on a 16-byte boundary but it only consumes 12 bytes
        } else if (value.isVector4) {
            // vec4
            info.boundary = 16;
            info.storage = 16;
        } else if (value.isMatrix3) {
            // mat3 (in STD140 a 3x3 matrix is represented as 3x4)
            info.boundary = 48;
            info.storage = 48;
        } else if (value.isMatrix4) {
            // mat4
            info.boundary = 64;
            info.storage = 64;
        } else if (value.isTexture) console.warn("THREE.WebGLRenderer: Texture samplers can not be part of an uniforms group.");
        else console.warn("THREE.WebGLRenderer: Unsupported uniform value type.", value);
        return info;
    }
    function onUniformsGroupsDispose(event) {
        const uniformsGroup = event.target;
        uniformsGroup.removeEventListener("dispose", onUniformsGroupsDispose);
        const index = allocatedBindingPoints.indexOf(uniformsGroup.__bindingPointIndex);
        allocatedBindingPoints.splice(index, 1);
        gl.deleteBuffer(buffers[uniformsGroup.id]);
        delete buffers[uniformsGroup.id];
        delete updateList[uniformsGroup.id];
    }
    function dispose() {
        for(const id in buffers)gl.deleteBuffer(buffers[id]);
        allocatedBindingPoints = [];
        buffers = {};
        updateList = {};
    }
    return {
        bind: bind,
        update: update,
        dispose: dispose
    };
}
class WebGLRenderer {
    constructor(parameters = {}){
        const { canvas = createCanvasElement(), context = null, depth = true, stencil = false, alpha = false, antialias = false, premultipliedAlpha = true, preserveDrawingBuffer = false, powerPreference = "default", failIfMajorPerformanceCaveat = false } = parameters;
        this.isWebGLRenderer = true;
        let _alpha;
        if (context !== null) {
            if (typeof WebGLRenderingContext !== "undefined" && context instanceof WebGLRenderingContext) throw new Error("THREE.WebGLRenderer: WebGL 1 is not supported since r163.");
            _alpha = context.getContextAttributes().alpha;
        } else _alpha = alpha;
        const uintClearColor = new Uint32Array(4);
        const intClearColor = new Int32Array(4);
        let currentRenderList = null;
        let currentRenderState = null;
        // render() can be called from within a callback triggered by another render.
        // We track this so that the nested render call gets its list and state isolated from the parent render call.
        const renderListStack = [];
        const renderStateStack = [];
        // public properties
        this.domElement = canvas;
        // Debug configuration container
        this.debug = {
            /**
			 * Enables error checking and reporting when shader programs are being compiled
			 * @type {boolean}
			 */ checkShaderErrors: true,
            /**
			 * Callback for custom error reporting.
			 * @type {?Function}
			 */ onShaderError: null
        };
        // clearing
        this.autoClear = true;
        this.autoClearColor = true;
        this.autoClearDepth = true;
        this.autoClearStencil = true;
        // scene graph
        this.sortObjects = true;
        // user-defined clipping
        this.clippingPlanes = [];
        this.localClippingEnabled = false;
        // physically based shading
        this._outputColorSpace = SRGBColorSpace;
        // tone mapping
        this.toneMapping = NoToneMapping;
        this.toneMappingExposure = 1.0;
        // internal properties
        const _this = this;
        let _isContextLost = false;
        // internal state cache
        let _currentActiveCubeFace = 0;
        let _currentActiveMipmapLevel = 0;
        let _currentRenderTarget = null;
        let _currentMaterialId = -1;
        let _currentCamera = null;
        const _currentViewport = new Vector4();
        const _currentScissor = new Vector4();
        let _currentScissorTest = null;
        const _currentClearColor = new Color(0x000000);
        let _currentClearAlpha = 0;
        //
        let _width = canvas.width;
        let _height = canvas.height;
        let _pixelRatio = 1;
        let _opaqueSort = null;
        let _transparentSort = null;
        const _viewport = new Vector4(0, 0, _width, _height);
        const _scissor = new Vector4(0, 0, _width, _height);
        let _scissorTest = false;
        // frustum
        const _frustum = new Frustum();
        // clipping
        let _clippingEnabled = false;
        let _localClippingEnabled = false;
        // camera matrices cache
        const _projScreenMatrix = new Matrix4();
        const _vector3 = new Vector3();
        const _vector4 = new Vector4();
        const _emptyScene = {
            background: null,
            fog: null,
            environment: null,
            overrideMaterial: null,
            isScene: true
        };
        let _renderBackground = false;
        function getTargetPixelRatio() {
            return _currentRenderTarget === null ? _pixelRatio : 1;
        }
        // initialize
        let _gl = context;
        function getContext(contextName, contextAttributes) {
            return canvas.getContext(contextName, contextAttributes);
        }
        try {
            const contextAttributes = {
                alpha: true,
                depth,
                stencil,
                antialias,
                premultipliedAlpha,
                preserveDrawingBuffer,
                powerPreference,
                failIfMajorPerformanceCaveat
            };
            // OffscreenCanvas does not have setAttribute, see #22811
            if ("setAttribute" in canvas) canvas.setAttribute("data-engine", `three.js r${REVISION}`);
            // event listeners must be registered before WebGL context is created, see #12753
            canvas.addEventListener("webglcontextlost", onContextLost, false);
            canvas.addEventListener("webglcontextrestored", onContextRestore, false);
            canvas.addEventListener("webglcontextcreationerror", onContextCreationError, false);
            if (_gl === null) {
                const contextName = "webgl2";
                _gl = getContext(contextName, contextAttributes);
                if (_gl === null) {
                    if (getContext(contextName)) throw new Error("Error creating WebGL context with your selected attributes.");
                    else throw new Error("Error creating WebGL context.");
                }
            }
        } catch (error) {
            console.error("THREE.WebGLRenderer: " + error.message);
            throw error;
        }
        let extensions, capabilities, state, info;
        let properties, textures, cubemaps, cubeuvmaps, attributes, geometries, objects;
        let programCache, materials, renderLists, renderStates, clipping, shadowMap;
        let background, morphtargets, bufferRenderer, indexedBufferRenderer;
        let utils, bindingStates, uniformsGroups;
        function initGLContext() {
            extensions = new WebGLExtensions(_gl);
            extensions.init();
            utils = new WebGLUtils(_gl, extensions);
            capabilities = new WebGLCapabilities(_gl, extensions, parameters, utils);
            state = new WebGLState(_gl);
            info = new WebGLInfo(_gl);
            properties = new WebGLProperties();
            textures = new WebGLTextures(_gl, extensions, state, properties, capabilities, utils, info);
            cubemaps = new WebGLCubeMaps(_this);
            cubeuvmaps = new WebGLCubeUVMaps(_this);
            attributes = new WebGLAttributes(_gl);
            bindingStates = new WebGLBindingStates(_gl, attributes);
            geometries = new WebGLGeometries(_gl, attributes, info, bindingStates);
            objects = new WebGLObjects(_gl, geometries, attributes, info);
            morphtargets = new WebGLMorphtargets(_gl, capabilities, textures);
            clipping = new WebGLClipping(properties);
            programCache = new WebGLPrograms(_this, cubemaps, cubeuvmaps, extensions, capabilities, bindingStates, clipping);
            materials = new WebGLMaterials(_this, properties);
            renderLists = new WebGLRenderLists();
            renderStates = new WebGLRenderStates(extensions);
            background = new WebGLBackground(_this, cubemaps, cubeuvmaps, state, objects, _alpha, premultipliedAlpha);
            shadowMap = new WebGLShadowMap(_this, objects, capabilities);
            uniformsGroups = new WebGLUniformsGroups(_gl, info, capabilities, state);
            bufferRenderer = new WebGLBufferRenderer(_gl, extensions, info);
            indexedBufferRenderer = new WebGLIndexedBufferRenderer(_gl, extensions, info);
            info.programs = programCache.programs;
            _this.capabilities = capabilities;
            _this.extensions = extensions;
            _this.properties = properties;
            _this.renderLists = renderLists;
            _this.shadowMap = shadowMap;
            _this.state = state;
            _this.info = info;
        }
        initGLContext();
        // xr
        const xr = new WebXRManager(_this, _gl);
        this.xr = xr;
        // API
        this.getContext = function() {
            return _gl;
        };
        this.getContextAttributes = function() {
            return _gl.getContextAttributes();
        };
        this.forceContextLoss = function() {
            const extension = extensions.get("WEBGL_lose_context");
            if (extension) extension.loseContext();
        };
        this.forceContextRestore = function() {
            const extension = extensions.get("WEBGL_lose_context");
            if (extension) extension.restoreContext();
        };
        this.getPixelRatio = function() {
            return _pixelRatio;
        };
        this.setPixelRatio = function(value) {
            if (value === undefined) return;
            _pixelRatio = value;
            this.setSize(_width, _height, false);
        };
        this.getSize = function(target) {
            return target.set(_width, _height);
        };
        this.setSize = function(width, height, updateStyle = true) {
            if (xr.isPresenting) {
                console.warn("THREE.WebGLRenderer: Can't change size while VR device is presenting.");
                return;
            }
            _width = width;
            _height = height;
            canvas.width = Math.floor(width * _pixelRatio);
            canvas.height = Math.floor(height * _pixelRatio);
            if (updateStyle === true) {
                canvas.style.width = width + "px";
                canvas.style.height = height + "px";
            }
            this.setViewport(0, 0, width, height);
        };
        this.getDrawingBufferSize = function(target) {
            return target.set(_width * _pixelRatio, _height * _pixelRatio).floor();
        };
        this.setDrawingBufferSize = function(width, height, pixelRatio) {
            _width = width;
            _height = height;
            _pixelRatio = pixelRatio;
            canvas.width = Math.floor(width * pixelRatio);
            canvas.height = Math.floor(height * pixelRatio);
            this.setViewport(0, 0, width, height);
        };
        this.getCurrentViewport = function(target) {
            return target.copy(_currentViewport);
        };
        this.getViewport = function(target) {
            return target.copy(_viewport);
        };
        this.setViewport = function(x, y, width, height) {
            if (x.isVector4) _viewport.set(x.x, x.y, x.z, x.w);
            else _viewport.set(x, y, width, height);
            state.viewport(_currentViewport.copy(_viewport).multiplyScalar(_pixelRatio).round());
        };
        this.getScissor = function(target) {
            return target.copy(_scissor);
        };
        this.setScissor = function(x, y, width, height) {
            if (x.isVector4) _scissor.set(x.x, x.y, x.z, x.w);
            else _scissor.set(x, y, width, height);
            state.scissor(_currentScissor.copy(_scissor).multiplyScalar(_pixelRatio).round());
        };
        this.getScissorTest = function() {
            return _scissorTest;
        };
        this.setScissorTest = function(boolean) {
            state.setScissorTest(_scissorTest = boolean);
        };
        this.setOpaqueSort = function(method) {
            _opaqueSort = method;
        };
        this.setTransparentSort = function(method) {
            _transparentSort = method;
        };
        // Clearing
        this.getClearColor = function(target) {
            return target.copy(background.getClearColor());
        };
        this.setClearColor = function() {
            background.setClearColor.apply(background, arguments);
        };
        this.getClearAlpha = function() {
            return background.getClearAlpha();
        };
        this.setClearAlpha = function() {
            background.setClearAlpha.apply(background, arguments);
        };
        this.clear = function(color = true, depth = true, stencil = true) {
            let bits = 0;
            if (color) {
                // check if we're trying to clear an integer target
                let isIntegerFormat = false;
                if (_currentRenderTarget !== null) {
                    const targetFormat = _currentRenderTarget.texture.format;
                    isIntegerFormat = targetFormat === RGBAIntegerFormat || targetFormat === RGIntegerFormat || targetFormat === RedIntegerFormat;
                }
                // use the appropriate clear functions to clear the target if it's a signed
                // or unsigned integer target
                if (isIntegerFormat) {
                    const targetType = _currentRenderTarget.texture.type;
                    const isUnsignedType = targetType === UnsignedByteType || targetType === UnsignedIntType || targetType === UnsignedShortType || targetType === UnsignedInt248Type || targetType === UnsignedShort4444Type || targetType === UnsignedShort5551Type;
                    const clearColor = background.getClearColor();
                    const a = background.getClearAlpha();
                    const r = clearColor.r;
                    const g = clearColor.g;
                    const b = clearColor.b;
                    if (isUnsignedType) {
                        uintClearColor[0] = r;
                        uintClearColor[1] = g;
                        uintClearColor[2] = b;
                        uintClearColor[3] = a;
                        _gl.clearBufferuiv(_gl.COLOR, 0, uintClearColor);
                    } else {
                        intClearColor[0] = r;
                        intClearColor[1] = g;
                        intClearColor[2] = b;
                        intClearColor[3] = a;
                        _gl.clearBufferiv(_gl.COLOR, 0, intClearColor);
                    }
                } else bits |= _gl.COLOR_BUFFER_BIT;
            }
            if (depth) bits |= _gl.DEPTH_BUFFER_BIT;
            if (stencil) {
                bits |= _gl.STENCIL_BUFFER_BIT;
                this.state.buffers.stencil.setMask(0xffffffff);
            }
            _gl.clear(bits);
        };
        this.clearColor = function() {
            this.clear(true, false, false);
        };
        this.clearDepth = function() {
            this.clear(false, true, false);
        };
        this.clearStencil = function() {
            this.clear(false, false, true);
        };
        //
        this.dispose = function() {
            canvas.removeEventListener("webglcontextlost", onContextLost, false);
            canvas.removeEventListener("webglcontextrestored", onContextRestore, false);
            canvas.removeEventListener("webglcontextcreationerror", onContextCreationError, false);
            renderLists.dispose();
            renderStates.dispose();
            properties.dispose();
            cubemaps.dispose();
            cubeuvmaps.dispose();
            objects.dispose();
            bindingStates.dispose();
            uniformsGroups.dispose();
            programCache.dispose();
            xr.dispose();
            xr.removeEventListener("sessionstart", onXRSessionStart);
            xr.removeEventListener("sessionend", onXRSessionEnd);
            animation.stop();
        };
        // Events
        function onContextLost(event) {
            event.preventDefault();
            console.log("THREE.WebGLRenderer: Context Lost.");
            _isContextLost = true;
        }
        function onContextRestore() {
            console.log("THREE.WebGLRenderer: Context Restored.");
            _isContextLost = false;
            const infoAutoReset = info.autoReset;
            const shadowMapEnabled = shadowMap.enabled;
            const shadowMapAutoUpdate = shadowMap.autoUpdate;
            const shadowMapNeedsUpdate = shadowMap.needsUpdate;
            const shadowMapType = shadowMap.type;
            initGLContext();
            info.autoReset = infoAutoReset;
            shadowMap.enabled = shadowMapEnabled;
            shadowMap.autoUpdate = shadowMapAutoUpdate;
            shadowMap.needsUpdate = shadowMapNeedsUpdate;
            shadowMap.type = shadowMapType;
        }
        function onContextCreationError(event) {
            console.error("THREE.WebGLRenderer: A WebGL context could not be created. Reason: ", event.statusMessage);
        }
        function onMaterialDispose(event) {
            const material = event.target;
            material.removeEventListener("dispose", onMaterialDispose);
            deallocateMaterial(material);
        }
        // Buffer deallocation
        function deallocateMaterial(material) {
            releaseMaterialProgramReferences(material);
            properties.remove(material);
        }
        function releaseMaterialProgramReferences(material) {
            const programs = properties.get(material).programs;
            if (programs !== undefined) {
                programs.forEach(function(program) {
                    programCache.releaseProgram(program);
                });
                if (material.isShaderMaterial) programCache.releaseShaderCache(material);
            }
        }
        // Buffer rendering
        this.renderBufferDirect = function(camera, scene, geometry, material, object, group) {
            if (scene === null) scene = _emptyScene; // renderBufferDirect second parameter used to be fog (could be null)
            const frontFaceCW = object.isMesh && object.matrixWorld.determinant() < 0;
            const program = setProgram(camera, scene, geometry, material, object);
            state.setMaterial(material, frontFaceCW);
            //
            let index = geometry.index;
            let rangeFactor = 1;
            if (material.wireframe === true) {
                index = geometries.getWireframeAttribute(geometry);
                if (index === undefined) return;
                rangeFactor = 2;
            }
            //
            const drawRange = geometry.drawRange;
            const position = geometry.attributes.position;
            let drawStart = drawRange.start * rangeFactor;
            let drawEnd = (drawRange.start + drawRange.count) * rangeFactor;
            if (group !== null) {
                drawStart = Math.max(drawStart, group.start * rangeFactor);
                drawEnd = Math.min(drawEnd, (group.start + group.count) * rangeFactor);
            }
            if (index !== null) {
                drawStart = Math.max(drawStart, 0);
                drawEnd = Math.min(drawEnd, index.count);
            } else if (position !== undefined && position !== null) {
                drawStart = Math.max(drawStart, 0);
                drawEnd = Math.min(drawEnd, position.count);
            }
            const drawCount = drawEnd - drawStart;
            if (drawCount < 0 || drawCount === Infinity) return;
            //
            bindingStates.setup(object, material, program, geometry, index);
            let attribute;
            let renderer = bufferRenderer;
            if (index !== null) {
                attribute = attributes.get(index);
                renderer = indexedBufferRenderer;
                renderer.setIndex(attribute);
            }
            //
            if (object.isMesh) {
                if (material.wireframe === true) {
                    state.setLineWidth(material.wireframeLinewidth * getTargetPixelRatio());
                    renderer.setMode(_gl.LINES);
                } else renderer.setMode(_gl.TRIANGLES);
            } else if (object.isLine) {
                let lineWidth = material.linewidth;
                if (lineWidth === undefined) lineWidth = 1; // Not using Line*Material
                state.setLineWidth(lineWidth * getTargetPixelRatio());
                if (object.isLineSegments) renderer.setMode(_gl.LINES);
                else if (object.isLineLoop) renderer.setMode(_gl.LINE_LOOP);
                else renderer.setMode(_gl.LINE_STRIP);
            } else if (object.isPoints) renderer.setMode(_gl.POINTS);
            else if (object.isSprite) renderer.setMode(_gl.TRIANGLES);
            if (object.isBatchedMesh) {
                if (object._multiDrawInstances !== null) renderer.renderMultiDrawInstances(object._multiDrawStarts, object._multiDrawCounts, object._multiDrawCount, object._multiDrawInstances);
                else if (!extensions.get("WEBGL_multi_draw")) {
                    const starts = object._multiDrawStarts;
                    const counts = object._multiDrawCounts;
                    const drawCount = object._multiDrawCount;
                    const bytesPerElement = index ? attributes.get(index).bytesPerElement : 1;
                    const uniforms = properties.get(material).currentProgram.getUniforms();
                    for(let i = 0; i < drawCount; i++){
                        uniforms.setValue(_gl, "_gl_DrawID", i);
                        renderer.render(starts[i] / bytesPerElement, counts[i]);
                    }
                } else renderer.renderMultiDraw(object._multiDrawStarts, object._multiDrawCounts, object._multiDrawCount);
            } else if (object.isInstancedMesh) renderer.renderInstances(drawStart, drawCount, object.count);
            else if (geometry.isInstancedBufferGeometry) {
                const maxInstanceCount = geometry._maxInstanceCount !== undefined ? geometry._maxInstanceCount : Infinity;
                const instanceCount = Math.min(geometry.instanceCount, maxInstanceCount);
                renderer.renderInstances(drawStart, drawCount, instanceCount);
            } else renderer.render(drawStart, drawCount);
        };
        // Compile
        function prepareMaterial(material, scene, object) {
            if (material.transparent === true && material.side === DoubleSide && material.forceSinglePass === false) {
                material.side = BackSide;
                material.needsUpdate = true;
                getProgram(material, scene, object);
                material.side = FrontSide;
                material.needsUpdate = true;
                getProgram(material, scene, object);
                material.side = DoubleSide;
            } else getProgram(material, scene, object);
        }
        this.compile = function(scene, camera, targetScene = null) {
            if (targetScene === null) targetScene = scene;
            currentRenderState = renderStates.get(targetScene);
            currentRenderState.init(camera);
            renderStateStack.push(currentRenderState);
            // gather lights from both the target scene and the new object that will be added to the scene.
            targetScene.traverseVisible(function(object) {
                if (object.isLight && object.layers.test(camera.layers)) {
                    currentRenderState.pushLight(object);
                    if (object.castShadow) currentRenderState.pushShadow(object);
                }
            });
            if (scene !== targetScene) scene.traverseVisible(function(object) {
                if (object.isLight && object.layers.test(camera.layers)) {
                    currentRenderState.pushLight(object);
                    if (object.castShadow) currentRenderState.pushShadow(object);
                }
            });
            currentRenderState.setupLights();
            // Only initialize materials in the new scene, not the targetScene.
            const materials = new Set();
            scene.traverse(function(object) {
                const material = object.material;
                if (material) {
                    if (Array.isArray(material)) for(let i = 0; i < material.length; i++){
                        const material2 = material[i];
                        prepareMaterial(material2, targetScene, object);
                        materials.add(material2);
                    }
                    else {
                        prepareMaterial(material, targetScene, object);
                        materials.add(material);
                    }
                }
            });
            renderStateStack.pop();
            currentRenderState = null;
            return materials;
        };
        // compileAsync
        this.compileAsync = function(scene, camera, targetScene = null) {
            const materials = this.compile(scene, camera, targetScene);
            // Wait for all the materials in the new object to indicate that they're
            // ready to be used before resolving the promise.
            return new Promise((resolve)=>{
                function checkMaterialsReady() {
                    materials.forEach(function(material) {
                        const materialProperties = properties.get(material);
                        const program = materialProperties.currentProgram;
                        if (program.isReady()) // remove any programs that report they're ready to use from the list
                        materials.delete(material);
                    });
                    // once the list of compiling materials is empty, call the callback
                    if (materials.size === 0) {
                        resolve(scene);
                        return;
                    }
                    // if some materials are still not ready, wait a bit and check again
                    setTimeout(checkMaterialsReady, 10);
                }
                if (extensions.get("KHR_parallel_shader_compile") !== null) // If we can check the compilation status of the materials without
                // blocking then do so right away.
                checkMaterialsReady();
                else // Otherwise start by waiting a bit to give the materials we just
                // initialized a chance to finish.
                setTimeout(checkMaterialsReady, 10);
            });
        };
        // Animation Loop
        let onAnimationFrameCallback = null;
        function onAnimationFrame(time) {
            if (onAnimationFrameCallback) onAnimationFrameCallback(time);
        }
        function onXRSessionStart() {
            animation.stop();
        }
        function onXRSessionEnd() {
            animation.start();
        }
        const animation = new WebGLAnimation();
        animation.setAnimationLoop(onAnimationFrame);
        if (typeof self !== "undefined") animation.setContext(self);
        this.setAnimationLoop = function(callback) {
            onAnimationFrameCallback = callback;
            xr.setAnimationLoop(callback);
            callback === null ? animation.stop() : animation.start();
        };
        xr.addEventListener("sessionstart", onXRSessionStart);
        xr.addEventListener("sessionend", onXRSessionEnd);
        // Rendering
        this.render = function(scene, camera) {
            if (camera !== undefined && camera.isCamera !== true) {
                console.error("THREE.WebGLRenderer.render: camera is not an instance of THREE.Camera.");
                return;
            }
            if (_isContextLost === true) return;
            // update scene graph
            if (scene.matrixWorldAutoUpdate === true) scene.updateMatrixWorld();
            // update camera matrices and frustum
            if (camera.parent === null && camera.matrixWorldAutoUpdate === true) camera.updateMatrixWorld();
            if (xr.enabled === true && xr.isPresenting === true) {
                if (xr.cameraAutoUpdate === true) xr.updateCamera(camera);
                camera = xr.getCamera(); // use XR camera for rendering
            }
            //
            if (scene.isScene === true) scene.onBeforeRender(_this, scene, camera, _currentRenderTarget);
            currentRenderState = renderStates.get(scene, renderStateStack.length);
            currentRenderState.init(camera);
            renderStateStack.push(currentRenderState);
            _projScreenMatrix.multiplyMatrices(camera.projectionMatrix, camera.matrixWorldInverse);
            _frustum.setFromProjectionMatrix(_projScreenMatrix);
            _localClippingEnabled = this.localClippingEnabled;
            _clippingEnabled = clipping.init(this.clippingPlanes, _localClippingEnabled);
            currentRenderList = renderLists.get(scene, renderListStack.length);
            currentRenderList.init();
            renderListStack.push(currentRenderList);
            if (xr.enabled === true && xr.isPresenting === true) {
                const depthSensingMesh = _this.xr.getDepthSensingMesh();
                if (depthSensingMesh !== null) projectObject(depthSensingMesh, camera, -Infinity, _this.sortObjects);
            }
            projectObject(scene, camera, 0, _this.sortObjects);
            currentRenderList.finish();
            if (_this.sortObjects === true) currentRenderList.sort(_opaqueSort, _transparentSort);
            _renderBackground = xr.enabled === false || xr.isPresenting === false || xr.hasDepthSensing() === false;
            if (_renderBackground) background.addToRenderList(currentRenderList, scene);
            //
            this.info.render.frame++;
            if (_clippingEnabled === true) clipping.beginShadows();
            const shadowsArray = currentRenderState.state.shadowsArray;
            shadowMap.render(shadowsArray, scene, camera);
            if (_clippingEnabled === true) clipping.endShadows();
            //
            if (this.info.autoReset === true) this.info.reset();
            // render scene
            const opaqueObjects = currentRenderList.opaque;
            const transmissiveObjects = currentRenderList.transmissive;
            currentRenderState.setupLights();
            if (camera.isArrayCamera) {
                const cameras = camera.cameras;
                if (transmissiveObjects.length > 0) for(let i = 0, l = cameras.length; i < l; i++){
                    const camera2 = cameras[i];
                    renderTransmissionPass(opaqueObjects, transmissiveObjects, scene, camera2);
                }
                if (_renderBackground) background.render(scene);
                for(let i = 0, l = cameras.length; i < l; i++){
                    const camera2 = cameras[i];
                    renderScene(currentRenderList, scene, camera2, camera2.viewport);
                }
            } else {
                if (transmissiveObjects.length > 0) renderTransmissionPass(opaqueObjects, transmissiveObjects, scene, camera);
                if (_renderBackground) background.render(scene);
                renderScene(currentRenderList, scene, camera);
            }
            //
            if (_currentRenderTarget !== null) {
                // resolve multisample renderbuffers to a single-sample texture if necessary
                textures.updateMultisampleRenderTarget(_currentRenderTarget);
                // Generate mipmap if we're using any kind of mipmap filtering
                textures.updateRenderTargetMipmap(_currentRenderTarget);
            }
            //
            if (scene.isScene === true) scene.onAfterRender(_this, scene, camera);
            // _gl.finish();
            bindingStates.resetDefaultState();
            _currentMaterialId = -1;
            _currentCamera = null;
            renderStateStack.pop();
            if (renderStateStack.length > 0) {
                currentRenderState = renderStateStack[renderStateStack.length - 1];
                if (_clippingEnabled === true) clipping.setGlobalState(_this.clippingPlanes, currentRenderState.state.camera);
            } else currentRenderState = null;
            renderListStack.pop();
            if (renderListStack.length > 0) currentRenderList = renderListStack[renderListStack.length - 1];
            else currentRenderList = null;
        };
        function projectObject(object, camera, groupOrder, sortObjects) {
            if (object.visible === false) return;
            const visible = object.layers.test(camera.layers);
            if (visible) {
                if (object.isGroup) groupOrder = object.renderOrder;
                else if (object.isLOD) {
                    if (object.autoUpdate === true) object.update(camera);
                } else if (object.isLight) {
                    currentRenderState.pushLight(object);
                    if (object.castShadow) currentRenderState.pushShadow(object);
                } else if (object.isSprite) {
                    if (!object.frustumCulled || _frustum.intersectsSprite(object)) {
                        if (sortObjects) _vector4.setFromMatrixPosition(object.matrixWorld).applyMatrix4(_projScreenMatrix);
                        const geometry = objects.update(object);
                        const material = object.material;
                        if (material.visible) currentRenderList.push(object, geometry, material, groupOrder, _vector4.z, null);
                    }
                } else if (object.isMesh || object.isLine || object.isPoints) {
                    if (!object.frustumCulled || _frustum.intersectsObject(object)) {
                        const geometry = objects.update(object);
                        const material = object.material;
                        if (sortObjects) {
                            if (object.boundingSphere !== undefined) {
                                if (object.boundingSphere === null) object.computeBoundingSphere();
                                _vector4.copy(object.boundingSphere.center);
                            } else {
                                if (geometry.boundingSphere === null) geometry.computeBoundingSphere();
                                _vector4.copy(geometry.boundingSphere.center);
                            }
                            _vector4.applyMatrix4(object.matrixWorld).applyMatrix4(_projScreenMatrix);
                        }
                        if (Array.isArray(material)) {
                            const groups = geometry.groups;
                            for(let i = 0, l = groups.length; i < l; i++){
                                const group = groups[i];
                                const groupMaterial = material[group.materialIndex];
                                if (groupMaterial && groupMaterial.visible) currentRenderList.push(object, geometry, groupMaterial, groupOrder, _vector4.z, group);
                            }
                        } else if (material.visible) currentRenderList.push(object, geometry, material, groupOrder, _vector4.z, null);
                    }
                }
            }
            const children = object.children;
            for(let i = 0, l = children.length; i < l; i++)projectObject(children[i], camera, groupOrder, sortObjects);
        }
        function renderScene(currentRenderList, scene, camera, viewport) {
            const opaqueObjects = currentRenderList.opaque;
            const transmissiveObjects = currentRenderList.transmissive;
            const transparentObjects = currentRenderList.transparent;
            currentRenderState.setupLightsView(camera);
            if (_clippingEnabled === true) clipping.setGlobalState(_this.clippingPlanes, camera);
            if (viewport) state.viewport(_currentViewport.copy(viewport));
            if (opaqueObjects.length > 0) renderObjects(opaqueObjects, scene, camera);
            if (transmissiveObjects.length > 0) renderObjects(transmissiveObjects, scene, camera);
            if (transparentObjects.length > 0) renderObjects(transparentObjects, scene, camera);
            // Ensure depth buffer writing is enabled so it can be cleared on next render
            state.buffers.depth.setTest(true);
            state.buffers.depth.setMask(true);
            state.buffers.color.setMask(true);
            state.setPolygonOffset(false);
        }
        function renderTransmissionPass(opaqueObjects, transmissiveObjects, scene, camera) {
            const overrideMaterial = scene.isScene === true ? scene.overrideMaterial : null;
            if (overrideMaterial !== null) return;
            if (currentRenderState.state.transmissionRenderTarget[camera.id] === undefined) currentRenderState.state.transmissionRenderTarget[camera.id] = new WebGLRenderTarget(1, 1, {
                generateMipmaps: true,
                type: extensions.has("EXT_color_buffer_half_float") || extensions.has("EXT_color_buffer_float") ? HalfFloatType : UnsignedByteType,
                minFilter: LinearMipmapLinearFilter,
                samples: 4,
                stencilBuffer: stencil,
                resolveDepthBuffer: false,
                resolveStencilBuffer: false,
                colorSpace: ColorManagement.workingColorSpace
            });
            const transmissionRenderTarget = currentRenderState.state.transmissionRenderTarget[camera.id];
            const activeViewport = camera.viewport || _currentViewport;
            transmissionRenderTarget.setSize(activeViewport.z, activeViewport.w);
            //
            const currentRenderTarget = _this.getRenderTarget();
            _this.setRenderTarget(transmissionRenderTarget);
            _this.getClearColor(_currentClearColor);
            _currentClearAlpha = _this.getClearAlpha();
            if (_currentClearAlpha < 1) _this.setClearColor(0xffffff, 0.5);
            if (_renderBackground) background.render(scene);
            else _this.clear();
            // Turn off the features which can affect the frag color for opaque objects pass.
            // Otherwise they are applied twice in opaque objects pass and transmission objects pass.
            const currentToneMapping = _this.toneMapping;
            _this.toneMapping = NoToneMapping;
            // Remove viewport from camera to avoid nested render calls resetting viewport to it (e.g Reflector).
            // Transmission render pass requires viewport to match the transmissionRenderTarget.
            const currentCameraViewport = camera.viewport;
            if (camera.viewport !== undefined) camera.viewport = undefined;
            currentRenderState.setupLightsView(camera);
            if (_clippingEnabled === true) clipping.setGlobalState(_this.clippingPlanes, camera);
            renderObjects(opaqueObjects, scene, camera);
            textures.updateMultisampleRenderTarget(transmissionRenderTarget);
            textures.updateRenderTargetMipmap(transmissionRenderTarget);
            if (extensions.has("WEBGL_multisampled_render_to_texture") === false) {
                let renderTargetNeedsUpdate = false;
                for(let i = 0, l = transmissiveObjects.length; i < l; i++){
                    const renderItem = transmissiveObjects[i];
                    const object = renderItem.object;
                    const geometry = renderItem.geometry;
                    const material = renderItem.material;
                    const group = renderItem.group;
                    if (material.side === DoubleSide && object.layers.test(camera.layers)) {
                        const currentSide = material.side;
                        material.side = BackSide;
                        material.needsUpdate = true;
                        renderObject(object, scene, camera, geometry, material, group);
                        material.side = currentSide;
                        material.needsUpdate = true;
                        renderTargetNeedsUpdate = true;
                    }
                }
                if (renderTargetNeedsUpdate === true) {
                    textures.updateMultisampleRenderTarget(transmissionRenderTarget);
                    textures.updateRenderTargetMipmap(transmissionRenderTarget);
                }
            }
            _this.setRenderTarget(currentRenderTarget);
            _this.setClearColor(_currentClearColor, _currentClearAlpha);
            if (currentCameraViewport !== undefined) camera.viewport = currentCameraViewport;
            _this.toneMapping = currentToneMapping;
        }
        function renderObjects(renderList, scene, camera) {
            const overrideMaterial = scene.isScene === true ? scene.overrideMaterial : null;
            for(let i = 0, l = renderList.length; i < l; i++){
                const renderItem = renderList[i];
                const object = renderItem.object;
                const geometry = renderItem.geometry;
                const material = overrideMaterial === null ? renderItem.material : overrideMaterial;
                const group = renderItem.group;
                if (object.layers.test(camera.layers)) renderObject(object, scene, camera, geometry, material, group);
            }
        }
        function renderObject(object, scene, camera, geometry, material, group) {
            object.onBeforeRender(_this, scene, camera, geometry, material, group);
            object.modelViewMatrix.multiplyMatrices(camera.matrixWorldInverse, object.matrixWorld);
            object.normalMatrix.getNormalMatrix(object.modelViewMatrix);
            if (material.transparent === true && material.side === DoubleSide && material.forceSinglePass === false) {
                material.side = BackSide;
                material.needsUpdate = true;
                _this.renderBufferDirect(camera, scene, geometry, material, object, group);
                material.side = FrontSide;
                material.needsUpdate = true;
                _this.renderBufferDirect(camera, scene, geometry, material, object, group);
                material.side = DoubleSide;
            } else _this.renderBufferDirect(camera, scene, geometry, material, object, group);
            object.onAfterRender(_this, scene, camera, geometry, material, group);
        }
        function getProgram(material, scene, object) {
            if (scene.isScene !== true) scene = _emptyScene; // scene could be a Mesh, Line, Points, ...
            const materialProperties = properties.get(material);
            const lights = currentRenderState.state.lights;
            const shadowsArray = currentRenderState.state.shadowsArray;
            const lightsStateVersion = lights.state.version;
            const parameters = programCache.getParameters(material, lights.state, shadowsArray, scene, object);
            const programCacheKey = programCache.getProgramCacheKey(parameters);
            let programs = materialProperties.programs;
            // always update environment and fog - changing these trigger an getProgram call, but it's possible that the program doesn't change
            materialProperties.environment = material.isMeshStandardMaterial ? scene.environment : null;
            materialProperties.fog = scene.fog;
            materialProperties.envMap = (material.isMeshStandardMaterial ? cubeuvmaps : cubemaps).get(material.envMap || materialProperties.environment);
            materialProperties.envMapRotation = materialProperties.environment !== null && material.envMap === null ? scene.environmentRotation : material.envMapRotation;
            if (programs === undefined) {
                // new material
                material.addEventListener("dispose", onMaterialDispose);
                programs = new Map();
                materialProperties.programs = programs;
            }
            let program = programs.get(programCacheKey);
            if (program !== undefined) // early out if program and light state is identical
            {
                if (materialProperties.currentProgram === program && materialProperties.lightsStateVersion === lightsStateVersion) {
                    updateCommonMaterialProperties(material, parameters);
                    return program;
                }
            } else {
                parameters.uniforms = programCache.getUniforms(material);
                material.onBeforeCompile(parameters, _this);
                program = programCache.acquireProgram(parameters, programCacheKey);
                programs.set(programCacheKey, program);
                materialProperties.uniforms = parameters.uniforms;
            }
            const uniforms = materialProperties.uniforms;
            if (!material.isShaderMaterial && !material.isRawShaderMaterial || material.clipping === true) uniforms.clippingPlanes = clipping.uniform;
            updateCommonMaterialProperties(material, parameters);
            // store the light setup it was created for
            materialProperties.needsLights = materialNeedsLights(material);
            materialProperties.lightsStateVersion = lightsStateVersion;
            if (materialProperties.needsLights) {
                // wire up the material to this renderer's lighting state
                uniforms.ambientLightColor.value = lights.state.ambient;
                uniforms.lightProbe.value = lights.state.probe;
                uniforms.directionalLights.value = lights.state.directional;
                uniforms.directionalLightShadows.value = lights.state.directionalShadow;
                uniforms.spotLights.value = lights.state.spot;
                uniforms.spotLightShadows.value = lights.state.spotShadow;
                uniforms.rectAreaLights.value = lights.state.rectArea;
                uniforms.ltc_1.value = lights.state.rectAreaLTC1;
                uniforms.ltc_2.value = lights.state.rectAreaLTC2;
                uniforms.pointLights.value = lights.state.point;
                uniforms.pointLightShadows.value = lights.state.pointShadow;
                uniforms.hemisphereLights.value = lights.state.hemi;
                uniforms.directionalShadowMap.value = lights.state.directionalShadowMap;
                uniforms.directionalShadowMatrix.value = lights.state.directionalShadowMatrix;
                uniforms.spotShadowMap.value = lights.state.spotShadowMap;
                uniforms.spotLightMatrix.value = lights.state.spotLightMatrix;
                uniforms.spotLightMap.value = lights.state.spotLightMap;
                uniforms.pointShadowMap.value = lights.state.pointShadowMap;
                uniforms.pointShadowMatrix.value = lights.state.pointShadowMatrix;
            // TODO (abelnation): add area lights shadow info to uniforms
            }
            materialProperties.currentProgram = program;
            materialProperties.uniformsList = null;
            return program;
        }
        function getUniformList(materialProperties) {
            if (materialProperties.uniformsList === null) {
                const progUniforms = materialProperties.currentProgram.getUniforms();
                materialProperties.uniformsList = WebGLUniforms.seqWithValue(progUniforms.seq, materialProperties.uniforms);
            }
            return materialProperties.uniformsList;
        }
        function updateCommonMaterialProperties(material, parameters) {
            const materialProperties = properties.get(material);
            materialProperties.outputColorSpace = parameters.outputColorSpace;
            materialProperties.batching = parameters.batching;
            materialProperties.batchingColor = parameters.batchingColor;
            materialProperties.instancing = parameters.instancing;
            materialProperties.instancingColor = parameters.instancingColor;
            materialProperties.instancingMorph = parameters.instancingMorph;
            materialProperties.skinning = parameters.skinning;
            materialProperties.morphTargets = parameters.morphTargets;
            materialProperties.morphNormals = parameters.morphNormals;
            materialProperties.morphColors = parameters.morphColors;
            materialProperties.morphTargetsCount = parameters.morphTargetsCount;
            materialProperties.numClippingPlanes = parameters.numClippingPlanes;
            materialProperties.numIntersection = parameters.numClipIntersection;
            materialProperties.vertexAlphas = parameters.vertexAlphas;
            materialProperties.vertexTangents = parameters.vertexTangents;
            materialProperties.toneMapping = parameters.toneMapping;
        }
        function setProgram(camera, scene, geometry, material, object) {
            if (scene.isScene !== true) scene = _emptyScene; // scene could be a Mesh, Line, Points, ...
            textures.resetTextureUnits();
            const fog = scene.fog;
            const environment = material.isMeshStandardMaterial ? scene.environment : null;
            const colorSpace1 = _currentRenderTarget === null ? _this.outputColorSpace : _currentRenderTarget.isXRRenderTarget === true ? _currentRenderTarget.texture.colorSpace : LinearSRGBColorSpace;
            const envMap = (material.isMeshStandardMaterial ? cubeuvmaps : cubemaps).get(material.envMap || environment);
            const vertexAlphas = material.vertexColors === true && !!geometry.attributes.color && geometry.attributes.color.itemSize === 4;
            const vertexTangents = !!geometry.attributes.tangent && (!!material.normalMap || material.anisotropy > 0);
            const morphTargets = !!geometry.morphAttributes.position;
            const morphNormals = !!geometry.morphAttributes.normal;
            const morphColors = !!geometry.morphAttributes.color;
            let toneMapping = NoToneMapping;
            if (material.toneMapped) {
                if (_currentRenderTarget === null || _currentRenderTarget.isXRRenderTarget === true) toneMapping = _this.toneMapping;
            }
            const morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;
            const morphTargetsCount = morphAttribute !== undefined ? morphAttribute.length : 0;
            const materialProperties = properties.get(material);
            const lights = currentRenderState.state.lights;
            if (_clippingEnabled === true) {
                if (_localClippingEnabled === true || camera !== _currentCamera) {
                    const useCache = camera === _currentCamera && material.id === _currentMaterialId;
                    // we might want to call this function with some ClippingGroup
                    // object instead of the material, once it becomes feasible
                    // (#8465, #8379)
                    clipping.setState(material, camera, useCache);
                }
            }
            //
            let needsProgramChange = false;
            if (material.version === materialProperties.__version) {
                if (materialProperties.needsLights && materialProperties.lightsStateVersion !== lights.state.version) needsProgramChange = true;
                else if (materialProperties.outputColorSpace !== colorSpace1) needsProgramChange = true;
                else if (object.isBatchedMesh && materialProperties.batching === false) needsProgramChange = true;
                else if (!object.isBatchedMesh && materialProperties.batching === true) needsProgramChange = true;
                else if (object.isBatchedMesh && materialProperties.batchingColor === true && object.colorTexture === null) needsProgramChange = true;
                else if (object.isBatchedMesh && materialProperties.batchingColor === false && object.colorTexture !== null) needsProgramChange = true;
                else if (object.isInstancedMesh && materialProperties.instancing === false) needsProgramChange = true;
                else if (!object.isInstancedMesh && materialProperties.instancing === true) needsProgramChange = true;
                else if (object.isSkinnedMesh && materialProperties.skinning === false) needsProgramChange = true;
                else if (!object.isSkinnedMesh && materialProperties.skinning === true) needsProgramChange = true;
                else if (object.isInstancedMesh && materialProperties.instancingColor === true && object.instanceColor === null) needsProgramChange = true;
                else if (object.isInstancedMesh && materialProperties.instancingColor === false && object.instanceColor !== null) needsProgramChange = true;
                else if (object.isInstancedMesh && materialProperties.instancingMorph === true && object.morphTexture === null) needsProgramChange = true;
                else if (object.isInstancedMesh && materialProperties.instancingMorph === false && object.morphTexture !== null) needsProgramChange = true;
                else if (materialProperties.envMap !== envMap) needsProgramChange = true;
                else if (material.fog === true && materialProperties.fog !== fog) needsProgramChange = true;
                else if (materialProperties.numClippingPlanes !== undefined && (materialProperties.numClippingPlanes !== clipping.numPlanes || materialProperties.numIntersection !== clipping.numIntersection)) needsProgramChange = true;
                else if (materialProperties.vertexAlphas !== vertexAlphas) needsProgramChange = true;
                else if (materialProperties.vertexTangents !== vertexTangents) needsProgramChange = true;
                else if (materialProperties.morphTargets !== morphTargets) needsProgramChange = true;
                else if (materialProperties.morphNormals !== morphNormals) needsProgramChange = true;
                else if (materialProperties.morphColors !== morphColors) needsProgramChange = true;
                else if (materialProperties.toneMapping !== toneMapping) needsProgramChange = true;
                else if (materialProperties.morphTargetsCount !== morphTargetsCount) needsProgramChange = true;
            } else {
                needsProgramChange = true;
                materialProperties.__version = material.version;
            }
            //
            let program = materialProperties.currentProgram;
            if (needsProgramChange === true) program = getProgram(material, scene, object);
            let refreshProgram = false;
            let refreshMaterial = false;
            let refreshLights = false;
            const p_uniforms = program.getUniforms(), m_uniforms = materialProperties.uniforms;
            if (state.useProgram(program.program)) {
                refreshProgram = true;
                refreshMaterial = true;
                refreshLights = true;
            }
            if (material.id !== _currentMaterialId) {
                _currentMaterialId = material.id;
                refreshMaterial = true;
            }
            if (refreshProgram || _currentCamera !== camera) {
                // common camera uniforms
                p_uniforms.setValue(_gl, "projectionMatrix", camera.projectionMatrix);
                p_uniforms.setValue(_gl, "viewMatrix", camera.matrixWorldInverse);
                const uCamPos = p_uniforms.map.cameraPosition;
                if (uCamPos !== undefined) uCamPos.setValue(_gl, _vector3.setFromMatrixPosition(camera.matrixWorld));
                if (capabilities.logarithmicDepthBuffer) p_uniforms.setValue(_gl, "logDepthBufFC", 2.0 / (Math.log(camera.far + 1.0) / Math.LN2));
                // consider moving isOrthographic to UniformLib and WebGLMaterials, see https://github.com/mrdoob/three.js/pull/26467#issuecomment-1645185067
                if (material.isMeshPhongMaterial || material.isMeshToonMaterial || material.isMeshLambertMaterial || material.isMeshBasicMaterial || material.isMeshStandardMaterial || material.isShaderMaterial) p_uniforms.setValue(_gl, "isOrthographic", camera.isOrthographicCamera === true);
                if (_currentCamera !== camera) {
                    _currentCamera = camera;
                    // lighting uniforms depend on the camera so enforce an update
                    // now, in case this material supports lights - or later, when
                    // the next material that does gets activated:
                    refreshMaterial = true; // set to true on material change
                    refreshLights = true; // remains set until update done
                }
            }
            // skinning and morph target uniforms must be set even if material didn't change
            // auto-setting of texture unit for bone and morph texture must go before other textures
            // otherwise textures used for skinning and morphing can take over texture units reserved for other material textures
            if (object.isSkinnedMesh) {
                p_uniforms.setOptional(_gl, object, "bindMatrix");
                p_uniforms.setOptional(_gl, object, "bindMatrixInverse");
                const skeleton = object.skeleton;
                if (skeleton) {
                    if (skeleton.boneTexture === null) skeleton.computeBoneTexture();
                    p_uniforms.setValue(_gl, "boneTexture", skeleton.boneTexture, textures);
                }
            }
            if (object.isBatchedMesh) {
                p_uniforms.setOptional(_gl, object, "batchingTexture");
                p_uniforms.setValue(_gl, "batchingTexture", object._matricesTexture, textures);
                p_uniforms.setOptional(_gl, object, "batchingIdTexture");
                p_uniforms.setValue(_gl, "batchingIdTexture", object._indirectTexture, textures);
                p_uniforms.setOptional(_gl, object, "batchingColorTexture");
                if (object._colorsTexture !== null) p_uniforms.setValue(_gl, "batchingColorTexture", object._colorsTexture, textures);
            }
            const morphAttributes = geometry.morphAttributes;
            if (morphAttributes.position !== undefined || morphAttributes.normal !== undefined || morphAttributes.color !== undefined) morphtargets.update(object, geometry, program);
            if (refreshMaterial || materialProperties.receiveShadow !== object.receiveShadow) {
                materialProperties.receiveShadow = object.receiveShadow;
                p_uniforms.setValue(_gl, "receiveShadow", object.receiveShadow);
            }
            // https://github.com/mrdoob/three.js/pull/24467#issuecomment-1209031512
            if (material.isMeshGouraudMaterial && material.envMap !== null) {
                m_uniforms.envMap.value = envMap;
                m_uniforms.flipEnvMap.value = envMap.isCubeTexture && envMap.isRenderTargetTexture === false ? -1 : 1;
            }
            if (material.isMeshStandardMaterial && material.envMap === null && scene.environment !== null) m_uniforms.envMapIntensity.value = scene.environmentIntensity;
            if (refreshMaterial) {
                p_uniforms.setValue(_gl, "toneMappingExposure", _this.toneMappingExposure);
                if (materialProperties.needsLights) // the current material requires lighting info
                // note: all lighting uniforms are always set correctly
                // they simply reference the renderer's state for their
                // values
                //
                // use the current material's .needsUpdate flags to set
                // the GL state when required
                markUniformsLightsNeedsUpdate(m_uniforms, refreshLights);
                // refresh uniforms common to several materials
                if (fog && material.fog === true) materials.refreshFogUniforms(m_uniforms, fog);
                materials.refreshMaterialUniforms(m_uniforms, material, _pixelRatio, _height, currentRenderState.state.transmissionRenderTarget[camera.id]);
                WebGLUniforms.upload(_gl, getUniformList(materialProperties), m_uniforms, textures);
            }
            if (material.isShaderMaterial && material.uniformsNeedUpdate === true) {
                WebGLUniforms.upload(_gl, getUniformList(materialProperties), m_uniforms, textures);
                material.uniformsNeedUpdate = false;
            }
            if (material.isSpriteMaterial) p_uniforms.setValue(_gl, "center", object.center);
            // common matrices
            p_uniforms.setValue(_gl, "modelViewMatrix", object.modelViewMatrix);
            p_uniforms.setValue(_gl, "normalMatrix", object.normalMatrix);
            p_uniforms.setValue(_gl, "modelMatrix", object.matrixWorld);
            // UBOs
            if (material.isShaderMaterial || material.isRawShaderMaterial) {
                const groups = material.uniformsGroups;
                for(let i = 0, l = groups.length; i < l; i++){
                    const group = groups[i];
                    uniformsGroups.update(group, program);
                    uniformsGroups.bind(group, program);
                }
            }
            return program;
        }
        // If uniforms are marked as clean, they don't need to be loaded to the GPU.
        function markUniformsLightsNeedsUpdate(uniforms, value) {
            uniforms.ambientLightColor.needsUpdate = value;
            uniforms.lightProbe.needsUpdate = value;
            uniforms.directionalLights.needsUpdate = value;
            uniforms.directionalLightShadows.needsUpdate = value;
            uniforms.pointLights.needsUpdate = value;
            uniforms.pointLightShadows.needsUpdate = value;
            uniforms.spotLights.needsUpdate = value;
            uniforms.spotLightShadows.needsUpdate = value;
            uniforms.rectAreaLights.needsUpdate = value;
            uniforms.hemisphereLights.needsUpdate = value;
        }
        function materialNeedsLights(material) {
            return material.isMeshLambertMaterial || material.isMeshToonMaterial || material.isMeshPhongMaterial || material.isMeshStandardMaterial || material.isShadowMaterial || material.isShaderMaterial && material.lights === true;
        }
        this.getActiveCubeFace = function() {
            return _currentActiveCubeFace;
        };
        this.getActiveMipmapLevel = function() {
            return _currentActiveMipmapLevel;
        };
        this.getRenderTarget = function() {
            return _currentRenderTarget;
        };
        this.setRenderTargetTextures = function(renderTarget, colorTexture, depthTexture) {
            properties.get(renderTarget.texture).__webglTexture = colorTexture;
            properties.get(renderTarget.depthTexture).__webglTexture = depthTexture;
            const renderTargetProperties = properties.get(renderTarget);
            renderTargetProperties.__hasExternalTextures = true;
            renderTargetProperties.__autoAllocateDepthBuffer = depthTexture === undefined;
            if (!renderTargetProperties.__autoAllocateDepthBuffer) // The multisample_render_to_texture extension doesn't work properly if there
            // are midframe flushes and an external depth buffer. Disable use of the extension.
            {
                if (extensions.has("WEBGL_multisampled_render_to_texture") === true) {
                    console.warn("THREE.WebGLRenderer: Render-to-texture extension was disabled because an external texture was provided");
                    renderTargetProperties.__useRenderToTexture = false;
                }
            }
        };
        this.setRenderTargetFramebuffer = function(renderTarget, defaultFramebuffer) {
            const renderTargetProperties = properties.get(renderTarget);
            renderTargetProperties.__webglFramebuffer = defaultFramebuffer;
            renderTargetProperties.__useDefaultFramebuffer = defaultFramebuffer === undefined;
        };
        this.setRenderTarget = function(renderTarget, activeCubeFace = 0, activeMipmapLevel = 0) {
            _currentRenderTarget = renderTarget;
            _currentActiveCubeFace = activeCubeFace;
            _currentActiveMipmapLevel = activeMipmapLevel;
            let useDefaultFramebuffer = true;
            let framebuffer = null;
            let isCube = false;
            let isRenderTarget3D = false;
            if (renderTarget) {
                const renderTargetProperties = properties.get(renderTarget);
                if (renderTargetProperties.__useDefaultFramebuffer !== undefined) {
                    // We need to make sure to rebind the framebuffer.
                    state.bindFramebuffer(_gl.FRAMEBUFFER, null);
                    useDefaultFramebuffer = false;
                } else if (renderTargetProperties.__webglFramebuffer === undefined) textures.setupRenderTarget(renderTarget);
                else if (renderTargetProperties.__hasExternalTextures) // Color and depth texture must be rebound in order for the swapchain to update.
                textures.rebindTextures(renderTarget, properties.get(renderTarget.texture).__webglTexture, properties.get(renderTarget.depthTexture).__webglTexture);
                const texture = renderTarget.texture;
                if (texture.isData3DTexture || texture.isDataArrayTexture || texture.isCompressedArrayTexture) isRenderTarget3D = true;
                const __webglFramebuffer = properties.get(renderTarget).__webglFramebuffer;
                if (renderTarget.isWebGLCubeRenderTarget) {
                    if (Array.isArray(__webglFramebuffer[activeCubeFace])) framebuffer = __webglFramebuffer[activeCubeFace][activeMipmapLevel];
                    else framebuffer = __webglFramebuffer[activeCubeFace];
                    isCube = true;
                } else if (renderTarget.samples > 0 && textures.useMultisampledRTT(renderTarget) === false) framebuffer = properties.get(renderTarget).__webglMultisampledFramebuffer;
                else if (Array.isArray(__webglFramebuffer)) framebuffer = __webglFramebuffer[activeMipmapLevel];
                else framebuffer = __webglFramebuffer;
                _currentViewport.copy(renderTarget.viewport);
                _currentScissor.copy(renderTarget.scissor);
                _currentScissorTest = renderTarget.scissorTest;
            } else {
                _currentViewport.copy(_viewport).multiplyScalar(_pixelRatio).floor();
                _currentScissor.copy(_scissor).multiplyScalar(_pixelRatio).floor();
                _currentScissorTest = _scissorTest;
            }
            const framebufferBound = state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);
            if (framebufferBound && useDefaultFramebuffer) state.drawBuffers(renderTarget, framebuffer);
            state.viewport(_currentViewport);
            state.scissor(_currentScissor);
            state.setScissorTest(_currentScissorTest);
            if (isCube) {
                const textureProperties = properties.get(renderTarget.texture);
                _gl.framebufferTexture2D(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_CUBE_MAP_POSITIVE_X + activeCubeFace, textureProperties.__webglTexture, activeMipmapLevel);
            } else if (isRenderTarget3D) {
                const textureProperties = properties.get(renderTarget.texture);
                const layer = activeCubeFace || 0;
                _gl.framebufferTextureLayer(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, textureProperties.__webglTexture, activeMipmapLevel || 0, layer);
            }
            _currentMaterialId = -1; // reset current material to ensure correct uniform bindings
        };
        this.readRenderTargetPixels = function(renderTarget, x, y, width, height, buffer, activeCubeFaceIndex) {
            if (!(renderTarget && renderTarget.isWebGLRenderTarget)) {
                console.error("THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not THREE.WebGLRenderTarget.");
                return;
            }
            let framebuffer = properties.get(renderTarget).__webglFramebuffer;
            if (renderTarget.isWebGLCubeRenderTarget && activeCubeFaceIndex !== undefined) framebuffer = framebuffer[activeCubeFaceIndex];
            if (framebuffer) {
                state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);
                try {
                    const texture = renderTarget.texture;
                    const textureFormat = texture.format;
                    const textureType = texture.type;
                    if (!capabilities.textureFormatReadable(textureFormat)) {
                        console.error("THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not in RGBA or implementation defined format.");
                        return;
                    }
                    if (!capabilities.textureTypeReadable(textureType)) {
                        console.error("THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not in UnsignedByteType or implementation defined type.");
                        return;
                    }
                    // the following if statement ensures valid read requests (no out-of-bounds pixels, see #8604)
                    if (x >= 0 && x <= renderTarget.width - width && y >= 0 && y <= renderTarget.height - height) _gl.readPixels(x, y, width, height, utils.convert(textureFormat), utils.convert(textureType), buffer);
                } finally{
                    // restore framebuffer of current render target if necessary
                    const framebuffer = _currentRenderTarget !== null ? properties.get(_currentRenderTarget).__webglFramebuffer : null;
                    state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);
                }
            }
        };
        this.readRenderTargetPixelsAsync = async function(renderTarget, x, y, width, height, buffer, activeCubeFaceIndex) {
            if (!(renderTarget && renderTarget.isWebGLRenderTarget)) throw new Error("THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not THREE.WebGLRenderTarget.");
            let framebuffer = properties.get(renderTarget).__webglFramebuffer;
            if (renderTarget.isWebGLCubeRenderTarget && activeCubeFaceIndex !== undefined) framebuffer = framebuffer[activeCubeFaceIndex];
            if (framebuffer) {
                state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);
                try {
                    const texture = renderTarget.texture;
                    const textureFormat = texture.format;
                    const textureType = texture.type;
                    if (!capabilities.textureFormatReadable(textureFormat)) throw new Error("THREE.WebGLRenderer.readRenderTargetPixelsAsync: renderTarget is not in RGBA or implementation defined format.");
                    if (!capabilities.textureTypeReadable(textureType)) throw new Error("THREE.WebGLRenderer.readRenderTargetPixelsAsync: renderTarget is not in UnsignedByteType or implementation defined type.");
                    // the following if statement ensures valid read requests (no out-of-bounds pixels, see #8604)
                    if (x >= 0 && x <= renderTarget.width - width && y >= 0 && y <= renderTarget.height - height) {
                        const glBuffer = _gl.createBuffer();
                        _gl.bindBuffer(_gl.PIXEL_PACK_BUFFER, glBuffer);
                        _gl.bufferData(_gl.PIXEL_PACK_BUFFER, buffer.byteLength, _gl.STREAM_READ);
                        _gl.readPixels(x, y, width, height, utils.convert(textureFormat), utils.convert(textureType), 0);
                        _gl.flush();
                        // check if the commands have finished every 8 ms
                        const sync = _gl.fenceSync(_gl.SYNC_GPU_COMMANDS_COMPLETE, 0);
                        await probeAsync(_gl, sync, 4);
                        try {
                            _gl.bindBuffer(_gl.PIXEL_PACK_BUFFER, glBuffer);
                            _gl.getBufferSubData(_gl.PIXEL_PACK_BUFFER, 0, buffer);
                        } finally{
                            _gl.deleteBuffer(glBuffer);
                            _gl.deleteSync(sync);
                        }
                        return buffer;
                    }
                } finally{
                    // restore framebuffer of current render target if necessary
                    const framebuffer = _currentRenderTarget !== null ? properties.get(_currentRenderTarget).__webglFramebuffer : null;
                    state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);
                }
            }
        };
        this.copyFramebufferToTexture = function(texture, position = null, level = 0) {
            // support previous signature with position first
            if (texture.isTexture !== true) {
                // @deprecated, r165
                console.warn("WebGLRenderer: copyFramebufferToTexture function signature has changed.");
                position = arguments[0] || null;
                texture = arguments[1];
            }
            const levelScale = Math.pow(2, -level);
            const width = Math.floor(texture.image.width * levelScale);
            const height = Math.floor(texture.image.height * levelScale);
            const x = position !== null ? position.x : 0;
            const y = position !== null ? position.y : 0;
            textures.setTexture2D(texture, 0);
            _gl.copyTexSubImage2D(_gl.TEXTURE_2D, level, 0, 0, x, y, width, height);
            state.unbindTexture();
        };
        this.copyTextureToTexture = function(srcTexture, dstTexture, srcRegion = null, dstPosition = null, level = 0) {
            // support previous signature with dstPosition first
            if (srcTexture.isTexture !== true) {
                // @deprecated, r165
                console.warn("WebGLRenderer: copyTextureToTexture function signature has changed.");
                dstPosition = arguments[0] || null;
                srcTexture = arguments[1];
                dstTexture = arguments[2];
                level = arguments[3] || 0;
                srcRegion = null;
            }
            let width, height, minX, minY;
            let dstX, dstY;
            if (srcRegion !== null) {
                width = srcRegion.max.x - srcRegion.min.x;
                height = srcRegion.max.y - srcRegion.min.y;
                minX = srcRegion.min.x;
                minY = srcRegion.min.y;
            } else {
                width = srcTexture.image.width;
                height = srcTexture.image.height;
                minX = 0;
                minY = 0;
            }
            if (dstPosition !== null) {
                dstX = dstPosition.x;
                dstY = dstPosition.y;
            } else {
                dstX = 0;
                dstY = 0;
            }
            const glFormat = utils.convert(dstTexture.format);
            const glType = utils.convert(dstTexture.type);
            textures.setTexture2D(dstTexture, 0);
            // As another texture upload may have changed pixelStorei
            // parameters, make sure they are correct for the dstTexture
            _gl.pixelStorei(_gl.UNPACK_FLIP_Y_WEBGL, dstTexture.flipY);
            _gl.pixelStorei(_gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, dstTexture.premultiplyAlpha);
            _gl.pixelStorei(_gl.UNPACK_ALIGNMENT, dstTexture.unpackAlignment);
            const currentUnpackRowLen = _gl.getParameter(_gl.UNPACK_ROW_LENGTH);
            const currentUnpackImageHeight = _gl.getParameter(_gl.UNPACK_IMAGE_HEIGHT);
            const currentUnpackSkipPixels = _gl.getParameter(_gl.UNPACK_SKIP_PIXELS);
            const currentUnpackSkipRows = _gl.getParameter(_gl.UNPACK_SKIP_ROWS);
            const currentUnpackSkipImages = _gl.getParameter(_gl.UNPACK_SKIP_IMAGES);
            const image = srcTexture.isCompressedTexture ? srcTexture.mipmaps[level] : srcTexture.image;
            _gl.pixelStorei(_gl.UNPACK_ROW_LENGTH, image.width);
            _gl.pixelStorei(_gl.UNPACK_IMAGE_HEIGHT, image.height);
            _gl.pixelStorei(_gl.UNPACK_SKIP_PIXELS, minX);
            _gl.pixelStorei(_gl.UNPACK_SKIP_ROWS, minY);
            if (srcTexture.isDataTexture) _gl.texSubImage2D(_gl.TEXTURE_2D, level, dstX, dstY, width, height, glFormat, glType, image.data);
            else if (srcTexture.isCompressedTexture) _gl.compressedTexSubImage2D(_gl.TEXTURE_2D, level, dstX, dstY, image.width, image.height, glFormat, image.data);
            else _gl.texSubImage2D(_gl.TEXTURE_2D, level, dstX, dstY, width, height, glFormat, glType, image);
            _gl.pixelStorei(_gl.UNPACK_ROW_LENGTH, currentUnpackRowLen);
            _gl.pixelStorei(_gl.UNPACK_IMAGE_HEIGHT, currentUnpackImageHeight);
            _gl.pixelStorei(_gl.UNPACK_SKIP_PIXELS, currentUnpackSkipPixels);
            _gl.pixelStorei(_gl.UNPACK_SKIP_ROWS, currentUnpackSkipRows);
            _gl.pixelStorei(_gl.UNPACK_SKIP_IMAGES, currentUnpackSkipImages);
            // Generate mipmaps only when copying level 0
            if (level === 0 && dstTexture.generateMipmaps) _gl.generateMipmap(_gl.TEXTURE_2D);
            state.unbindTexture();
        };
        this.copyTextureToTexture3D = function(srcTexture, dstTexture, srcRegion = null, dstPosition = null, level = 0) {
            // support previous signature with source box first
            if (srcTexture.isTexture !== true) {
                // @deprecated, r165
                console.warn("WebGLRenderer: copyTextureToTexture3D function signature has changed.");
                srcRegion = arguments[0] || null;
                dstPosition = arguments[1] || null;
                srcTexture = arguments[2];
                dstTexture = arguments[3];
                level = arguments[4] || 0;
            }
            let width, height, depth, minX, minY, minZ;
            let dstX, dstY, dstZ;
            const image = srcTexture.isCompressedTexture ? srcTexture.mipmaps[level] : srcTexture.image;
            if (srcRegion !== null) {
                width = srcRegion.max.x - srcRegion.min.x;
                height = srcRegion.max.y - srcRegion.min.y;
                depth = srcRegion.max.z - srcRegion.min.z;
                minX = srcRegion.min.x;
                minY = srcRegion.min.y;
                minZ = srcRegion.min.z;
            } else {
                width = image.width;
                height = image.height;
                depth = image.depth;
                minX = 0;
                minY = 0;
                minZ = 0;
            }
            if (dstPosition !== null) {
                dstX = dstPosition.x;
                dstY = dstPosition.y;
                dstZ = dstPosition.z;
            } else {
                dstX = 0;
                dstY = 0;
                dstZ = 0;
            }
            const glFormat = utils.convert(dstTexture.format);
            const glType = utils.convert(dstTexture.type);
            let glTarget;
            if (dstTexture.isData3DTexture) {
                textures.setTexture3D(dstTexture, 0);
                glTarget = _gl.TEXTURE_3D;
            } else if (dstTexture.isDataArrayTexture || dstTexture.isCompressedArrayTexture) {
                textures.setTexture2DArray(dstTexture, 0);
                glTarget = _gl.TEXTURE_2D_ARRAY;
            } else {
                console.warn("THREE.WebGLRenderer.copyTextureToTexture3D: only supports THREE.DataTexture3D and THREE.DataTexture2DArray.");
                return;
            }
            _gl.pixelStorei(_gl.UNPACK_FLIP_Y_WEBGL, dstTexture.flipY);
            _gl.pixelStorei(_gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, dstTexture.premultiplyAlpha);
            _gl.pixelStorei(_gl.UNPACK_ALIGNMENT, dstTexture.unpackAlignment);
            const currentUnpackRowLen = _gl.getParameter(_gl.UNPACK_ROW_LENGTH);
            const currentUnpackImageHeight = _gl.getParameter(_gl.UNPACK_IMAGE_HEIGHT);
            const currentUnpackSkipPixels = _gl.getParameter(_gl.UNPACK_SKIP_PIXELS);
            const currentUnpackSkipRows = _gl.getParameter(_gl.UNPACK_SKIP_ROWS);
            const currentUnpackSkipImages = _gl.getParameter(_gl.UNPACK_SKIP_IMAGES);
            _gl.pixelStorei(_gl.UNPACK_ROW_LENGTH, image.width);
            _gl.pixelStorei(_gl.UNPACK_IMAGE_HEIGHT, image.height);
            _gl.pixelStorei(_gl.UNPACK_SKIP_PIXELS, minX);
            _gl.pixelStorei(_gl.UNPACK_SKIP_ROWS, minY);
            _gl.pixelStorei(_gl.UNPACK_SKIP_IMAGES, minZ);
            if (srcTexture.isDataTexture || srcTexture.isData3DTexture) _gl.texSubImage3D(glTarget, level, dstX, dstY, dstZ, width, height, depth, glFormat, glType, image.data);
            else if (dstTexture.isCompressedArrayTexture) _gl.compressedTexSubImage3D(glTarget, level, dstX, dstY, dstZ, width, height, depth, glFormat, image.data);
            else _gl.texSubImage3D(glTarget, level, dstX, dstY, dstZ, width, height, depth, glFormat, glType, image);
            _gl.pixelStorei(_gl.UNPACK_ROW_LENGTH, currentUnpackRowLen);
            _gl.pixelStorei(_gl.UNPACK_IMAGE_HEIGHT, currentUnpackImageHeight);
            _gl.pixelStorei(_gl.UNPACK_SKIP_PIXELS, currentUnpackSkipPixels);
            _gl.pixelStorei(_gl.UNPACK_SKIP_ROWS, currentUnpackSkipRows);
            _gl.pixelStorei(_gl.UNPACK_SKIP_IMAGES, currentUnpackSkipImages);
            // Generate mipmaps only when copying level 0
            if (level === 0 && dstTexture.generateMipmaps) _gl.generateMipmap(glTarget);
            state.unbindTexture();
        };
        this.initRenderTarget = function(target) {
            if (properties.get(target).__webglFramebuffer === undefined) textures.setupRenderTarget(target);
        };
        this.initTexture = function(texture) {
            if (texture.isCubeTexture) textures.setTextureCube(texture, 0);
            else if (texture.isData3DTexture) textures.setTexture3D(texture, 0);
            else if (texture.isDataArrayTexture || texture.isCompressedArrayTexture) textures.setTexture2DArray(texture, 0);
            else textures.setTexture2D(texture, 0);
            state.unbindTexture();
        };
        this.resetState = function() {
            _currentActiveCubeFace = 0;
            _currentActiveMipmapLevel = 0;
            _currentRenderTarget = null;
            state.reset();
            bindingStates.reset();
        };
        if (typeof __THREE_DEVTOOLS__ !== "undefined") __THREE_DEVTOOLS__.dispatchEvent(new CustomEvent("observe", {
            detail: this
        }));
    }
    get coordinateSystem() {
        return WebGLCoordinateSystem;
    }
    get outputColorSpace() {
        return this._outputColorSpace;
    }
    set outputColorSpace(colorSpace1) {
        this._outputColorSpace = colorSpace1;
        const gl = this.getContext();
        gl.drawingBufferColorSpace = colorSpace1 === DisplayP3ColorSpace ? "display-p3" : "srgb";
        gl.unpackColorSpace = ColorManagement.workingColorSpace === LinearDisplayP3ColorSpace ? "display-p3" : "srgb";
    }
}
class FogExp2 {
    constructor(color, density = 0.00025){
        this.isFogExp2 = true;
        this.name = "";
        this.color = new Color(color);
        this.density = density;
    }
    clone() {
        return new FogExp2(this.color, this.density);
    }
    toJSON() {
        return {
            type: "FogExp2",
            name: this.name,
            color: this.color.getHex(),
            density: this.density
        };
    }
}
class Fog {
    constructor(color, near = 1, far = 1000){
        this.isFog = true;
        this.name = "";
        this.color = new Color(color);
        this.near = near;
        this.far = far;
    }
    clone() {
        return new Fog(this.color, this.near, this.far);
    }
    toJSON() {
        return {
            type: "Fog",
            name: this.name,
            color: this.color.getHex(),
            near: this.near,
            far: this.far
        };
    }
}
class Scene extends Object3D {
    constructor(){
        super();
        this.isScene = true;
        this.type = "Scene";
        this.background = null;
        this.environment = null;
        this.fog = null;
        this.backgroundBlurriness = 0;
        this.backgroundIntensity = 1;
        this.backgroundRotation = new Euler();
        this.environmentIntensity = 1;
        this.environmentRotation = new Euler();
        this.overrideMaterial = null;
        if (typeof __THREE_DEVTOOLS__ !== "undefined") __THREE_DEVTOOLS__.dispatchEvent(new CustomEvent("observe", {
            detail: this
        }));
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        if (source.background !== null) this.background = source.background.clone();
        if (source.environment !== null) this.environment = source.environment.clone();
        if (source.fog !== null) this.fog = source.fog.clone();
        this.backgroundBlurriness = source.backgroundBlurriness;
        this.backgroundIntensity = source.backgroundIntensity;
        this.backgroundRotation.copy(source.backgroundRotation);
        this.environmentIntensity = source.environmentIntensity;
        this.environmentRotation.copy(source.environmentRotation);
        if (source.overrideMaterial !== null) this.overrideMaterial = source.overrideMaterial.clone();
        this.matrixAutoUpdate = source.matrixAutoUpdate;
        return this;
    }
    toJSON(meta) {
        const data = super.toJSON(meta);
        if (this.fog !== null) data.object.fog = this.fog.toJSON();
        if (this.backgroundBlurriness > 0) data.object.backgroundBlurriness = this.backgroundBlurriness;
        if (this.backgroundIntensity !== 1) data.object.backgroundIntensity = this.backgroundIntensity;
        data.object.backgroundRotation = this.backgroundRotation.toArray();
        if (this.environmentIntensity !== 1) data.object.environmentIntensity = this.environmentIntensity;
        data.object.environmentRotation = this.environmentRotation.toArray();
        return data;
    }
}
class InterleavedBuffer {
    constructor(array, stride){
        this.isInterleavedBuffer = true;
        this.array = array;
        this.stride = stride;
        this.count = array !== undefined ? array.length / stride : 0;
        this.usage = StaticDrawUsage;
        this._updateRange = {
            offset: 0,
            count: -1
        };
        this.updateRanges = [];
        this.version = 0;
        this.uuid = generateUUID();
    }
    onUploadCallback() {}
    set needsUpdate(value) {
        if (value === true) this.version++;
    }
    get updateRange() {
        warnOnce("THREE.InterleavedBuffer: updateRange() is deprecated and will be removed in r169. Use addUpdateRange() instead."); // @deprecated, r159
        return this._updateRange;
    }
    setUsage(value) {
        this.usage = value;
        return this;
    }
    addUpdateRange(start, count) {
        this.updateRanges.push({
            start,
            count
        });
    }
    clearUpdateRanges() {
        this.updateRanges.length = 0;
    }
    copy(source) {
        this.array = new source.array.constructor(source.array);
        this.count = source.count;
        this.stride = source.stride;
        this.usage = source.usage;
        return this;
    }
    copyAt(index1, attribute, index2) {
        index1 *= this.stride;
        index2 *= attribute.stride;
        for(let i = 0, l = this.stride; i < l; i++)this.array[index1 + i] = attribute.array[index2 + i];
        return this;
    }
    set(value, offset = 0) {
        this.array.set(value, offset);
        return this;
    }
    clone(data) {
        if (data.arrayBuffers === undefined) data.arrayBuffers = {};
        if (this.array.buffer._uuid === undefined) this.array.buffer._uuid = generateUUID();
        if (data.arrayBuffers[this.array.buffer._uuid] === undefined) data.arrayBuffers[this.array.buffer._uuid] = this.array.slice(0).buffer;
        const array = new this.array.constructor(data.arrayBuffers[this.array.buffer._uuid]);
        const ib = new this.constructor(array, this.stride);
        ib.setUsage(this.usage);
        return ib;
    }
    onUpload(callback) {
        this.onUploadCallback = callback;
        return this;
    }
    toJSON(data) {
        if (data.arrayBuffers === undefined) data.arrayBuffers = {};
        // generate UUID for array buffer if necessary
        if (this.array.buffer._uuid === undefined) this.array.buffer._uuid = generateUUID();
        if (data.arrayBuffers[this.array.buffer._uuid] === undefined) data.arrayBuffers[this.array.buffer._uuid] = Array.from(new Uint32Array(this.array.buffer));
        //
        return {
            uuid: this.uuid,
            buffer: this.array.buffer._uuid,
            type: this.array.constructor.name,
            stride: this.stride
        };
    }
}
const _vector$6 = /*@__PURE__*/ new Vector3();
class InterleavedBufferAttribute {
    constructor(interleavedBuffer, itemSize, offset, normalized = false){
        this.isInterleavedBufferAttribute = true;
        this.name = "";
        this.data = interleavedBuffer;
        this.itemSize = itemSize;
        this.offset = offset;
        this.normalized = normalized;
    }
    get count() {
        return this.data.count;
    }
    get array() {
        return this.data.array;
    }
    set needsUpdate(value) {
        this.data.needsUpdate = value;
    }
    applyMatrix4(m) {
        for(let i = 0, l = this.data.count; i < l; i++){
            _vector$6.fromBufferAttribute(this, i);
            _vector$6.applyMatrix4(m);
            this.setXYZ(i, _vector$6.x, _vector$6.y, _vector$6.z);
        }
        return this;
    }
    applyNormalMatrix(m) {
        for(let i = 0, l = this.count; i < l; i++){
            _vector$6.fromBufferAttribute(this, i);
            _vector$6.applyNormalMatrix(m);
            this.setXYZ(i, _vector$6.x, _vector$6.y, _vector$6.z);
        }
        return this;
    }
    transformDirection(m) {
        for(let i = 0, l = this.count; i < l; i++){
            _vector$6.fromBufferAttribute(this, i);
            _vector$6.transformDirection(m);
            this.setXYZ(i, _vector$6.x, _vector$6.y, _vector$6.z);
        }
        return this;
    }
    getComponent(index, component) {
        let value = this.array[index * this.data.stride + this.offset + component];
        if (this.normalized) value = denormalize(value, this.array);
        return value;
    }
    setComponent(index, component, value) {
        if (this.normalized) value = normalize(value, this.array);
        this.data.array[index * this.data.stride + this.offset + component] = value;
        return this;
    }
    setX(index, x) {
        if (this.normalized) x = normalize(x, this.array);
        this.data.array[index * this.data.stride + this.offset] = x;
        return this;
    }
    setY(index, y) {
        if (this.normalized) y = normalize(y, this.array);
        this.data.array[index * this.data.stride + this.offset + 1] = y;
        return this;
    }
    setZ(index, z) {
        if (this.normalized) z = normalize(z, this.array);
        this.data.array[index * this.data.stride + this.offset + 2] = z;
        return this;
    }
    setW(index, w) {
        if (this.normalized) w = normalize(w, this.array);
        this.data.array[index * this.data.stride + this.offset + 3] = w;
        return this;
    }
    getX(index) {
        let x = this.data.array[index * this.data.stride + this.offset];
        if (this.normalized) x = denormalize(x, this.array);
        return x;
    }
    getY(index) {
        let y = this.data.array[index * this.data.stride + this.offset + 1];
        if (this.normalized) y = denormalize(y, this.array);
        return y;
    }
    getZ(index) {
        let z = this.data.array[index * this.data.stride + this.offset + 2];
        if (this.normalized) z = denormalize(z, this.array);
        return z;
    }
    getW(index) {
        let w = this.data.array[index * this.data.stride + this.offset + 3];
        if (this.normalized) w = denormalize(w, this.array);
        return w;
    }
    setXY(index, x, y) {
        index = index * this.data.stride + this.offset;
        if (this.normalized) {
            x = normalize(x, this.array);
            y = normalize(y, this.array);
        }
        this.data.array[index + 0] = x;
        this.data.array[index + 1] = y;
        return this;
    }
    setXYZ(index, x, y, z) {
        index = index * this.data.stride + this.offset;
        if (this.normalized) {
            x = normalize(x, this.array);
            y = normalize(y, this.array);
            z = normalize(z, this.array);
        }
        this.data.array[index + 0] = x;
        this.data.array[index + 1] = y;
        this.data.array[index + 2] = z;
        return this;
    }
    setXYZW(index, x, y, z, w) {
        index = index * this.data.stride + this.offset;
        if (this.normalized) {
            x = normalize(x, this.array);
            y = normalize(y, this.array);
            z = normalize(z, this.array);
            w = normalize(w, this.array);
        }
        this.data.array[index + 0] = x;
        this.data.array[index + 1] = y;
        this.data.array[index + 2] = z;
        this.data.array[index + 3] = w;
        return this;
    }
    clone(data) {
        if (data === undefined) {
            console.log("THREE.InterleavedBufferAttribute.clone(): Cloning an interleaved buffer attribute will de-interleave buffer data.");
            const array = [];
            for(let i = 0; i < this.count; i++){
                const index = i * this.data.stride + this.offset;
                for(let j = 0; j < this.itemSize; j++)array.push(this.data.array[index + j]);
            }
            return new BufferAttribute(new this.array.constructor(array), this.itemSize, this.normalized);
        } else {
            if (data.interleavedBuffers === undefined) data.interleavedBuffers = {};
            if (data.interleavedBuffers[this.data.uuid] === undefined) data.interleavedBuffers[this.data.uuid] = this.data.clone(data);
            return new InterleavedBufferAttribute(data.interleavedBuffers[this.data.uuid], this.itemSize, this.offset, this.normalized);
        }
    }
    toJSON(data) {
        if (data === undefined) {
            console.log("THREE.InterleavedBufferAttribute.toJSON(): Serializing an interleaved buffer attribute will de-interleave buffer data.");
            const array = [];
            for(let i = 0; i < this.count; i++){
                const index = i * this.data.stride + this.offset;
                for(let j = 0; j < this.itemSize; j++)array.push(this.data.array[index + j]);
            }
            // de-interleave data and save it as an ordinary buffer attribute for now
            return {
                itemSize: this.itemSize,
                type: this.array.constructor.name,
                array: array,
                normalized: this.normalized
            };
        } else {
            // save as true interleaved attribute
            if (data.interleavedBuffers === undefined) data.interleavedBuffers = {};
            if (data.interleavedBuffers[this.data.uuid] === undefined) data.interleavedBuffers[this.data.uuid] = this.data.toJSON(data);
            return {
                isInterleavedBufferAttribute: true,
                itemSize: this.itemSize,
                data: this.data.uuid,
                offset: this.offset,
                normalized: this.normalized
            };
        }
    }
}
class SpriteMaterial extends Material {
    constructor(parameters){
        super();
        this.isSpriteMaterial = true;
        this.type = "SpriteMaterial";
        this.color = new Color(0xffffff);
        this.map = null;
        this.alphaMap = null;
        this.rotation = 0;
        this.sizeAttenuation = true;
        this.transparent = true;
        this.fog = true;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.color.copy(source.color);
        this.map = source.map;
        this.alphaMap = source.alphaMap;
        this.rotation = source.rotation;
        this.sizeAttenuation = source.sizeAttenuation;
        this.fog = source.fog;
        return this;
    }
}
let _geometry;
const _intersectPoint = /*@__PURE__*/ new Vector3();
const _worldScale = /*@__PURE__*/ new Vector3();
const _mvPosition = /*@__PURE__*/ new Vector3();
const _alignedPosition = /*@__PURE__*/ new Vector2();
const _rotatedPosition = /*@__PURE__*/ new Vector2();
const _viewWorldMatrix = /*@__PURE__*/ new Matrix4();
const _vA = /*@__PURE__*/ new Vector3();
const _vB = /*@__PURE__*/ new Vector3();
const _vC = /*@__PURE__*/ new Vector3();
const _uvA = /*@__PURE__*/ new Vector2();
const _uvB = /*@__PURE__*/ new Vector2();
const _uvC = /*@__PURE__*/ new Vector2();
class Sprite extends Object3D {
    constructor(material = new SpriteMaterial()){
        super();
        this.isSprite = true;
        this.type = "Sprite";
        if (_geometry === undefined) {
            _geometry = new BufferGeometry();
            const float32Array = new Float32Array([
                -0.5,
                -0.5,
                0,
                0,
                0,
                0.5,
                -0.5,
                0,
                1,
                0,
                0.5,
                0.5,
                0,
                1,
                1,
                -0.5,
                0.5,
                0,
                0,
                1
            ]);
            const interleavedBuffer = new InterleavedBuffer(float32Array, 5);
            _geometry.setIndex([
                0,
                1,
                2,
                0,
                2,
                3
            ]);
            _geometry.setAttribute("position", new InterleavedBufferAttribute(interleavedBuffer, 3, 0, false));
            _geometry.setAttribute("uv", new InterleavedBufferAttribute(interleavedBuffer, 2, 3, false));
        }
        this.geometry = _geometry;
        this.material = material;
        this.center = new Vector2(0.5, 0.5);
    }
    raycast(raycaster, intersects) {
        if (raycaster.camera === null) console.error('THREE.Sprite: "Raycaster.camera" needs to be set in order to raycast against sprites.');
        _worldScale.setFromMatrixScale(this.matrixWorld);
        _viewWorldMatrix.copy(raycaster.camera.matrixWorld);
        this.modelViewMatrix.multiplyMatrices(raycaster.camera.matrixWorldInverse, this.matrixWorld);
        _mvPosition.setFromMatrixPosition(this.modelViewMatrix);
        if (raycaster.camera.isPerspectiveCamera && this.material.sizeAttenuation === false) _worldScale.multiplyScalar(-_mvPosition.z);
        const rotation = this.material.rotation;
        let sin, cos;
        if (rotation !== 0) {
            cos = Math.cos(rotation);
            sin = Math.sin(rotation);
        }
        const center = this.center;
        transformVertex(_vA.set(-0.5, -0.5, 0), _mvPosition, center, _worldScale, sin, cos);
        transformVertex(_vB.set(0.5, -0.5, 0), _mvPosition, center, _worldScale, sin, cos);
        transformVertex(_vC.set(0.5, 0.5, 0), _mvPosition, center, _worldScale, sin, cos);
        _uvA.set(0, 0);
        _uvB.set(1, 0);
        _uvC.set(1, 1);
        // check first triangle
        let intersect = raycaster.ray.intersectTriangle(_vA, _vB, _vC, false, _intersectPoint);
        if (intersect === null) {
            // check second triangle
            transformVertex(_vB.set(-0.5, 0.5, 0), _mvPosition, center, _worldScale, sin, cos);
            _uvB.set(0, 1);
            intersect = raycaster.ray.intersectTriangle(_vA, _vC, _vB, false, _intersectPoint);
            if (intersect === null) return;
        }
        const distance = raycaster.ray.origin.distanceTo(_intersectPoint);
        if (distance < raycaster.near || distance > raycaster.far) return;
        intersects.push({
            distance: distance,
            point: _intersectPoint.clone(),
            uv: Triangle.getInterpolation(_intersectPoint, _vA, _vB, _vC, _uvA, _uvB, _uvC, new Vector2()),
            face: null,
            object: this
        });
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        if (source.center !== undefined) this.center.copy(source.center);
        this.material = source.material;
        return this;
    }
}
function transformVertex(vertexPosition, mvPosition, center, scale, sin, cos) {
    // compute position in camera space
    _alignedPosition.subVectors(vertexPosition, center).addScalar(0.5).multiply(scale);
    // to check if rotation is not zero
    if (sin !== undefined) {
        _rotatedPosition.x = cos * _alignedPosition.x - sin * _alignedPosition.y;
        _rotatedPosition.y = sin * _alignedPosition.x + cos * _alignedPosition.y;
    } else _rotatedPosition.copy(_alignedPosition);
    vertexPosition.copy(mvPosition);
    vertexPosition.x += _rotatedPosition.x;
    vertexPosition.y += _rotatedPosition.y;
    // transform to world space
    vertexPosition.applyMatrix4(_viewWorldMatrix);
}
const _v1$2 = /*@__PURE__*/ new Vector3();
const _v2$1 = /*@__PURE__*/ new Vector3();
class LOD extends Object3D {
    constructor(){
        super();
        this._currentLevel = 0;
        this.type = "LOD";
        Object.defineProperties(this, {
            levels: {
                enumerable: true,
                value: []
            },
            isLOD: {
                value: true
            }
        });
        this.autoUpdate = true;
    }
    copy(source) {
        super.copy(source, false);
        const levels = source.levels;
        for(let i = 0, l = levels.length; i < l; i++){
            const level = levels[i];
            this.addLevel(level.object.clone(), level.distance, level.hysteresis);
        }
        this.autoUpdate = source.autoUpdate;
        return this;
    }
    addLevel(object, distance = 0, hysteresis = 0) {
        distance = Math.abs(distance);
        const levels = this.levels;
        let l;
        for(l = 0; l < levels.length; l++){
            if (distance < levels[l].distance) break;
        }
        levels.splice(l, 0, {
            distance: distance,
            hysteresis: hysteresis,
            object: object
        });
        this.add(object);
        return this;
    }
    getCurrentLevel() {
        return this._currentLevel;
    }
    getObjectForDistance(distance) {
        const levels = this.levels;
        if (levels.length > 0) {
            let i, l;
            for(i = 1, l = levels.length; i < l; i++){
                let levelDistance = levels[i].distance;
                if (levels[i].object.visible) levelDistance -= levelDistance * levels[i].hysteresis;
                if (distance < levelDistance) break;
            }
            return levels[i - 1].object;
        }
        return null;
    }
    raycast(raycaster, intersects) {
        const levels = this.levels;
        if (levels.length > 0) {
            _v1$2.setFromMatrixPosition(this.matrixWorld);
            const distance = raycaster.ray.origin.distanceTo(_v1$2);
            this.getObjectForDistance(distance).raycast(raycaster, intersects);
        }
    }
    update(camera) {
        const levels = this.levels;
        if (levels.length > 1) {
            _v1$2.setFromMatrixPosition(camera.matrixWorld);
            _v2$1.setFromMatrixPosition(this.matrixWorld);
            const distance = _v1$2.distanceTo(_v2$1) / camera.zoom;
            levels[0].object.visible = true;
            let i, l;
            for(i = 1, l = levels.length; i < l; i++){
                let levelDistance = levels[i].distance;
                if (levels[i].object.visible) levelDistance -= levelDistance * levels[i].hysteresis;
                if (distance >= levelDistance) {
                    levels[i - 1].object.visible = false;
                    levels[i].object.visible = true;
                } else break;
            }
            this._currentLevel = i - 1;
            for(; i < l; i++)levels[i].object.visible = false;
        }
    }
    toJSON(meta) {
        const data = super.toJSON(meta);
        if (this.autoUpdate === false) data.object.autoUpdate = false;
        data.object.levels = [];
        const levels = this.levels;
        for(let i = 0, l = levels.length; i < l; i++){
            const level = levels[i];
            data.object.levels.push({
                object: level.object.uuid,
                distance: level.distance,
                hysteresis: level.hysteresis
            });
        }
        return data;
    }
}
const _basePosition = /*@__PURE__*/ new Vector3();
const _skinIndex = /*@__PURE__*/ new Vector4();
const _skinWeight = /*@__PURE__*/ new Vector4();
const _vector3 = /*@__PURE__*/ new Vector3();
const _matrix4 = /*@__PURE__*/ new Matrix4();
const _vertex = /*@__PURE__*/ new Vector3();
const _sphere$4 = /*@__PURE__*/ new Sphere();
const _inverseMatrix$2 = /*@__PURE__*/ new Matrix4();
const _ray$2 = /*@__PURE__*/ new Ray();
class SkinnedMesh extends Mesh {
    constructor(geometry, material){
        super(geometry, material);
        this.isSkinnedMesh = true;
        this.type = "SkinnedMesh";
        this.bindMode = AttachedBindMode;
        this.bindMatrix = new Matrix4();
        this.bindMatrixInverse = new Matrix4();
        this.boundingBox = null;
        this.boundingSphere = null;
    }
    computeBoundingBox() {
        const geometry = this.geometry;
        if (this.boundingBox === null) this.boundingBox = new Box3();
        this.boundingBox.makeEmpty();
        const positionAttribute = geometry.getAttribute("position");
        for(let i = 0; i < positionAttribute.count; i++){
            this.getVertexPosition(i, _vertex);
            this.boundingBox.expandByPoint(_vertex);
        }
    }
    computeBoundingSphere() {
        const geometry = this.geometry;
        if (this.boundingSphere === null) this.boundingSphere = new Sphere();
        this.boundingSphere.makeEmpty();
        const positionAttribute = geometry.getAttribute("position");
        for(let i = 0; i < positionAttribute.count; i++){
            this.getVertexPosition(i, _vertex);
            this.boundingSphere.expandByPoint(_vertex);
        }
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.bindMode = source.bindMode;
        this.bindMatrix.copy(source.bindMatrix);
        this.bindMatrixInverse.copy(source.bindMatrixInverse);
        this.skeleton = source.skeleton;
        if (source.boundingBox !== null) this.boundingBox = source.boundingBox.clone();
        if (source.boundingSphere !== null) this.boundingSphere = source.boundingSphere.clone();
        return this;
    }
    raycast(raycaster, intersects) {
        const material = this.material;
        const matrixWorld = this.matrixWorld;
        if (material === undefined) return;
        // test with bounding sphere in world space
        if (this.boundingSphere === null) this.computeBoundingSphere();
        _sphere$4.copy(this.boundingSphere);
        _sphere$4.applyMatrix4(matrixWorld);
        if (raycaster.ray.intersectsSphere(_sphere$4) === false) return;
        // convert ray to local space of skinned mesh
        _inverseMatrix$2.copy(matrixWorld).invert();
        _ray$2.copy(raycaster.ray).applyMatrix4(_inverseMatrix$2);
        // test with bounding box in local space
        if (this.boundingBox !== null) {
            if (_ray$2.intersectsBox(this.boundingBox) === false) return;
        }
        // test for intersections with geometry
        this._computeIntersections(raycaster, intersects, _ray$2);
    }
    getVertexPosition(index, target) {
        super.getVertexPosition(index, target);
        this.applyBoneTransform(index, target);
        return target;
    }
    bind(skeleton, bindMatrix) {
        this.skeleton = skeleton;
        if (bindMatrix === undefined) {
            this.updateMatrixWorld(true);
            this.skeleton.calculateInverses();
            bindMatrix = this.matrixWorld;
        }
        this.bindMatrix.copy(bindMatrix);
        this.bindMatrixInverse.copy(bindMatrix).invert();
    }
    pose() {
        this.skeleton.pose();
    }
    normalizeSkinWeights() {
        const vector = new Vector4();
        const skinWeight = this.geometry.attributes.skinWeight;
        for(let i = 0, l = skinWeight.count; i < l; i++){
            vector.fromBufferAttribute(skinWeight, i);
            const scale = 1.0 / vector.manhattanLength();
            if (scale !== Infinity) vector.multiplyScalar(scale);
            else vector.set(1, 0, 0, 0); // do something reasonable
            skinWeight.setXYZW(i, vector.x, vector.y, vector.z, vector.w);
        }
    }
    updateMatrixWorld(force) {
        super.updateMatrixWorld(force);
        if (this.bindMode === AttachedBindMode) this.bindMatrixInverse.copy(this.matrixWorld).invert();
        else if (this.bindMode === DetachedBindMode) this.bindMatrixInverse.copy(this.bindMatrix).invert();
        else console.warn("THREE.SkinnedMesh: Unrecognized bindMode: " + this.bindMode);
    }
    applyBoneTransform(index, vector) {
        const skeleton = this.skeleton;
        const geometry = this.geometry;
        _skinIndex.fromBufferAttribute(geometry.attributes.skinIndex, index);
        _skinWeight.fromBufferAttribute(geometry.attributes.skinWeight, index);
        _basePosition.copy(vector).applyMatrix4(this.bindMatrix);
        vector.set(0, 0, 0);
        for(let i = 0; i < 4; i++){
            const weight = _skinWeight.getComponent(i);
            if (weight !== 0) {
                const boneIndex = _skinIndex.getComponent(i);
                _matrix4.multiplyMatrices(skeleton.bones[boneIndex].matrixWorld, skeleton.boneInverses[boneIndex]);
                vector.addScaledVector(_vector3.copy(_basePosition).applyMatrix4(_matrix4), weight);
            }
        }
        return vector.applyMatrix4(this.bindMatrixInverse);
    }
}
class Bone extends Object3D {
    constructor(){
        super();
        this.isBone = true;
        this.type = "Bone";
    }
}
class DataTexture extends Texture {
    constructor(data = null, width = 1, height = 1, format, type, mapping, wrapS, wrapT, magFilter = NearestFilter, minFilter = NearestFilter, anisotropy, colorSpace1){
        super(null, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace1);
        this.isDataTexture = true;
        this.image = {
            data: data,
            width: width,
            height: height
        };
        this.generateMipmaps = false;
        this.flipY = false;
        this.unpackAlignment = 1;
    }
}
const _offsetMatrix = /*@__PURE__*/ new Matrix4();
const _identityMatrix$1 = /*@__PURE__*/ new Matrix4();
class Skeleton {
    constructor(bones = [], boneInverses = []){
        this.uuid = generateUUID();
        this.bones = bones.slice(0);
        this.boneInverses = boneInverses;
        this.boneMatrices = null;
        this.boneTexture = null;
        this.init();
    }
    init() {
        const bones = this.bones;
        const boneInverses = this.boneInverses;
        this.boneMatrices = new Float32Array(bones.length * 16);
        // calculate inverse bone matrices if necessary
        if (boneInverses.length === 0) this.calculateInverses();
        else // handle special case
        if (bones.length !== boneInverses.length) {
            console.warn("THREE.Skeleton: Number of inverse bone matrices does not match amount of bones.");
            this.boneInverses = [];
            for(let i = 0, il = this.bones.length; i < il; i++)this.boneInverses.push(new Matrix4());
        }
    }
    calculateInverses() {
        this.boneInverses.length = 0;
        for(let i = 0, il = this.bones.length; i < il; i++){
            const inverse = new Matrix4();
            if (this.bones[i]) inverse.copy(this.bones[i].matrixWorld).invert();
            this.boneInverses.push(inverse);
        }
    }
    pose() {
        // recover the bind-time world matrices
        for(let i = 0, il = this.bones.length; i < il; i++){
            const bone = this.bones[i];
            if (bone) bone.matrixWorld.copy(this.boneInverses[i]).invert();
        }
        // compute the local matrices, positions, rotations and scales
        for(let i = 0, il = this.bones.length; i < il; i++){
            const bone = this.bones[i];
            if (bone) {
                if (bone.parent && bone.parent.isBone) {
                    bone.matrix.copy(bone.parent.matrixWorld).invert();
                    bone.matrix.multiply(bone.matrixWorld);
                } else bone.matrix.copy(bone.matrixWorld);
                bone.matrix.decompose(bone.position, bone.quaternion, bone.scale);
            }
        }
    }
    update() {
        const bones = this.bones;
        const boneInverses = this.boneInverses;
        const boneMatrices = this.boneMatrices;
        const boneTexture = this.boneTexture;
        // flatten bone matrices to array
        for(let i = 0, il = bones.length; i < il; i++){
            // compute the offset between the current and the original transform
            const matrix = bones[i] ? bones[i].matrixWorld : _identityMatrix$1;
            _offsetMatrix.multiplyMatrices(matrix, boneInverses[i]);
            _offsetMatrix.toArray(boneMatrices, i * 16);
        }
        if (boneTexture !== null) boneTexture.needsUpdate = true;
    }
    clone() {
        return new Skeleton(this.bones, this.boneInverses);
    }
    computeBoneTexture() {
        // layout (1 matrix = 4 pixels)
        //      RGBA RGBA RGBA RGBA (=> column1, column2, column3, column4)
        //  with  8x8  pixel texture max   16 bones * 4 pixels =  (8 * 8)
        //       16x16 pixel texture max   64 bones * 4 pixels = (16 * 16)
        //       32x32 pixel texture max  256 bones * 4 pixels = (32 * 32)
        //       64x64 pixel texture max 1024 bones * 4 pixels = (64 * 64)
        let size = Math.sqrt(this.bones.length * 4); // 4 pixels needed for 1 matrix
        size = Math.ceil(size / 4) * 4;
        size = Math.max(size, 4);
        const boneMatrices = new Float32Array(size * size * 4); // 4 floats per RGBA pixel
        boneMatrices.set(this.boneMatrices); // copy current values
        const boneTexture = new DataTexture(boneMatrices, size, size, RGBAFormat, FloatType);
        boneTexture.needsUpdate = true;
        this.boneMatrices = boneMatrices;
        this.boneTexture = boneTexture;
        return this;
    }
    getBoneByName(name) {
        for(let i = 0, il = this.bones.length; i < il; i++){
            const bone = this.bones[i];
            if (bone.name === name) return bone;
        }
        return undefined;
    }
    dispose() {
        if (this.boneTexture !== null) {
            this.boneTexture.dispose();
            this.boneTexture = null;
        }
    }
    fromJSON(json, bones) {
        this.uuid = json.uuid;
        for(let i = 0, l = json.bones.length; i < l; i++){
            const uuid = json.bones[i];
            let bone = bones[uuid];
            if (bone === undefined) {
                console.warn("THREE.Skeleton: No bone found with UUID:", uuid);
                bone = new Bone();
            }
            this.bones.push(bone);
            this.boneInverses.push(new Matrix4().fromArray(json.boneInverses[i]));
        }
        this.init();
        return this;
    }
    toJSON() {
        const data = {
            metadata: {
                version: 4.6,
                type: "Skeleton",
                generator: "Skeleton.toJSON"
            },
            bones: [],
            boneInverses: []
        };
        data.uuid = this.uuid;
        const bones = this.bones;
        const boneInverses = this.boneInverses;
        for(let i = 0, l = bones.length; i < l; i++){
            const bone = bones[i];
            data.bones.push(bone.uuid);
            const boneInverse = boneInverses[i];
            data.boneInverses.push(boneInverse.toArray());
        }
        return data;
    }
}
class InstancedBufferAttribute extends BufferAttribute {
    constructor(array, itemSize, normalized, meshPerAttribute = 1){
        super(array, itemSize, normalized);
        this.isInstancedBufferAttribute = true;
        this.meshPerAttribute = meshPerAttribute;
    }
    copy(source) {
        super.copy(source);
        this.meshPerAttribute = source.meshPerAttribute;
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.meshPerAttribute = this.meshPerAttribute;
        data.isInstancedBufferAttribute = true;
        return data;
    }
}
const _instanceLocalMatrix = /*@__PURE__*/ new Matrix4();
const _instanceWorldMatrix = /*@__PURE__*/ new Matrix4();
const _instanceIntersects = [];
const _box3 = /*@__PURE__*/ new Box3();
const _identity = /*@__PURE__*/ new Matrix4();
const _mesh$1 = /*@__PURE__*/ new Mesh();
const _sphere$3 = /*@__PURE__*/ new Sphere();
class InstancedMesh extends Mesh {
    constructor(geometry, material, count){
        super(geometry, material);
        this.isInstancedMesh = true;
        this.instanceMatrix = new InstancedBufferAttribute(new Float32Array(count * 16), 16);
        this.instanceColor = null;
        this.morphTexture = null;
        this.count = count;
        this.boundingBox = null;
        this.boundingSphere = null;
        for(let i = 0; i < count; i++)this.setMatrixAt(i, _identity);
    }
    computeBoundingBox() {
        const geometry = this.geometry;
        const count = this.count;
        if (this.boundingBox === null) this.boundingBox = new Box3();
        if (geometry.boundingBox === null) geometry.computeBoundingBox();
        this.boundingBox.makeEmpty();
        for(let i = 0; i < count; i++){
            this.getMatrixAt(i, _instanceLocalMatrix);
            _box3.copy(geometry.boundingBox).applyMatrix4(_instanceLocalMatrix);
            this.boundingBox.union(_box3);
        }
    }
    computeBoundingSphere() {
        const geometry = this.geometry;
        const count = this.count;
        if (this.boundingSphere === null) this.boundingSphere = new Sphere();
        if (geometry.boundingSphere === null) geometry.computeBoundingSphere();
        this.boundingSphere.makeEmpty();
        for(let i = 0; i < count; i++){
            this.getMatrixAt(i, _instanceLocalMatrix);
            _sphere$3.copy(geometry.boundingSphere).applyMatrix4(_instanceLocalMatrix);
            this.boundingSphere.union(_sphere$3);
        }
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.instanceMatrix.copy(source.instanceMatrix);
        if (source.morphTexture !== null) this.morphTexture = source.morphTexture.clone();
        if (source.instanceColor !== null) this.instanceColor = source.instanceColor.clone();
        this.count = source.count;
        if (source.boundingBox !== null) this.boundingBox = source.boundingBox.clone();
        if (source.boundingSphere !== null) this.boundingSphere = source.boundingSphere.clone();
        return this;
    }
    getColorAt(index, color) {
        color.fromArray(this.instanceColor.array, index * 3);
    }
    getMatrixAt(index, matrix) {
        matrix.fromArray(this.instanceMatrix.array, index * 16);
    }
    getMorphAt(index, object) {
        const objectInfluences = object.morphTargetInfluences;
        const array = this.morphTexture.source.data.data;
        const len = objectInfluences.length + 1; // All influences + the baseInfluenceSum
        const dataIndex = index * len + 1; // Skip the baseInfluenceSum at the beginning
        for(let i = 0; i < objectInfluences.length; i++)objectInfluences[i] = array[dataIndex + i];
    }
    raycast(raycaster, intersects) {
        const matrixWorld = this.matrixWorld;
        const raycastTimes = this.count;
        _mesh$1.geometry = this.geometry;
        _mesh$1.material = this.material;
        if (_mesh$1.material === undefined) return;
        // test with bounding sphere first
        if (this.boundingSphere === null) this.computeBoundingSphere();
        _sphere$3.copy(this.boundingSphere);
        _sphere$3.applyMatrix4(matrixWorld);
        if (raycaster.ray.intersectsSphere(_sphere$3) === false) return;
        // now test each instance
        for(let instanceId = 0; instanceId < raycastTimes; instanceId++){
            // calculate the world matrix for each instance
            this.getMatrixAt(instanceId, _instanceLocalMatrix);
            _instanceWorldMatrix.multiplyMatrices(matrixWorld, _instanceLocalMatrix);
            // the mesh represents this single instance
            _mesh$1.matrixWorld = _instanceWorldMatrix;
            _mesh$1.raycast(raycaster, _instanceIntersects);
            // process the result of raycast
            for(let i = 0, l = _instanceIntersects.length; i < l; i++){
                const intersect = _instanceIntersects[i];
                intersect.instanceId = instanceId;
                intersect.object = this;
                intersects.push(intersect);
            }
            _instanceIntersects.length = 0;
        }
    }
    setColorAt(index, color) {
        if (this.instanceColor === null) this.instanceColor = new InstancedBufferAttribute(new Float32Array(this.instanceMatrix.count * 3), 3);
        color.toArray(this.instanceColor.array, index * 3);
    }
    setMatrixAt(index, matrix) {
        matrix.toArray(this.instanceMatrix.array, index * 16);
    }
    setMorphAt(index, object) {
        const objectInfluences = object.morphTargetInfluences;
        const len = objectInfluences.length + 1; // morphBaseInfluence + all influences
        if (this.morphTexture === null) this.morphTexture = new DataTexture(new Float32Array(len * this.count), len, this.count, RedFormat, FloatType);
        const array = this.morphTexture.source.data.data;
        let morphInfluencesSum = 0;
        for(let i = 0; i < objectInfluences.length; i++)morphInfluencesSum += objectInfluences[i];
        const morphBaseInfluence = this.geometry.morphTargetsRelative ? 1 : 1 - morphInfluencesSum;
        const dataIndex = len * index;
        array[dataIndex] = morphBaseInfluence;
        array.set(objectInfluences, dataIndex + 1);
    }
    updateMorphTargets() {}
    dispose() {
        this.dispatchEvent({
            type: "dispose"
        });
        if (this.morphTexture !== null) {
            this.morphTexture.dispose();
            this.morphTexture = null;
        }
        return this;
    }
}
function sortOpaque(a, b) {
    return a.z - b.z;
}
function sortTransparent(a, b) {
    return b.z - a.z;
}
class MultiDrawRenderList {
    constructor(){
        this.index = 0;
        this.pool = [];
        this.list = [];
    }
    push(drawRange, z, index) {
        const pool = this.pool;
        const list = this.list;
        if (this.index >= pool.length) pool.push({
            start: -1,
            count: -1,
            z: -1,
            index: -1
        });
        const item = pool[this.index];
        list.push(item);
        this.index++;
        item.start = drawRange.start;
        item.count = drawRange.count;
        item.z = z;
        item.index = index;
    }
    reset() {
        this.list.length = 0;
        this.index = 0;
    }
}
const _matrix$1 = /*@__PURE__*/ new Matrix4();
const _invMatrixWorld = /*@__PURE__*/ new Matrix4();
const _identityMatrix = /*@__PURE__*/ new Matrix4();
const _whiteColor = /*@__PURE__*/ new Color(1, 1, 1);
const _projScreenMatrix$2 = /*@__PURE__*/ new Matrix4();
const _frustum = /*@__PURE__*/ new Frustum();
const _box$1 = /*@__PURE__*/ new Box3();
const _sphere$2 = /*@__PURE__*/ new Sphere();
const _vector$5 = /*@__PURE__*/ new Vector3();
const _forward = /*@__PURE__*/ new Vector3();
const _temp = /*@__PURE__*/ new Vector3();
const _renderList = /*@__PURE__*/ new MultiDrawRenderList();
const _mesh = /*@__PURE__*/ new Mesh();
const _batchIntersects = [];
// @TODO: SkinnedMesh support?
// @TODO: geometry.groups support?
// @TODO: geometry.drawRange support?
// @TODO: geometry.morphAttributes support?
// @TODO: Support uniform parameter per geometry
// @TODO: Add an "optimize" function to pack geometry and remove data gaps
// copies data from attribute "src" into "target" starting at "targetOffset"
function copyAttributeData(src, target, targetOffset = 0) {
    const itemSize = target.itemSize;
    if (src.isInterleavedBufferAttribute || src.array.constructor !== target.array.constructor) {
        // use the component getters and setters if the array data cannot
        // be copied directly
        const vertexCount = src.count;
        for(let i = 0; i < vertexCount; i++)for(let c = 0; c < itemSize; c++)target.setComponent(i + targetOffset, c, src.getComponent(i, c));
    } else // faster copy approach using typed array set function
    target.array.set(src.array, targetOffset * itemSize);
    target.needsUpdate = true;
}
class BatchedMesh extends Mesh {
    get maxInstanceCount() {
        return this._maxInstanceCount;
    }
    constructor(maxInstanceCount, maxVertexCount, maxIndexCount = maxVertexCount * 2, material){
        super(new BufferGeometry(), material);
        this.isBatchedMesh = true;
        this.perObjectFrustumCulled = true;
        this.sortObjects = true;
        this.boundingBox = null;
        this.boundingSphere = null;
        this.customSort = null;
        // stores visible, active, and geometry id per object
        this._drawInfo = [];
        // geometry information
        this._drawRanges = [];
        this._reservedRanges = [];
        this._bounds = [];
        this._maxInstanceCount = maxInstanceCount;
        this._maxVertexCount = maxVertexCount;
        this._maxIndexCount = maxIndexCount;
        this._geometryInitialized = false;
        this._geometryCount = 0;
        this._multiDrawCounts = new Int32Array(maxInstanceCount);
        this._multiDrawStarts = new Int32Array(maxInstanceCount);
        this._multiDrawCount = 0;
        this._multiDrawInstances = null;
        this._visibilityChanged = true;
        // Local matrix per geometry by using data texture
        this._matricesTexture = null;
        this._indirectTexture = null;
        this._colorsTexture = null;
        this._initMatricesTexture();
        this._initIndirectTexture();
    }
    _initMatricesTexture() {
        // layout (1 matrix = 4 pixels)
        //      RGBA RGBA RGBA RGBA (=> column1, column2, column3, column4)
        //  with  8x8  pixel texture max   16 matrices * 4 pixels =  (8 * 8)
        //       16x16 pixel texture max   64 matrices * 4 pixels = (16 * 16)
        //       32x32 pixel texture max  256 matrices * 4 pixels = (32 * 32)
        //       64x64 pixel texture max 1024 matrices * 4 pixels = (64 * 64)
        let size = Math.sqrt(this._maxInstanceCount * 4); // 4 pixels needed for 1 matrix
        size = Math.ceil(size / 4) * 4;
        size = Math.max(size, 4);
        const matricesArray = new Float32Array(size * size * 4); // 4 floats per RGBA pixel
        const matricesTexture = new DataTexture(matricesArray, size, size, RGBAFormat, FloatType);
        this._matricesTexture = matricesTexture;
    }
    _initIndirectTexture() {
        let size = Math.sqrt(this._maxInstanceCount);
        size = Math.ceil(size);
        const indirectArray = new Uint32Array(size * size);
        const indirectTexture = new DataTexture(indirectArray, size, size, RedIntegerFormat, UnsignedIntType);
        this._indirectTexture = indirectTexture;
    }
    _initColorsTexture() {
        let size = Math.sqrt(this._maxIndexCount);
        size = Math.ceil(size);
        // 4 floats per RGBA pixel initialized to white
        const colorsArray = new Float32Array(size * size * 4).fill(1);
        const colorsTexture = new DataTexture(colorsArray, size, size, RGBAFormat, FloatType);
        colorsTexture.colorSpace = ColorManagement.workingColorSpace;
        this._colorsTexture = colorsTexture;
    }
    _initializeGeometry(reference) {
        const geometry = this.geometry;
        const maxVertexCount = this._maxVertexCount;
        const maxIndexCount = this._maxIndexCount;
        if (this._geometryInitialized === false) {
            for(const attributeName in reference.attributes){
                const srcAttribute = reference.getAttribute(attributeName);
                const { array, itemSize, normalized } = srcAttribute;
                const dstArray = new array.constructor(maxVertexCount * itemSize);
                const dstAttribute = new BufferAttribute(dstArray, itemSize, normalized);
                geometry.setAttribute(attributeName, dstAttribute);
            }
            if (reference.getIndex() !== null) {
                // Reserve last u16 index for primitive restart.
                const indexArray = maxVertexCount > 65535 ? new Uint32Array(maxIndexCount) : new Uint16Array(maxIndexCount);
                geometry.setIndex(new BufferAttribute(indexArray, 1));
            }
            this._geometryInitialized = true;
        }
    }
    // Make sure the geometry is compatible with the existing combined geometry attributes
    _validateGeometry(geometry) {
        // check to ensure the geometries are using consistent attributes and indices
        const batchGeometry = this.geometry;
        if (Boolean(geometry.getIndex()) !== Boolean(batchGeometry.getIndex())) throw new Error('BatchedMesh: All geometries must consistently have "index".');
        for(const attributeName in batchGeometry.attributes){
            if (!geometry.hasAttribute(attributeName)) throw new Error(`BatchedMesh: Added geometry missing "${attributeName}". All geometries must have consistent attributes.`);
            const srcAttribute = geometry.getAttribute(attributeName);
            const dstAttribute = batchGeometry.getAttribute(attributeName);
            if (srcAttribute.itemSize !== dstAttribute.itemSize || srcAttribute.normalized !== dstAttribute.normalized) throw new Error("BatchedMesh: All attributes must have a consistent itemSize and normalized value.");
        }
    }
    setCustomSort(func) {
        this.customSort = func;
        return this;
    }
    computeBoundingBox() {
        if (this.boundingBox === null) this.boundingBox = new Box3();
        const geometryCount = this._geometryCount;
        const boundingBox = this.boundingBox;
        const drawInfo = this._drawInfo;
        boundingBox.makeEmpty();
        for(let i = 0; i < geometryCount; i++){
            if (drawInfo[i].active === false) continue;
            const geometryId = drawInfo[i].geometryIndex;
            this.getMatrixAt(i, _matrix$1);
            this.getBoundingBoxAt(geometryId, _box$1).applyMatrix4(_matrix$1);
            boundingBox.union(_box$1);
        }
    }
    computeBoundingSphere() {
        if (this.boundingSphere === null) this.boundingSphere = new Sphere();
        const boundingSphere = this.boundingSphere;
        const drawInfo = this._drawInfo;
        boundingSphere.makeEmpty();
        for(let i = 0, l = drawInfo.length; i < l; i++){
            if (drawInfo[i].active === false) continue;
            const geometryId = drawInfo[i].geometryIndex;
            this.getMatrixAt(i, _matrix$1);
            this.getBoundingSphereAt(geometryId, _sphere$2).applyMatrix4(_matrix$1);
            boundingSphere.union(_sphere$2);
        }
    }
    addInstance(geometryId) {
        // ensure we're not over geometry
        if (this._drawInfo.length >= this._maxInstanceCount) throw new Error("BatchedMesh: Maximum item count reached.");
        this._drawInfo.push({
            visible: true,
            active: true,
            geometryIndex: geometryId
        });
        // initialize the matrix
        const drawId = this._drawInfo.length - 1;
        const matricesTexture = this._matricesTexture;
        const matricesArray = matricesTexture.image.data;
        _identityMatrix.toArray(matricesArray, drawId * 16);
        matricesTexture.needsUpdate = true;
        const colorsTexture = this._colorsTexture;
        if (colorsTexture) {
            _whiteColor.toArray(colorsTexture.image.data, drawId * 4);
            colorsTexture.needsUpdate = true;
        }
        return drawId;
    }
    addGeometry(geometry, vertexCount = -1, indexCount = -1) {
        this._initializeGeometry(geometry);
        this._validateGeometry(geometry);
        // ensure we're not over geometry
        if (this._drawInfo.length >= this._maxInstanceCount) throw new Error("BatchedMesh: Maximum item count reached.");
        // get the necessary range fo the geometry
        const reservedRange = {
            vertexStart: -1,
            vertexCount: -1,
            indexStart: -1,
            indexCount: -1
        };
        let lastRange = null;
        const reservedRanges = this._reservedRanges;
        const drawRanges = this._drawRanges;
        const bounds = this._bounds;
        if (this._geometryCount !== 0) lastRange = reservedRanges[reservedRanges.length - 1];
        if (vertexCount === -1) reservedRange.vertexCount = geometry.getAttribute("position").count;
        else reservedRange.vertexCount = vertexCount;
        if (lastRange === null) reservedRange.vertexStart = 0;
        else reservedRange.vertexStart = lastRange.vertexStart + lastRange.vertexCount;
        const index = geometry.getIndex();
        const hasIndex = index !== null;
        if (hasIndex) {
            if (indexCount === -1) reservedRange.indexCount = index.count;
            else reservedRange.indexCount = indexCount;
            if (lastRange === null) reservedRange.indexStart = 0;
            else reservedRange.indexStart = lastRange.indexStart + lastRange.indexCount;
        }
        if (reservedRange.indexStart !== -1 && reservedRange.indexStart + reservedRange.indexCount > this._maxIndexCount || reservedRange.vertexStart + reservedRange.vertexCount > this._maxVertexCount) throw new Error("BatchedMesh: Reserved space request exceeds the maximum buffer size.");
        // update id
        const geometryId = this._geometryCount;
        this._geometryCount++;
        // add the reserved range and draw range objects
        reservedRanges.push(reservedRange);
        drawRanges.push({
            start: hasIndex ? reservedRange.indexStart : reservedRange.vertexStart,
            count: -1
        });
        bounds.push({
            boxInitialized: false,
            box: new Box3(),
            sphereInitialized: false,
            sphere: new Sphere()
        });
        // update the geometry
        this.setGeometryAt(geometryId, geometry);
        return geometryId;
    }
    setGeometryAt(geometryId, geometry) {
        if (geometryId >= this._geometryCount) throw new Error("BatchedMesh: Maximum geometry count reached.");
        this._validateGeometry(geometry);
        const batchGeometry = this.geometry;
        const hasIndex = batchGeometry.getIndex() !== null;
        const dstIndex = batchGeometry.getIndex();
        const srcIndex = geometry.getIndex();
        const reservedRange = this._reservedRanges[geometryId];
        if (hasIndex && srcIndex.count > reservedRange.indexCount || geometry.attributes.position.count > reservedRange.vertexCount) throw new Error("BatchedMesh: Reserved space not large enough for provided geometry.");
        // copy geometry over
        const vertexStart = reservedRange.vertexStart;
        const vertexCount = reservedRange.vertexCount;
        for(const attributeName in batchGeometry.attributes){
            // copy attribute data
            const srcAttribute = geometry.getAttribute(attributeName);
            const dstAttribute = batchGeometry.getAttribute(attributeName);
            copyAttributeData(srcAttribute, dstAttribute, vertexStart);
            // fill the rest in with zeroes
            const itemSize = srcAttribute.itemSize;
            for(let i = srcAttribute.count, l = vertexCount; i < l; i++){
                const index = vertexStart + i;
                for(let c = 0; c < itemSize; c++)dstAttribute.setComponent(index, c, 0);
            }
            dstAttribute.needsUpdate = true;
            dstAttribute.addUpdateRange(vertexStart * itemSize, vertexCount * itemSize);
        }
        // copy index
        if (hasIndex) {
            const indexStart = reservedRange.indexStart;
            // copy index data over
            for(let i = 0; i < srcIndex.count; i++)dstIndex.setX(indexStart + i, vertexStart + srcIndex.getX(i));
            // fill the rest in with zeroes
            for(let i = srcIndex.count, l = reservedRange.indexCount; i < l; i++)dstIndex.setX(indexStart + i, vertexStart);
            dstIndex.needsUpdate = true;
            dstIndex.addUpdateRange(indexStart, reservedRange.indexCount);
        }
        // store the bounding boxes
        const bound = this._bounds[geometryId];
        if (geometry.boundingBox !== null) {
            bound.box.copy(geometry.boundingBox);
            bound.boxInitialized = true;
        } else bound.boxInitialized = false;
        if (geometry.boundingSphere !== null) {
            bound.sphere.copy(geometry.boundingSphere);
            bound.sphereInitialized = true;
        } else bound.sphereInitialized = false;
        // set drawRange count
        const drawRange = this._drawRanges[geometryId];
        const posAttr = geometry.getAttribute("position");
        drawRange.count = hasIndex ? srcIndex.count : posAttr.count;
        this._visibilityChanged = true;
        return geometryId;
    }
    /*
	deleteGeometry( geometryId ) {

		// TODO: delete geometry and associated instances

	}
	*/ /*
	deleteInstance( instanceId ) {

		// Note: User needs to call optimize() afterward to pack the data.

		const drawInfo = this._drawInfo;
		if ( instanceId >= drawInfo.length || drawInfo[ instanceId ].active === false ) {

			return this;

		}

		drawInfo[ instanceId ].active = false;
		this._visibilityChanged = true;

		return this;

	}
	*/ // get bounding box and compute it if it doesn't exist
    getBoundingBoxAt(geometryId, target) {
        if (geometryId >= this._geometryCount) return null;
        // compute bounding box
        const bound = this._bounds[geometryId];
        const box = bound.box;
        const geometry = this.geometry;
        if (bound.boxInitialized === false) {
            box.makeEmpty();
            const index = geometry.index;
            const position = geometry.attributes.position;
            const drawRange = this._drawRanges[geometryId];
            for(let i = drawRange.start, l = drawRange.start + drawRange.count; i < l; i++){
                let iv = i;
                if (index) iv = index.getX(iv);
                box.expandByPoint(_vector$5.fromBufferAttribute(position, iv));
            }
            bound.boxInitialized = true;
        }
        target.copy(box);
        return target;
    }
    // get bounding sphere and compute it if it doesn't exist
    getBoundingSphereAt(geometryId, target) {
        if (geometryId >= this._geometryCount) return null;
        // compute bounding sphere
        const bound = this._bounds[geometryId];
        const sphere = bound.sphere;
        const geometry = this.geometry;
        if (bound.sphereInitialized === false) {
            sphere.makeEmpty();
            this.getBoundingBoxAt(geometryId, _box$1);
            _box$1.getCenter(sphere.center);
            const index = geometry.index;
            const position = geometry.attributes.position;
            const drawRange = this._drawRanges[geometryId];
            let maxRadiusSq = 0;
            for(let i = drawRange.start, l = drawRange.start + drawRange.count; i < l; i++){
                let iv = i;
                if (index) iv = index.getX(iv);
                _vector$5.fromBufferAttribute(position, iv);
                maxRadiusSq = Math.max(maxRadiusSq, sphere.center.distanceToSquared(_vector$5));
            }
            sphere.radius = Math.sqrt(maxRadiusSq);
            bound.sphereInitialized = true;
        }
        target.copy(sphere);
        return target;
    }
    setMatrixAt(instanceId, matrix) {
        // @TODO: Map geometryId to index of the arrays because
        //        optimize() can make geometryId mismatch the index
        const drawInfo = this._drawInfo;
        const matricesTexture = this._matricesTexture;
        const matricesArray = this._matricesTexture.image.data;
        if (instanceId >= drawInfo.length || drawInfo[instanceId].active === false) return this;
        matrix.toArray(matricesArray, instanceId * 16);
        matricesTexture.needsUpdate = true;
        return this;
    }
    getMatrixAt(instanceId, matrix) {
        const drawInfo = this._drawInfo;
        const matricesArray = this._matricesTexture.image.data;
        if (instanceId >= drawInfo.length || drawInfo[instanceId].active === false) return null;
        return matrix.fromArray(matricesArray, instanceId * 16);
    }
    setColorAt(instanceId, color) {
        if (this._colorsTexture === null) this._initColorsTexture();
        // @TODO: Map id to index of the arrays because
        //        optimize() can make id mismatch the index
        const colorsTexture = this._colorsTexture;
        const colorsArray = this._colorsTexture.image.data;
        const drawInfo = this._drawInfo;
        if (instanceId >= drawInfo.length || drawInfo[instanceId].active === false) return this;
        color.toArray(colorsArray, instanceId * 4);
        colorsTexture.needsUpdate = true;
        return this;
    }
    getColorAt(instanceId, color) {
        const colorsArray = this._colorsTexture.image.data;
        const drawInfo = this._drawInfo;
        if (instanceId >= drawInfo.length || drawInfo[instanceId].active === false) return null;
        return color.fromArray(colorsArray, instanceId * 4);
    }
    setVisibleAt(instanceId, value) {
        // if the geometry is out of range, not active, or visibility state
        // does not change then return early
        const drawInfo = this._drawInfo;
        if (instanceId >= drawInfo.length || drawInfo[instanceId].active === false || drawInfo[instanceId].visible === value) return this;
        drawInfo[instanceId].visible = value;
        this._visibilityChanged = true;
        return this;
    }
    getVisibleAt(instanceId) {
        // return early if the geometry is out of range or not active
        const drawInfo = this._drawInfo;
        if (instanceId >= drawInfo.length || drawInfo[instanceId].active === false) return false;
        return drawInfo[instanceId].visible;
    }
    raycast(raycaster, intersects) {
        const drawInfo = this._drawInfo;
        const drawRanges = this._drawRanges;
        const matrixWorld = this.matrixWorld;
        const batchGeometry = this.geometry;
        // iterate over each geometry
        _mesh.material = this.material;
        _mesh.geometry.index = batchGeometry.index;
        _mesh.geometry.attributes = batchGeometry.attributes;
        if (_mesh.geometry.boundingBox === null) _mesh.geometry.boundingBox = new Box3();
        if (_mesh.geometry.boundingSphere === null) _mesh.geometry.boundingSphere = new Sphere();
        for(let i = 0, l = drawInfo.length; i < l; i++){
            if (!drawInfo[i].visible || !drawInfo[i].active) continue;
            const geometryId = drawInfo[i].geometryIndex;
            const drawRange = drawRanges[geometryId];
            _mesh.geometry.setDrawRange(drawRange.start, drawRange.count);
            // ge the intersects
            this.getMatrixAt(i, _mesh.matrixWorld).premultiply(matrixWorld);
            this.getBoundingBoxAt(geometryId, _mesh.geometry.boundingBox);
            this.getBoundingSphereAt(geometryId, _mesh.geometry.boundingSphere);
            _mesh.raycast(raycaster, _batchIntersects);
            // add batch id to the intersects
            for(let j = 0, l = _batchIntersects.length; j < l; j++){
                const intersect = _batchIntersects[j];
                intersect.object = this;
                intersect.batchId = i;
                intersects.push(intersect);
            }
            _batchIntersects.length = 0;
        }
        _mesh.material = null;
        _mesh.geometry.index = null;
        _mesh.geometry.attributes = {};
        _mesh.geometry.setDrawRange(0, Infinity);
    }
    copy(source) {
        super.copy(source);
        this.geometry = source.geometry.clone();
        this.perObjectFrustumCulled = source.perObjectFrustumCulled;
        this.sortObjects = source.sortObjects;
        this.boundingBox = source.boundingBox !== null ? source.boundingBox.clone() : null;
        this.boundingSphere = source.boundingSphere !== null ? source.boundingSphere.clone() : null;
        this._drawRanges = source._drawRanges.map((range)=>({
                ...range
            }));
        this._reservedRanges = source._reservedRanges.map((range)=>({
                ...range
            }));
        this._drawInfo = source._drawInfo.map((inf)=>({
                ...inf
            }));
        this._bounds = source._bounds.map((bound)=>({
                boxInitialized: bound.boxInitialized,
                box: bound.box.clone(),
                sphereInitialized: bound.sphereInitialized,
                sphere: bound.sphere.clone()
            }));
        this._maxInstanceCount = source._maxInstanceCount;
        this._maxVertexCount = source._maxVertexCount;
        this._maxIndexCount = source._maxIndexCount;
        this._geometryInitialized = source._geometryInitialized;
        this._geometryCount = source._geometryCount;
        this._multiDrawCounts = source._multiDrawCounts.slice();
        this._multiDrawStarts = source._multiDrawStarts.slice();
        this._matricesTexture = source._matricesTexture.clone();
        this._matricesTexture.image.data = this._matricesTexture.image.slice();
        if (this._colorsTexture !== null) {
            this._colorsTexture = source._colorsTexture.clone();
            this._colorsTexture.image.data = this._colorsTexture.image.slice();
        }
        return this;
    }
    dispose() {
        // Assuming the geometry is not shared with other meshes
        this.geometry.dispose();
        this._matricesTexture.dispose();
        this._matricesTexture = null;
        this._indirectTexture.dispose();
        this._indirectTexture = null;
        if (this._colorsTexture !== null) {
            this._colorsTexture.dispose();
            this._colorsTexture = null;
        }
        return this;
    }
    onBeforeRender(renderer, scene, camera, geometry, material /*, _group*/ ) {
        // if visibility has not changed and frustum culling and object sorting is not required
        // then skip iterating over all items
        if (!this._visibilityChanged && !this.perObjectFrustumCulled && !this.sortObjects) return;
        // the indexed version of the multi draw function requires specifying the start
        // offset in bytes.
        const index = geometry.getIndex();
        const bytesPerElement = index === null ? 1 : index.array.BYTES_PER_ELEMENT;
        const drawInfo = this._drawInfo;
        const multiDrawStarts = this._multiDrawStarts;
        const multiDrawCounts = this._multiDrawCounts;
        const drawRanges = this._drawRanges;
        const perObjectFrustumCulled = this.perObjectFrustumCulled;
        const indirectTexture = this._indirectTexture;
        const indirectArray = indirectTexture.image.data;
        // prepare the frustum in the local frame
        if (perObjectFrustumCulled) {
            _projScreenMatrix$2.multiplyMatrices(camera.projectionMatrix, camera.matrixWorldInverse).multiply(this.matrixWorld);
            _frustum.setFromProjectionMatrix(_projScreenMatrix$2, renderer.coordinateSystem);
        }
        let count = 0;
        if (this.sortObjects) {
            // get the camera position in the local frame
            _invMatrixWorld.copy(this.matrixWorld).invert();
            _vector$5.setFromMatrixPosition(camera.matrixWorld).applyMatrix4(_invMatrixWorld);
            _forward.set(0, 0, -1).transformDirection(camera.matrixWorld).transformDirection(_invMatrixWorld);
            for(let i = 0, l = drawInfo.length; i < l; i++)if (drawInfo[i].visible && drawInfo[i].active) {
                const geometryId = drawInfo[i].geometryIndex;
                // get the bounds in world space
                this.getMatrixAt(i, _matrix$1);
                this.getBoundingSphereAt(geometryId, _sphere$2).applyMatrix4(_matrix$1);
                // determine whether the batched geometry is within the frustum
                let culled = false;
                if (perObjectFrustumCulled) culled = !_frustum.intersectsSphere(_sphere$2);
                if (!culled) {
                    // get the distance from camera used for sorting
                    const z = _temp.subVectors(_sphere$2.center, _vector$5).dot(_forward);
                    _renderList.push(drawRanges[geometryId], z, i);
                }
            }
            // Sort the draw ranges and prep for rendering
            const list = _renderList.list;
            const customSort = this.customSort;
            if (customSort === null) list.sort(material.transparent ? sortTransparent : sortOpaque);
            else customSort.call(this, list, camera);
            for(let i = 0, l = list.length; i < l; i++){
                const item = list[i];
                multiDrawStarts[count] = item.start * bytesPerElement;
                multiDrawCounts[count] = item.count;
                indirectArray[count] = item.index;
                count++;
            }
            _renderList.reset();
        } else {
            for(let i = 0, l = drawInfo.length; i < l; i++)if (drawInfo[i].visible && drawInfo[i].active) {
                const geometryId = drawInfo[i].geometryIndex;
                // determine whether the batched geometry is within the frustum
                let culled = false;
                if (perObjectFrustumCulled) {
                    // get the bounds in world space
                    this.getMatrixAt(i, _matrix$1);
                    this.getBoundingSphereAt(geometryId, _sphere$2).applyMatrix4(_matrix$1);
                    culled = !_frustum.intersectsSphere(_sphere$2);
                }
                if (!culled) {
                    const range = drawRanges[geometryId];
                    multiDrawStarts[count] = range.start * bytesPerElement;
                    multiDrawCounts[count] = range.count;
                    indirectArray[count] = i;
                    count++;
                }
            }
        }
        indirectTexture.needsUpdate = true;
        this._multiDrawCount = count;
        this._visibilityChanged = false;
    }
    onBeforeShadow(renderer, object, camera, shadowCamera, geometry, depthMaterial /* , group */ ) {
        this.onBeforeRender(renderer, null, shadowCamera, geometry, depthMaterial);
    }
}
class LineBasicMaterial extends Material {
    constructor(parameters){
        super();
        this.isLineBasicMaterial = true;
        this.type = "LineBasicMaterial";
        this.color = new Color(0xffffff);
        this.map = null;
        this.linewidth = 1;
        this.linecap = "round";
        this.linejoin = "round";
        this.fog = true;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.color.copy(source.color);
        this.map = source.map;
        this.linewidth = source.linewidth;
        this.linecap = source.linecap;
        this.linejoin = source.linejoin;
        this.fog = source.fog;
        return this;
    }
}
const _vStart = /*@__PURE__*/ new Vector3();
const _vEnd = /*@__PURE__*/ new Vector3();
const _inverseMatrix$1 = /*@__PURE__*/ new Matrix4();
const _ray$1 = /*@__PURE__*/ new Ray();
const _sphere$1 = /*@__PURE__*/ new Sphere();
const _intersectPointOnRay = /*@__PURE__*/ new Vector3();
const _intersectPointOnSegment = /*@__PURE__*/ new Vector3();
class Line extends Object3D {
    constructor(geometry = new BufferGeometry(), material = new LineBasicMaterial()){
        super();
        this.isLine = true;
        this.type = "Line";
        this.geometry = geometry;
        this.material = material;
        this.updateMorphTargets();
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.material = Array.isArray(source.material) ? source.material.slice() : source.material;
        this.geometry = source.geometry;
        return this;
    }
    computeLineDistances() {
        const geometry = this.geometry;
        // we assume non-indexed geometry
        if (geometry.index === null) {
            const positionAttribute = geometry.attributes.position;
            const lineDistances = [
                0
            ];
            for(let i = 1, l = positionAttribute.count; i < l; i++){
                _vStart.fromBufferAttribute(positionAttribute, i - 1);
                _vEnd.fromBufferAttribute(positionAttribute, i);
                lineDistances[i] = lineDistances[i - 1];
                lineDistances[i] += _vStart.distanceTo(_vEnd);
            }
            geometry.setAttribute("lineDistance", new Float32BufferAttribute(lineDistances, 1));
        } else console.warn("THREE.Line.computeLineDistances(): Computation only possible with non-indexed BufferGeometry.");
        return this;
    }
    raycast(raycaster, intersects) {
        const geometry = this.geometry;
        const matrixWorld = this.matrixWorld;
        const threshold = raycaster.params.Line.threshold;
        const drawRange = geometry.drawRange;
        // Checking boundingSphere distance to ray
        if (geometry.boundingSphere === null) geometry.computeBoundingSphere();
        _sphere$1.copy(geometry.boundingSphere);
        _sphere$1.applyMatrix4(matrixWorld);
        _sphere$1.radius += threshold;
        if (raycaster.ray.intersectsSphere(_sphere$1) === false) return;
        //
        _inverseMatrix$1.copy(matrixWorld).invert();
        _ray$1.copy(raycaster.ray).applyMatrix4(_inverseMatrix$1);
        const localThreshold = threshold / ((this.scale.x + this.scale.y + this.scale.z) / 3);
        const localThresholdSq = localThreshold * localThreshold;
        const step = this.isLineSegments ? 2 : 1;
        const index = geometry.index;
        const attributes = geometry.attributes;
        const positionAttribute = attributes.position;
        if (index !== null) {
            const start = Math.max(0, drawRange.start);
            const end = Math.min(index.count, drawRange.start + drawRange.count);
            for(let i = start, l = end - 1; i < l; i += step){
                const a = index.getX(i);
                const b = index.getX(i + 1);
                const intersect = checkIntersection(this, raycaster, _ray$1, localThresholdSq, a, b);
                if (intersect) intersects.push(intersect);
            }
            if (this.isLineLoop) {
                const a = index.getX(end - 1);
                const b = index.getX(start);
                const intersect = checkIntersection(this, raycaster, _ray$1, localThresholdSq, a, b);
                if (intersect) intersects.push(intersect);
            }
        } else {
            const start = Math.max(0, drawRange.start);
            const end = Math.min(positionAttribute.count, drawRange.start + drawRange.count);
            for(let i = start, l = end - 1; i < l; i += step){
                const intersect = checkIntersection(this, raycaster, _ray$1, localThresholdSq, i, i + 1);
                if (intersect) intersects.push(intersect);
            }
            if (this.isLineLoop) {
                const intersect = checkIntersection(this, raycaster, _ray$1, localThresholdSq, end - 1, start);
                if (intersect) intersects.push(intersect);
            }
        }
    }
    updateMorphTargets() {
        const geometry = this.geometry;
        const morphAttributes = geometry.morphAttributes;
        const keys = Object.keys(morphAttributes);
        if (keys.length > 0) {
            const morphAttribute = morphAttributes[keys[0]];
            if (morphAttribute !== undefined) {
                this.morphTargetInfluences = [];
                this.morphTargetDictionary = {};
                for(let m = 0, ml = morphAttribute.length; m < ml; m++){
                    const name = morphAttribute[m].name || String(m);
                    this.morphTargetInfluences.push(0);
                    this.morphTargetDictionary[name] = m;
                }
            }
        }
    }
}
function checkIntersection(object, raycaster, ray, thresholdSq, a, b) {
    const positionAttribute = object.geometry.attributes.position;
    _vStart.fromBufferAttribute(positionAttribute, a);
    _vEnd.fromBufferAttribute(positionAttribute, b);
    const distSq = ray.distanceSqToSegment(_vStart, _vEnd, _intersectPointOnRay, _intersectPointOnSegment);
    if (distSq > thresholdSq) return;
    _intersectPointOnRay.applyMatrix4(object.matrixWorld); // Move back to world space for distance calculation
    const distance = raycaster.ray.origin.distanceTo(_intersectPointOnRay);
    if (distance < raycaster.near || distance > raycaster.far) return;
    return {
        distance: distance,
        // What do we want? intersection point on the ray or on the segment??
        // point: raycaster.ray.at( distance ),
        point: _intersectPointOnSegment.clone().applyMatrix4(object.matrixWorld),
        index: a,
        face: null,
        faceIndex: null,
        object: object
    };
}
const _start = /*@__PURE__*/ new Vector3();
const _end = /*@__PURE__*/ new Vector3();
class LineSegments extends Line {
    constructor(geometry, material){
        super(geometry, material);
        this.isLineSegments = true;
        this.type = "LineSegments";
    }
    computeLineDistances() {
        const geometry = this.geometry;
        // we assume non-indexed geometry
        if (geometry.index === null) {
            const positionAttribute = geometry.attributes.position;
            const lineDistances = [];
            for(let i = 0, l = positionAttribute.count; i < l; i += 2){
                _start.fromBufferAttribute(positionAttribute, i);
                _end.fromBufferAttribute(positionAttribute, i + 1);
                lineDistances[i] = i === 0 ? 0 : lineDistances[i - 1];
                lineDistances[i + 1] = lineDistances[i] + _start.distanceTo(_end);
            }
            geometry.setAttribute("lineDistance", new Float32BufferAttribute(lineDistances, 1));
        } else console.warn("THREE.LineSegments.computeLineDistances(): Computation only possible with non-indexed BufferGeometry.");
        return this;
    }
}
class LineLoop extends Line {
    constructor(geometry, material){
        super(geometry, material);
        this.isLineLoop = true;
        this.type = "LineLoop";
    }
}
class PointsMaterial extends Material {
    constructor(parameters){
        super();
        this.isPointsMaterial = true;
        this.type = "PointsMaterial";
        this.color = new Color(0xffffff);
        this.map = null;
        this.alphaMap = null;
        this.size = 1;
        this.sizeAttenuation = true;
        this.fog = true;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.color.copy(source.color);
        this.map = source.map;
        this.alphaMap = source.alphaMap;
        this.size = source.size;
        this.sizeAttenuation = source.sizeAttenuation;
        this.fog = source.fog;
        return this;
    }
}
const _inverseMatrix = /*@__PURE__*/ new Matrix4();
const _ray = /*@__PURE__*/ new Ray();
const _sphere = /*@__PURE__*/ new Sphere();
const _position$2 = /*@__PURE__*/ new Vector3();
class Points extends Object3D {
    constructor(geometry = new BufferGeometry(), material = new PointsMaterial()){
        super();
        this.isPoints = true;
        this.type = "Points";
        this.geometry = geometry;
        this.material = material;
        this.updateMorphTargets();
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.material = Array.isArray(source.material) ? source.material.slice() : source.material;
        this.geometry = source.geometry;
        return this;
    }
    raycast(raycaster, intersects) {
        const geometry = this.geometry;
        const matrixWorld = this.matrixWorld;
        const threshold = raycaster.params.Points.threshold;
        const drawRange = geometry.drawRange;
        // Checking boundingSphere distance to ray
        if (geometry.boundingSphere === null) geometry.computeBoundingSphere();
        _sphere.copy(geometry.boundingSphere);
        _sphere.applyMatrix4(matrixWorld);
        _sphere.radius += threshold;
        if (raycaster.ray.intersectsSphere(_sphere) === false) return;
        //
        _inverseMatrix.copy(matrixWorld).invert();
        _ray.copy(raycaster.ray).applyMatrix4(_inverseMatrix);
        const localThreshold = threshold / ((this.scale.x + this.scale.y + this.scale.z) / 3);
        const localThresholdSq = localThreshold * localThreshold;
        const index = geometry.index;
        const attributes = geometry.attributes;
        const positionAttribute = attributes.position;
        if (index !== null) {
            const start = Math.max(0, drawRange.start);
            const end = Math.min(index.count, drawRange.start + drawRange.count);
            for(let i = start, il = end; i < il; i++){
                const a = index.getX(i);
                _position$2.fromBufferAttribute(positionAttribute, a);
                testPoint(_position$2, a, localThresholdSq, matrixWorld, raycaster, intersects, this);
            }
        } else {
            const start = Math.max(0, drawRange.start);
            const end = Math.min(positionAttribute.count, drawRange.start + drawRange.count);
            for(let i = start, l = end; i < l; i++){
                _position$2.fromBufferAttribute(positionAttribute, i);
                testPoint(_position$2, i, localThresholdSq, matrixWorld, raycaster, intersects, this);
            }
        }
    }
    updateMorphTargets() {
        const geometry = this.geometry;
        const morphAttributes = geometry.morphAttributes;
        const keys = Object.keys(morphAttributes);
        if (keys.length > 0) {
            const morphAttribute = morphAttributes[keys[0]];
            if (morphAttribute !== undefined) {
                this.morphTargetInfluences = [];
                this.morphTargetDictionary = {};
                for(let m = 0, ml = morphAttribute.length; m < ml; m++){
                    const name = morphAttribute[m].name || String(m);
                    this.morphTargetInfluences.push(0);
                    this.morphTargetDictionary[name] = m;
                }
            }
        }
    }
}
function testPoint(point, index, localThresholdSq, matrixWorld, raycaster, intersects, object) {
    const rayPointDistanceSq = _ray.distanceSqToPoint(point);
    if (rayPointDistanceSq < localThresholdSq) {
        const intersectPoint = new Vector3();
        _ray.closestPointToPoint(point, intersectPoint);
        intersectPoint.applyMatrix4(matrixWorld);
        const distance = raycaster.ray.origin.distanceTo(intersectPoint);
        if (distance < raycaster.near || distance > raycaster.far) return;
        intersects.push({
            distance: distance,
            distanceToRay: Math.sqrt(rayPointDistanceSq),
            point: intersectPoint,
            index: index,
            face: null,
            object: object
        });
    }
}
class VideoTexture extends Texture {
    constructor(video, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy){
        super(video, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy);
        this.isVideoTexture = true;
        this.minFilter = minFilter !== undefined ? minFilter : LinearFilter;
        this.magFilter = magFilter !== undefined ? magFilter : LinearFilter;
        this.generateMipmaps = false;
        const scope = this;
        function updateVideo() {
            scope.needsUpdate = true;
            video.requestVideoFrameCallback(updateVideo);
        }
        if ("requestVideoFrameCallback" in video) video.requestVideoFrameCallback(updateVideo);
    }
    clone() {
        return new this.constructor(this.image).copy(this);
    }
    update() {
        const video = this.image;
        const hasVideoFrameCallback = "requestVideoFrameCallback" in video;
        if (hasVideoFrameCallback === false && video.readyState >= video.HAVE_CURRENT_DATA) this.needsUpdate = true;
    }
}
class FramebufferTexture extends Texture {
    constructor(width, height){
        super({
            width,
            height
        });
        this.isFramebufferTexture = true;
        this.magFilter = NearestFilter;
        this.minFilter = NearestFilter;
        this.generateMipmaps = false;
        this.needsUpdate = true;
    }
}
class CompressedTexture extends Texture {
    constructor(mipmaps, width, height, format, type, mapping, wrapS, wrapT, magFilter, minFilter, anisotropy, colorSpace1){
        super(null, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace1);
        this.isCompressedTexture = true;
        this.image = {
            width: width,
            height: height
        };
        this.mipmaps = mipmaps;
        // no flipping for cube textures
        // (also flipping doesn't work for compressed textures )
        this.flipY = false;
        // can't generate mipmaps for compressed textures
        // mips must be embedded in DDS files
        this.generateMipmaps = false;
    }
}
class CompressedArrayTexture extends CompressedTexture {
    constructor(mipmaps, width, height, depth, format, type){
        super(mipmaps, width, height, format, type);
        this.isCompressedArrayTexture = true;
        this.image.depth = depth;
        this.wrapR = ClampToEdgeWrapping;
        this.layerUpdates = new Set();
    }
    addLayerUpdate(layerIndex) {
        this.layerUpdates.add(layerIndex);
    }
    clearLayerUpdates() {
        this.layerUpdates.clear();
    }
}
class CompressedCubeTexture extends CompressedTexture {
    constructor(images, format, type){
        super(undefined, images[0].width, images[0].height, format, type, CubeReflectionMapping);
        this.isCompressedCubeTexture = true;
        this.isCubeTexture = true;
        this.image = images;
    }
}
class CanvasTexture extends Texture {
    constructor(canvas, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy){
        super(canvas, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy);
        this.isCanvasTexture = true;
        this.needsUpdate = true;
    }
}
/**
 * Extensible curve object.
 *
 * Some common of curve methods:
 * .getPoint( t, optionalTarget ), .getTangent( t, optionalTarget )
 * .getPointAt( u, optionalTarget ), .getTangentAt( u, optionalTarget )
 * .getPoints(), .getSpacedPoints()
 * .getLength()
 * .updateArcLengths()
 *
 * This following curves inherit from THREE.Curve:
 *
 * -- 2D curves --
 * THREE.ArcCurve
 * THREE.CubicBezierCurve
 * THREE.EllipseCurve
 * THREE.LineCurve
 * THREE.QuadraticBezierCurve
 * THREE.SplineCurve
 *
 * -- 3D curves --
 * THREE.CatmullRomCurve3
 * THREE.CubicBezierCurve3
 * THREE.LineCurve3
 * THREE.QuadraticBezierCurve3
 *
 * A series of curves can be represented as a THREE.CurvePath.
 *
 **/ class Curve {
    constructor(){
        this.type = "Curve";
        this.arcLengthDivisions = 200;
    }
    // Virtual base class method to overwrite and implement in subclasses
    //	- t [0 .. 1]
    getPoint() {
        console.warn("THREE.Curve: .getPoint() not implemented.");
        return null;
    }
    // Get point at relative position in curve according to arc length
    // - u [0 .. 1]
    getPointAt(u, optionalTarget) {
        const t = this.getUtoTmapping(u);
        return this.getPoint(t, optionalTarget);
    }
    // Get sequence of points using getPoint( t )
    getPoints(divisions = 5) {
        const points = [];
        for(let d = 0; d <= divisions; d++)points.push(this.getPoint(d / divisions));
        return points;
    }
    // Get sequence of points using getPointAt( u )
    getSpacedPoints(divisions = 5) {
        const points = [];
        for(let d = 0; d <= divisions; d++)points.push(this.getPointAt(d / divisions));
        return points;
    }
    // Get total curve arc length
    getLength() {
        const lengths = this.getLengths();
        return lengths[lengths.length - 1];
    }
    // Get list of cumulative segment lengths
    getLengths(divisions = this.arcLengthDivisions) {
        if (this.cacheArcLengths && this.cacheArcLengths.length === divisions + 1 && !this.needsUpdate) return this.cacheArcLengths;
        this.needsUpdate = false;
        const cache = [];
        let current, last = this.getPoint(0);
        let sum = 0;
        cache.push(0);
        for(let p = 1; p <= divisions; p++){
            current = this.getPoint(p / divisions);
            sum += current.distanceTo(last);
            cache.push(sum);
            last = current;
        }
        this.cacheArcLengths = cache;
        return cache; // { sums: cache, sum: sum }; Sum is in the last element.
    }
    updateArcLengths() {
        this.needsUpdate = true;
        this.getLengths();
    }
    // Given u ( 0 .. 1 ), get a t to find p. This gives you points which are equidistant
    getUtoTmapping(u, distance) {
        const arcLengths = this.getLengths();
        let i = 0;
        const il = arcLengths.length;
        let targetArcLength; // The targeted u distance value to get
        if (distance) targetArcLength = distance;
        else targetArcLength = u * arcLengths[il - 1];
        // binary search for the index with largest value smaller than target u distance
        let low = 0, high = il - 1, comparison;
        while(low <= high){
            i = Math.floor(low + (high - low) / 2); // less likely to overflow, though probably not issue here, JS doesn't really have integers, all numbers are floats
            comparison = arcLengths[i] - targetArcLength;
            if (comparison < 0) low = i + 1;
            else if (comparison > 0) high = i - 1;
            else {
                high = i;
                break;
            // DONE
            }
        }
        i = high;
        if (arcLengths[i] === targetArcLength) return i / (il - 1);
        // we could get finer grain at lengths, or use simple interpolation between two points
        const lengthBefore = arcLengths[i];
        const lengthAfter = arcLengths[i + 1];
        const segmentLength = lengthAfter - lengthBefore;
        // determine where we are between the 'before' and 'after' points
        const segmentFraction = (targetArcLength - lengthBefore) / segmentLength;
        // add that fractional amount to t
        const t = (i + segmentFraction) / (il - 1);
        return t;
    }
    // Returns a unit vector tangent at t
    // In case any sub curve does not implement its tangent derivation,
    // 2 points a small delta apart will be used to find its gradient
    // which seems to give a reasonable approximation
    getTangent(t, optionalTarget) {
        const delta = 0.0001;
        let t1 = t - delta;
        let t2 = t + delta;
        // Capping in case of danger
        if (t1 < 0) t1 = 0;
        if (t2 > 1) t2 = 1;
        const pt1 = this.getPoint(t1);
        const pt2 = this.getPoint(t2);
        const tangent = optionalTarget || (pt1.isVector2 ? new Vector2() : new Vector3());
        tangent.copy(pt2).sub(pt1).normalize();
        return tangent;
    }
    getTangentAt(u, optionalTarget) {
        const t = this.getUtoTmapping(u);
        return this.getTangent(t, optionalTarget);
    }
    computeFrenetFrames(segments, closed) {
        // see http://www.cs.indiana.edu/pub/techreports/TR425.pdf
        const normal = new Vector3();
        const tangents = [];
        const normals = [];
        const binormals = [];
        const vec = new Vector3();
        const mat = new Matrix4();
        // compute the tangent vectors for each segment on the curve
        for(let i = 0; i <= segments; i++){
            const u = i / segments;
            tangents[i] = this.getTangentAt(u, new Vector3());
        }
        // select an initial normal vector perpendicular to the first tangent vector,
        // and in the direction of the minimum tangent xyz component
        normals[0] = new Vector3();
        binormals[0] = new Vector3();
        let min = Number.MAX_VALUE;
        const tx = Math.abs(tangents[0].x);
        const ty = Math.abs(tangents[0].y);
        const tz = Math.abs(tangents[0].z);
        if (tx <= min) {
            min = tx;
            normal.set(1, 0, 0);
        }
        if (ty <= min) {
            min = ty;
            normal.set(0, 1, 0);
        }
        if (tz <= min) normal.set(0, 0, 1);
        vec.crossVectors(tangents[0], normal).normalize();
        normals[0].crossVectors(tangents[0], vec);
        binormals[0].crossVectors(tangents[0], normals[0]);
        // compute the slowly-varying normal and binormal vectors for each segment on the curve
        for(let i = 1; i <= segments; i++){
            normals[i] = normals[i - 1].clone();
            binormals[i] = binormals[i - 1].clone();
            vec.crossVectors(tangents[i - 1], tangents[i]);
            if (vec.length() > Number.EPSILON) {
                vec.normalize();
                const theta = Math.acos(clamp(tangents[i - 1].dot(tangents[i]), -1, 1)); // clamp for floating pt errors
                normals[i].applyMatrix4(mat.makeRotationAxis(vec, theta));
            }
            binormals[i].crossVectors(tangents[i], normals[i]);
        }
        // if the curve is closed, postprocess the vectors so the first and last normal vectors are the same
        if (closed === true) {
            let theta = Math.acos(clamp(normals[0].dot(normals[segments]), -1, 1));
            theta /= segments;
            if (tangents[0].dot(vec.crossVectors(normals[0], normals[segments])) > 0) theta = -theta;
            for(let i = 1; i <= segments; i++){
                // twist a little...
                normals[i].applyMatrix4(mat.makeRotationAxis(tangents[i], theta * i));
                binormals[i].crossVectors(tangents[i], normals[i]);
            }
        }
        return {
            tangents: tangents,
            normals: normals,
            binormals: binormals
        };
    }
    clone() {
        return new this.constructor().copy(this);
    }
    copy(source) {
        this.arcLengthDivisions = source.arcLengthDivisions;
        return this;
    }
    toJSON() {
        const data = {
            metadata: {
                version: 4.6,
                type: "Curve",
                generator: "Curve.toJSON"
            }
        };
        data.arcLengthDivisions = this.arcLengthDivisions;
        data.type = this.type;
        return data;
    }
    fromJSON(json) {
        this.arcLengthDivisions = json.arcLengthDivisions;
        return this;
    }
}
class EllipseCurve extends Curve {
    constructor(aX = 0, aY = 0, xRadius = 1, yRadius = 1, aStartAngle = 0, aEndAngle = Math.PI * 2, aClockwise = false, aRotation = 0){
        super();
        this.isEllipseCurve = true;
        this.type = "EllipseCurve";
        this.aX = aX;
        this.aY = aY;
        this.xRadius = xRadius;
        this.yRadius = yRadius;
        this.aStartAngle = aStartAngle;
        this.aEndAngle = aEndAngle;
        this.aClockwise = aClockwise;
        this.aRotation = aRotation;
    }
    getPoint(t, optionalTarget = new Vector2()) {
        const point = optionalTarget;
        const twoPi = Math.PI * 2;
        let deltaAngle = this.aEndAngle - this.aStartAngle;
        const samePoints = Math.abs(deltaAngle) < Number.EPSILON;
        // ensures that deltaAngle is 0 .. 2 PI
        while(deltaAngle < 0)deltaAngle += twoPi;
        while(deltaAngle > twoPi)deltaAngle -= twoPi;
        if (deltaAngle < Number.EPSILON) {
            if (samePoints) deltaAngle = 0;
            else deltaAngle = twoPi;
        }
        if (this.aClockwise === true && !samePoints) {
            if (deltaAngle === twoPi) deltaAngle = -twoPi;
            else deltaAngle = deltaAngle - twoPi;
        }
        const angle = this.aStartAngle + t * deltaAngle;
        let x = this.aX + this.xRadius * Math.cos(angle);
        let y = this.aY + this.yRadius * Math.sin(angle);
        if (this.aRotation !== 0) {
            const cos = Math.cos(this.aRotation);
            const sin = Math.sin(this.aRotation);
            const tx = x - this.aX;
            const ty = y - this.aY;
            // Rotate the point about the center of the ellipse.
            x = tx * cos - ty * sin + this.aX;
            y = tx * sin + ty * cos + this.aY;
        }
        return point.set(x, y);
    }
    copy(source) {
        super.copy(source);
        this.aX = source.aX;
        this.aY = source.aY;
        this.xRadius = source.xRadius;
        this.yRadius = source.yRadius;
        this.aStartAngle = source.aStartAngle;
        this.aEndAngle = source.aEndAngle;
        this.aClockwise = source.aClockwise;
        this.aRotation = source.aRotation;
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.aX = this.aX;
        data.aY = this.aY;
        data.xRadius = this.xRadius;
        data.yRadius = this.yRadius;
        data.aStartAngle = this.aStartAngle;
        data.aEndAngle = this.aEndAngle;
        data.aClockwise = this.aClockwise;
        data.aRotation = this.aRotation;
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.aX = json.aX;
        this.aY = json.aY;
        this.xRadius = json.xRadius;
        this.yRadius = json.yRadius;
        this.aStartAngle = json.aStartAngle;
        this.aEndAngle = json.aEndAngle;
        this.aClockwise = json.aClockwise;
        this.aRotation = json.aRotation;
        return this;
    }
}
class ArcCurve extends EllipseCurve {
    constructor(aX, aY, aRadius, aStartAngle, aEndAngle, aClockwise){
        super(aX, aY, aRadius, aRadius, aStartAngle, aEndAngle, aClockwise);
        this.isArcCurve = true;
        this.type = "ArcCurve";
    }
}
/**
 * Centripetal CatmullRom Curve - which is useful for avoiding
 * cusps and self-intersections in non-uniform catmull rom curves.
 * http://www.cemyuksel.com/research/catmullrom_param/catmullrom.pdf
 *
 * curve.type accepts centripetal(default), chordal and catmullrom
 * curve.tension is used for catmullrom which defaults to 0.5
 */ /*
Based on an optimized c++ solution in
 - http://stackoverflow.com/questions/9489736/catmull-rom-curve-with-no-cusps-and-no-self-intersections/
 - http://ideone.com/NoEbVM

This CubicPoly class could be used for reusing some variables and calculations,
but for three.js curve use, it could be possible inlined and flatten into a single function call
which can be placed in CurveUtils.
*/ function CubicPoly() {
    let c0 = 0, c1 = 0, c2 = 0, c3 = 0;
    /*
	 * Compute coefficients for a cubic polynomial
	 *   p(s) = c0 + c1*s + c2*s^2 + c3*s^3
	 * such that
	 *   p(0) = x0, p(1) = x1
	 *  and
	 *   p'(0) = t0, p'(1) = t1.
	 */ function init(x0, x1, t0, t1) {
        c0 = x0;
        c1 = t0;
        c2 = -3 * x0 + 3 * x1 - 2 * t0 - t1;
        c3 = 2 * x0 - 2 * x1 + t0 + t1;
    }
    return {
        initCatmullRom: function(x0, x1, x2, x3, tension) {
            init(x1, x2, tension * (x2 - x0), tension * (x3 - x1));
        },
        initNonuniformCatmullRom: function(x0, x1, x2, x3, dt0, dt1, dt2) {
            // compute tangents when parameterized in [t1,t2]
            let t1 = (x1 - x0) / dt0 - (x2 - x0) / (dt0 + dt1) + (x2 - x1) / dt1;
            let t2 = (x2 - x1) / dt1 - (x3 - x1) / (dt1 + dt2) + (x3 - x2) / dt2;
            // rescale tangents for parametrization in [0,1]
            t1 *= dt1;
            t2 *= dt1;
            init(x1, x2, t1, t2);
        },
        calc: function(t) {
            const t2 = t * t;
            const t3 = t2 * t;
            return c0 + c1 * t + c2 * t2 + c3 * t3;
        }
    };
}
//
const tmp = /*@__PURE__*/ new Vector3();
const px = /*@__PURE__*/ new CubicPoly();
const py = /*@__PURE__*/ new CubicPoly();
const pz = /*@__PURE__*/ new CubicPoly();
class CatmullRomCurve3 extends Curve {
    constructor(points = [], closed = false, curveType = "centripetal", tension = 0.5){
        super();
        this.isCatmullRomCurve3 = true;
        this.type = "CatmullRomCurve3";
        this.points = points;
        this.closed = closed;
        this.curveType = curveType;
        this.tension = tension;
    }
    getPoint(t, optionalTarget = new Vector3()) {
        const point = optionalTarget;
        const points = this.points;
        const l = points.length;
        const p = (l - (this.closed ? 0 : 1)) * t;
        let intPoint = Math.floor(p);
        let weight = p - intPoint;
        if (this.closed) intPoint += intPoint > 0 ? 0 : (Math.floor(Math.abs(intPoint) / l) + 1) * l;
        else if (weight === 0 && intPoint === l - 1) {
            intPoint = l - 2;
            weight = 1;
        }
        let p0, p3; // 4 points (p1 & p2 defined below)
        if (this.closed || intPoint > 0) p0 = points[(intPoint - 1) % l];
        else {
            // extrapolate first point
            tmp.subVectors(points[0], points[1]).add(points[0]);
            p0 = tmp;
        }
        const p1 = points[intPoint % l];
        const p2 = points[(intPoint + 1) % l];
        if (this.closed || intPoint + 2 < l) p3 = points[(intPoint + 2) % l];
        else {
            // extrapolate last point
            tmp.subVectors(points[l - 1], points[l - 2]).add(points[l - 1]);
            p3 = tmp;
        }
        if (this.curveType === "centripetal" || this.curveType === "chordal") {
            // init Centripetal / Chordal Catmull-Rom
            const pow = this.curveType === "chordal" ? 0.5 : 0.25;
            let dt0 = Math.pow(p0.distanceToSquared(p1), pow);
            let dt1 = Math.pow(p1.distanceToSquared(p2), pow);
            let dt2 = Math.pow(p2.distanceToSquared(p3), pow);
            // safety check for repeated points
            if (dt1 < 1e-4) dt1 = 1.0;
            if (dt0 < 1e-4) dt0 = dt1;
            if (dt2 < 1e-4) dt2 = dt1;
            px.initNonuniformCatmullRom(p0.x, p1.x, p2.x, p3.x, dt0, dt1, dt2);
            py.initNonuniformCatmullRom(p0.y, p1.y, p2.y, p3.y, dt0, dt1, dt2);
            pz.initNonuniformCatmullRom(p0.z, p1.z, p2.z, p3.z, dt0, dt1, dt2);
        } else if (this.curveType === "catmullrom") {
            px.initCatmullRom(p0.x, p1.x, p2.x, p3.x, this.tension);
            py.initCatmullRom(p0.y, p1.y, p2.y, p3.y, this.tension);
            pz.initCatmullRom(p0.z, p1.z, p2.z, p3.z, this.tension);
        }
        point.set(px.calc(weight), py.calc(weight), pz.calc(weight));
        return point;
    }
    copy(source) {
        super.copy(source);
        this.points = [];
        for(let i = 0, l = source.points.length; i < l; i++){
            const point = source.points[i];
            this.points.push(point.clone());
        }
        this.closed = source.closed;
        this.curveType = source.curveType;
        this.tension = source.tension;
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.points = [];
        for(let i = 0, l = this.points.length; i < l; i++){
            const point = this.points[i];
            data.points.push(point.toArray());
        }
        data.closed = this.closed;
        data.curveType = this.curveType;
        data.tension = this.tension;
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.points = [];
        for(let i = 0, l = json.points.length; i < l; i++){
            const point = json.points[i];
            this.points.push(new Vector3().fromArray(point));
        }
        this.closed = json.closed;
        this.curveType = json.curveType;
        this.tension = json.tension;
        return this;
    }
}
/**
 * Bezier Curves formulas obtained from
 * https://en.wikipedia.org/wiki/B%C3%A9zier_curve
 */ function CatmullRom(t, p0, p1, p2, p3) {
    const v0 = (p2 - p0) * 0.5;
    const v1 = (p3 - p1) * 0.5;
    const t2 = t * t;
    const t3 = t * t2;
    return (2 * p1 - 2 * p2 + v0 + v1) * t3 + (-3 * p1 + 3 * p2 - 2 * v0 - v1) * t2 + v0 * t + p1;
}
//
function QuadraticBezierP0(t, p) {
    const k = 1 - t;
    return k * k * p;
}
function QuadraticBezierP1(t, p) {
    return 2 * (1 - t) * t * p;
}
function QuadraticBezierP2(t, p) {
    return t * t * p;
}
function QuadraticBezier(t, p0, p1, p2) {
    return QuadraticBezierP0(t, p0) + QuadraticBezierP1(t, p1) + QuadraticBezierP2(t, p2);
}
//
function CubicBezierP0(t, p) {
    const k = 1 - t;
    return k * k * k * p;
}
function CubicBezierP1(t, p) {
    const k = 1 - t;
    return 3 * k * k * t * p;
}
function CubicBezierP2(t, p) {
    return 3 * (1 - t) * t * t * p;
}
function CubicBezierP3(t, p) {
    return t * t * t * p;
}
function CubicBezier(t, p0, p1, p2, p3) {
    return CubicBezierP0(t, p0) + CubicBezierP1(t, p1) + CubicBezierP2(t, p2) + CubicBezierP3(t, p3);
}
class CubicBezierCurve extends Curve {
    constructor(v0 = new Vector2(), v1 = new Vector2(), v2 = new Vector2(), v3 = new Vector2()){
        super();
        this.isCubicBezierCurve = true;
        this.type = "CubicBezierCurve";
        this.v0 = v0;
        this.v1 = v1;
        this.v2 = v2;
        this.v3 = v3;
    }
    getPoint(t, optionalTarget = new Vector2()) {
        const point = optionalTarget;
        const v0 = this.v0, v1 = this.v1, v2 = this.v2, v3 = this.v3;
        point.set(CubicBezier(t, v0.x, v1.x, v2.x, v3.x), CubicBezier(t, v0.y, v1.y, v2.y, v3.y));
        return point;
    }
    copy(source) {
        super.copy(source);
        this.v0.copy(source.v0);
        this.v1.copy(source.v1);
        this.v2.copy(source.v2);
        this.v3.copy(source.v3);
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.v0 = this.v0.toArray();
        data.v1 = this.v1.toArray();
        data.v2 = this.v2.toArray();
        data.v3 = this.v3.toArray();
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.v0.fromArray(json.v0);
        this.v1.fromArray(json.v1);
        this.v2.fromArray(json.v2);
        this.v3.fromArray(json.v3);
        return this;
    }
}
class CubicBezierCurve3 extends Curve {
    constructor(v0 = new Vector3(), v1 = new Vector3(), v2 = new Vector3(), v3 = new Vector3()){
        super();
        this.isCubicBezierCurve3 = true;
        this.type = "CubicBezierCurve3";
        this.v0 = v0;
        this.v1 = v1;
        this.v2 = v2;
        this.v3 = v3;
    }
    getPoint(t, optionalTarget = new Vector3()) {
        const point = optionalTarget;
        const v0 = this.v0, v1 = this.v1, v2 = this.v2, v3 = this.v3;
        point.set(CubicBezier(t, v0.x, v1.x, v2.x, v3.x), CubicBezier(t, v0.y, v1.y, v2.y, v3.y), CubicBezier(t, v0.z, v1.z, v2.z, v3.z));
        return point;
    }
    copy(source) {
        super.copy(source);
        this.v0.copy(source.v0);
        this.v1.copy(source.v1);
        this.v2.copy(source.v2);
        this.v3.copy(source.v3);
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.v0 = this.v0.toArray();
        data.v1 = this.v1.toArray();
        data.v2 = this.v2.toArray();
        data.v3 = this.v3.toArray();
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.v0.fromArray(json.v0);
        this.v1.fromArray(json.v1);
        this.v2.fromArray(json.v2);
        this.v3.fromArray(json.v3);
        return this;
    }
}
class LineCurve extends Curve {
    constructor(v1 = new Vector2(), v2 = new Vector2()){
        super();
        this.isLineCurve = true;
        this.type = "LineCurve";
        this.v1 = v1;
        this.v2 = v2;
    }
    getPoint(t, optionalTarget = new Vector2()) {
        const point = optionalTarget;
        if (t === 1) point.copy(this.v2);
        else {
            point.copy(this.v2).sub(this.v1);
            point.multiplyScalar(t).add(this.v1);
        }
        return point;
    }
    // Line curve is linear, so we can overwrite default getPointAt
    getPointAt(u, optionalTarget) {
        return this.getPoint(u, optionalTarget);
    }
    getTangent(t, optionalTarget = new Vector2()) {
        return optionalTarget.subVectors(this.v2, this.v1).normalize();
    }
    getTangentAt(u, optionalTarget) {
        return this.getTangent(u, optionalTarget);
    }
    copy(source) {
        super.copy(source);
        this.v1.copy(source.v1);
        this.v2.copy(source.v2);
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.v1 = this.v1.toArray();
        data.v2 = this.v2.toArray();
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.v1.fromArray(json.v1);
        this.v2.fromArray(json.v2);
        return this;
    }
}
class LineCurve3 extends Curve {
    constructor(v1 = new Vector3(), v2 = new Vector3()){
        super();
        this.isLineCurve3 = true;
        this.type = "LineCurve3";
        this.v1 = v1;
        this.v2 = v2;
    }
    getPoint(t, optionalTarget = new Vector3()) {
        const point = optionalTarget;
        if (t === 1) point.copy(this.v2);
        else {
            point.copy(this.v2).sub(this.v1);
            point.multiplyScalar(t).add(this.v1);
        }
        return point;
    }
    // Line curve is linear, so we can overwrite default getPointAt
    getPointAt(u, optionalTarget) {
        return this.getPoint(u, optionalTarget);
    }
    getTangent(t, optionalTarget = new Vector3()) {
        return optionalTarget.subVectors(this.v2, this.v1).normalize();
    }
    getTangentAt(u, optionalTarget) {
        return this.getTangent(u, optionalTarget);
    }
    copy(source) {
        super.copy(source);
        this.v1.copy(source.v1);
        this.v2.copy(source.v2);
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.v1 = this.v1.toArray();
        data.v2 = this.v2.toArray();
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.v1.fromArray(json.v1);
        this.v2.fromArray(json.v2);
        return this;
    }
}
class QuadraticBezierCurve extends Curve {
    constructor(v0 = new Vector2(), v1 = new Vector2(), v2 = new Vector2()){
        super();
        this.isQuadraticBezierCurve = true;
        this.type = "QuadraticBezierCurve";
        this.v0 = v0;
        this.v1 = v1;
        this.v2 = v2;
    }
    getPoint(t, optionalTarget = new Vector2()) {
        const point = optionalTarget;
        const v0 = this.v0, v1 = this.v1, v2 = this.v2;
        point.set(QuadraticBezier(t, v0.x, v1.x, v2.x), QuadraticBezier(t, v0.y, v1.y, v2.y));
        return point;
    }
    copy(source) {
        super.copy(source);
        this.v0.copy(source.v0);
        this.v1.copy(source.v1);
        this.v2.copy(source.v2);
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.v0 = this.v0.toArray();
        data.v1 = this.v1.toArray();
        data.v2 = this.v2.toArray();
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.v0.fromArray(json.v0);
        this.v1.fromArray(json.v1);
        this.v2.fromArray(json.v2);
        return this;
    }
}
class QuadraticBezierCurve3 extends Curve {
    constructor(v0 = new Vector3(), v1 = new Vector3(), v2 = new Vector3()){
        super();
        this.isQuadraticBezierCurve3 = true;
        this.type = "QuadraticBezierCurve3";
        this.v0 = v0;
        this.v1 = v1;
        this.v2 = v2;
    }
    getPoint(t, optionalTarget = new Vector3()) {
        const point = optionalTarget;
        const v0 = this.v0, v1 = this.v1, v2 = this.v2;
        point.set(QuadraticBezier(t, v0.x, v1.x, v2.x), QuadraticBezier(t, v0.y, v1.y, v2.y), QuadraticBezier(t, v0.z, v1.z, v2.z));
        return point;
    }
    copy(source) {
        super.copy(source);
        this.v0.copy(source.v0);
        this.v1.copy(source.v1);
        this.v2.copy(source.v2);
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.v0 = this.v0.toArray();
        data.v1 = this.v1.toArray();
        data.v2 = this.v2.toArray();
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.v0.fromArray(json.v0);
        this.v1.fromArray(json.v1);
        this.v2.fromArray(json.v2);
        return this;
    }
}
class SplineCurve extends Curve {
    constructor(points = []){
        super();
        this.isSplineCurve = true;
        this.type = "SplineCurve";
        this.points = points;
    }
    getPoint(t, optionalTarget = new Vector2()) {
        const point = optionalTarget;
        const points = this.points;
        const p = (points.length - 1) * t;
        const intPoint = Math.floor(p);
        const weight = p - intPoint;
        const p0 = points[intPoint === 0 ? intPoint : intPoint - 1];
        const p1 = points[intPoint];
        const p2 = points[intPoint > points.length - 2 ? points.length - 1 : intPoint + 1];
        const p3 = points[intPoint > points.length - 3 ? points.length - 1 : intPoint + 2];
        point.set(CatmullRom(weight, p0.x, p1.x, p2.x, p3.x), CatmullRom(weight, p0.y, p1.y, p2.y, p3.y));
        return point;
    }
    copy(source) {
        super.copy(source);
        this.points = [];
        for(let i = 0, l = source.points.length; i < l; i++){
            const point = source.points[i];
            this.points.push(point.clone());
        }
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.points = [];
        for(let i = 0, l = this.points.length; i < l; i++){
            const point = this.points[i];
            data.points.push(point.toArray());
        }
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.points = [];
        for(let i = 0, l = json.points.length; i < l; i++){
            const point = json.points[i];
            this.points.push(new Vector2().fromArray(point));
        }
        return this;
    }
}
var Curves = /*#__PURE__*/ Object.freeze({
    __proto__: null,
    ArcCurve: ArcCurve,
    CatmullRomCurve3: CatmullRomCurve3,
    CubicBezierCurve: CubicBezierCurve,
    CubicBezierCurve3: CubicBezierCurve3,
    EllipseCurve: EllipseCurve,
    LineCurve: LineCurve,
    LineCurve3: LineCurve3,
    QuadraticBezierCurve: QuadraticBezierCurve,
    QuadraticBezierCurve3: QuadraticBezierCurve3,
    SplineCurve: SplineCurve
});
/**************************************************************
 *	Curved Path - a curve path is simply a array of connected
 *  curves, but retains the api of a curve
 **************************************************************/ class CurvePath extends Curve {
    constructor(){
        super();
        this.type = "CurvePath";
        this.curves = [];
        this.autoClose = false; // Automatically closes the path
    }
    add(curve) {
        this.curves.push(curve);
    }
    closePath() {
        // Add a line curve if start and end of lines are not connected
        const startPoint = this.curves[0].getPoint(0);
        const endPoint = this.curves[this.curves.length - 1].getPoint(1);
        if (!startPoint.equals(endPoint)) {
            const lineType = startPoint.isVector2 === true ? "LineCurve" : "LineCurve3";
            this.curves.push(new Curves[lineType](endPoint, startPoint));
        }
        return this;
    }
    // To get accurate point with reference to
    // entire path distance at time t,
    // following has to be done:
    // 1. Length of each sub path have to be known
    // 2. Locate and identify type of curve
    // 3. Get t for the curve
    // 4. Return curve.getPointAt(t')
    getPoint(t, optionalTarget) {
        const d = t * this.getLength();
        const curveLengths = this.getCurveLengths();
        let i = 0;
        // To think about boundaries points.
        while(i < curveLengths.length){
            if (curveLengths[i] >= d) {
                const diff = curveLengths[i] - d;
                const curve = this.curves[i];
                const segmentLength = curve.getLength();
                const u = segmentLength === 0 ? 0 : 1 - diff / segmentLength;
                return curve.getPointAt(u, optionalTarget);
            }
            i++;
        }
        return null;
    // loop where sum != 0, sum > d , sum+1 <d
    }
    // We cannot use the default THREE.Curve getPoint() with getLength() because in
    // THREE.Curve, getLength() depends on getPoint() but in THREE.CurvePath
    // getPoint() depends on getLength
    getLength() {
        const lens = this.getCurveLengths();
        return lens[lens.length - 1];
    }
    // cacheLengths must be recalculated.
    updateArcLengths() {
        this.needsUpdate = true;
        this.cacheLengths = null;
        this.getCurveLengths();
    }
    // Compute lengths and cache them
    // We cannot overwrite getLengths() because UtoT mapping uses it.
    getCurveLengths() {
        // We use cache values if curves and cache array are same length
        if (this.cacheLengths && this.cacheLengths.length === this.curves.length) return this.cacheLengths;
        // Get length of sub-curve
        // Push sums into cached array
        const lengths = [];
        let sums = 0;
        for(let i = 0, l = this.curves.length; i < l; i++){
            sums += this.curves[i].getLength();
            lengths.push(sums);
        }
        this.cacheLengths = lengths;
        return lengths;
    }
    getSpacedPoints(divisions = 40) {
        const points = [];
        for(let i = 0; i <= divisions; i++)points.push(this.getPoint(i / divisions));
        if (this.autoClose) points.push(points[0]);
        return points;
    }
    getPoints(divisions = 12) {
        const points = [];
        let last;
        for(let i = 0, curves = this.curves; i < curves.length; i++){
            const curve = curves[i];
            const resolution = curve.isEllipseCurve ? divisions * 2 : curve.isLineCurve || curve.isLineCurve3 ? 1 : curve.isSplineCurve ? divisions * curve.points.length : divisions;
            const pts = curve.getPoints(resolution);
            for(let j = 0; j < pts.length; j++){
                const point = pts[j];
                if (last && last.equals(point)) continue; // ensures no consecutive points are duplicates
                points.push(point);
                last = point;
            }
        }
        if (this.autoClose && points.length > 1 && !points[points.length - 1].equals(points[0])) points.push(points[0]);
        return points;
    }
    copy(source) {
        super.copy(source);
        this.curves = [];
        for(let i = 0, l = source.curves.length; i < l; i++){
            const curve = source.curves[i];
            this.curves.push(curve.clone());
        }
        this.autoClose = source.autoClose;
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.autoClose = this.autoClose;
        data.curves = [];
        for(let i = 0, l = this.curves.length; i < l; i++){
            const curve = this.curves[i];
            data.curves.push(curve.toJSON());
        }
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.autoClose = json.autoClose;
        this.curves = [];
        for(let i = 0, l = json.curves.length; i < l; i++){
            const curve = json.curves[i];
            this.curves.push(new Curves[curve.type]().fromJSON(curve));
        }
        return this;
    }
}
class Path extends CurvePath {
    constructor(points){
        super();
        this.type = "Path";
        this.currentPoint = new Vector2();
        if (points) this.setFromPoints(points);
    }
    setFromPoints(points) {
        this.moveTo(points[0].x, points[0].y);
        for(let i = 1, l = points.length; i < l; i++)this.lineTo(points[i].x, points[i].y);
        return this;
    }
    moveTo(x, y) {
        this.currentPoint.set(x, y); // TODO consider referencing vectors instead of copying?
        return this;
    }
    lineTo(x, y) {
        const curve = new LineCurve(this.currentPoint.clone(), new Vector2(x, y));
        this.curves.push(curve);
        this.currentPoint.set(x, y);
        return this;
    }
    quadraticCurveTo(aCPx, aCPy, aX, aY) {
        const curve = new QuadraticBezierCurve(this.currentPoint.clone(), new Vector2(aCPx, aCPy), new Vector2(aX, aY));
        this.curves.push(curve);
        this.currentPoint.set(aX, aY);
        return this;
    }
    bezierCurveTo(aCP1x, aCP1y, aCP2x, aCP2y, aX, aY) {
        const curve = new CubicBezierCurve(this.currentPoint.clone(), new Vector2(aCP1x, aCP1y), new Vector2(aCP2x, aCP2y), new Vector2(aX, aY));
        this.curves.push(curve);
        this.currentPoint.set(aX, aY);
        return this;
    }
    splineThru(pts /*Array of Vector*/ ) {
        const npts = [
            this.currentPoint.clone()
        ].concat(pts);
        const curve = new SplineCurve(npts);
        this.curves.push(curve);
        this.currentPoint.copy(pts[pts.length - 1]);
        return this;
    }
    arc(aX, aY, aRadius, aStartAngle, aEndAngle, aClockwise) {
        const x0 = this.currentPoint.x;
        const y0 = this.currentPoint.y;
        this.absarc(aX + x0, aY + y0, aRadius, aStartAngle, aEndAngle, aClockwise);
        return this;
    }
    absarc(aX, aY, aRadius, aStartAngle, aEndAngle, aClockwise) {
        this.absellipse(aX, aY, aRadius, aRadius, aStartAngle, aEndAngle, aClockwise);
        return this;
    }
    ellipse(aX, aY, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation) {
        const x0 = this.currentPoint.x;
        const y0 = this.currentPoint.y;
        this.absellipse(aX + x0, aY + y0, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation);
        return this;
    }
    absellipse(aX, aY, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation) {
        const curve = new EllipseCurve(aX, aY, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation);
        if (this.curves.length > 0) {
            // if a previous curve is present, attempt to join
            const firstPoint = curve.getPoint(0);
            if (!firstPoint.equals(this.currentPoint)) this.lineTo(firstPoint.x, firstPoint.y);
        }
        this.curves.push(curve);
        const lastPoint = curve.getPoint(1);
        this.currentPoint.copy(lastPoint);
        return this;
    }
    copy(source) {
        super.copy(source);
        this.currentPoint.copy(source.currentPoint);
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.currentPoint = this.currentPoint.toArray();
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.currentPoint.fromArray(json.currentPoint);
        return this;
    }
}
class LatheGeometry extends BufferGeometry {
    constructor(points = [
        new Vector2(0, -0.5),
        new Vector2(0.5, 0),
        new Vector2(0, 0.5)
    ], segments = 12, phiStart = 0, phiLength = Math.PI * 2){
        super();
        this.type = "LatheGeometry";
        this.parameters = {
            points: points,
            segments: segments,
            phiStart: phiStart,
            phiLength: phiLength
        };
        segments = Math.floor(segments);
        // clamp phiLength so it's in range of [ 0, 2PI ]
        phiLength = clamp(phiLength, 0, Math.PI * 2);
        // buffers
        const indices = [];
        const vertices = [];
        const uvs = [];
        const initNormals = [];
        const normals = [];
        // helper variables
        const inverseSegments = 1.0 / segments;
        const vertex = new Vector3();
        const uv = new Vector2();
        const normal = new Vector3();
        const curNormal = new Vector3();
        const prevNormal = new Vector3();
        let dx = 0;
        let dy = 0;
        // pre-compute normals for initial "meridian"
        for(let j = 0; j <= points.length - 1; j++)switch(j){
            case 0:
                dx = points[j + 1].x - points[j].x;
                dy = points[j + 1].y - points[j].y;
                normal.x = dy * 1.0;
                normal.y = -dx;
                normal.z = dy * 0.0;
                prevNormal.copy(normal);
                normal.normalize();
                initNormals.push(normal.x, normal.y, normal.z);
                break;
            case points.length - 1:
                initNormals.push(prevNormal.x, prevNormal.y, prevNormal.z);
                break;
            default:
                dx = points[j + 1].x - points[j].x;
                dy = points[j + 1].y - points[j].y;
                normal.x = dy * 1.0;
                normal.y = -dx;
                normal.z = dy * 0.0;
                curNormal.copy(normal);
                normal.x += prevNormal.x;
                normal.y += prevNormal.y;
                normal.z += prevNormal.z;
                normal.normalize();
                initNormals.push(normal.x, normal.y, normal.z);
                prevNormal.copy(curNormal);
        }
        // generate vertices, uvs and normals
        for(let i = 0; i <= segments; i++){
            const phi = phiStart + i * inverseSegments * phiLength;
            const sin = Math.sin(phi);
            const cos = Math.cos(phi);
            for(let j = 0; j <= points.length - 1; j++){
                // vertex
                vertex.x = points[j].x * sin;
                vertex.y = points[j].y;
                vertex.z = points[j].x * cos;
                vertices.push(vertex.x, vertex.y, vertex.z);
                // uv
                uv.x = i / segments;
                uv.y = j / (points.length - 1);
                uvs.push(uv.x, uv.y);
                // normal
                const x = initNormals[3 * j + 0] * sin;
                const y = initNormals[3 * j + 1];
                const z = initNormals[3 * j + 0] * cos;
                normals.push(x, y, z);
            }
        }
        // indices
        for(let i = 0; i < segments; i++)for(let j = 0; j < points.length - 1; j++){
            const base = j + i * points.length;
            const a = base;
            const b = base + points.length;
            const c = base + points.length + 1;
            const d = base + 1;
            // faces
            indices.push(a, b, d);
            indices.push(c, d, b);
        }
        // build geometry
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    static fromJSON(data) {
        return new LatheGeometry(data.points, data.segments, data.phiStart, data.phiLength);
    }
}
class CapsuleGeometry extends LatheGeometry {
    constructor(radius = 1, length = 1, capSegments = 4, radialSegments = 8){
        const path = new Path();
        path.absarc(0, -length / 2, radius, Math.PI * 1.5, 0);
        path.absarc(0, length / 2, radius, 0, Math.PI * 0.5);
        super(path.getPoints(capSegments), radialSegments);
        this.type = "CapsuleGeometry";
        this.parameters = {
            radius: radius,
            length: length,
            capSegments: capSegments,
            radialSegments: radialSegments
        };
    }
    static fromJSON(data) {
        return new CapsuleGeometry(data.radius, data.length, data.capSegments, data.radialSegments);
    }
}
class CircleGeometry extends BufferGeometry {
    constructor(radius = 1, segments = 32, thetaStart = 0, thetaLength = Math.PI * 2){
        super();
        this.type = "CircleGeometry";
        this.parameters = {
            radius: radius,
            segments: segments,
            thetaStart: thetaStart,
            thetaLength: thetaLength
        };
        segments = Math.max(3, segments);
        // buffers
        const indices = [];
        const vertices = [];
        const normals = [];
        const uvs = [];
        // helper variables
        const vertex = new Vector3();
        const uv = new Vector2();
        // center point
        vertices.push(0, 0, 0);
        normals.push(0, 0, 1);
        uvs.push(0.5, 0.5);
        for(let s = 0, i = 3; s <= segments; s++, i += 3){
            const segment = thetaStart + s / segments * thetaLength;
            // vertex
            vertex.x = radius * Math.cos(segment);
            vertex.y = radius * Math.sin(segment);
            vertices.push(vertex.x, vertex.y, vertex.z);
            // normal
            normals.push(0, 0, 1);
            // uvs
            uv.x = (vertices[i] / radius + 1) / 2;
            uv.y = (vertices[i + 1] / radius + 1) / 2;
            uvs.push(uv.x, uv.y);
        }
        // indices
        for(let i = 1; i <= segments; i++)indices.push(i, i + 1, 0);
        // build geometry
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    static fromJSON(data) {
        return new CircleGeometry(data.radius, data.segments, data.thetaStart, data.thetaLength);
    }
}
class CylinderGeometry extends BufferGeometry {
    constructor(radiusTop = 1, radiusBottom = 1, height = 1, radialSegments = 32, heightSegments = 1, openEnded = false, thetaStart = 0, thetaLength = Math.PI * 2){
        super();
        this.type = "CylinderGeometry";
        this.parameters = {
            radiusTop: radiusTop,
            radiusBottom: radiusBottom,
            height: height,
            radialSegments: radialSegments,
            heightSegments: heightSegments,
            openEnded: openEnded,
            thetaStart: thetaStart,
            thetaLength: thetaLength
        };
        const scope = this;
        radialSegments = Math.floor(radialSegments);
        heightSegments = Math.floor(heightSegments);
        // buffers
        const indices = [];
        const vertices = [];
        const normals = [];
        const uvs = [];
        // helper variables
        let index = 0;
        const indexArray = [];
        const halfHeight = height / 2;
        let groupStart = 0;
        // generate geometry
        generateTorso();
        if (openEnded === false) {
            if (radiusTop > 0) generateCap(true);
            if (radiusBottom > 0) generateCap(false);
        }
        // build geometry
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
        function generateTorso() {
            const normal = new Vector3();
            const vertex = new Vector3();
            let groupCount = 0;
            // this will be used to calculate the normal
            const slope = (radiusBottom - radiusTop) / height;
            // generate vertices, normals and uvs
            for(let y = 0; y <= heightSegments; y++){
                const indexRow = [];
                const v = y / heightSegments;
                // calculate the radius of the current row
                const radius = v * (radiusBottom - radiusTop) + radiusTop;
                for(let x = 0; x <= radialSegments; x++){
                    const u = x / radialSegments;
                    const theta = u * thetaLength + thetaStart;
                    const sinTheta = Math.sin(theta);
                    const cosTheta = Math.cos(theta);
                    // vertex
                    vertex.x = radius * sinTheta;
                    vertex.y = -v * height + halfHeight;
                    vertex.z = radius * cosTheta;
                    vertices.push(vertex.x, vertex.y, vertex.z);
                    // normal
                    normal.set(sinTheta, slope, cosTheta).normalize();
                    normals.push(normal.x, normal.y, normal.z);
                    // uv
                    uvs.push(u, 1 - v);
                    // save index of vertex in respective row
                    indexRow.push(index++);
                }
                // now save vertices of the row in our index array
                indexArray.push(indexRow);
            }
            // generate indices
            for(let x = 0; x < radialSegments; x++)for(let y = 0; y < heightSegments; y++){
                // we use the index array to access the correct indices
                const a = indexArray[y][x];
                const b = indexArray[y + 1][x];
                const c = indexArray[y + 1][x + 1];
                const d = indexArray[y][x + 1];
                // faces
                indices.push(a, b, d);
                indices.push(b, c, d);
                // update group counter
                groupCount += 6;
            }
            // add a group to the geometry. this will ensure multi material support
            scope.addGroup(groupStart, groupCount, 0);
            // calculate new start value for groups
            groupStart += groupCount;
        }
        function generateCap(top) {
            // save the index of the first center vertex
            const centerIndexStart = index;
            const uv = new Vector2();
            const vertex = new Vector3();
            let groupCount = 0;
            const radius = top === true ? radiusTop : radiusBottom;
            const sign = top === true ? 1 : -1;
            // first we generate the center vertex data of the cap.
            // because the geometry needs one set of uvs per face,
            // we must generate a center vertex per face/segment
            for(let x = 1; x <= radialSegments; x++){
                // vertex
                vertices.push(0, halfHeight * sign, 0);
                // normal
                normals.push(0, sign, 0);
                // uv
                uvs.push(0.5, 0.5);
                // increase index
                index++;
            }
            // save the index of the last center vertex
            const centerIndexEnd = index;
            // now we generate the surrounding vertices, normals and uvs
            for(let x = 0; x <= radialSegments; x++){
                const u = x / radialSegments;
                const theta = u * thetaLength + thetaStart;
                const cosTheta = Math.cos(theta);
                const sinTheta = Math.sin(theta);
                // vertex
                vertex.x = radius * sinTheta;
                vertex.y = halfHeight * sign;
                vertex.z = radius * cosTheta;
                vertices.push(vertex.x, vertex.y, vertex.z);
                // normal
                normals.push(0, sign, 0);
                // uv
                uv.x = cosTheta * 0.5 + 0.5;
                uv.y = sinTheta * 0.5 * sign + 0.5;
                uvs.push(uv.x, uv.y);
                // increase index
                index++;
            }
            // generate indices
            for(let x = 0; x < radialSegments; x++){
                const c = centerIndexStart + x;
                const i = centerIndexEnd + x;
                if (top === true) // face top
                indices.push(i, i + 1, c);
                else // face bottom
                indices.push(i + 1, i, c);
                groupCount += 3;
            }
            // add a group to the geometry. this will ensure multi material support
            scope.addGroup(groupStart, groupCount, top === true ? 1 : 2);
            // calculate new start value for groups
            groupStart += groupCount;
        }
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    static fromJSON(data) {
        return new CylinderGeometry(data.radiusTop, data.radiusBottom, data.height, data.radialSegments, data.heightSegments, data.openEnded, data.thetaStart, data.thetaLength);
    }
}
class ConeGeometry extends CylinderGeometry {
    constructor(radius = 1, height = 1, radialSegments = 32, heightSegments = 1, openEnded = false, thetaStart = 0, thetaLength = Math.PI * 2){
        super(0, radius, height, radialSegments, heightSegments, openEnded, thetaStart, thetaLength);
        this.type = "ConeGeometry";
        this.parameters = {
            radius: radius,
            height: height,
            radialSegments: radialSegments,
            heightSegments: heightSegments,
            openEnded: openEnded,
            thetaStart: thetaStart,
            thetaLength: thetaLength
        };
    }
    static fromJSON(data) {
        return new ConeGeometry(data.radius, data.height, data.radialSegments, data.heightSegments, data.openEnded, data.thetaStart, data.thetaLength);
    }
}
class PolyhedronGeometry extends BufferGeometry {
    constructor(vertices = [], indices = [], radius = 1, detail = 0){
        super();
        this.type = "PolyhedronGeometry";
        this.parameters = {
            vertices: vertices,
            indices: indices,
            radius: radius,
            detail: detail
        };
        // default buffer data
        const vertexBuffer = [];
        const uvBuffer = [];
        // the subdivision creates the vertex buffer data
        subdivide(detail);
        // all vertices should lie on a conceptual sphere with a given radius
        applyRadius(radius);
        // finally, create the uv data
        generateUVs();
        // build non-indexed geometry
        this.setAttribute("position", new Float32BufferAttribute(vertexBuffer, 3));
        this.setAttribute("normal", new Float32BufferAttribute(vertexBuffer.slice(), 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvBuffer, 2));
        if (detail === 0) this.computeVertexNormals(); // flat normals
        else this.normalizeNormals(); // smooth normals
        // helper functions
        function subdivide(detail) {
            const a = new Vector3();
            const b = new Vector3();
            const c = new Vector3();
            // iterate over all faces and apply a subdivision with the given detail value
            for(let i = 0; i < indices.length; i += 3){
                // get the vertices of the face
                getVertexByIndex(indices[i + 0], a);
                getVertexByIndex(indices[i + 1], b);
                getVertexByIndex(indices[i + 2], c);
                // perform subdivision
                subdivideFace(a, b, c, detail);
            }
        }
        function subdivideFace(a, b, c, detail) {
            const cols = detail + 1;
            // we use this multidimensional array as a data structure for creating the subdivision
            const v = [];
            // construct all of the vertices for this subdivision
            for(let i = 0; i <= cols; i++){
                v[i] = [];
                const aj = a.clone().lerp(c, i / cols);
                const bj = b.clone().lerp(c, i / cols);
                const rows = cols - i;
                for(let j = 0; j <= rows; j++)if (j === 0 && i === cols) v[i][j] = aj;
                else v[i][j] = aj.clone().lerp(bj, j / rows);
            }
            // construct all of the faces
            for(let i = 0; i < cols; i++)for(let j = 0; j < 2 * (cols - i) - 1; j++){
                const k = Math.floor(j / 2);
                if (j % 2 === 0) {
                    pushVertex(v[i][k + 1]);
                    pushVertex(v[i + 1][k]);
                    pushVertex(v[i][k]);
                } else {
                    pushVertex(v[i][k + 1]);
                    pushVertex(v[i + 1][k + 1]);
                    pushVertex(v[i + 1][k]);
                }
            }
        }
        function applyRadius(radius) {
            const vertex = new Vector3();
            // iterate over the entire buffer and apply the radius to each vertex
            for(let i = 0; i < vertexBuffer.length; i += 3){
                vertex.x = vertexBuffer[i + 0];
                vertex.y = vertexBuffer[i + 1];
                vertex.z = vertexBuffer[i + 2];
                vertex.normalize().multiplyScalar(radius);
                vertexBuffer[i + 0] = vertex.x;
                vertexBuffer[i + 1] = vertex.y;
                vertexBuffer[i + 2] = vertex.z;
            }
        }
        function generateUVs() {
            const vertex = new Vector3();
            for(let i = 0; i < vertexBuffer.length; i += 3){
                vertex.x = vertexBuffer[i + 0];
                vertex.y = vertexBuffer[i + 1];
                vertex.z = vertexBuffer[i + 2];
                const u = azimuth(vertex) / 2 / Math.PI + 0.5;
                const v = inclination(vertex) / Math.PI + 0.5;
                uvBuffer.push(u, 1 - v);
            }
            correctUVs();
            correctSeam();
        }
        function correctSeam() {
            // handle case when face straddles the seam, see #3269
            for(let i = 0; i < uvBuffer.length; i += 6){
                // uv data of a single face
                const x0 = uvBuffer[i + 0];
                const x1 = uvBuffer[i + 2];
                const x2 = uvBuffer[i + 4];
                const max = Math.max(x0, x1, x2);
                const min = Math.min(x0, x1, x2);
                // 0.9 is somewhat arbitrary
                if (max > 0.9 && min < 0.1) {
                    if (x0 < 0.2) uvBuffer[i + 0] += 1;
                    if (x1 < 0.2) uvBuffer[i + 2] += 1;
                    if (x2 < 0.2) uvBuffer[i + 4] += 1;
                }
            }
        }
        function pushVertex(vertex) {
            vertexBuffer.push(vertex.x, vertex.y, vertex.z);
        }
        function getVertexByIndex(index, vertex) {
            const stride = index * 3;
            vertex.x = vertices[stride + 0];
            vertex.y = vertices[stride + 1];
            vertex.z = vertices[stride + 2];
        }
        function correctUVs() {
            const a = new Vector3();
            const b = new Vector3();
            const c = new Vector3();
            const centroid = new Vector3();
            const uvA = new Vector2();
            const uvB = new Vector2();
            const uvC = new Vector2();
            for(let i = 0, j = 0; i < vertexBuffer.length; i += 9, j += 6){
                a.set(vertexBuffer[i + 0], vertexBuffer[i + 1], vertexBuffer[i + 2]);
                b.set(vertexBuffer[i + 3], vertexBuffer[i + 4], vertexBuffer[i + 5]);
                c.set(vertexBuffer[i + 6], vertexBuffer[i + 7], vertexBuffer[i + 8]);
                uvA.set(uvBuffer[j + 0], uvBuffer[j + 1]);
                uvB.set(uvBuffer[j + 2], uvBuffer[j + 3]);
                uvC.set(uvBuffer[j + 4], uvBuffer[j + 5]);
                centroid.copy(a).add(b).add(c).divideScalar(3);
                const azi = azimuth(centroid);
                correctUV(uvA, j + 0, a, azi);
                correctUV(uvB, j + 2, b, azi);
                correctUV(uvC, j + 4, c, azi);
            }
        }
        function correctUV(uv, stride, vector, azimuth) {
            if (azimuth < 0 && uv.x === 1) uvBuffer[stride] = uv.x - 1;
            if (vector.x === 0 && vector.z === 0) uvBuffer[stride] = azimuth / 2 / Math.PI + 0.5;
        }
        // Angle around the Y axis, counter-clockwise when looking from above.
        function azimuth(vector) {
            return Math.atan2(vector.z, -vector.x);
        }
        // Angle above the XZ plane.
        function inclination(vector) {
            return Math.atan2(-vector.y, Math.sqrt(vector.x * vector.x + vector.z * vector.z));
        }
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    static fromJSON(data) {
        return new PolyhedronGeometry(data.vertices, data.indices, data.radius, data.details);
    }
}
class DodecahedronGeometry extends PolyhedronGeometry {
    constructor(radius = 1, detail = 0){
        const t = (1 + Math.sqrt(5)) / 2;
        const r = 1 / t;
        const vertices = [
            // (1, 1, 1)
            -1,
            -1,
            -1,
            -1,
            -1,
            1,
            -1,
            1,
            -1,
            -1,
            1,
            1,
            1,
            -1,
            -1,
            1,
            -1,
            1,
            1,
            1,
            -1,
            1,
            1,
            1,
            // (0, 1/, )
            0,
            -r,
            -t,
            0,
            -r,
            t,
            0,
            r,
            -t,
            0,
            r,
            t,
            // (1/, , 0)
            -r,
            -t,
            0,
            -r,
            t,
            0,
            r,
            -t,
            0,
            r,
            t,
            0,
            // (, 0, 1/)
            -t,
            0,
            -r,
            t,
            0,
            -r,
            -t,
            0,
            r,
            t,
            0,
            r
        ];
        const indices = [
            3,
            11,
            7,
            3,
            7,
            15,
            3,
            15,
            13,
            7,
            19,
            17,
            7,
            17,
            6,
            7,
            6,
            15,
            17,
            4,
            8,
            17,
            8,
            10,
            17,
            10,
            6,
            8,
            0,
            16,
            8,
            16,
            2,
            8,
            2,
            10,
            0,
            12,
            1,
            0,
            1,
            18,
            0,
            18,
            16,
            6,
            10,
            2,
            6,
            2,
            13,
            6,
            13,
            15,
            2,
            16,
            18,
            2,
            18,
            3,
            2,
            3,
            13,
            18,
            1,
            9,
            18,
            9,
            11,
            18,
            11,
            3,
            4,
            14,
            12,
            4,
            12,
            0,
            4,
            0,
            8,
            11,
            9,
            5,
            11,
            5,
            19,
            11,
            19,
            7,
            19,
            5,
            14,
            19,
            14,
            4,
            19,
            4,
            17,
            1,
            12,
            14,
            1,
            14,
            5,
            1,
            5,
            9
        ];
        super(vertices, indices, radius, detail);
        this.type = "DodecahedronGeometry";
        this.parameters = {
            radius: radius,
            detail: detail
        };
    }
    static fromJSON(data) {
        return new DodecahedronGeometry(data.radius, data.detail);
    }
}
const _v0 = /*@__PURE__*/ new Vector3();
const _v1$1 = /*@__PURE__*/ new Vector3();
const _normal = /*@__PURE__*/ new Vector3();
const _triangle = /*@__PURE__*/ new Triangle();
class EdgesGeometry extends BufferGeometry {
    constructor(geometry = null, thresholdAngle = 1){
        super();
        this.type = "EdgesGeometry";
        this.parameters = {
            geometry: geometry,
            thresholdAngle: thresholdAngle
        };
        if (geometry !== null) {
            const precisionPoints = 4;
            const precision = Math.pow(10, precisionPoints);
            const thresholdDot = Math.cos(DEG2RAD * thresholdAngle);
            const indexAttr = geometry.getIndex();
            const positionAttr = geometry.getAttribute("position");
            const indexCount = indexAttr ? indexAttr.count : positionAttr.count;
            const indexArr = [
                0,
                0,
                0
            ];
            const vertKeys = [
                "a",
                "b",
                "c"
            ];
            const hashes = new Array(3);
            const edgeData = {};
            const vertices = [];
            for(let i = 0; i < indexCount; i += 3){
                if (indexAttr) {
                    indexArr[0] = indexAttr.getX(i);
                    indexArr[1] = indexAttr.getX(i + 1);
                    indexArr[2] = indexAttr.getX(i + 2);
                } else {
                    indexArr[0] = i;
                    indexArr[1] = i + 1;
                    indexArr[2] = i + 2;
                }
                const { a, b, c } = _triangle;
                a.fromBufferAttribute(positionAttr, indexArr[0]);
                b.fromBufferAttribute(positionAttr, indexArr[1]);
                c.fromBufferAttribute(positionAttr, indexArr[2]);
                _triangle.getNormal(_normal);
                // create hashes for the edge from the vertices
                hashes[0] = `${Math.round(a.x * precision)},${Math.round(a.y * precision)},${Math.round(a.z * precision)}`;
                hashes[1] = `${Math.round(b.x * precision)},${Math.round(b.y * precision)},${Math.round(b.z * precision)}`;
                hashes[2] = `${Math.round(c.x * precision)},${Math.round(c.y * precision)},${Math.round(c.z * precision)}`;
                // skip degenerate triangles
                if (hashes[0] === hashes[1] || hashes[1] === hashes[2] || hashes[2] === hashes[0]) continue;
                // iterate over every edge
                for(let j = 0; j < 3; j++){
                    // get the first and next vertex making up the edge
                    const jNext = (j + 1) % 3;
                    const vecHash0 = hashes[j];
                    const vecHash1 = hashes[jNext];
                    const v0 = _triangle[vertKeys[j]];
                    const v1 = _triangle[vertKeys[jNext]];
                    const hash = `${vecHash0}_${vecHash1}`;
                    const reverseHash = `${vecHash1}_${vecHash0}`;
                    if (reverseHash in edgeData && edgeData[reverseHash]) {
                        // if we found a sibling edge add it into the vertex array if
                        // it meets the angle threshold and delete the edge from the map.
                        if (_normal.dot(edgeData[reverseHash].normal) <= thresholdDot) {
                            vertices.push(v0.x, v0.y, v0.z);
                            vertices.push(v1.x, v1.y, v1.z);
                        }
                        edgeData[reverseHash] = null;
                    } else if (!(hash in edgeData)) // if we've already got an edge here then skip adding a new one
                    edgeData[hash] = {
                        index0: indexArr[j],
                        index1: indexArr[jNext],
                        normal: _normal.clone()
                    };
                }
            }
            // iterate over all remaining, unmatched edges and add them to the vertex array
            for(const key in edgeData)if (edgeData[key]) {
                const { index0, index1 } = edgeData[key];
                _v0.fromBufferAttribute(positionAttr, index0);
                _v1$1.fromBufferAttribute(positionAttr, index1);
                vertices.push(_v0.x, _v0.y, _v0.z);
                vertices.push(_v1$1.x, _v1$1.y, _v1$1.z);
            }
            this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        }
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
}
class Shape extends Path {
    constructor(points){
        super(points);
        this.uuid = generateUUID();
        this.type = "Shape";
        this.holes = [];
    }
    getPointsHoles(divisions) {
        const holesPts = [];
        for(let i = 0, l = this.holes.length; i < l; i++)holesPts[i] = this.holes[i].getPoints(divisions);
        return holesPts;
    }
    // get points of shape and holes (keypoints based on segments parameter)
    extractPoints(divisions) {
        return {
            shape: this.getPoints(divisions),
            holes: this.getPointsHoles(divisions)
        };
    }
    copy(source) {
        super.copy(source);
        this.holes = [];
        for(let i = 0, l = source.holes.length; i < l; i++){
            const hole = source.holes[i];
            this.holes.push(hole.clone());
        }
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.uuid = this.uuid;
        data.holes = [];
        for(let i = 0, l = this.holes.length; i < l; i++){
            const hole = this.holes[i];
            data.holes.push(hole.toJSON());
        }
        return data;
    }
    fromJSON(json) {
        super.fromJSON(json);
        this.uuid = json.uuid;
        this.holes = [];
        for(let i = 0, l = json.holes.length; i < l; i++){
            const hole = json.holes[i];
            this.holes.push(new Path().fromJSON(hole));
        }
        return this;
    }
}
/**
 * Port from https://github.com/mapbox/earcut (v2.2.4)
 */ const Earcut = {
    triangulate: function(data, holeIndices, dim = 2) {
        const hasHoles = holeIndices && holeIndices.length;
        const outerLen = hasHoles ? holeIndices[0] * dim : data.length;
        let outerNode = linkedList(data, 0, outerLen, dim, true);
        const triangles = [];
        if (!outerNode || outerNode.next === outerNode.prev) return triangles;
        let minX, minY, maxX, maxY, x, y, invSize;
        if (hasHoles) outerNode = eliminateHoles(data, holeIndices, outerNode, dim);
        // if the shape is not too simple, we'll use z-order curve hash later; calculate polygon bbox
        if (data.length > 80 * dim) {
            minX = maxX = data[0];
            minY = maxY = data[1];
            for(let i = dim; i < outerLen; i += dim){
                x = data[i];
                y = data[i + 1];
                if (x < minX) minX = x;
                if (y < minY) minY = y;
                if (x > maxX) maxX = x;
                if (y > maxY) maxY = y;
            }
            // minX, minY and invSize are later used to transform coords into integers for z-order calculation
            invSize = Math.max(maxX - minX, maxY - minY);
            invSize = invSize !== 0 ? 32767 / invSize : 0;
        }
        earcutLinked(outerNode, triangles, dim, minX, minY, invSize, 0);
        return triangles;
    }
};
// create a circular doubly linked list from polygon points in the specified winding order
function linkedList(data, start, end, dim, clockwise) {
    let i, last;
    if (clockwise === signedArea(data, start, end, dim) > 0) for(i = start; i < end; i += dim)last = insertNode(i, data[i], data[i + 1], last);
    else for(i = end - dim; i >= start; i -= dim)last = insertNode(i, data[i], data[i + 1], last);
    if (last && equals(last, last.next)) {
        removeNode(last);
        last = last.next;
    }
    return last;
}
// eliminate colinear or duplicate points
function filterPoints(start, end) {
    if (!start) return start;
    if (!end) end = start;
    let p = start, again;
    do {
        again = false;
        if (!p.steiner && (equals(p, p.next) || area(p.prev, p, p.next) === 0)) {
            removeNode(p);
            p = end = p.prev;
            if (p === p.next) break;
            again = true;
        } else p = p.next;
    }while (again || p !== end);
    return end;
}
// main ear slicing loop which triangulates a polygon (given as a linked list)
function earcutLinked(ear, triangles, dim, minX, minY, invSize, pass) {
    if (!ear) return;
    // interlink polygon nodes in z-order
    if (!pass && invSize) indexCurve(ear, minX, minY, invSize);
    let stop = ear, prev, next;
    // iterate through ears, slicing them one by one
    while(ear.prev !== ear.next){
        prev = ear.prev;
        next = ear.next;
        if (invSize ? isEarHashed(ear, minX, minY, invSize) : isEar(ear)) {
            // cut off the triangle
            triangles.push(prev.i / dim | 0);
            triangles.push(ear.i / dim | 0);
            triangles.push(next.i / dim | 0);
            removeNode(ear);
            // skipping the next vertex leads to less sliver triangles
            ear = next.next;
            stop = next.next;
            continue;
        }
        ear = next;
        // if we looped through the whole remaining polygon and can't find any more ears
        if (ear === stop) {
            // try filtering points and slicing again
            if (!pass) earcutLinked(filterPoints(ear), triangles, dim, minX, minY, invSize, 1);
            else if (pass === 1) {
                ear = cureLocalIntersections(filterPoints(ear), triangles, dim);
                earcutLinked(ear, triangles, dim, minX, minY, invSize, 2);
            // as a last resort, try splitting the remaining polygon into two
            } else if (pass === 2) splitEarcut(ear, triangles, dim, minX, minY, invSize);
            break;
        }
    }
}
// check whether a polygon node forms a valid ear with adjacent nodes
function isEar(ear) {
    const a = ear.prev, b = ear, c = ear.next;
    if (area(a, b, c) >= 0) return false; // reflex, can't be an ear
    // now make sure we don't have other points inside the potential ear
    const ax = a.x, bx = b.x, cx = c.x, ay = a.y, by = b.y, cy = c.y;
    // triangle bbox; min & max are calculated like this for speed
    const x0 = ax < bx ? ax < cx ? ax : cx : bx < cx ? bx : cx, y0 = ay < by ? ay < cy ? ay : cy : by < cy ? by : cy, x1 = ax > bx ? ax > cx ? ax : cx : bx > cx ? bx : cx, y1 = ay > by ? ay > cy ? ay : cy : by > cy ? by : cy;
    let p = c.next;
    while(p !== a){
        if (p.x >= x0 && p.x <= x1 && p.y >= y0 && p.y <= y1 && pointInTriangle(ax, ay, bx, by, cx, cy, p.x, p.y) && area(p.prev, p, p.next) >= 0) return false;
        p = p.next;
    }
    return true;
}
function isEarHashed(ear, minX, minY, invSize) {
    const a = ear.prev, b = ear, c = ear.next;
    if (area(a, b, c) >= 0) return false; // reflex, can't be an ear
    const ax = a.x, bx = b.x, cx = c.x, ay = a.y, by = b.y, cy = c.y;
    // triangle bbox; min & max are calculated like this for speed
    const x0 = ax < bx ? ax < cx ? ax : cx : bx < cx ? bx : cx, y0 = ay < by ? ay < cy ? ay : cy : by < cy ? by : cy, x1 = ax > bx ? ax > cx ? ax : cx : bx > cx ? bx : cx, y1 = ay > by ? ay > cy ? ay : cy : by > cy ? by : cy;
    // z-order range for the current triangle bbox;
    const minZ = zOrder(x0, y0, minX, minY, invSize), maxZ = zOrder(x1, y1, minX, minY, invSize);
    let p = ear.prevZ, n = ear.nextZ;
    // look for points inside the triangle in both directions
    while(p && p.z >= minZ && n && n.z <= maxZ){
        if (p.x >= x0 && p.x <= x1 && p.y >= y0 && p.y <= y1 && p !== a && p !== c && pointInTriangle(ax, ay, bx, by, cx, cy, p.x, p.y) && area(p.prev, p, p.next) >= 0) return false;
        p = p.prevZ;
        if (n.x >= x0 && n.x <= x1 && n.y >= y0 && n.y <= y1 && n !== a && n !== c && pointInTriangle(ax, ay, bx, by, cx, cy, n.x, n.y) && area(n.prev, n, n.next) >= 0) return false;
        n = n.nextZ;
    }
    // look for remaining points in decreasing z-order
    while(p && p.z >= minZ){
        if (p.x >= x0 && p.x <= x1 && p.y >= y0 && p.y <= y1 && p !== a && p !== c && pointInTriangle(ax, ay, bx, by, cx, cy, p.x, p.y) && area(p.prev, p, p.next) >= 0) return false;
        p = p.prevZ;
    }
    // look for remaining points in increasing z-order
    while(n && n.z <= maxZ){
        if (n.x >= x0 && n.x <= x1 && n.y >= y0 && n.y <= y1 && n !== a && n !== c && pointInTriangle(ax, ay, bx, by, cx, cy, n.x, n.y) && area(n.prev, n, n.next) >= 0) return false;
        n = n.nextZ;
    }
    return true;
}
// go through all polygon nodes and cure small local self-intersections
function cureLocalIntersections(start, triangles, dim) {
    let p = start;
    do {
        const a = p.prev, b = p.next.next;
        if (!equals(a, b) && intersects(a, p, p.next, b) && locallyInside(a, b) && locallyInside(b, a)) {
            triangles.push(a.i / dim | 0);
            triangles.push(p.i / dim | 0);
            triangles.push(b.i / dim | 0);
            // remove two nodes involved
            removeNode(p);
            removeNode(p.next);
            p = start = b;
        }
        p = p.next;
    }while (p !== start);
    return filterPoints(p);
}
// try splitting polygon into two and triangulate them independently
function splitEarcut(start, triangles, dim, minX, minY, invSize) {
    // look for a valid diagonal that divides the polygon into two
    let a = start;
    do {
        let b = a.next.next;
        while(b !== a.prev){
            if (a.i !== b.i && isValidDiagonal(a, b)) {
                // split the polygon in two by the diagonal
                let c = splitPolygon(a, b);
                // filter colinear points around the cuts
                a = filterPoints(a, a.next);
                c = filterPoints(c, c.next);
                // run earcut on each half
                earcutLinked(a, triangles, dim, minX, minY, invSize, 0);
                earcutLinked(c, triangles, dim, minX, minY, invSize, 0);
                return;
            }
            b = b.next;
        }
        a = a.next;
    }while (a !== start);
}
// link every hole into the outer loop, producing a single-ring polygon without holes
function eliminateHoles(data, holeIndices, outerNode, dim) {
    const queue = [];
    let i, len, start, end, list;
    for(i = 0, len = holeIndices.length; i < len; i++){
        start = holeIndices[i] * dim;
        end = i < len - 1 ? holeIndices[i + 1] * dim : data.length;
        list = linkedList(data, start, end, dim, false);
        if (list === list.next) list.steiner = true;
        queue.push(getLeftmost(list));
    }
    queue.sort(compareX);
    // process holes from left to right
    for(i = 0; i < queue.length; i++)outerNode = eliminateHole(queue[i], outerNode);
    return outerNode;
}
function compareX(a, b) {
    return a.x - b.x;
}
// find a bridge between vertices that connects hole with an outer ring and link it
function eliminateHole(hole, outerNode) {
    const bridge = findHoleBridge(hole, outerNode);
    if (!bridge) return outerNode;
    const bridgeReverse = splitPolygon(bridge, hole);
    // filter collinear points around the cuts
    filterPoints(bridgeReverse, bridgeReverse.next);
    return filterPoints(bridge, bridge.next);
}
// David Eberly's algorithm for finding a bridge between hole and outer polygon
function findHoleBridge(hole, outerNode) {
    let p = outerNode, qx = -Infinity, m;
    const hx = hole.x, hy = hole.y;
    // find a segment intersected by a ray from the hole's leftmost point to the left;
    // segment's endpoint with lesser x will be potential connection point
    do {
        if (hy <= p.y && hy >= p.next.y && p.next.y !== p.y) {
            const x = p.x + (hy - p.y) * (p.next.x - p.x) / (p.next.y - p.y);
            if (x <= hx && x > qx) {
                qx = x;
                m = p.x < p.next.x ? p : p.next;
                if (x === hx) return m; // hole touches outer segment; pick leftmost endpoint
            }
        }
        p = p.next;
    }while (p !== outerNode);
    if (!m) return null;
    // look for points inside the triangle of hole point, segment intersection and endpoint;
    // if there are no points found, we have a valid connection;
    // otherwise choose the point of the minimum angle with the ray as connection point
    const stop = m, mx = m.x, my = m.y;
    let tanMin = Infinity, tan;
    p = m;
    do {
        if (hx >= p.x && p.x >= mx && hx !== p.x && pointInTriangle(hy < my ? hx : qx, hy, mx, my, hy < my ? qx : hx, hy, p.x, p.y)) {
            tan = Math.abs(hy - p.y) / (hx - p.x); // tangential
            if (locallyInside(p, hole) && (tan < tanMin || tan === tanMin && (p.x > m.x || p.x === m.x && sectorContainsSector(m, p)))) {
                m = p;
                tanMin = tan;
            }
        }
        p = p.next;
    }while (p !== stop);
    return m;
}
// whether sector in vertex m contains sector in vertex p in the same coordinates
function sectorContainsSector(m, p) {
    return area(m.prev, m, p.prev) < 0 && area(p.next, m, m.next) < 0;
}
// interlink polygon nodes in z-order
function indexCurve(start, minX, minY, invSize) {
    let p = start;
    do {
        if (p.z === 0) p.z = zOrder(p.x, p.y, minX, minY, invSize);
        p.prevZ = p.prev;
        p.nextZ = p.next;
        p = p.next;
    }while (p !== start);
    p.prevZ.nextZ = null;
    p.prevZ = null;
    sortLinked(p);
}
// Simon Tatham's linked list merge sort algorithm
// http://www.chiark.greenend.org.uk/~sgtatham/algorithms/listsort.html
function sortLinked(list) {
    let i, p, q, e, tail, numMerges, pSize, qSize, inSize = 1;
    do {
        p = list;
        list = null;
        tail = null;
        numMerges = 0;
        while(p){
            numMerges++;
            q = p;
            pSize = 0;
            for(i = 0; i < inSize; i++){
                pSize++;
                q = q.nextZ;
                if (!q) break;
            }
            qSize = inSize;
            while(pSize > 0 || qSize > 0 && q){
                if (pSize !== 0 && (qSize === 0 || !q || p.z <= q.z)) {
                    e = p;
                    p = p.nextZ;
                    pSize--;
                } else {
                    e = q;
                    q = q.nextZ;
                    qSize--;
                }
                if (tail) tail.nextZ = e;
                else list = e;
                e.prevZ = tail;
                tail = e;
            }
            p = q;
        }
        tail.nextZ = null;
        inSize *= 2;
    }while (numMerges > 1);
    return list;
}
// z-order of a point given coords and inverse of the longer side of data bbox
function zOrder(x, y, minX, minY, invSize) {
    // coords are transformed into non-negative 15-bit integer range
    x = (x - minX) * invSize | 0;
    y = (y - minY) * invSize | 0;
    x = (x | x << 8) & 0x00FF00FF;
    x = (x | x << 4) & 0x0F0F0F0F;
    x = (x | x << 2) & 0x33333333;
    x = (x | x << 1) & 0x55555555;
    y = (y | y << 8) & 0x00FF00FF;
    y = (y | y << 4) & 0x0F0F0F0F;
    y = (y | y << 2) & 0x33333333;
    y = (y | y << 1) & 0x55555555;
    return x | y << 1;
}
// find the leftmost node of a polygon ring
function getLeftmost(start) {
    let p = start, leftmost = start;
    do {
        if (p.x < leftmost.x || p.x === leftmost.x && p.y < leftmost.y) leftmost = p;
        p = p.next;
    }while (p !== start);
    return leftmost;
}
// check if a point lies within a convex triangle
function pointInTriangle(ax, ay, bx, by, cx, cy, px, py) {
    return (cx - px) * (ay - py) >= (ax - px) * (cy - py) && (ax - px) * (by - py) >= (bx - px) * (ay - py) && (bx - px) * (cy - py) >= (cx - px) * (by - py);
}
// check if a diagonal between two polygon nodes is valid (lies in polygon interior)
function isValidDiagonal(a, b) {
    return a.next.i !== b.i && a.prev.i !== b.i && !intersectsPolygon(a, b) && // dones't intersect other edges
    (locallyInside(a, b) && locallyInside(b, a) && middleInside(a, b) && // locally visible
    (area(a.prev, a, b.prev) || area(a, b.prev, b)) || // does not create opposite-facing sectors
    equals(a, b) && area(a.prev, a, a.next) > 0 && area(b.prev, b, b.next) > 0); // special zero-length case
}
// signed area of a triangle
function area(p, q, r) {
    return (q.y - p.y) * (r.x - q.x) - (q.x - p.x) * (r.y - q.y);
}
// check if two points are equal
function equals(p1, p2) {
    return p1.x === p2.x && p1.y === p2.y;
}
// check if two segments intersect
function intersects(p1, q1, p2, q2) {
    const o1 = sign(area(p1, q1, p2));
    const o2 = sign(area(p1, q1, q2));
    const o3 = sign(area(p2, q2, p1));
    const o4 = sign(area(p2, q2, q1));
    if (o1 !== o2 && o3 !== o4) return true; // general case
    if (o1 === 0 && onSegment(p1, p2, q1)) return true; // p1, q1 and p2 are collinear and p2 lies on p1q1
    if (o2 === 0 && onSegment(p1, q2, q1)) return true; // p1, q1 and q2 are collinear and q2 lies on p1q1
    if (o3 === 0 && onSegment(p2, p1, q2)) return true; // p2, q2 and p1 are collinear and p1 lies on p2q2
    if (o4 === 0 && onSegment(p2, q1, q2)) return true; // p2, q2 and q1 are collinear and q1 lies on p2q2
    return false;
}
// for collinear points p, q, r, check if point q lies on segment pr
function onSegment(p, q, r) {
    return q.x <= Math.max(p.x, r.x) && q.x >= Math.min(p.x, r.x) && q.y <= Math.max(p.y, r.y) && q.y >= Math.min(p.y, r.y);
}
function sign(num) {
    return num > 0 ? 1 : num < 0 ? -1 : 0;
}
// check if a polygon diagonal intersects any polygon segments
function intersectsPolygon(a, b) {
    let p = a;
    do {
        if (p.i !== a.i && p.next.i !== a.i && p.i !== b.i && p.next.i !== b.i && intersects(p, p.next, a, b)) return true;
        p = p.next;
    }while (p !== a);
    return false;
}
// check if a polygon diagonal is locally inside the polygon
function locallyInside(a, b) {
    return area(a.prev, a, a.next) < 0 ? area(a, b, a.next) >= 0 && area(a, a.prev, b) >= 0 : area(a, b, a.prev) < 0 || area(a, a.next, b) < 0;
}
// check if the middle point of a polygon diagonal is inside the polygon
function middleInside(a, b) {
    let p = a, inside = false;
    const px = (a.x + b.x) / 2, py = (a.y + b.y) / 2;
    do {
        if (p.y > py !== p.next.y > py && p.next.y !== p.y && px < (p.next.x - p.x) * (py - p.y) / (p.next.y - p.y) + p.x) inside = !inside;
        p = p.next;
    }while (p !== a);
    return inside;
}
// link two polygon vertices with a bridge; if the vertices belong to the same ring, it splits polygon into two;
// if one belongs to the outer ring and another to a hole, it merges it into a single ring
function splitPolygon(a, b) {
    const a2 = new Node(a.i, a.x, a.y), b2 = new Node(b.i, b.x, b.y), an = a.next, bp = b.prev;
    a.next = b;
    b.prev = a;
    a2.next = an;
    an.prev = a2;
    b2.next = a2;
    a2.prev = b2;
    bp.next = b2;
    b2.prev = bp;
    return b2;
}
// create a node and optionally link it with previous one (in a circular doubly linked list)
function insertNode(i, x, y, last) {
    const p = new Node(i, x, y);
    if (!last) {
        p.prev = p;
        p.next = p;
    } else {
        p.next = last.next;
        p.prev = last;
        last.next.prev = p;
        last.next = p;
    }
    return p;
}
function removeNode(p) {
    p.next.prev = p.prev;
    p.prev.next = p.next;
    if (p.prevZ) p.prevZ.nextZ = p.nextZ;
    if (p.nextZ) p.nextZ.prevZ = p.prevZ;
}
function Node(i, x, y) {
    // vertex index in coordinates array
    this.i = i;
    // vertex coordinates
    this.x = x;
    this.y = y;
    // previous and next vertex nodes in a polygon ring
    this.prev = null;
    this.next = null;
    // z-order curve value
    this.z = 0;
    // previous and next nodes in z-order
    this.prevZ = null;
    this.nextZ = null;
    // indicates whether this is a steiner point
    this.steiner = false;
}
function signedArea(data, start, end, dim) {
    let sum = 0;
    for(let i = start, j = end - dim; i < end; i += dim){
        sum += (data[j] - data[i]) * (data[i + 1] + data[j + 1]);
        j = i;
    }
    return sum;
}
class ShapeUtils {
    // calculate area of the contour polygon
    static area(contour) {
        const n = contour.length;
        let a = 0.0;
        for(let p = n - 1, q = 0; q < n; p = q++)a += contour[p].x * contour[q].y - contour[q].x * contour[p].y;
        return a * 0.5;
    }
    static isClockWise(pts) {
        return ShapeUtils.area(pts) < 0;
    }
    static triangulateShape(contour, holes) {
        const vertices = []; // flat array of vertices like [ x0,y0, x1,y1, x2,y2, ... ]
        const holeIndices = []; // array of hole indices
        const faces = []; // final array of vertex indices like [ [ a,b,d ], [ b,c,d ] ]
        removeDupEndPts(contour);
        addContour(vertices, contour);
        //
        let holeIndex = contour.length;
        holes.forEach(removeDupEndPts);
        for(let i = 0; i < holes.length; i++){
            holeIndices.push(holeIndex);
            holeIndex += holes[i].length;
            addContour(vertices, holes[i]);
        }
        //
        const triangles = Earcut.triangulate(vertices, holeIndices);
        //
        for(let i = 0; i < triangles.length; i += 3)faces.push(triangles.slice(i, i + 3));
        return faces;
    }
}
function removeDupEndPts(points) {
    const l = points.length;
    if (l > 2 && points[l - 1].equals(points[0])) points.pop();
}
function addContour(vertices, contour) {
    for(let i = 0; i < contour.length; i++){
        vertices.push(contour[i].x);
        vertices.push(contour[i].y);
    }
}
/**
 * Creates extruded geometry from a path shape.
 *
 * parameters = {
 *
 *  curveSegments: <int>, // number of points on the curves
 *  steps: <int>, // number of points for z-side extrusions / used for subdividing segments of extrude spline too
 *  depth: <float>, // Depth to extrude the shape
 *
 *  bevelEnabled: <bool>, // turn on bevel
 *  bevelThickness: <float>, // how deep into the original shape bevel goes
 *  bevelSize: <float>, // how far from shape outline (including bevelOffset) is bevel
 *  bevelOffset: <float>, // how far from shape outline does bevel start
 *  bevelSegments: <int>, // number of bevel layers
 *
 *  extrudePath: <THREE.Curve> // curve to extrude shape along
 *
 *  UVGenerator: <Object> // object that provides UV generator functions
 *
 * }
 */ class ExtrudeGeometry extends BufferGeometry {
    constructor(shapes = new Shape([
        new Vector2(0.5, 0.5),
        new Vector2(-0.5, 0.5),
        new Vector2(-0.5, -0.5),
        new Vector2(0.5, -0.5)
    ]), options = {}){
        super();
        this.type = "ExtrudeGeometry";
        this.parameters = {
            shapes: shapes,
            options: options
        };
        shapes = Array.isArray(shapes) ? shapes : [
            shapes
        ];
        const scope = this;
        const verticesArray = [];
        const uvArray = [];
        for(let i = 0, l = shapes.length; i < l; i++){
            const shape = shapes[i];
            addShape(shape);
        }
        // build geometry
        this.setAttribute("position", new Float32BufferAttribute(verticesArray, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvArray, 2));
        this.computeVertexNormals();
        // functions
        function addShape(shape) {
            const placeholder = [];
            // options
            const curveSegments = options.curveSegments !== undefined ? options.curveSegments : 12;
            const steps = options.steps !== undefined ? options.steps : 1;
            const depth = options.depth !== undefined ? options.depth : 1;
            let bevelEnabled = options.bevelEnabled !== undefined ? options.bevelEnabled : true;
            let bevelThickness = options.bevelThickness !== undefined ? options.bevelThickness : 0.2;
            let bevelSize = options.bevelSize !== undefined ? options.bevelSize : bevelThickness - 0.1;
            let bevelOffset = options.bevelOffset !== undefined ? options.bevelOffset : 0;
            let bevelSegments = options.bevelSegments !== undefined ? options.bevelSegments : 3;
            const extrudePath = options.extrudePath;
            const uvgen = options.UVGenerator !== undefined ? options.UVGenerator : WorldUVGenerator;
            //
            let extrudePts, extrudeByPath = false;
            let splineTube, binormal, normal, position2;
            if (extrudePath) {
                extrudePts = extrudePath.getSpacedPoints(steps);
                extrudeByPath = true;
                bevelEnabled = false; // bevels not supported for path extrusion
                // SETUP TNB variables
                // TODO1 - have a .isClosed in spline?
                splineTube = extrudePath.computeFrenetFrames(steps, false);
                // console.log(splineTube, 'splineTube', splineTube.normals.length, 'steps', steps, 'extrudePts', extrudePts.length);
                binormal = new Vector3();
                normal = new Vector3();
                position2 = new Vector3();
            }
            // Safeguards if bevels are not enabled
            if (!bevelEnabled) {
                bevelSegments = 0;
                bevelThickness = 0;
                bevelSize = 0;
                bevelOffset = 0;
            }
            // Variables initialization
            const shapePoints = shape.extractPoints(curveSegments);
            let vertices = shapePoints.shape;
            const holes = shapePoints.holes;
            const reverse = !ShapeUtils.isClockWise(vertices);
            if (reverse) {
                vertices = vertices.reverse();
                // Maybe we should also check if holes are in the opposite direction, just to be safe ...
                for(let h = 0, hl = holes.length; h < hl; h++){
                    const ahole = holes[h];
                    if (ShapeUtils.isClockWise(ahole)) holes[h] = ahole.reverse();
                }
            }
            const faces = ShapeUtils.triangulateShape(vertices, holes);
            /* Vertices */ const contour = vertices; // vertices has all points but contour has only points of circumference
            for(let h = 0, hl = holes.length; h < hl; h++){
                const ahole = holes[h];
                vertices = vertices.concat(ahole);
            }
            function scalePt2(pt, vec, size) {
                if (!vec) console.error("THREE.ExtrudeGeometry: vec does not exist");
                return pt.clone().addScaledVector(vec, size);
            }
            const vlen = vertices.length, flen = faces.length;
            // Find directions for point movement
            function getBevelVec(inPt, inPrev, inNext) {
                // computes for inPt the corresponding point inPt' on a new contour
                //   shifted by 1 unit (length of normalized vector) to the left
                // if we walk along contour clockwise, this new contour is outside the old one
                //
                // inPt' is the intersection of the two lines parallel to the two
                //  adjacent edges of inPt at a distance of 1 unit on the left side.
                let v_trans_x, v_trans_y, shrink_by; // resulting translation vector for inPt
                // good reading for geometry algorithms (here: line-line intersection)
                // http://geomalgorithms.com/a05-_intersect-1.html
                const v_prev_x = inPt.x - inPrev.x, v_prev_y = inPt.y - inPrev.y;
                const v_next_x = inNext.x - inPt.x, v_next_y = inNext.y - inPt.y;
                const v_prev_lensq = v_prev_x * v_prev_x + v_prev_y * v_prev_y;
                // check for collinear edges
                const collinear0 = v_prev_x * v_next_y - v_prev_y * v_next_x;
                if (Math.abs(collinear0) > Number.EPSILON) {
                    // not collinear
                    // length of vectors for normalizing
                    const v_prev_len = Math.sqrt(v_prev_lensq);
                    const v_next_len = Math.sqrt(v_next_x * v_next_x + v_next_y * v_next_y);
                    // shift adjacent points by unit vectors to the left
                    const ptPrevShift_x = inPrev.x - v_prev_y / v_prev_len;
                    const ptPrevShift_y = inPrev.y + v_prev_x / v_prev_len;
                    const ptNextShift_x = inNext.x - v_next_y / v_next_len;
                    const ptNextShift_y = inNext.y + v_next_x / v_next_len;
                    // scaling factor for v_prev to intersection point
                    const sf = ((ptNextShift_x - ptPrevShift_x) * v_next_y - (ptNextShift_y - ptPrevShift_y) * v_next_x) / (v_prev_x * v_next_y - v_prev_y * v_next_x);
                    // vector from inPt to intersection point
                    v_trans_x = ptPrevShift_x + v_prev_x * sf - inPt.x;
                    v_trans_y = ptPrevShift_y + v_prev_y * sf - inPt.y;
                    // Don't normalize!, otherwise sharp corners become ugly
                    //  but prevent crazy spikes
                    const v_trans_lensq = v_trans_x * v_trans_x + v_trans_y * v_trans_y;
                    if (v_trans_lensq <= 2) return new Vector2(v_trans_x, v_trans_y);
                    else shrink_by = Math.sqrt(v_trans_lensq / 2);
                } else {
                    // handle special case of collinear edges
                    let direction_eq = false; // assumes: opposite
                    if (v_prev_x > Number.EPSILON) {
                        if (v_next_x > Number.EPSILON) direction_eq = true;
                    } else {
                        if (v_prev_x < -Number.EPSILON) {
                            if (v_next_x < -Number.EPSILON) direction_eq = true;
                        } else if (Math.sign(v_prev_y) === Math.sign(v_next_y)) direction_eq = true;
                    }
                    if (direction_eq) {
                        // console.log("Warning: lines are a straight sequence");
                        v_trans_x = -v_prev_y;
                        v_trans_y = v_prev_x;
                        shrink_by = Math.sqrt(v_prev_lensq);
                    } else {
                        // console.log("Warning: lines are a straight spike");
                        v_trans_x = v_prev_x;
                        v_trans_y = v_prev_y;
                        shrink_by = Math.sqrt(v_prev_lensq / 2);
                    }
                }
                return new Vector2(v_trans_x / shrink_by, v_trans_y / shrink_by);
            }
            const contourMovements = [];
            for(let i = 0, il = contour.length, j = il - 1, k = i + 1; i < il; i++, j++, k++){
                if (j === il) j = 0;
                if (k === il) k = 0;
                //  (j)---(i)---(k)
                // console.log('i,j,k', i, j , k)
                contourMovements[i] = getBevelVec(contour[i], contour[j], contour[k]);
            }
            const holesMovements = [];
            let oneHoleMovements, verticesMovements = contourMovements.concat();
            for(let h = 0, hl = holes.length; h < hl; h++){
                const ahole = holes[h];
                oneHoleMovements = [];
                for(let i = 0, il = ahole.length, j = il - 1, k = i + 1; i < il; i++, j++, k++){
                    if (j === il) j = 0;
                    if (k === il) k = 0;
                    //  (j)---(i)---(k)
                    oneHoleMovements[i] = getBevelVec(ahole[i], ahole[j], ahole[k]);
                }
                holesMovements.push(oneHoleMovements);
                verticesMovements = verticesMovements.concat(oneHoleMovements);
            }
            // Loop bevelSegments, 1 for the front, 1 for the back
            for(let b = 0; b < bevelSegments; b++){
                //for ( b = bevelSegments; b > 0; b -- ) {
                const t = b / bevelSegments;
                const z = bevelThickness * Math.cos(t * Math.PI / 2);
                const bs = bevelSize * Math.sin(t * Math.PI / 2) + bevelOffset;
                // contract shape
                for(let i = 0, il = contour.length; i < il; i++){
                    const vert = scalePt2(contour[i], contourMovements[i], bs);
                    v(vert.x, vert.y, -z);
                }
                // expand holes
                for(let h = 0, hl = holes.length; h < hl; h++){
                    const ahole = holes[h];
                    oneHoleMovements = holesMovements[h];
                    for(let i = 0, il = ahole.length; i < il; i++){
                        const vert = scalePt2(ahole[i], oneHoleMovements[i], bs);
                        v(vert.x, vert.y, -z);
                    }
                }
            }
            const bs = bevelSize + bevelOffset;
            // Back facing vertices
            for(let i = 0; i < vlen; i++){
                const vert = bevelEnabled ? scalePt2(vertices[i], verticesMovements[i], bs) : vertices[i];
                if (!extrudeByPath) v(vert.x, vert.y, 0);
                else {
                    // v( vert.x, vert.y + extrudePts[ 0 ].y, extrudePts[ 0 ].x );
                    normal.copy(splineTube.normals[0]).multiplyScalar(vert.x);
                    binormal.copy(splineTube.binormals[0]).multiplyScalar(vert.y);
                    position2.copy(extrudePts[0]).add(normal).add(binormal);
                    v(position2.x, position2.y, position2.z);
                }
            }
            // Add stepped vertices...
            // Including front facing vertices
            for(let s = 1; s <= steps; s++)for(let i = 0; i < vlen; i++){
                const vert = bevelEnabled ? scalePt2(vertices[i], verticesMovements[i], bs) : vertices[i];
                if (!extrudeByPath) v(vert.x, vert.y, depth / steps * s);
                else {
                    // v( vert.x, vert.y + extrudePts[ s - 1 ].y, extrudePts[ s - 1 ].x );
                    normal.copy(splineTube.normals[s]).multiplyScalar(vert.x);
                    binormal.copy(splineTube.binormals[s]).multiplyScalar(vert.y);
                    position2.copy(extrudePts[s]).add(normal).add(binormal);
                    v(position2.x, position2.y, position2.z);
                }
            }
            // Add bevel segments planes
            //for ( b = 1; b <= bevelSegments; b ++ ) {
            for(let b = bevelSegments - 1; b >= 0; b--){
                const t = b / bevelSegments;
                const z = bevelThickness * Math.cos(t * Math.PI / 2);
                const bs = bevelSize * Math.sin(t * Math.PI / 2) + bevelOffset;
                // contract shape
                for(let i = 0, il = contour.length; i < il; i++){
                    const vert = scalePt2(contour[i], contourMovements[i], bs);
                    v(vert.x, vert.y, depth + z);
                }
                // expand holes
                for(let h = 0, hl = holes.length; h < hl; h++){
                    const ahole = holes[h];
                    oneHoleMovements = holesMovements[h];
                    for(let i = 0, il = ahole.length; i < il; i++){
                        const vert = scalePt2(ahole[i], oneHoleMovements[i], bs);
                        if (!extrudeByPath) v(vert.x, vert.y, depth + z);
                        else v(vert.x, vert.y + extrudePts[steps - 1].y, extrudePts[steps - 1].x + z);
                    }
                }
            }
            /* Faces */ // Top and bottom faces
            buildLidFaces();
            // Sides faces
            buildSideFaces();
            /////  Internal functions
            function buildLidFaces() {
                const start = verticesArray.length / 3;
                if (bevelEnabled) {
                    let layer = 0; // steps + 1
                    let offset = vlen * layer;
                    // Bottom faces
                    for(let i = 0; i < flen; i++){
                        const face = faces[i];
                        f3(face[2] + offset, face[1] + offset, face[0] + offset);
                    }
                    layer = steps + bevelSegments * 2;
                    offset = vlen * layer;
                    // Top faces
                    for(let i = 0; i < flen; i++){
                        const face = faces[i];
                        f3(face[0] + offset, face[1] + offset, face[2] + offset);
                    }
                } else {
                    // Bottom faces
                    for(let i = 0; i < flen; i++){
                        const face = faces[i];
                        f3(face[2], face[1], face[0]);
                    }
                    // Top faces
                    for(let i = 0; i < flen; i++){
                        const face = faces[i];
                        f3(face[0] + vlen * steps, face[1] + vlen * steps, face[2] + vlen * steps);
                    }
                }
                scope.addGroup(start, verticesArray.length / 3 - start, 0);
            }
            // Create faces for the z-sides of the shape
            function buildSideFaces() {
                const start = verticesArray.length / 3;
                let layeroffset = 0;
                sidewalls(contour, layeroffset);
                layeroffset += contour.length;
                for(let h = 0, hl = holes.length; h < hl; h++){
                    const ahole = holes[h];
                    sidewalls(ahole, layeroffset);
                    //, true
                    layeroffset += ahole.length;
                }
                scope.addGroup(start, verticesArray.length / 3 - start, 1);
            }
            function sidewalls(contour, layeroffset) {
                let i = contour.length;
                while(--i >= 0){
                    const j = i;
                    let k = i - 1;
                    if (k < 0) k = contour.length - 1;
                    //console.log('b', i,j, i-1, k,vertices.length);
                    for(let s = 0, sl = steps + bevelSegments * 2; s < sl; s++){
                        const slen1 = vlen * s;
                        const slen2 = vlen * (s + 1);
                        const a = layeroffset + j + slen1, b = layeroffset + k + slen1, c = layeroffset + k + slen2, d = layeroffset + j + slen2;
                        f4(a, b, c, d);
                    }
                }
            }
            function v(x, y, z) {
                placeholder.push(x);
                placeholder.push(y);
                placeholder.push(z);
            }
            function f3(a, b, c) {
                addVertex(a);
                addVertex(b);
                addVertex(c);
                const nextIndex = verticesArray.length / 3;
                const uvs = uvgen.generateTopUV(scope, verticesArray, nextIndex - 3, nextIndex - 2, nextIndex - 1);
                addUV(uvs[0]);
                addUV(uvs[1]);
                addUV(uvs[2]);
            }
            function f4(a, b, c, d) {
                addVertex(a);
                addVertex(b);
                addVertex(d);
                addVertex(b);
                addVertex(c);
                addVertex(d);
                const nextIndex = verticesArray.length / 3;
                const uvs = uvgen.generateSideWallUV(scope, verticesArray, nextIndex - 6, nextIndex - 3, nextIndex - 2, nextIndex - 1);
                addUV(uvs[0]);
                addUV(uvs[1]);
                addUV(uvs[3]);
                addUV(uvs[1]);
                addUV(uvs[2]);
                addUV(uvs[3]);
            }
            function addVertex(index) {
                verticesArray.push(placeholder[index * 3 + 0]);
                verticesArray.push(placeholder[index * 3 + 1]);
                verticesArray.push(placeholder[index * 3 + 2]);
            }
            function addUV(vector2) {
                uvArray.push(vector2.x);
                uvArray.push(vector2.y);
            }
        }
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        const shapes = this.parameters.shapes;
        const options = this.parameters.options;
        return toJSON$1(shapes, options, data);
    }
    static fromJSON(data, shapes) {
        const geometryShapes = [];
        for(let j = 0, jl = data.shapes.length; j < jl; j++){
            const shape = shapes[data.shapes[j]];
            geometryShapes.push(shape);
        }
        const extrudePath = data.options.extrudePath;
        if (extrudePath !== undefined) data.options.extrudePath = new Curves[extrudePath.type]().fromJSON(extrudePath);
        return new ExtrudeGeometry(geometryShapes, data.options);
    }
}
const WorldUVGenerator = {
    generateTopUV: function(geometry, vertices, indexA, indexB, indexC) {
        const a_x = vertices[indexA * 3];
        const a_y = vertices[indexA * 3 + 1];
        const b_x = vertices[indexB * 3];
        const b_y = vertices[indexB * 3 + 1];
        const c_x = vertices[indexC * 3];
        const c_y = vertices[indexC * 3 + 1];
        return [
            new Vector2(a_x, a_y),
            new Vector2(b_x, b_y),
            new Vector2(c_x, c_y)
        ];
    },
    generateSideWallUV: function(geometry, vertices, indexA, indexB, indexC, indexD) {
        const a_x = vertices[indexA * 3];
        const a_y = vertices[indexA * 3 + 1];
        const a_z = vertices[indexA * 3 + 2];
        const b_x = vertices[indexB * 3];
        const b_y = vertices[indexB * 3 + 1];
        const b_z = vertices[indexB * 3 + 2];
        const c_x = vertices[indexC * 3];
        const c_y = vertices[indexC * 3 + 1];
        const c_z = vertices[indexC * 3 + 2];
        const d_x = vertices[indexD * 3];
        const d_y = vertices[indexD * 3 + 1];
        const d_z = vertices[indexD * 3 + 2];
        if (Math.abs(a_y - b_y) < Math.abs(a_x - b_x)) return [
            new Vector2(a_x, 1 - a_z),
            new Vector2(b_x, 1 - b_z),
            new Vector2(c_x, 1 - c_z),
            new Vector2(d_x, 1 - d_z)
        ];
        else return [
            new Vector2(a_y, 1 - a_z),
            new Vector2(b_y, 1 - b_z),
            new Vector2(c_y, 1 - c_z),
            new Vector2(d_y, 1 - d_z)
        ];
    }
};
function toJSON$1(shapes, options, data) {
    data.shapes = [];
    if (Array.isArray(shapes)) for(let i = 0, l = shapes.length; i < l; i++){
        const shape = shapes[i];
        data.shapes.push(shape.uuid);
    }
    else data.shapes.push(shapes.uuid);
    data.options = Object.assign({}, options);
    if (options.extrudePath !== undefined) data.options.extrudePath = options.extrudePath.toJSON();
    return data;
}
class IcosahedronGeometry extends PolyhedronGeometry {
    constructor(radius = 1, detail = 0){
        const t = (1 + Math.sqrt(5)) / 2;
        const vertices = [
            -1,
            t,
            0,
            1,
            t,
            0,
            -1,
            -t,
            0,
            1,
            -t,
            0,
            0,
            -1,
            t,
            0,
            1,
            t,
            0,
            -1,
            -t,
            0,
            1,
            -t,
            t,
            0,
            -1,
            t,
            0,
            1,
            -t,
            0,
            -1,
            -t,
            0,
            1
        ];
        const indices = [
            0,
            11,
            5,
            0,
            5,
            1,
            0,
            1,
            7,
            0,
            7,
            10,
            0,
            10,
            11,
            1,
            5,
            9,
            5,
            11,
            4,
            11,
            10,
            2,
            10,
            7,
            6,
            7,
            1,
            8,
            3,
            9,
            4,
            3,
            4,
            2,
            3,
            2,
            6,
            3,
            6,
            8,
            3,
            8,
            9,
            4,
            9,
            5,
            2,
            4,
            11,
            6,
            2,
            10,
            8,
            6,
            7,
            9,
            8,
            1
        ];
        super(vertices, indices, radius, detail);
        this.type = "IcosahedronGeometry";
        this.parameters = {
            radius: radius,
            detail: detail
        };
    }
    static fromJSON(data) {
        return new IcosahedronGeometry(data.radius, data.detail);
    }
}
class OctahedronGeometry extends PolyhedronGeometry {
    constructor(radius = 1, detail = 0){
        const vertices = [
            1,
            0,
            0,
            -1,
            0,
            0,
            0,
            1,
            0,
            0,
            -1,
            0,
            0,
            0,
            1,
            0,
            0,
            -1
        ];
        const indices = [
            0,
            2,
            4,
            0,
            4,
            3,
            0,
            3,
            5,
            0,
            5,
            2,
            1,
            2,
            5,
            1,
            5,
            3,
            1,
            3,
            4,
            1,
            4,
            2
        ];
        super(vertices, indices, radius, detail);
        this.type = "OctahedronGeometry";
        this.parameters = {
            radius: radius,
            detail: detail
        };
    }
    static fromJSON(data) {
        return new OctahedronGeometry(data.radius, data.detail);
    }
}
class RingGeometry extends BufferGeometry {
    constructor(innerRadius = 0.5, outerRadius = 1, thetaSegments = 32, phiSegments = 1, thetaStart = 0, thetaLength = Math.PI * 2){
        super();
        this.type = "RingGeometry";
        this.parameters = {
            innerRadius: innerRadius,
            outerRadius: outerRadius,
            thetaSegments: thetaSegments,
            phiSegments: phiSegments,
            thetaStart: thetaStart,
            thetaLength: thetaLength
        };
        thetaSegments = Math.max(3, thetaSegments);
        phiSegments = Math.max(1, phiSegments);
        // buffers
        const indices = [];
        const vertices = [];
        const normals = [];
        const uvs = [];
        // some helper variables
        let radius = innerRadius;
        const radiusStep = (outerRadius - innerRadius) / phiSegments;
        const vertex = new Vector3();
        const uv = new Vector2();
        // generate vertices, normals and uvs
        for(let j = 0; j <= phiSegments; j++){
            for(let i = 0; i <= thetaSegments; i++){
                // values are generate from the inside of the ring to the outside
                const segment = thetaStart + i / thetaSegments * thetaLength;
                // vertex
                vertex.x = radius * Math.cos(segment);
                vertex.y = radius * Math.sin(segment);
                vertices.push(vertex.x, vertex.y, vertex.z);
                // normal
                normals.push(0, 0, 1);
                // uv
                uv.x = (vertex.x / outerRadius + 1) / 2;
                uv.y = (vertex.y / outerRadius + 1) / 2;
                uvs.push(uv.x, uv.y);
            }
            // increase the radius for next row of vertices
            radius += radiusStep;
        }
        // indices
        for(let j = 0; j < phiSegments; j++){
            const thetaSegmentLevel = j * (thetaSegments + 1);
            for(let i = 0; i < thetaSegments; i++){
                const segment = i + thetaSegmentLevel;
                const a = segment;
                const b = segment + thetaSegments + 1;
                const c = segment + thetaSegments + 2;
                const d = segment + 1;
                // faces
                indices.push(a, b, d);
                indices.push(b, c, d);
            }
        }
        // build geometry
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    static fromJSON(data) {
        return new RingGeometry(data.innerRadius, data.outerRadius, data.thetaSegments, data.phiSegments, data.thetaStart, data.thetaLength);
    }
}
class ShapeGeometry extends BufferGeometry {
    constructor(shapes = new Shape([
        new Vector2(0, 0.5),
        new Vector2(-0.5, -0.5),
        new Vector2(0.5, -0.5)
    ]), curveSegments = 12){
        super();
        this.type = "ShapeGeometry";
        this.parameters = {
            shapes: shapes,
            curveSegments: curveSegments
        };
        // buffers
        const indices = [];
        const vertices = [];
        const normals = [];
        const uvs = [];
        // helper variables
        let groupStart = 0;
        let groupCount = 0;
        // allow single and array values for "shapes" parameter
        if (Array.isArray(shapes) === false) addShape(shapes);
        else for(let i = 0; i < shapes.length; i++){
            addShape(shapes[i]);
            this.addGroup(groupStart, groupCount, i); // enables MultiMaterial support
            groupStart += groupCount;
            groupCount = 0;
        }
        // build geometry
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
        // helper functions
        function addShape(shape) {
            const indexOffset = vertices.length / 3;
            const points = shape.extractPoints(curveSegments);
            let shapeVertices = points.shape;
            const shapeHoles = points.holes;
            // check direction of vertices
            if (ShapeUtils.isClockWise(shapeVertices) === false) shapeVertices = shapeVertices.reverse();
            for(let i = 0, l = shapeHoles.length; i < l; i++){
                const shapeHole = shapeHoles[i];
                if (ShapeUtils.isClockWise(shapeHole) === true) shapeHoles[i] = shapeHole.reverse();
            }
            const faces = ShapeUtils.triangulateShape(shapeVertices, shapeHoles);
            // join vertices of inner and outer paths to a single array
            for(let i = 0, l = shapeHoles.length; i < l; i++){
                const shapeHole = shapeHoles[i];
                shapeVertices = shapeVertices.concat(shapeHole);
            }
            // vertices, normals, uvs
            for(let i = 0, l = shapeVertices.length; i < l; i++){
                const vertex = shapeVertices[i];
                vertices.push(vertex.x, vertex.y, 0);
                normals.push(0, 0, 1);
                uvs.push(vertex.x, vertex.y); // world uvs
            }
            // indices
            for(let i = 0, l = faces.length; i < l; i++){
                const face = faces[i];
                const a = face[0] + indexOffset;
                const b = face[1] + indexOffset;
                const c = face[2] + indexOffset;
                indices.push(a, b, c);
                groupCount += 3;
            }
        }
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        const shapes = this.parameters.shapes;
        return toJSON(shapes, data);
    }
    static fromJSON(data, shapes) {
        const geometryShapes = [];
        for(let j = 0, jl = data.shapes.length; j < jl; j++){
            const shape = shapes[data.shapes[j]];
            geometryShapes.push(shape);
        }
        return new ShapeGeometry(geometryShapes, data.curveSegments);
    }
}
function toJSON(shapes, data) {
    data.shapes = [];
    if (Array.isArray(shapes)) for(let i = 0, l = shapes.length; i < l; i++){
        const shape = shapes[i];
        data.shapes.push(shape.uuid);
    }
    else data.shapes.push(shapes.uuid);
    return data;
}
class SphereGeometry extends BufferGeometry {
    constructor(radius = 1, widthSegments = 32, heightSegments = 16, phiStart = 0, phiLength = Math.PI * 2, thetaStart = 0, thetaLength = Math.PI){
        super();
        this.type = "SphereGeometry";
        this.parameters = {
            radius: radius,
            widthSegments: widthSegments,
            heightSegments: heightSegments,
            phiStart: phiStart,
            phiLength: phiLength,
            thetaStart: thetaStart,
            thetaLength: thetaLength
        };
        widthSegments = Math.max(3, Math.floor(widthSegments));
        heightSegments = Math.max(2, Math.floor(heightSegments));
        const thetaEnd = Math.min(thetaStart + thetaLength, Math.PI);
        let index = 0;
        const grid = [];
        const vertex = new Vector3();
        const normal = new Vector3();
        // buffers
        const indices = [];
        const vertices = [];
        const normals = [];
        const uvs = [];
        // generate vertices, normals and uvs
        for(let iy = 0; iy <= heightSegments; iy++){
            const verticesRow = [];
            const v = iy / heightSegments;
            // special case for the poles
            let uOffset = 0;
            if (iy === 0 && thetaStart === 0) uOffset = 0.5 / widthSegments;
            else if (iy === heightSegments && thetaEnd === Math.PI) uOffset = -0.5 / widthSegments;
            for(let ix = 0; ix <= widthSegments; ix++){
                const u = ix / widthSegments;
                // vertex
                vertex.x = -radius * Math.cos(phiStart + u * phiLength) * Math.sin(thetaStart + v * thetaLength);
                vertex.y = radius * Math.cos(thetaStart + v * thetaLength);
                vertex.z = radius * Math.sin(phiStart + u * phiLength) * Math.sin(thetaStart + v * thetaLength);
                vertices.push(vertex.x, vertex.y, vertex.z);
                // normal
                normal.copy(vertex).normalize();
                normals.push(normal.x, normal.y, normal.z);
                // uv
                uvs.push(u + uOffset, 1 - v);
                verticesRow.push(index++);
            }
            grid.push(verticesRow);
        }
        // indices
        for(let iy = 0; iy < heightSegments; iy++)for(let ix = 0; ix < widthSegments; ix++){
            const a = grid[iy][ix + 1];
            const b = grid[iy][ix];
            const c = grid[iy + 1][ix];
            const d = grid[iy + 1][ix + 1];
            if (iy !== 0 || thetaStart > 0) indices.push(a, b, d);
            if (iy !== heightSegments - 1 || thetaEnd < Math.PI) indices.push(b, c, d);
        }
        // build geometry
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    static fromJSON(data) {
        return new SphereGeometry(data.radius, data.widthSegments, data.heightSegments, data.phiStart, data.phiLength, data.thetaStart, data.thetaLength);
    }
}
class TetrahedronGeometry extends PolyhedronGeometry {
    constructor(radius = 1, detail = 0){
        const vertices = [
            1,
            1,
            1,
            -1,
            -1,
            1,
            -1,
            1,
            -1,
            1,
            -1,
            -1
        ];
        const indices = [
            2,
            1,
            0,
            0,
            3,
            2,
            1,
            3,
            0,
            2,
            3,
            1
        ];
        super(vertices, indices, radius, detail);
        this.type = "TetrahedronGeometry";
        this.parameters = {
            radius: radius,
            detail: detail
        };
    }
    static fromJSON(data) {
        return new TetrahedronGeometry(data.radius, data.detail);
    }
}
class TorusGeometry extends BufferGeometry {
    constructor(radius = 1, tube = 0.4, radialSegments = 12, tubularSegments = 48, arc = Math.PI * 2){
        super();
        this.type = "TorusGeometry";
        this.parameters = {
            radius: radius,
            tube: tube,
            radialSegments: radialSegments,
            tubularSegments: tubularSegments,
            arc: arc
        };
        radialSegments = Math.floor(radialSegments);
        tubularSegments = Math.floor(tubularSegments);
        // buffers
        const indices = [];
        const vertices = [];
        const normals = [];
        const uvs = [];
        // helper variables
        const center = new Vector3();
        const vertex = new Vector3();
        const normal = new Vector3();
        // generate vertices, normals and uvs
        for(let j = 0; j <= radialSegments; j++)for(let i = 0; i <= tubularSegments; i++){
            const u = i / tubularSegments * arc;
            const v = j / radialSegments * Math.PI * 2;
            // vertex
            vertex.x = (radius + tube * Math.cos(v)) * Math.cos(u);
            vertex.y = (radius + tube * Math.cos(v)) * Math.sin(u);
            vertex.z = tube * Math.sin(v);
            vertices.push(vertex.x, vertex.y, vertex.z);
            // normal
            center.x = radius * Math.cos(u);
            center.y = radius * Math.sin(u);
            normal.subVectors(vertex, center).normalize();
            normals.push(normal.x, normal.y, normal.z);
            // uv
            uvs.push(i / tubularSegments);
            uvs.push(j / radialSegments);
        }
        // generate indices
        for(let j = 1; j <= radialSegments; j++)for(let i = 1; i <= tubularSegments; i++){
            // indices
            const a = (tubularSegments + 1) * j + i - 1;
            const b = (tubularSegments + 1) * (j - 1) + i - 1;
            const c = (tubularSegments + 1) * (j - 1) + i;
            const d = (tubularSegments + 1) * j + i;
            // faces
            indices.push(a, b, d);
            indices.push(b, c, d);
        }
        // build geometry
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    static fromJSON(data) {
        return new TorusGeometry(data.radius, data.tube, data.radialSegments, data.tubularSegments, data.arc);
    }
}
class TorusKnotGeometry extends BufferGeometry {
    constructor(radius = 1, tube = 0.4, tubularSegments = 64, radialSegments = 8, p = 2, q = 3){
        super();
        this.type = "TorusKnotGeometry";
        this.parameters = {
            radius: radius,
            tube: tube,
            tubularSegments: tubularSegments,
            radialSegments: radialSegments,
            p: p,
            q: q
        };
        tubularSegments = Math.floor(tubularSegments);
        radialSegments = Math.floor(radialSegments);
        // buffers
        const indices = [];
        const vertices = [];
        const normals = [];
        const uvs = [];
        // helper variables
        const vertex = new Vector3();
        const normal = new Vector3();
        const P1 = new Vector3();
        const P2 = new Vector3();
        const B = new Vector3();
        const T = new Vector3();
        const N = new Vector3();
        // generate vertices, normals and uvs
        for(let i = 0; i <= tubularSegments; ++i){
            // the radian "u" is used to calculate the position on the torus curve of the current tubular segment
            const u = i / tubularSegments * p * Math.PI * 2;
            // now we calculate two points. P1 is our current position on the curve, P2 is a little farther ahead.
            // these points are used to create a special "coordinate space", which is necessary to calculate the correct vertex positions
            calculatePositionOnCurve(u, p, q, radius, P1);
            calculatePositionOnCurve(u + 0.01, p, q, radius, P2);
            // calculate orthonormal basis
            T.subVectors(P2, P1);
            N.addVectors(P2, P1);
            B.crossVectors(T, N);
            N.crossVectors(B, T);
            // normalize B, N. T can be ignored, we don't use it
            B.normalize();
            N.normalize();
            for(let j = 0; j <= radialSegments; ++j){
                // now calculate the vertices. they are nothing more than an extrusion of the torus curve.
                // because we extrude a shape in the xy-plane, there is no need to calculate a z-value.
                const v = j / radialSegments * Math.PI * 2;
                const cx = -tube * Math.cos(v);
                const cy = tube * Math.sin(v);
                // now calculate the final vertex position.
                // first we orient the extrusion with our basis vectors, then we add it to the current position on the curve
                vertex.x = P1.x + (cx * N.x + cy * B.x);
                vertex.y = P1.y + (cx * N.y + cy * B.y);
                vertex.z = P1.z + (cx * N.z + cy * B.z);
                vertices.push(vertex.x, vertex.y, vertex.z);
                // normal (P1 is always the center/origin of the extrusion, thus we can use it to calculate the normal)
                normal.subVectors(vertex, P1).normalize();
                normals.push(normal.x, normal.y, normal.z);
                // uv
                uvs.push(i / tubularSegments);
                uvs.push(j / radialSegments);
            }
        }
        // generate indices
        for(let j = 1; j <= tubularSegments; j++)for(let i = 1; i <= radialSegments; i++){
            // indices
            const a = (radialSegments + 1) * (j - 1) + (i - 1);
            const b = (radialSegments + 1) * j + (i - 1);
            const c = (radialSegments + 1) * j + i;
            const d = (radialSegments + 1) * (j - 1) + i;
            // faces
            indices.push(a, b, d);
            indices.push(b, c, d);
        }
        // build geometry
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
        // this function calculates the current position on the torus curve
        function calculatePositionOnCurve(u, p, q, radius, position) {
            const cu = Math.cos(u);
            const su = Math.sin(u);
            const quOverP = q / p * u;
            const cs = Math.cos(quOverP);
            position.x = radius * (2 + cs) * 0.5 * cu;
            position.y = radius * (2 + cs) * su * 0.5;
            position.z = radius * Math.sin(quOverP) * 0.5;
        }
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    static fromJSON(data) {
        return new TorusKnotGeometry(data.radius, data.tube, data.tubularSegments, data.radialSegments, data.p, data.q);
    }
}
class TubeGeometry extends BufferGeometry {
    constructor(path = new QuadraticBezierCurve3(new Vector3(-1, -1, 0), new Vector3(-1, 1, 0), new Vector3(1, 1, 0)), tubularSegments = 64, radius = 1, radialSegments = 8, closed = false){
        super();
        this.type = "TubeGeometry";
        this.parameters = {
            path: path,
            tubularSegments: tubularSegments,
            radius: radius,
            radialSegments: radialSegments,
            closed: closed
        };
        const frames = path.computeFrenetFrames(tubularSegments, closed);
        // expose internals
        this.tangents = frames.tangents;
        this.normals = frames.normals;
        this.binormals = frames.binormals;
        // helper variables
        const vertex = new Vector3();
        const normal = new Vector3();
        const uv = new Vector2();
        let P = new Vector3();
        // buffer
        const vertices = [];
        const normals = [];
        const uvs = [];
        const indices = [];
        // create buffer data
        generateBufferData();
        // build geometry
        this.setIndex(indices);
        this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        this.setAttribute("normal", new Float32BufferAttribute(normals, 3));
        this.setAttribute("uv", new Float32BufferAttribute(uvs, 2));
        // functions
        function generateBufferData() {
            for(let i = 0; i < tubularSegments; i++)generateSegment(i);
            // if the geometry is not closed, generate the last row of vertices and normals
            // at the regular position on the given path
            //
            // if the geometry is closed, duplicate the first row of vertices and normals (uvs will differ)
            generateSegment(closed === false ? tubularSegments : 0);
            // uvs are generated in a separate function.
            // this makes it easy compute correct values for closed geometries
            generateUVs();
            // finally create faces
            generateIndices();
        }
        function generateSegment(i) {
            // we use getPointAt to sample evenly distributed points from the given path
            P = path.getPointAt(i / tubularSegments, P);
            // retrieve corresponding normal and binormal
            const N = frames.normals[i];
            const B = frames.binormals[i];
            // generate normals and vertices for the current segment
            for(let j = 0; j <= radialSegments; j++){
                const v = j / radialSegments * Math.PI * 2;
                const sin = Math.sin(v);
                const cos = -Math.cos(v);
                // normal
                normal.x = cos * N.x + sin * B.x;
                normal.y = cos * N.y + sin * B.y;
                normal.z = cos * N.z + sin * B.z;
                normal.normalize();
                normals.push(normal.x, normal.y, normal.z);
                // vertex
                vertex.x = P.x + radius * normal.x;
                vertex.y = P.y + radius * normal.y;
                vertex.z = P.z + radius * normal.z;
                vertices.push(vertex.x, vertex.y, vertex.z);
            }
        }
        function generateIndices() {
            for(let j = 1; j <= tubularSegments; j++)for(let i = 1; i <= radialSegments; i++){
                const a = (radialSegments + 1) * (j - 1) + (i - 1);
                const b = (radialSegments + 1) * j + (i - 1);
                const c = (radialSegments + 1) * j + i;
                const d = (radialSegments + 1) * (j - 1) + i;
                // faces
                indices.push(a, b, d);
                indices.push(b, c, d);
            }
        }
        function generateUVs() {
            for(let i = 0; i <= tubularSegments; i++)for(let j = 0; j <= radialSegments; j++){
                uv.x = i / tubularSegments;
                uv.y = j / radialSegments;
                uvs.push(uv.x, uv.y);
            }
        }
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.path = this.parameters.path.toJSON();
        return data;
    }
    static fromJSON(data) {
        // This only works for built-in curves (e.g. CatmullRomCurve3).
        // User defined curves or instances of CurvePath will not be deserialized.
        return new TubeGeometry(new Curves[data.path.type]().fromJSON(data.path), data.tubularSegments, data.radius, data.radialSegments, data.closed);
    }
}
class WireframeGeometry extends BufferGeometry {
    constructor(geometry = null){
        super();
        this.type = "WireframeGeometry";
        this.parameters = {
            geometry: geometry
        };
        if (geometry !== null) {
            // buffer
            const vertices = [];
            const edges = new Set();
            // helper variables
            const start = new Vector3();
            const end = new Vector3();
            if (geometry.index !== null) {
                // indexed BufferGeometry
                const position = geometry.attributes.position;
                const indices = geometry.index;
                let groups = geometry.groups;
                if (groups.length === 0) groups = [
                    {
                        start: 0,
                        count: indices.count,
                        materialIndex: 0
                    }
                ];
                // create a data structure that contains all edges without duplicates
                for(let o = 0, ol = groups.length; o < ol; ++o){
                    const group = groups[o];
                    const groupStart = group.start;
                    const groupCount = group.count;
                    for(let i = groupStart, l = groupStart + groupCount; i < l; i += 3)for(let j = 0; j < 3; j++){
                        const index1 = indices.getX(i + j);
                        const index2 = indices.getX(i + (j + 1) % 3);
                        start.fromBufferAttribute(position, index1);
                        end.fromBufferAttribute(position, index2);
                        if (isUniqueEdge(start, end, edges) === true) {
                            vertices.push(start.x, start.y, start.z);
                            vertices.push(end.x, end.y, end.z);
                        }
                    }
                }
            } else {
                // non-indexed BufferGeometry
                const position = geometry.attributes.position;
                for(let i = 0, l = position.count / 3; i < l; i++)for(let j = 0; j < 3; j++){
                    // three edges per triangle, an edge is represented as (index1, index2)
                    // e.g. the first triangle has the following edges: (0,1),(1,2),(2,0)
                    const index1 = 3 * i + j;
                    const index2 = 3 * i + (j + 1) % 3;
                    start.fromBufferAttribute(position, index1);
                    end.fromBufferAttribute(position, index2);
                    if (isUniqueEdge(start, end, edges) === true) {
                        vertices.push(start.x, start.y, start.z);
                        vertices.push(end.x, end.y, end.z);
                    }
                }
            }
            // build geometry
            this.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        }
    }
    copy(source) {
        super.copy(source);
        this.parameters = Object.assign({}, source.parameters);
        return this;
    }
}
function isUniqueEdge(start, end, edges) {
    const hash1 = `${start.x},${start.y},${start.z}-${end.x},${end.y},${end.z}`;
    const hash2 = `${end.x},${end.y},${end.z}-${start.x},${start.y},${start.z}`; // coincident edge
    if (edges.has(hash1) === true || edges.has(hash2) === true) return false;
    else {
        edges.add(hash1);
        edges.add(hash2);
        return true;
    }
}
var Geometries = /*#__PURE__*/ Object.freeze({
    __proto__: null,
    BoxGeometry: BoxGeometry,
    CapsuleGeometry: CapsuleGeometry,
    CircleGeometry: CircleGeometry,
    ConeGeometry: ConeGeometry,
    CylinderGeometry: CylinderGeometry,
    DodecahedronGeometry: DodecahedronGeometry,
    EdgesGeometry: EdgesGeometry,
    ExtrudeGeometry: ExtrudeGeometry,
    IcosahedronGeometry: IcosahedronGeometry,
    LatheGeometry: LatheGeometry,
    OctahedronGeometry: OctahedronGeometry,
    PlaneGeometry: PlaneGeometry,
    PolyhedronGeometry: PolyhedronGeometry,
    RingGeometry: RingGeometry,
    ShapeGeometry: ShapeGeometry,
    SphereGeometry: SphereGeometry,
    TetrahedronGeometry: TetrahedronGeometry,
    TorusGeometry: TorusGeometry,
    TorusKnotGeometry: TorusKnotGeometry,
    TubeGeometry: TubeGeometry,
    WireframeGeometry: WireframeGeometry
});
class ShadowMaterial extends Material {
    constructor(parameters){
        super();
        this.isShadowMaterial = true;
        this.type = "ShadowMaterial";
        this.color = new Color(0x000000);
        this.transparent = true;
        this.fog = true;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.color.copy(source.color);
        this.fog = source.fog;
        return this;
    }
}
class RawShaderMaterial extends ShaderMaterial {
    constructor(parameters){
        super(parameters);
        this.isRawShaderMaterial = true;
        this.type = "RawShaderMaterial";
    }
}
class MeshStandardMaterial extends Material {
    constructor(parameters){
        super();
        this.isMeshStandardMaterial = true;
        this.defines = {
            "STANDARD": ""
        };
        this.type = "MeshStandardMaterial";
        this.color = new Color(0xffffff); // diffuse
        this.roughness = 1.0;
        this.metalness = 0.0;
        this.map = null;
        this.lightMap = null;
        this.lightMapIntensity = 1.0;
        this.aoMap = null;
        this.aoMapIntensity = 1.0;
        this.emissive = new Color(0x000000);
        this.emissiveIntensity = 1.0;
        this.emissiveMap = null;
        this.bumpMap = null;
        this.bumpScale = 1;
        this.normalMap = null;
        this.normalMapType = TangentSpaceNormalMap;
        this.normalScale = new Vector2(1, 1);
        this.displacementMap = null;
        this.displacementScale = 1;
        this.displacementBias = 0;
        this.roughnessMap = null;
        this.metalnessMap = null;
        this.alphaMap = null;
        this.envMap = null;
        this.envMapRotation = new Euler();
        this.envMapIntensity = 1.0;
        this.wireframe = false;
        this.wireframeLinewidth = 1;
        this.wireframeLinecap = "round";
        this.wireframeLinejoin = "round";
        this.flatShading = false;
        this.fog = true;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.defines = {
            "STANDARD": ""
        };
        this.color.copy(source.color);
        this.roughness = source.roughness;
        this.metalness = source.metalness;
        this.map = source.map;
        this.lightMap = source.lightMap;
        this.lightMapIntensity = source.lightMapIntensity;
        this.aoMap = source.aoMap;
        this.aoMapIntensity = source.aoMapIntensity;
        this.emissive.copy(source.emissive);
        this.emissiveMap = source.emissiveMap;
        this.emissiveIntensity = source.emissiveIntensity;
        this.bumpMap = source.bumpMap;
        this.bumpScale = source.bumpScale;
        this.normalMap = source.normalMap;
        this.normalMapType = source.normalMapType;
        this.normalScale.copy(source.normalScale);
        this.displacementMap = source.displacementMap;
        this.displacementScale = source.displacementScale;
        this.displacementBias = source.displacementBias;
        this.roughnessMap = source.roughnessMap;
        this.metalnessMap = source.metalnessMap;
        this.alphaMap = source.alphaMap;
        this.envMap = source.envMap;
        this.envMapRotation.copy(source.envMapRotation);
        this.envMapIntensity = source.envMapIntensity;
        this.wireframe = source.wireframe;
        this.wireframeLinewidth = source.wireframeLinewidth;
        this.wireframeLinecap = source.wireframeLinecap;
        this.wireframeLinejoin = source.wireframeLinejoin;
        this.flatShading = source.flatShading;
        this.fog = source.fog;
        return this;
    }
}
class MeshPhysicalMaterial extends MeshStandardMaterial {
    constructor(parameters){
        super();
        this.isMeshPhysicalMaterial = true;
        this.defines = {
            "STANDARD": "",
            "PHYSICAL": ""
        };
        this.type = "MeshPhysicalMaterial";
        this.anisotropyRotation = 0;
        this.anisotropyMap = null;
        this.clearcoatMap = null;
        this.clearcoatRoughness = 0.0;
        this.clearcoatRoughnessMap = null;
        this.clearcoatNormalScale = new Vector2(1, 1);
        this.clearcoatNormalMap = null;
        this.ior = 1.5;
        Object.defineProperty(this, "reflectivity", {
            get: function() {
                return clamp(2.5 * (this.ior - 1) / (this.ior + 1), 0, 1);
            },
            set: function(reflectivity) {
                this.ior = (1 + 0.4 * reflectivity) / (1 - 0.4 * reflectivity);
            }
        });
        this.iridescenceMap = null;
        this.iridescenceIOR = 1.3;
        this.iridescenceThicknessRange = [
            100,
            400
        ];
        this.iridescenceThicknessMap = null;
        this.sheenColor = new Color(0x000000);
        this.sheenColorMap = null;
        this.sheenRoughness = 1.0;
        this.sheenRoughnessMap = null;
        this.transmissionMap = null;
        this.thickness = 0;
        this.thicknessMap = null;
        this.attenuationDistance = Infinity;
        this.attenuationColor = new Color(1, 1, 1);
        this.specularIntensity = 1.0;
        this.specularIntensityMap = null;
        this.specularColor = new Color(1, 1, 1);
        this.specularColorMap = null;
        this._anisotropy = 0;
        this._clearcoat = 0;
        this._dispersion = 0;
        this._iridescence = 0;
        this._sheen = 0.0;
        this._transmission = 0;
        this.setValues(parameters);
    }
    get anisotropy() {
        return this._anisotropy;
    }
    set anisotropy(value) {
        if (this._anisotropy > 0 !== value > 0) this.version++;
        this._anisotropy = value;
    }
    get clearcoat() {
        return this._clearcoat;
    }
    set clearcoat(value) {
        if (this._clearcoat > 0 !== value > 0) this.version++;
        this._clearcoat = value;
    }
    get iridescence() {
        return this._iridescence;
    }
    set iridescence(value) {
        if (this._iridescence > 0 !== value > 0) this.version++;
        this._iridescence = value;
    }
    get dispersion() {
        return this._dispersion;
    }
    set dispersion(value) {
        if (this._dispersion > 0 !== value > 0) this.version++;
        this._dispersion = value;
    }
    get sheen() {
        return this._sheen;
    }
    set sheen(value) {
        if (this._sheen > 0 !== value > 0) this.version++;
        this._sheen = value;
    }
    get transmission() {
        return this._transmission;
    }
    set transmission(value) {
        if (this._transmission > 0 !== value > 0) this.version++;
        this._transmission = value;
    }
    copy(source) {
        super.copy(source);
        this.defines = {
            "STANDARD": "",
            "PHYSICAL": ""
        };
        this.anisotropy = source.anisotropy;
        this.anisotropyRotation = source.anisotropyRotation;
        this.anisotropyMap = source.anisotropyMap;
        this.clearcoat = source.clearcoat;
        this.clearcoatMap = source.clearcoatMap;
        this.clearcoatRoughness = source.clearcoatRoughness;
        this.clearcoatRoughnessMap = source.clearcoatRoughnessMap;
        this.clearcoatNormalMap = source.clearcoatNormalMap;
        this.clearcoatNormalScale.copy(source.clearcoatNormalScale);
        this.dispersion = source.dispersion;
        this.ior = source.ior;
        this.iridescence = source.iridescence;
        this.iridescenceMap = source.iridescenceMap;
        this.iridescenceIOR = source.iridescenceIOR;
        this.iridescenceThicknessRange = [
            ...source.iridescenceThicknessRange
        ];
        this.iridescenceThicknessMap = source.iridescenceThicknessMap;
        this.sheen = source.sheen;
        this.sheenColor.copy(source.sheenColor);
        this.sheenColorMap = source.sheenColorMap;
        this.sheenRoughness = source.sheenRoughness;
        this.sheenRoughnessMap = source.sheenRoughnessMap;
        this.transmission = source.transmission;
        this.transmissionMap = source.transmissionMap;
        this.thickness = source.thickness;
        this.thicknessMap = source.thicknessMap;
        this.attenuationDistance = source.attenuationDistance;
        this.attenuationColor.copy(source.attenuationColor);
        this.specularIntensity = source.specularIntensity;
        this.specularIntensityMap = source.specularIntensityMap;
        this.specularColor.copy(source.specularColor);
        this.specularColorMap = source.specularColorMap;
        return this;
    }
}
class MeshPhongMaterial extends Material {
    constructor(parameters){
        super();
        this.isMeshPhongMaterial = true;
        this.type = "MeshPhongMaterial";
        this.color = new Color(0xffffff); // diffuse
        this.specular = new Color(0x111111);
        this.shininess = 30;
        this.map = null;
        this.lightMap = null;
        this.lightMapIntensity = 1.0;
        this.aoMap = null;
        this.aoMapIntensity = 1.0;
        this.emissive = new Color(0x000000);
        this.emissiveIntensity = 1.0;
        this.emissiveMap = null;
        this.bumpMap = null;
        this.bumpScale = 1;
        this.normalMap = null;
        this.normalMapType = TangentSpaceNormalMap;
        this.normalScale = new Vector2(1, 1);
        this.displacementMap = null;
        this.displacementScale = 1;
        this.displacementBias = 0;
        this.specularMap = null;
        this.alphaMap = null;
        this.envMap = null;
        this.envMapRotation = new Euler();
        this.combine = MultiplyOperation;
        this.reflectivity = 1;
        this.refractionRatio = 0.98;
        this.wireframe = false;
        this.wireframeLinewidth = 1;
        this.wireframeLinecap = "round";
        this.wireframeLinejoin = "round";
        this.flatShading = false;
        this.fog = true;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.color.copy(source.color);
        this.specular.copy(source.specular);
        this.shininess = source.shininess;
        this.map = source.map;
        this.lightMap = source.lightMap;
        this.lightMapIntensity = source.lightMapIntensity;
        this.aoMap = source.aoMap;
        this.aoMapIntensity = source.aoMapIntensity;
        this.emissive.copy(source.emissive);
        this.emissiveMap = source.emissiveMap;
        this.emissiveIntensity = source.emissiveIntensity;
        this.bumpMap = source.bumpMap;
        this.bumpScale = source.bumpScale;
        this.normalMap = source.normalMap;
        this.normalMapType = source.normalMapType;
        this.normalScale.copy(source.normalScale);
        this.displacementMap = source.displacementMap;
        this.displacementScale = source.displacementScale;
        this.displacementBias = source.displacementBias;
        this.specularMap = source.specularMap;
        this.alphaMap = source.alphaMap;
        this.envMap = source.envMap;
        this.envMapRotation.copy(source.envMapRotation);
        this.combine = source.combine;
        this.reflectivity = source.reflectivity;
        this.refractionRatio = source.refractionRatio;
        this.wireframe = source.wireframe;
        this.wireframeLinewidth = source.wireframeLinewidth;
        this.wireframeLinecap = source.wireframeLinecap;
        this.wireframeLinejoin = source.wireframeLinejoin;
        this.flatShading = source.flatShading;
        this.fog = source.fog;
        return this;
    }
}
class MeshToonMaterial extends Material {
    constructor(parameters){
        super();
        this.isMeshToonMaterial = true;
        this.defines = {
            "TOON": ""
        };
        this.type = "MeshToonMaterial";
        this.color = new Color(0xffffff);
        this.map = null;
        this.gradientMap = null;
        this.lightMap = null;
        this.lightMapIntensity = 1.0;
        this.aoMap = null;
        this.aoMapIntensity = 1.0;
        this.emissive = new Color(0x000000);
        this.emissiveIntensity = 1.0;
        this.emissiveMap = null;
        this.bumpMap = null;
        this.bumpScale = 1;
        this.normalMap = null;
        this.normalMapType = TangentSpaceNormalMap;
        this.normalScale = new Vector2(1, 1);
        this.displacementMap = null;
        this.displacementScale = 1;
        this.displacementBias = 0;
        this.alphaMap = null;
        this.wireframe = false;
        this.wireframeLinewidth = 1;
        this.wireframeLinecap = "round";
        this.wireframeLinejoin = "round";
        this.fog = true;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.color.copy(source.color);
        this.map = source.map;
        this.gradientMap = source.gradientMap;
        this.lightMap = source.lightMap;
        this.lightMapIntensity = source.lightMapIntensity;
        this.aoMap = source.aoMap;
        this.aoMapIntensity = source.aoMapIntensity;
        this.emissive.copy(source.emissive);
        this.emissiveMap = source.emissiveMap;
        this.emissiveIntensity = source.emissiveIntensity;
        this.bumpMap = source.bumpMap;
        this.bumpScale = source.bumpScale;
        this.normalMap = source.normalMap;
        this.normalMapType = source.normalMapType;
        this.normalScale.copy(source.normalScale);
        this.displacementMap = source.displacementMap;
        this.displacementScale = source.displacementScale;
        this.displacementBias = source.displacementBias;
        this.alphaMap = source.alphaMap;
        this.wireframe = source.wireframe;
        this.wireframeLinewidth = source.wireframeLinewidth;
        this.wireframeLinecap = source.wireframeLinecap;
        this.wireframeLinejoin = source.wireframeLinejoin;
        this.fog = source.fog;
        return this;
    }
}
class MeshNormalMaterial extends Material {
    constructor(parameters){
        super();
        this.isMeshNormalMaterial = true;
        this.type = "MeshNormalMaterial";
        this.bumpMap = null;
        this.bumpScale = 1;
        this.normalMap = null;
        this.normalMapType = TangentSpaceNormalMap;
        this.normalScale = new Vector2(1, 1);
        this.displacementMap = null;
        this.displacementScale = 1;
        this.displacementBias = 0;
        this.wireframe = false;
        this.wireframeLinewidth = 1;
        this.flatShading = false;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.bumpMap = source.bumpMap;
        this.bumpScale = source.bumpScale;
        this.normalMap = source.normalMap;
        this.normalMapType = source.normalMapType;
        this.normalScale.copy(source.normalScale);
        this.displacementMap = source.displacementMap;
        this.displacementScale = source.displacementScale;
        this.displacementBias = source.displacementBias;
        this.wireframe = source.wireframe;
        this.wireframeLinewidth = source.wireframeLinewidth;
        this.flatShading = source.flatShading;
        return this;
    }
}
class MeshLambertMaterial extends Material {
    constructor(parameters){
        super();
        this.isMeshLambertMaterial = true;
        this.type = "MeshLambertMaterial";
        this.color = new Color(0xffffff); // diffuse
        this.map = null;
        this.lightMap = null;
        this.lightMapIntensity = 1.0;
        this.aoMap = null;
        this.aoMapIntensity = 1.0;
        this.emissive = new Color(0x000000);
        this.emissiveIntensity = 1.0;
        this.emissiveMap = null;
        this.bumpMap = null;
        this.bumpScale = 1;
        this.normalMap = null;
        this.normalMapType = TangentSpaceNormalMap;
        this.normalScale = new Vector2(1, 1);
        this.displacementMap = null;
        this.displacementScale = 1;
        this.displacementBias = 0;
        this.specularMap = null;
        this.alphaMap = null;
        this.envMap = null;
        this.envMapRotation = new Euler();
        this.combine = MultiplyOperation;
        this.reflectivity = 1;
        this.refractionRatio = 0.98;
        this.wireframe = false;
        this.wireframeLinewidth = 1;
        this.wireframeLinecap = "round";
        this.wireframeLinejoin = "round";
        this.flatShading = false;
        this.fog = true;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.color.copy(source.color);
        this.map = source.map;
        this.lightMap = source.lightMap;
        this.lightMapIntensity = source.lightMapIntensity;
        this.aoMap = source.aoMap;
        this.aoMapIntensity = source.aoMapIntensity;
        this.emissive.copy(source.emissive);
        this.emissiveMap = source.emissiveMap;
        this.emissiveIntensity = source.emissiveIntensity;
        this.bumpMap = source.bumpMap;
        this.bumpScale = source.bumpScale;
        this.normalMap = source.normalMap;
        this.normalMapType = source.normalMapType;
        this.normalScale.copy(source.normalScale);
        this.displacementMap = source.displacementMap;
        this.displacementScale = source.displacementScale;
        this.displacementBias = source.displacementBias;
        this.specularMap = source.specularMap;
        this.alphaMap = source.alphaMap;
        this.envMap = source.envMap;
        this.envMapRotation.copy(source.envMapRotation);
        this.combine = source.combine;
        this.reflectivity = source.reflectivity;
        this.refractionRatio = source.refractionRatio;
        this.wireframe = source.wireframe;
        this.wireframeLinewidth = source.wireframeLinewidth;
        this.wireframeLinecap = source.wireframeLinecap;
        this.wireframeLinejoin = source.wireframeLinejoin;
        this.flatShading = source.flatShading;
        this.fog = source.fog;
        return this;
    }
}
class MeshMatcapMaterial extends Material {
    constructor(parameters){
        super();
        this.isMeshMatcapMaterial = true;
        this.defines = {
            "MATCAP": ""
        };
        this.type = "MeshMatcapMaterial";
        this.color = new Color(0xffffff); // diffuse
        this.matcap = null;
        this.map = null;
        this.bumpMap = null;
        this.bumpScale = 1;
        this.normalMap = null;
        this.normalMapType = TangentSpaceNormalMap;
        this.normalScale = new Vector2(1, 1);
        this.displacementMap = null;
        this.displacementScale = 1;
        this.displacementBias = 0;
        this.alphaMap = null;
        this.flatShading = false;
        this.fog = true;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.defines = {
            "MATCAP": ""
        };
        this.color.copy(source.color);
        this.matcap = source.matcap;
        this.map = source.map;
        this.bumpMap = source.bumpMap;
        this.bumpScale = source.bumpScale;
        this.normalMap = source.normalMap;
        this.normalMapType = source.normalMapType;
        this.normalScale.copy(source.normalScale);
        this.displacementMap = source.displacementMap;
        this.displacementScale = source.displacementScale;
        this.displacementBias = source.displacementBias;
        this.alphaMap = source.alphaMap;
        this.flatShading = source.flatShading;
        this.fog = source.fog;
        return this;
    }
}
class LineDashedMaterial extends LineBasicMaterial {
    constructor(parameters){
        super();
        this.isLineDashedMaterial = true;
        this.type = "LineDashedMaterial";
        this.scale = 1;
        this.dashSize = 3;
        this.gapSize = 1;
        this.setValues(parameters);
    }
    copy(source) {
        super.copy(source);
        this.scale = source.scale;
        this.dashSize = source.dashSize;
        this.gapSize = source.gapSize;
        return this;
    }
}
// converts an array to a specific type
function convertArray(array, type, forceClone) {
    if (!array || // let 'undefined' and 'null' pass
    !forceClone && array.constructor === type) return array;
    if (typeof type.BYTES_PER_ELEMENT === "number") return new type(array); // create typed array
    return Array.prototype.slice.call(array); // create Array
}
function isTypedArray(object) {
    return ArrayBuffer.isView(object) && !(object instanceof DataView);
}
// returns an array by which times and values can be sorted
function getKeyframeOrder(times) {
    function compareTime(i, j) {
        return times[i] - times[j];
    }
    const n = times.length;
    const result = new Array(n);
    for(let i = 0; i !== n; ++i)result[i] = i;
    result.sort(compareTime);
    return result;
}
// uses the array previously returned by 'getKeyframeOrder' to sort data
function sortedArray(values, stride, order) {
    const nValues = values.length;
    const result = new values.constructor(nValues);
    for(let i = 0, dstOffset = 0; dstOffset !== nValues; ++i){
        const srcOffset = order[i] * stride;
        for(let j = 0; j !== stride; ++j)result[dstOffset++] = values[srcOffset + j];
    }
    return result;
}
// function for parsing AOS keyframe formats
function flattenJSON(jsonKeys, times, values, valuePropertyName) {
    let i = 1, key = jsonKeys[0];
    while(key !== undefined && key[valuePropertyName] === undefined)key = jsonKeys[i++];
    if (key === undefined) return; // no data
    let value = key[valuePropertyName];
    if (value === undefined) return; // no data
    if (Array.isArray(value)) do {
        value = key[valuePropertyName];
        if (value !== undefined) {
            times.push(key.time);
            values.push.apply(values, value); // push all elements
        }
        key = jsonKeys[i++];
    }while (key !== undefined);
    else if (value.toArray !== undefined) // ...assume THREE.Math-ish
    do {
        value = key[valuePropertyName];
        if (value !== undefined) {
            times.push(key.time);
            value.toArray(values, values.length);
        }
        key = jsonKeys[i++];
    }while (key !== undefined);
    else // otherwise push as-is
    do {
        value = key[valuePropertyName];
        if (value !== undefined) {
            times.push(key.time);
            values.push(value);
        }
        key = jsonKeys[i++];
    }while (key !== undefined);
}
function subclip(sourceClip, name, startFrame, endFrame, fps = 30) {
    const clip = sourceClip.clone();
    clip.name = name;
    const tracks = [];
    for(let i = 0; i < clip.tracks.length; ++i){
        const track = clip.tracks[i];
        const valueSize = track.getValueSize();
        const times = [];
        const values = [];
        for(let j = 0; j < track.times.length; ++j){
            const frame = track.times[j] * fps;
            if (frame < startFrame || frame >= endFrame) continue;
            times.push(track.times[j]);
            for(let k = 0; k < valueSize; ++k)values.push(track.values[j * valueSize + k]);
        }
        if (times.length === 0) continue;
        track.times = convertArray(times, track.times.constructor);
        track.values = convertArray(values, track.values.constructor);
        tracks.push(track);
    }
    clip.tracks = tracks;
    // find minimum .times value across all tracks in the trimmed clip
    let minStartTime = Infinity;
    for(let i = 0; i < clip.tracks.length; ++i)if (minStartTime > clip.tracks[i].times[0]) minStartTime = clip.tracks[i].times[0];
    // shift all tracks such that clip begins at t=0
    for(let i = 0; i < clip.tracks.length; ++i)clip.tracks[i].shift(-1 * minStartTime);
    clip.resetDuration();
    return clip;
}
function makeClipAdditive(targetClip, referenceFrame = 0, referenceClip = targetClip, fps = 30) {
    if (fps <= 0) fps = 30;
    const numTracks = referenceClip.tracks.length;
    const referenceTime = referenceFrame / fps;
    // Make each track's values relative to the values at the reference frame
    for(let i = 0; i < numTracks; ++i){
        const referenceTrack = referenceClip.tracks[i];
        const referenceTrackType = referenceTrack.ValueTypeName;
        // Skip this track if it's non-numeric
        if (referenceTrackType === "bool" || referenceTrackType === "string") continue;
        // Find the track in the target clip whose name and type matches the reference track
        const targetTrack = targetClip.tracks.find(function(track) {
            return track.name === referenceTrack.name && track.ValueTypeName === referenceTrackType;
        });
        if (targetTrack === undefined) continue;
        let referenceOffset = 0;
        const referenceValueSize = referenceTrack.getValueSize();
        if (referenceTrack.createInterpolant.isInterpolantFactoryMethodGLTFCubicSpline) referenceOffset = referenceValueSize / 3;
        let targetOffset = 0;
        const targetValueSize = targetTrack.getValueSize();
        if (targetTrack.createInterpolant.isInterpolantFactoryMethodGLTFCubicSpline) targetOffset = targetValueSize / 3;
        const lastIndex = referenceTrack.times.length - 1;
        let referenceValue;
        // Find the value to subtract out of the track
        if (referenceTime <= referenceTrack.times[0]) {
            // Reference frame is earlier than the first keyframe, so just use the first keyframe
            const startIndex = referenceOffset;
            const endIndex = referenceValueSize - referenceOffset;
            referenceValue = referenceTrack.values.slice(startIndex, endIndex);
        } else if (referenceTime >= referenceTrack.times[lastIndex]) {
            // Reference frame is after the last keyframe, so just use the last keyframe
            const startIndex = lastIndex * referenceValueSize + referenceOffset;
            const endIndex = startIndex + referenceValueSize - referenceOffset;
            referenceValue = referenceTrack.values.slice(startIndex, endIndex);
        } else {
            // Interpolate to the reference value
            const interpolant = referenceTrack.createInterpolant();
            const startIndex = referenceOffset;
            const endIndex = referenceValueSize - referenceOffset;
            interpolant.evaluate(referenceTime);
            referenceValue = interpolant.resultBuffer.slice(startIndex, endIndex);
        }
        // Conjugate the quaternion
        if (referenceTrackType === "quaternion") {
            const referenceQuat = new Quaternion().fromArray(referenceValue).normalize().conjugate();
            referenceQuat.toArray(referenceValue);
        }
        // Subtract the reference value from all of the track values
        const numTimes = targetTrack.times.length;
        for(let j = 0; j < numTimes; ++j){
            const valueStart = j * targetValueSize + targetOffset;
            if (referenceTrackType === "quaternion") // Multiply the conjugate for quaternion track types
            Quaternion.multiplyQuaternionsFlat(targetTrack.values, valueStart, referenceValue, 0, targetTrack.values, valueStart);
            else {
                const valueEnd = targetValueSize - targetOffset * 2;
                // Subtract each value for all other numeric track types
                for(let k = 0; k < valueEnd; ++k)targetTrack.values[valueStart + k] -= referenceValue[k];
            }
        }
    }
    targetClip.blendMode = AdditiveAnimationBlendMode;
    return targetClip;
}
const AnimationUtils = {
    convertArray: convertArray,
    isTypedArray: isTypedArray,
    getKeyframeOrder: getKeyframeOrder,
    sortedArray: sortedArray,
    flattenJSON: flattenJSON,
    subclip: subclip,
    makeClipAdditive: makeClipAdditive
};
/**
 * Abstract base class of interpolants over parametric samples.
 *
 * The parameter domain is one dimensional, typically the time or a path
 * along a curve defined by the data.
 *
 * The sample values can have any dimensionality and derived classes may
 * apply special interpretations to the data.
 *
 * This class provides the interval seek in a Template Method, deferring
 * the actual interpolation to derived classes.
 *
 * Time complexity is O(1) for linear access crossing at most two points
 * and O(log N) for random access, where N is the number of positions.
 *
 * References:
 *
 * 		http://www.oodesign.com/template-method-pattern.html
 *
 */ class Interpolant {
    constructor(parameterPositions, sampleValues, sampleSize, resultBuffer){
        this.parameterPositions = parameterPositions;
        this._cachedIndex = 0;
        this.resultBuffer = resultBuffer !== undefined ? resultBuffer : new sampleValues.constructor(sampleSize);
        this.sampleValues = sampleValues;
        this.valueSize = sampleSize;
        this.settings = null;
        this.DefaultSettings_ = {};
    }
    evaluate(t) {
        const pp = this.parameterPositions;
        let i1 = this._cachedIndex, t1 = pp[i1], t0 = pp[i1 - 1];
        validate_interval: {
            seek: {
                let right;
                linear_scan: {
                    //- See http://jsperf.com/comparison-to-undefined/3
                    //- slower code:
                    //-
                    //- 				if ( t >= t1 || t1 === undefined ) {
                    forward_scan: if (!(t < t1)) {
                        for(let giveUpAt = i1 + 2;;){
                            if (t1 === undefined) {
                                if (t < t0) break forward_scan;
                                // after end
                                i1 = pp.length;
                                this._cachedIndex = i1;
                                return this.copySampleValue_(i1 - 1);
                            }
                            if (i1 === giveUpAt) break; // this loop
                            t0 = t1;
                            t1 = pp[++i1];
                            if (t < t1) break seek;
                        }
                        // prepare binary search on the right side of the index
                        right = pp.length;
                        break linear_scan;
                    }
                    //- slower code:
                    //-					if ( t < t0 || t0 === undefined ) {
                    if (!(t >= t0)) {
                        // looping?
                        const t1global = pp[1];
                        if (t < t1global) {
                            i1 = 2; // + 1, using the scan for the details
                            t0 = t1global;
                        }
                        // linear reverse scan
                        for(let giveUpAt = i1 - 2;;){
                            if (t0 === undefined) {
                                // before start
                                this._cachedIndex = 0;
                                return this.copySampleValue_(0);
                            }
                            if (i1 === giveUpAt) break; // this loop
                            t1 = t0;
                            t0 = pp[--i1 - 1];
                            if (t >= t0) break seek;
                        }
                        // prepare binary search on the left side of the index
                        right = i1;
                        i1 = 0;
                        break linear_scan;
                    }
                    break validate_interval;
                } // linear scan
                // binary search
                while(i1 < right){
                    const mid = i1 + right >>> 1;
                    if (t < pp[mid]) right = mid;
                    else i1 = mid + 1;
                }
                t1 = pp[i1];
                t0 = pp[i1 - 1];
                // check boundary cases, again
                if (t0 === undefined) {
                    this._cachedIndex = 0;
                    return this.copySampleValue_(0);
                }
                if (t1 === undefined) {
                    i1 = pp.length;
                    this._cachedIndex = i1;
                    return this.copySampleValue_(i1 - 1);
                }
            } // seek
            this._cachedIndex = i1;
            this.intervalChanged_(i1, t0, t1);
        } // validate_interval
        return this.interpolate_(i1, t0, t, t1);
    }
    getSettings_() {
        return this.settings || this.DefaultSettings_;
    }
    copySampleValue_(index) {
        // copies a sample value to the result buffer
        const result = this.resultBuffer, values = this.sampleValues, stride = this.valueSize, offset = index * stride;
        for(let i = 0; i !== stride; ++i)result[i] = values[offset + i];
        return result;
    }
    // Template methods for derived classes:
    interpolate_() {
        throw new Error("call to abstract method");
    // implementations shall return this.resultBuffer
    }
    intervalChanged_() {
    // empty
    }
}
/**
 * Fast and simple cubic spline interpolant.
 *
 * It was derived from a Hermitian construction setting the first derivative
 * at each sample position to the linear slope between neighboring positions
 * over their parameter interval.
 */ class CubicInterpolant extends Interpolant {
    constructor(parameterPositions, sampleValues, sampleSize, resultBuffer){
        super(parameterPositions, sampleValues, sampleSize, resultBuffer);
        this._weightPrev = -0;
        this._offsetPrev = -0;
        this._weightNext = -0;
        this._offsetNext = -0;
        this.DefaultSettings_ = {
            endingStart: ZeroCurvatureEnding,
            endingEnd: ZeroCurvatureEnding
        };
    }
    intervalChanged_(i1, t0, t1) {
        const pp = this.parameterPositions;
        let iPrev = i1 - 2, iNext = i1 + 1, tPrev = pp[iPrev], tNext = pp[iNext];
        if (tPrev === undefined) switch(this.getSettings_().endingStart){
            case ZeroSlopeEnding:
                // f'(t0) = 0
                iPrev = i1;
                tPrev = 2 * t0 - t1;
                break;
            case WrapAroundEnding:
                // use the other end of the curve
                iPrev = pp.length - 2;
                tPrev = t0 + pp[iPrev] - pp[iPrev + 1];
                break;
            default:
                // f''(t0) = 0 a.k.a. Natural Spline
                iPrev = i1;
                tPrev = t1;
        }
        if (tNext === undefined) switch(this.getSettings_().endingEnd){
            case ZeroSlopeEnding:
                // f'(tN) = 0
                iNext = i1;
                tNext = 2 * t1 - t0;
                break;
            case WrapAroundEnding:
                // use the other end of the curve
                iNext = 1;
                tNext = t1 + pp[1] - pp[0];
                break;
            default:
                // f''(tN) = 0, a.k.a. Natural Spline
                iNext = i1 - 1;
                tNext = t0;
        }
        const halfDt = (t1 - t0) * 0.5, stride = this.valueSize;
        this._weightPrev = halfDt / (t0 - tPrev);
        this._weightNext = halfDt / (tNext - t1);
        this._offsetPrev = iPrev * stride;
        this._offsetNext = iNext * stride;
    }
    interpolate_(i1, t0, t, t1) {
        const result = this.resultBuffer, values = this.sampleValues, stride = this.valueSize, o1 = i1 * stride, o0 = o1 - stride, oP = this._offsetPrev, oN = this._offsetNext, wP = this._weightPrev, wN = this._weightNext, p = (t - t0) / (t1 - t0), pp = p * p, ppp = pp * p;
        // evaluate polynomials
        const sP = -wP * ppp + 2 * wP * pp - wP * p;
        const s0 = (1 + wP) * ppp + (-1.5 - 2 * wP) * pp + (-0.5 + wP) * p + 1;
        const s1 = (-1 - wN) * ppp + (1.5 + wN) * pp + 0.5 * p;
        const sN = wN * ppp - wN * pp;
        // combine data linearly
        for(let i = 0; i !== stride; ++i)result[i] = sP * values[oP + i] + s0 * values[o0 + i] + s1 * values[o1 + i] + sN * values[oN + i];
        return result;
    }
}
class LinearInterpolant extends Interpolant {
    constructor(parameterPositions, sampleValues, sampleSize, resultBuffer){
        super(parameterPositions, sampleValues, sampleSize, resultBuffer);
    }
    interpolate_(i1, t0, t, t1) {
        const result = this.resultBuffer, values = this.sampleValues, stride = this.valueSize, offset1 = i1 * stride, offset0 = offset1 - stride, weight1 = (t - t0) / (t1 - t0), weight0 = 1 - weight1;
        for(let i = 0; i !== stride; ++i)result[i] = values[offset0 + i] * weight0 + values[offset1 + i] * weight1;
        return result;
    }
}
/**
 *
 * Interpolant that evaluates to the sample value at the position preceding
 * the parameter.
 */ class DiscreteInterpolant extends Interpolant {
    constructor(parameterPositions, sampleValues, sampleSize, resultBuffer){
        super(parameterPositions, sampleValues, sampleSize, resultBuffer);
    }
    interpolate_(i1 /*, t0, t, t1 */ ) {
        return this.copySampleValue_(i1 - 1);
    }
}
class KeyframeTrack {
    constructor(name, times, values, interpolation){
        if (name === undefined) throw new Error("THREE.KeyframeTrack: track name is undefined");
        if (times === undefined || times.length === 0) throw new Error("THREE.KeyframeTrack: no keyframes in track named " + name);
        this.name = name;
        this.times = convertArray(times, this.TimeBufferType);
        this.values = convertArray(values, this.ValueBufferType);
        this.setInterpolation(interpolation || this.DefaultInterpolation);
    }
    // Serialization (in static context, because of constructor invocation
    // and automatic invocation of .toJSON):
    static toJSON(track) {
        const trackType = track.constructor;
        let json;
        // derived classes can define a static toJSON method
        if (trackType.toJSON !== this.toJSON) json = trackType.toJSON(track);
        else {
            // by default, we assume the data can be serialized as-is
            json = {
                "name": track.name,
                "times": convertArray(track.times, Array),
                "values": convertArray(track.values, Array)
            };
            const interpolation = track.getInterpolation();
            if (interpolation !== track.DefaultInterpolation) json.interpolation = interpolation;
        }
        json.type = track.ValueTypeName; // mandatory
        return json;
    }
    InterpolantFactoryMethodDiscrete(result) {
        return new DiscreteInterpolant(this.times, this.values, this.getValueSize(), result);
    }
    InterpolantFactoryMethodLinear(result) {
        return new LinearInterpolant(this.times, this.values, this.getValueSize(), result);
    }
    InterpolantFactoryMethodSmooth(result) {
        return new CubicInterpolant(this.times, this.values, this.getValueSize(), result);
    }
    setInterpolation(interpolation) {
        let factoryMethod;
        switch(interpolation){
            case InterpolateDiscrete:
                factoryMethod = this.InterpolantFactoryMethodDiscrete;
                break;
            case InterpolateLinear:
                factoryMethod = this.InterpolantFactoryMethodLinear;
                break;
            case InterpolateSmooth:
                factoryMethod = this.InterpolantFactoryMethodSmooth;
                break;
        }
        if (factoryMethod === undefined) {
            const message = "unsupported interpolation for " + this.ValueTypeName + " keyframe track named " + this.name;
            if (this.createInterpolant === undefined) {
                // fall back to default, unless the default itself is messed up
                if (interpolation !== this.DefaultInterpolation) this.setInterpolation(this.DefaultInterpolation);
                else throw new Error(message); // fatal, in this case
            }
            console.warn("THREE.KeyframeTrack:", message);
            return this;
        }
        this.createInterpolant = factoryMethod;
        return this;
    }
    getInterpolation() {
        switch(this.createInterpolant){
            case this.InterpolantFactoryMethodDiscrete:
                return InterpolateDiscrete;
            case this.InterpolantFactoryMethodLinear:
                return InterpolateLinear;
            case this.InterpolantFactoryMethodSmooth:
                return InterpolateSmooth;
        }
    }
    getValueSize() {
        return this.values.length / this.times.length;
    }
    // move all keyframes either forwards or backwards in time
    shift(timeOffset) {
        if (timeOffset !== 0.0) {
            const times = this.times;
            for(let i = 0, n = times.length; i !== n; ++i)times[i] += timeOffset;
        }
        return this;
    }
    // scale all keyframe times by a factor (useful for frame <-> seconds conversions)
    scale(timeScale) {
        if (timeScale !== 1.0) {
            const times = this.times;
            for(let i = 0, n = times.length; i !== n; ++i)times[i] *= timeScale;
        }
        return this;
    }
    // removes keyframes before and after animation without changing any values within the range [startTime, endTime].
    // IMPORTANT: We do not shift around keys to the start of the track time, because for interpolated keys this will change their values
    trim(startTime, endTime) {
        const times = this.times, nKeys = times.length;
        let from = 0, to = nKeys - 1;
        while(from !== nKeys && times[from] < startTime)++from;
        while(to !== -1 && times[to] > endTime)--to;
        ++to; // inclusive -> exclusive bound
        if (from !== 0 || to !== nKeys) {
            // empty tracks are forbidden, so keep at least one keyframe
            if (from >= to) {
                to = Math.max(to, 1);
                from = to - 1;
            }
            const stride = this.getValueSize();
            this.times = times.slice(from, to);
            this.values = this.values.slice(from * stride, to * stride);
        }
        return this;
    }
    // ensure we do not get a GarbageInGarbageOut situation, make sure tracks are at least minimally viable
    validate() {
        let valid = true;
        const valueSize = this.getValueSize();
        if (valueSize - Math.floor(valueSize) !== 0) {
            console.error("THREE.KeyframeTrack: Invalid value size in track.", this);
            valid = false;
        }
        const times = this.times, values = this.values, nKeys = times.length;
        if (nKeys === 0) {
            console.error("THREE.KeyframeTrack: Track is empty.", this);
            valid = false;
        }
        let prevTime = null;
        for(let i = 0; i !== nKeys; i++){
            const currTime = times[i];
            if (typeof currTime === "number" && isNaN(currTime)) {
                console.error("THREE.KeyframeTrack: Time is not a valid number.", this, i, currTime);
                valid = false;
                break;
            }
            if (prevTime !== null && prevTime > currTime) {
                console.error("THREE.KeyframeTrack: Out of order keys.", this, i, currTime, prevTime);
                valid = false;
                break;
            }
            prevTime = currTime;
        }
        if (values !== undefined) {
            if (isTypedArray(values)) for(let i = 0, n = values.length; i !== n; ++i){
                const value = values[i];
                if (isNaN(value)) {
                    console.error("THREE.KeyframeTrack: Value is not a valid number.", this, i, value);
                    valid = false;
                    break;
                }
            }
        }
        return valid;
    }
    // removes equivalent sequential keys as common in morph target sequences
    // (0,0,0,0,1,1,1,0,0,0,0,0,0,0) --> (0,0,1,1,0,0)
    optimize() {
        // times or values may be shared with other tracks, so overwriting is unsafe
        const times = this.times.slice(), values = this.values.slice(), stride = this.getValueSize(), smoothInterpolation = this.getInterpolation() === InterpolateSmooth, lastIndex = times.length - 1;
        let writeIndex = 1;
        for(let i = 1; i < lastIndex; ++i){
            let keep = false;
            const time = times[i];
            const timeNext = times[i + 1];
            // remove adjacent keyframes scheduled at the same time
            if (time !== timeNext && (i !== 1 || time !== times[0])) {
                if (!smoothInterpolation) {
                    // remove unnecessary keyframes same as their neighbors
                    const offset = i * stride, offsetP = offset - stride, offsetN = offset + stride;
                    for(let j = 0; j !== stride; ++j){
                        const value = values[offset + j];
                        if (value !== values[offsetP + j] || value !== values[offsetN + j]) {
                            keep = true;
                            break;
                        }
                    }
                } else keep = true;
            }
            // in-place compaction
            if (keep) {
                if (i !== writeIndex) {
                    times[writeIndex] = times[i];
                    const readOffset = i * stride, writeOffset = writeIndex * stride;
                    for(let j = 0; j !== stride; ++j)values[writeOffset + j] = values[readOffset + j];
                }
                ++writeIndex;
            }
        }
        // flush last keyframe (compaction looks ahead)
        if (lastIndex > 0) {
            times[writeIndex] = times[lastIndex];
            for(let readOffset = lastIndex * stride, writeOffset = writeIndex * stride, j = 0; j !== stride; ++j)values[writeOffset + j] = values[readOffset + j];
            ++writeIndex;
        }
        if (writeIndex !== times.length) {
            this.times = times.slice(0, writeIndex);
            this.values = values.slice(0, writeIndex * stride);
        } else {
            this.times = times;
            this.values = values;
        }
        return this;
    }
    clone() {
        const times = this.times.slice();
        const values = this.values.slice();
        const TypedKeyframeTrack = this.constructor;
        const track = new TypedKeyframeTrack(this.name, times, values);
        // Interpolant argument to constructor is not saved, so copy the factory method directly.
        track.createInterpolant = this.createInterpolant;
        return track;
    }
}
KeyframeTrack.prototype.TimeBufferType = Float32Array;
KeyframeTrack.prototype.ValueBufferType = Float32Array;
KeyframeTrack.prototype.DefaultInterpolation = InterpolateLinear;
/**
 * A Track of Boolean keyframe values.
 */ class BooleanKeyframeTrack extends KeyframeTrack {
    // No interpolation parameter because only InterpolateDiscrete is valid.
    constructor(name, times, values){
        super(name, times, values);
    }
}
BooleanKeyframeTrack.prototype.ValueTypeName = "bool";
BooleanKeyframeTrack.prototype.ValueBufferType = Array;
BooleanKeyframeTrack.prototype.DefaultInterpolation = InterpolateDiscrete;
BooleanKeyframeTrack.prototype.InterpolantFactoryMethodLinear = undefined;
BooleanKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;
/**
 * A Track of keyframe values that represent color.
 */ class ColorKeyframeTrack extends KeyframeTrack {
}
ColorKeyframeTrack.prototype.ValueTypeName = "color";
/**
 * A Track of numeric keyframe values.
 */ class NumberKeyframeTrack extends KeyframeTrack {
}
NumberKeyframeTrack.prototype.ValueTypeName = "number";
/**
 * Spherical linear unit quaternion interpolant.
 */ class QuaternionLinearInterpolant extends Interpolant {
    constructor(parameterPositions, sampleValues, sampleSize, resultBuffer){
        super(parameterPositions, sampleValues, sampleSize, resultBuffer);
    }
    interpolate_(i1, t0, t, t1) {
        const result = this.resultBuffer, values = this.sampleValues, stride = this.valueSize, alpha = (t - t0) / (t1 - t0);
        let offset = i1 * stride;
        for(let end = offset + stride; offset !== end; offset += 4)Quaternion.slerpFlat(result, 0, values, offset - stride, values, offset, alpha);
        return result;
    }
}
/**
 * A Track of quaternion keyframe values.
 */ class QuaternionKeyframeTrack extends KeyframeTrack {
    InterpolantFactoryMethodLinear(result) {
        return new QuaternionLinearInterpolant(this.times, this.values, this.getValueSize(), result);
    }
}
QuaternionKeyframeTrack.prototype.ValueTypeName = "quaternion";
// ValueBufferType is inherited
// DefaultInterpolation is inherited;
QuaternionKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;
/**
 * A Track that interpolates Strings
 */ class StringKeyframeTrack extends KeyframeTrack {
    // No interpolation parameter because only InterpolateDiscrete is valid.
    constructor(name, times, values){
        super(name, times, values);
    }
}
StringKeyframeTrack.prototype.ValueTypeName = "string";
StringKeyframeTrack.prototype.ValueBufferType = Array;
StringKeyframeTrack.prototype.DefaultInterpolation = InterpolateDiscrete;
StringKeyframeTrack.prototype.InterpolantFactoryMethodLinear = undefined;
StringKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;
/**
 * A Track of vectored keyframe values.
 */ class VectorKeyframeTrack extends KeyframeTrack {
}
VectorKeyframeTrack.prototype.ValueTypeName = "vector";
class AnimationClip {
    constructor(name = "", duration = -1, tracks = [], blendMode = NormalAnimationBlendMode){
        this.name = name;
        this.tracks = tracks;
        this.duration = duration;
        this.blendMode = blendMode;
        this.uuid = generateUUID();
        // this means it should figure out its duration by scanning the tracks
        if (this.duration < 0) this.resetDuration();
    }
    static parse(json) {
        const tracks = [], jsonTracks = json.tracks, frameTime = 1.0 / (json.fps || 1.0);
        for(let i = 0, n = jsonTracks.length; i !== n; ++i)tracks.push(parseKeyframeTrack(jsonTracks[i]).scale(frameTime));
        const clip = new this(json.name, json.duration, tracks, json.blendMode);
        clip.uuid = json.uuid;
        return clip;
    }
    static toJSON(clip) {
        const tracks = [], clipTracks = clip.tracks;
        const json = {
            "name": clip.name,
            "duration": clip.duration,
            "tracks": tracks,
            "uuid": clip.uuid,
            "blendMode": clip.blendMode
        };
        for(let i = 0, n = clipTracks.length; i !== n; ++i)tracks.push(KeyframeTrack.toJSON(clipTracks[i]));
        return json;
    }
    static CreateFromMorphTargetSequence(name, morphTargetSequence, fps, noLoop) {
        const numMorphTargets = morphTargetSequence.length;
        const tracks = [];
        for(let i = 0; i < numMorphTargets; i++){
            let times = [];
            let values = [];
            times.push((i + numMorphTargets - 1) % numMorphTargets, i, (i + 1) % numMorphTargets);
            values.push(0, 1, 0);
            const order = getKeyframeOrder(times);
            times = sortedArray(times, 1, order);
            values = sortedArray(values, 1, order);
            // if there is a key at the first frame, duplicate it as the
            // last frame as well for perfect loop.
            if (!noLoop && times[0] === 0) {
                times.push(numMorphTargets);
                values.push(values[0]);
            }
            tracks.push(new NumberKeyframeTrack(".morphTargetInfluences[" + morphTargetSequence[i].name + "]", times, values).scale(1.0 / fps));
        }
        return new this(name, -1, tracks);
    }
    static findByName(objectOrClipArray, name) {
        let clipArray = objectOrClipArray;
        if (!Array.isArray(objectOrClipArray)) {
            const o = objectOrClipArray;
            clipArray = o.geometry && o.geometry.animations || o.animations;
        }
        for(let i = 0; i < clipArray.length; i++){
            if (clipArray[i].name === name) return clipArray[i];
        }
        return null;
    }
    static CreateClipsFromMorphTargetSequences(morphTargets, fps, noLoop) {
        const animationToMorphTargets = {};
        // tested with https://regex101.com/ on trick sequences
        // such flamingo_flyA_003, flamingo_run1_003, crdeath0059
        const pattern = /^([\w-]*?)([\d]+)$/;
        // sort morph target names into animation groups based
        // patterns like Walk_001, Walk_002, Run_001, Run_002
        for(let i = 0, il = morphTargets.length; i < il; i++){
            const morphTarget = morphTargets[i];
            const parts = morphTarget.name.match(pattern);
            if (parts && parts.length > 1) {
                const name = parts[1];
                let animationMorphTargets = animationToMorphTargets[name];
                if (!animationMorphTargets) animationToMorphTargets[name] = animationMorphTargets = [];
                animationMorphTargets.push(morphTarget);
            }
        }
        const clips = [];
        for(const name in animationToMorphTargets)clips.push(this.CreateFromMorphTargetSequence(name, animationToMorphTargets[name], fps, noLoop));
        return clips;
    }
    // parse the animation.hierarchy format
    static parseAnimation(animation, bones) {
        if (!animation) {
            console.error("THREE.AnimationClip: No animation in JSONLoader data.");
            return null;
        }
        const addNonemptyTrack = function(trackType, trackName, animationKeys, propertyName, destTracks) {
            // only return track if there are actually keys.
            if (animationKeys.length !== 0) {
                const times = [];
                const values = [];
                flattenJSON(animationKeys, times, values, propertyName);
                // empty keys are filtered out, so check again
                if (times.length !== 0) destTracks.push(new trackType(trackName, times, values));
            }
        };
        const tracks = [];
        const clipName = animation.name || "default";
        const fps = animation.fps || 30;
        const blendMode = animation.blendMode;
        // automatic length determination in AnimationClip.
        let duration = animation.length || -1;
        const hierarchyTracks = animation.hierarchy || [];
        for(let h = 0; h < hierarchyTracks.length; h++){
            const animationKeys = hierarchyTracks[h].keys;
            // skip empty tracks
            if (!animationKeys || animationKeys.length === 0) continue;
            // process morph targets
            if (animationKeys[0].morphTargets) {
                // figure out all morph targets used in this track
                const morphTargetNames = {};
                let k;
                for(k = 0; k < animationKeys.length; k++){
                    if (animationKeys[k].morphTargets) for(let m = 0; m < animationKeys[k].morphTargets.length; m++)morphTargetNames[animationKeys[k].morphTargets[m]] = -1;
                }
                // create a track for each morph target with all zero
                // morphTargetInfluences except for the keys in which
                // the morphTarget is named.
                for(const morphTargetName in morphTargetNames){
                    const times = [];
                    const values = [];
                    for(let m = 0; m !== animationKeys[k].morphTargets.length; ++m){
                        const animationKey = animationKeys[k];
                        times.push(animationKey.time);
                        values.push(animationKey.morphTarget === morphTargetName ? 1 : 0);
                    }
                    tracks.push(new NumberKeyframeTrack(".morphTargetInfluence[" + morphTargetName + "]", times, values));
                }
                duration = morphTargetNames.length * fps;
            } else {
                // ...assume skeletal animation
                const boneName = ".bones[" + bones[h].name + "]";
                addNonemptyTrack(VectorKeyframeTrack, boneName + ".position", animationKeys, "pos", tracks);
                addNonemptyTrack(QuaternionKeyframeTrack, boneName + ".quaternion", animationKeys, "rot", tracks);
                addNonemptyTrack(VectorKeyframeTrack, boneName + ".scale", animationKeys, "scl", tracks);
            }
        }
        if (tracks.length === 0) return null;
        const clip = new this(clipName, duration, tracks, blendMode);
        return clip;
    }
    resetDuration() {
        const tracks = this.tracks;
        let duration = 0;
        for(let i = 0, n = tracks.length; i !== n; ++i){
            const track = this.tracks[i];
            duration = Math.max(duration, track.times[track.times.length - 1]);
        }
        this.duration = duration;
        return this;
    }
    trim() {
        for(let i = 0; i < this.tracks.length; i++)this.tracks[i].trim(0, this.duration);
        return this;
    }
    validate() {
        let valid = true;
        for(let i = 0; i < this.tracks.length; i++)valid = valid && this.tracks[i].validate();
        return valid;
    }
    optimize() {
        for(let i = 0; i < this.tracks.length; i++)this.tracks[i].optimize();
        return this;
    }
    clone() {
        const tracks = [];
        for(let i = 0; i < this.tracks.length; i++)tracks.push(this.tracks[i].clone());
        return new this.constructor(this.name, this.duration, tracks, this.blendMode);
    }
    toJSON() {
        return this.constructor.toJSON(this);
    }
}
function getTrackTypeForValueTypeName(typeName) {
    switch(typeName.toLowerCase()){
        case "scalar":
        case "double":
        case "float":
        case "number":
        case "integer":
            return NumberKeyframeTrack;
        case "vector":
        case "vector2":
        case "vector3":
        case "vector4":
            return VectorKeyframeTrack;
        case "color":
            return ColorKeyframeTrack;
        case "quaternion":
            return QuaternionKeyframeTrack;
        case "bool":
        case "boolean":
            return BooleanKeyframeTrack;
        case "string":
            return StringKeyframeTrack;
    }
    throw new Error("THREE.KeyframeTrack: Unsupported typeName: " + typeName);
}
function parseKeyframeTrack(json) {
    if (json.type === undefined) throw new Error("THREE.KeyframeTrack: track type undefined, can not parse");
    const trackType = getTrackTypeForValueTypeName(json.type);
    if (json.times === undefined) {
        const times = [], values = [];
        flattenJSON(json.keys, times, values, "value");
        json.times = times;
        json.values = values;
    }
    // derived classes can define a static parse method
    if (trackType.parse !== undefined) return trackType.parse(json);
    else // by default, we assume a constructor compatible with the base
    return new trackType(json.name, json.times, json.values, json.interpolation);
}
const Cache = {
    enabled: false,
    files: {},
    add: function(key, file) {
        if (this.enabled === false) return;
        // console.log( 'THREE.Cache', 'Adding key:', key );
        this.files[key] = file;
    },
    get: function(key) {
        if (this.enabled === false) return;
        // console.log( 'THREE.Cache', 'Checking key:', key );
        return this.files[key];
    },
    remove: function(key) {
        delete this.files[key];
    },
    clear: function() {
        this.files = {};
    }
};
class LoadingManager {
    constructor(onLoad, onProgress, onError){
        const scope = this;
        let isLoading = false;
        let itemsLoaded = 0;
        let itemsTotal = 0;
        let urlModifier = undefined;
        const handlers = [];
        // Refer to #5689 for the reason why we don't set .onStart
        // in the constructor
        this.onStart = undefined;
        this.onLoad = onLoad;
        this.onProgress = onProgress;
        this.onError = onError;
        this.itemStart = function(url) {
            itemsTotal++;
            if (isLoading === false) {
                if (scope.onStart !== undefined) scope.onStart(url, itemsLoaded, itemsTotal);
            }
            isLoading = true;
        };
        this.itemEnd = function(url) {
            itemsLoaded++;
            if (scope.onProgress !== undefined) scope.onProgress(url, itemsLoaded, itemsTotal);
            if (itemsLoaded === itemsTotal) {
                isLoading = false;
                if (scope.onLoad !== undefined) scope.onLoad();
            }
        };
        this.itemError = function(url) {
            if (scope.onError !== undefined) scope.onError(url);
        };
        this.resolveURL = function(url) {
            if (urlModifier) return urlModifier(url);
            return url;
        };
        this.setURLModifier = function(transform) {
            urlModifier = transform;
            return this;
        };
        this.addHandler = function(regex, loader) {
            handlers.push(regex, loader);
            return this;
        };
        this.removeHandler = function(regex) {
            const index = handlers.indexOf(regex);
            if (index !== -1) handlers.splice(index, 2);
            return this;
        };
        this.getHandler = function(file) {
            for(let i = 0, l = handlers.length; i < l; i += 2){
                const regex = handlers[i];
                const loader = handlers[i + 1];
                if (regex.global) regex.lastIndex = 0; // see #17920
                if (regex.test(file)) return loader;
            }
            return null;
        };
    }
}
const DefaultLoadingManager = /*@__PURE__*/ new LoadingManager();
class Loader {
    constructor(manager){
        this.manager = manager !== undefined ? manager : DefaultLoadingManager;
        this.crossOrigin = "anonymous";
        this.withCredentials = false;
        this.path = "";
        this.resourcePath = "";
        this.requestHeader = {};
    }
    load() {}
    loadAsync(url, onProgress) {
        const scope = this;
        return new Promise(function(resolve, reject) {
            scope.load(url, resolve, onProgress, reject);
        });
    }
    parse() {}
    setCrossOrigin(crossOrigin) {
        this.crossOrigin = crossOrigin;
        return this;
    }
    setWithCredentials(value) {
        this.withCredentials = value;
        return this;
    }
    setPath(path) {
        this.path = path;
        return this;
    }
    setResourcePath(resourcePath) {
        this.resourcePath = resourcePath;
        return this;
    }
    setRequestHeader(requestHeader) {
        this.requestHeader = requestHeader;
        return this;
    }
}
Loader.DEFAULT_MATERIAL_NAME = "__DEFAULT";
const loading = {};
class HttpError extends Error {
    constructor(message, response){
        super(message);
        this.response = response;
    }
}
class FileLoader extends Loader {
    constructor(manager){
        super(manager);
    }
    load(url, onLoad, onProgress, onError) {
        if (url === undefined) url = "";
        if (this.path !== undefined) url = this.path + url;
        url = this.manager.resolveURL(url);
        const cached = Cache.get(url);
        if (cached !== undefined) {
            this.manager.itemStart(url);
            setTimeout(()=>{
                if (onLoad) onLoad(cached);
                this.manager.itemEnd(url);
            }, 0);
            return cached;
        }
        // Check if request is duplicate
        if (loading[url] !== undefined) {
            loading[url].push({
                onLoad: onLoad,
                onProgress: onProgress,
                onError: onError
            });
            return;
        }
        // Initialise array for duplicate requests
        loading[url] = [];
        loading[url].push({
            onLoad: onLoad,
            onProgress: onProgress,
            onError: onError
        });
        // create request
        const req = new Request(url, {
            headers: new Headers(this.requestHeader),
            credentials: this.withCredentials ? "include" : "same-origin"
        });
        // record states ( avoid data race )
        const mimeType = this.mimeType;
        const responseType = this.responseType;
        // start the fetch
        fetch(req).then((response)=>{
            if (response.status === 200 || response.status === 0) {
                // Some browsers return HTTP Status 0 when using non-http protocol
                // e.g. 'file://' or 'data://'. Handle as success.
                if (response.status === 0) console.warn("THREE.FileLoader: HTTP Status 0 received.");
                // Workaround: Checking if response.body === undefined for Alipay browser #23548
                if (typeof ReadableStream === "undefined" || response.body === undefined || response.body.getReader === undefined) return response;
                const callbacks = loading[url];
                const reader = response.body.getReader();
                // Nginx needs X-File-Size check
                // https://serverfault.com/questions/482875/why-does-nginx-remove-content-length-header-for-chunked-content
                const contentLength = response.headers.get("X-File-Size") || response.headers.get("Content-Length");
                const total = contentLength ? parseInt(contentLength) : 0;
                const lengthComputable = total !== 0;
                let loaded = 0;
                // periodically read data into the new stream tracking while download progress
                const stream = new ReadableStream({
                    start (controller) {
                        readData();
                        function readData() {
                            reader.read().then(({ done, value })=>{
                                if (done) controller.close();
                                else {
                                    loaded += value.byteLength;
                                    const event = new ProgressEvent("progress", {
                                        lengthComputable,
                                        loaded,
                                        total
                                    });
                                    for(let i = 0, il = callbacks.length; i < il; i++){
                                        const callback = callbacks[i];
                                        if (callback.onProgress) callback.onProgress(event);
                                    }
                                    controller.enqueue(value);
                                    readData();
                                }
                            }, (e)=>{
                                controller.error(e);
                            });
                        }
                    }
                });
                return new Response(stream);
            } else throw new HttpError(`fetch for "${response.url}" responded with ${response.status}: ${response.statusText}`, response);
        }).then((response)=>{
            switch(responseType){
                case "arraybuffer":
                    return response.arrayBuffer();
                case "blob":
                    return response.blob();
                case "document":
                    return response.text().then((text)=>{
                        const parser = new DOMParser();
                        return parser.parseFromString(text, mimeType);
                    });
                case "json":
                    return response.json();
                default:
                    if (mimeType === undefined) return response.text();
                    else {
                        // sniff encoding
                        const re = /charset="?([^;"\s]*)"?/i;
                        const exec = re.exec(mimeType);
                        const label = exec && exec[1] ? exec[1].toLowerCase() : undefined;
                        const decoder = new TextDecoder(label);
                        return response.arrayBuffer().then((ab)=>decoder.decode(ab));
                    }
            }
        }).then((data)=>{
            // Add to cache only on HTTP success, so that we do not cache
            // error response bodies as proper responses to requests.
            Cache.add(url, data);
            const callbacks = loading[url];
            delete loading[url];
            for(let i = 0, il = callbacks.length; i < il; i++){
                const callback = callbacks[i];
                if (callback.onLoad) callback.onLoad(data);
            }
        }).catch((err)=>{
            // Abort errors and other errors are handled the same
            const callbacks = loading[url];
            if (callbacks === undefined) {
                // When onLoad was called and url was deleted in `loading`
                this.manager.itemError(url);
                throw err;
            }
            delete loading[url];
            for(let i = 0, il = callbacks.length; i < il; i++){
                const callback = callbacks[i];
                if (callback.onError) callback.onError(err);
            }
            this.manager.itemError(url);
        }).finally(()=>{
            this.manager.itemEnd(url);
        });
        this.manager.itemStart(url);
    }
    setResponseType(value) {
        this.responseType = value;
        return this;
    }
    setMimeType(value) {
        this.mimeType = value;
        return this;
    }
}
class AnimationLoader extends Loader {
    constructor(manager){
        super(manager);
    }
    load(url, onLoad, onProgress, onError) {
        const scope = this;
        const loader = new FileLoader(this.manager);
        loader.setPath(this.path);
        loader.setRequestHeader(this.requestHeader);
        loader.setWithCredentials(this.withCredentials);
        loader.load(url, function(text) {
            try {
                onLoad(scope.parse(JSON.parse(text)));
            } catch (e) {
                if (onError) onError(e);
                else console.error(e);
                scope.manager.itemError(url);
            }
        }, onProgress, onError);
    }
    parse(json) {
        const animations = [];
        for(let i = 0; i < json.length; i++){
            const clip = AnimationClip.parse(json[i]);
            animations.push(clip);
        }
        return animations;
    }
}
/**
 * Abstract Base class to block based textures loader (dds, pvr, ...)
 *
 * Sub classes have to implement the parse() method which will be used in load().
 */ class CompressedTextureLoader extends Loader {
    constructor(manager){
        super(manager);
    }
    load(url, onLoad, onProgress, onError) {
        const scope = this;
        const images = [];
        const texture = new CompressedTexture();
        const loader = new FileLoader(this.manager);
        loader.setPath(this.path);
        loader.setResponseType("arraybuffer");
        loader.setRequestHeader(this.requestHeader);
        loader.setWithCredentials(scope.withCredentials);
        let loaded = 0;
        function loadTexture(i) {
            loader.load(url[i], function(buffer) {
                const texDatas = scope.parse(buffer, true);
                images[i] = {
                    width: texDatas.width,
                    height: texDatas.height,
                    format: texDatas.format,
                    mipmaps: texDatas.mipmaps
                };
                loaded += 1;
                if (loaded === 6) {
                    if (texDatas.mipmapCount === 1) texture.minFilter = LinearFilter;
                    texture.image = images;
                    texture.format = texDatas.format;
                    texture.needsUpdate = true;
                    if (onLoad) onLoad(texture);
                }
            }, onProgress, onError);
        }
        if (Array.isArray(url)) for(let i = 0, il = url.length; i < il; ++i)loadTexture(i);
        else // compressed cubemap texture stored in a single DDS file
        loader.load(url, function(buffer) {
            const texDatas = scope.parse(buffer, true);
            if (texDatas.isCubemap) {
                const faces = texDatas.mipmaps.length / texDatas.mipmapCount;
                for(let f = 0; f < faces; f++){
                    images[f] = {
                        mipmaps: []
                    };
                    for(let i = 0; i < texDatas.mipmapCount; i++){
                        images[f].mipmaps.push(texDatas.mipmaps[f * texDatas.mipmapCount + i]);
                        images[f].format = texDatas.format;
                        images[f].width = texDatas.width;
                        images[f].height = texDatas.height;
                    }
                }
                texture.image = images;
            } else {
                texture.image.width = texDatas.width;
                texture.image.height = texDatas.height;
                texture.mipmaps = texDatas.mipmaps;
            }
            if (texDatas.mipmapCount === 1) texture.minFilter = LinearFilter;
            texture.format = texDatas.format;
            texture.needsUpdate = true;
            if (onLoad) onLoad(texture);
        }, onProgress, onError);
        return texture;
    }
}
class ImageLoader extends Loader {
    constructor(manager){
        super(manager);
    }
    load(url, onLoad, onProgress, onError) {
        if (this.path !== undefined) url = this.path + url;
        url = this.manager.resolveURL(url);
        const scope = this;
        const cached = Cache.get(url);
        if (cached !== undefined) {
            scope.manager.itemStart(url);
            setTimeout(function() {
                if (onLoad) onLoad(cached);
                scope.manager.itemEnd(url);
            }, 0);
            return cached;
        }
        const image = createElementNS("img");
        function onImageLoad() {
            removeEventListeners();
            Cache.add(url, this);
            if (onLoad) onLoad(this);
            scope.manager.itemEnd(url);
        }
        function onImageError(event) {
            removeEventListeners();
            if (onError) onError(event);
            scope.manager.itemError(url);
            scope.manager.itemEnd(url);
        }
        function removeEventListeners() {
            image.removeEventListener("load", onImageLoad, false);
            image.removeEventListener("error", onImageError, false);
        }
        image.addEventListener("load", onImageLoad, false);
        image.addEventListener("error", onImageError, false);
        if (url.slice(0, 5) !== "data:") {
            if (this.crossOrigin !== undefined) image.crossOrigin = this.crossOrigin;
        }
        scope.manager.itemStart(url);
        image.src = url;
        return image;
    }
}
class CubeTextureLoader extends Loader {
    constructor(manager){
        super(manager);
    }
    load(urls, onLoad, onProgress, onError) {
        const texture = new CubeTexture();
        texture.colorSpace = SRGBColorSpace;
        const loader = new ImageLoader(this.manager);
        loader.setCrossOrigin(this.crossOrigin);
        loader.setPath(this.path);
        let loaded = 0;
        function loadTexture(i) {
            loader.load(urls[i], function(image) {
                texture.images[i] = image;
                loaded++;
                if (loaded === 6) {
                    texture.needsUpdate = true;
                    if (onLoad) onLoad(texture);
                }
            }, undefined, onError);
        }
        for(let i = 0; i < urls.length; ++i)loadTexture(i);
        return texture;
    }
}
/**
 * Abstract Base class to load generic binary textures formats (rgbe, hdr, ...)
 *
 * Sub classes have to implement the parse() method which will be used in load().
 */ class DataTextureLoader extends Loader {
    constructor(manager){
        super(manager);
    }
    load(url, onLoad, onProgress, onError) {
        const scope = this;
        const texture = new DataTexture();
        const loader = new FileLoader(this.manager);
        loader.setResponseType("arraybuffer");
        loader.setRequestHeader(this.requestHeader);
        loader.setPath(this.path);
        loader.setWithCredentials(scope.withCredentials);
        loader.load(url, function(buffer) {
            let texData;
            try {
                texData = scope.parse(buffer);
            } catch (error) {
                if (onError !== undefined) onError(error);
                else {
                    console.error(error);
                    return;
                }
            }
            if (texData.image !== undefined) texture.image = texData.image;
            else if (texData.data !== undefined) {
                texture.image.width = texData.width;
                texture.image.height = texData.height;
                texture.image.data = texData.data;
            }
            texture.wrapS = texData.wrapS !== undefined ? texData.wrapS : ClampToEdgeWrapping;
            texture.wrapT = texData.wrapT !== undefined ? texData.wrapT : ClampToEdgeWrapping;
            texture.magFilter = texData.magFilter !== undefined ? texData.magFilter : LinearFilter;
            texture.minFilter = texData.minFilter !== undefined ? texData.minFilter : LinearFilter;
            texture.anisotropy = texData.anisotropy !== undefined ? texData.anisotropy : 1;
            if (texData.colorSpace !== undefined) texture.colorSpace = texData.colorSpace;
            if (texData.flipY !== undefined) texture.flipY = texData.flipY;
            if (texData.format !== undefined) texture.format = texData.format;
            if (texData.type !== undefined) texture.type = texData.type;
            if (texData.mipmaps !== undefined) {
                texture.mipmaps = texData.mipmaps;
                texture.minFilter = LinearMipmapLinearFilter; // presumably...
            }
            if (texData.mipmapCount === 1) texture.minFilter = LinearFilter;
            if (texData.generateMipmaps !== undefined) texture.generateMipmaps = texData.generateMipmaps;
            texture.needsUpdate = true;
            if (onLoad) onLoad(texture, texData);
        }, onProgress, onError);
        return texture;
    }
}
class TextureLoader extends Loader {
    constructor(manager){
        super(manager);
    }
    load(url, onLoad, onProgress, onError) {
        const texture = new Texture();
        const loader = new ImageLoader(this.manager);
        loader.setCrossOrigin(this.crossOrigin);
        loader.setPath(this.path);
        loader.load(url, function(image) {
            texture.image = image;
            texture.needsUpdate = true;
            if (onLoad !== undefined) onLoad(texture);
        }, onProgress, onError);
        return texture;
    }
}
class Light extends Object3D {
    constructor(color, intensity = 1){
        super();
        this.isLight = true;
        this.type = "Light";
        this.color = new Color(color);
        this.intensity = intensity;
    }
    dispose() {
    // Empty here in base class; some subclasses override.
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.color.copy(source.color);
        this.intensity = source.intensity;
        return this;
    }
    toJSON(meta) {
        const data = super.toJSON(meta);
        data.object.color = this.color.getHex();
        data.object.intensity = this.intensity;
        if (this.groundColor !== undefined) data.object.groundColor = this.groundColor.getHex();
        if (this.distance !== undefined) data.object.distance = this.distance;
        if (this.angle !== undefined) data.object.angle = this.angle;
        if (this.decay !== undefined) data.object.decay = this.decay;
        if (this.penumbra !== undefined) data.object.penumbra = this.penumbra;
        if (this.shadow !== undefined) data.object.shadow = this.shadow.toJSON();
        if (this.target !== undefined) data.object.target = this.target.uuid;
        return data;
    }
}
class HemisphereLight extends Light {
    constructor(skyColor, groundColor, intensity){
        super(skyColor, intensity);
        this.isHemisphereLight = true;
        this.type = "HemisphereLight";
        this.position.copy(Object3D.DEFAULT_UP);
        this.updateMatrix();
        this.groundColor = new Color(groundColor);
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.groundColor.copy(source.groundColor);
        return this;
    }
}
const _projScreenMatrix$1 = /*@__PURE__*/ new Matrix4();
const _lightPositionWorld$1 = /*@__PURE__*/ new Vector3();
const _lookTarget$1 = /*@__PURE__*/ new Vector3();
class LightShadow {
    constructor(camera){
        this.camera = camera;
        this.intensity = 1;
        this.bias = 0;
        this.normalBias = 0;
        this.radius = 1;
        this.blurSamples = 8;
        this.mapSize = new Vector2(512, 512);
        this.map = null;
        this.mapPass = null;
        this.matrix = new Matrix4();
        this.autoUpdate = true;
        this.needsUpdate = false;
        this._frustum = new Frustum();
        this._frameExtents = new Vector2(1, 1);
        this._viewportCount = 1;
        this._viewports = [
            new Vector4(0, 0, 1, 1)
        ];
    }
    getViewportCount() {
        return this._viewportCount;
    }
    getFrustum() {
        return this._frustum;
    }
    updateMatrices(light) {
        const shadowCamera = this.camera;
        const shadowMatrix = this.matrix;
        _lightPositionWorld$1.setFromMatrixPosition(light.matrixWorld);
        shadowCamera.position.copy(_lightPositionWorld$1);
        _lookTarget$1.setFromMatrixPosition(light.target.matrixWorld);
        shadowCamera.lookAt(_lookTarget$1);
        shadowCamera.updateMatrixWorld();
        _projScreenMatrix$1.multiplyMatrices(shadowCamera.projectionMatrix, shadowCamera.matrixWorldInverse);
        this._frustum.setFromProjectionMatrix(_projScreenMatrix$1);
        shadowMatrix.set(0.5, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 1.0);
        shadowMatrix.multiply(_projScreenMatrix$1);
    }
    getViewport(viewportIndex) {
        return this._viewports[viewportIndex];
    }
    getFrameExtents() {
        return this._frameExtents;
    }
    dispose() {
        if (this.map) this.map.dispose();
        if (this.mapPass) this.mapPass.dispose();
    }
    copy(source) {
        this.camera = source.camera.clone();
        this.intensity = source.intensity;
        this.bias = source.bias;
        this.radius = source.radius;
        this.mapSize.copy(source.mapSize);
        return this;
    }
    clone() {
        return new this.constructor().copy(this);
    }
    toJSON() {
        const object = {};
        if (this.intensity !== 1) object.intensity = this.intensity;
        if (this.bias !== 0) object.bias = this.bias;
        if (this.normalBias !== 0) object.normalBias = this.normalBias;
        if (this.radius !== 1) object.radius = this.radius;
        if (this.mapSize.x !== 512 || this.mapSize.y !== 512) object.mapSize = this.mapSize.toArray();
        object.camera = this.camera.toJSON(false).object;
        delete object.camera.matrix;
        return object;
    }
}
class SpotLightShadow extends LightShadow {
    constructor(){
        super(new PerspectiveCamera(50, 1, 0.5, 500));
        this.isSpotLightShadow = true;
        this.focus = 1;
    }
    updateMatrices(light) {
        const camera = this.camera;
        const fov = RAD2DEG * 2 * light.angle * this.focus;
        const aspect = this.mapSize.width / this.mapSize.height;
        const far = light.distance || camera.far;
        if (fov !== camera.fov || aspect !== camera.aspect || far !== camera.far) {
            camera.fov = fov;
            camera.aspect = aspect;
            camera.far = far;
            camera.updateProjectionMatrix();
        }
        super.updateMatrices(light);
    }
    copy(source) {
        super.copy(source);
        this.focus = source.focus;
        return this;
    }
}
class SpotLight extends Light {
    constructor(color, intensity, distance = 0, angle = Math.PI / 3, penumbra = 0, decay = 2){
        super(color, intensity);
        this.isSpotLight = true;
        this.type = "SpotLight";
        this.position.copy(Object3D.DEFAULT_UP);
        this.updateMatrix();
        this.target = new Object3D();
        this.distance = distance;
        this.angle = angle;
        this.penumbra = penumbra;
        this.decay = decay;
        this.map = null;
        this.shadow = new SpotLightShadow();
    }
    get power() {
        // compute the light's luminous power (in lumens) from its intensity (in candela)
        // by convention for a spotlight, luminous power (lm) =  * luminous intensity (cd)
        return this.intensity * Math.PI;
    }
    set power(power) {
        // set the light's intensity (in candela) from the desired luminous power (in lumens)
        this.intensity = power / Math.PI;
    }
    dispose() {
        this.shadow.dispose();
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.distance = source.distance;
        this.angle = source.angle;
        this.penumbra = source.penumbra;
        this.decay = source.decay;
        this.target = source.target.clone();
        this.shadow = source.shadow.clone();
        return this;
    }
}
const _projScreenMatrix = /*@__PURE__*/ new Matrix4();
const _lightPositionWorld = /*@__PURE__*/ new Vector3();
const _lookTarget = /*@__PURE__*/ new Vector3();
class PointLightShadow extends LightShadow {
    constructor(){
        super(new PerspectiveCamera(90, 1, 0.5, 500));
        this.isPointLightShadow = true;
        this._frameExtents = new Vector2(4, 2);
        this._viewportCount = 6;
        this._viewports = [
            // These viewports map a cube-map onto a 2D texture with the
            // following orientation:
            //
            //  xzXZ
            //   y Y
            //
            // X - Positive x direction
            // x - Negative x direction
            // Y - Positive y direction
            // y - Negative y direction
            // Z - Positive z direction
            // z - Negative z direction
            // positive X
            new Vector4(2, 1, 1, 1),
            // negative X
            new Vector4(0, 1, 1, 1),
            // positive Z
            new Vector4(3, 1, 1, 1),
            // negative Z
            new Vector4(1, 1, 1, 1),
            // positive Y
            new Vector4(3, 0, 1, 1),
            // negative Y
            new Vector4(1, 0, 1, 1)
        ];
        this._cubeDirections = [
            new Vector3(1, 0, 0),
            new Vector3(-1, 0, 0),
            new Vector3(0, 0, 1),
            new Vector3(0, 0, -1),
            new Vector3(0, 1, 0),
            new Vector3(0, -1, 0)
        ];
        this._cubeUps = [
            new Vector3(0, 1, 0),
            new Vector3(0, 1, 0),
            new Vector3(0, 1, 0),
            new Vector3(0, 1, 0),
            new Vector3(0, 0, 1),
            new Vector3(0, 0, -1)
        ];
    }
    updateMatrices(light, viewportIndex = 0) {
        const camera = this.camera;
        const shadowMatrix = this.matrix;
        const far = light.distance || camera.far;
        if (far !== camera.far) {
            camera.far = far;
            camera.updateProjectionMatrix();
        }
        _lightPositionWorld.setFromMatrixPosition(light.matrixWorld);
        camera.position.copy(_lightPositionWorld);
        _lookTarget.copy(camera.position);
        _lookTarget.add(this._cubeDirections[viewportIndex]);
        camera.up.copy(this._cubeUps[viewportIndex]);
        camera.lookAt(_lookTarget);
        camera.updateMatrixWorld();
        shadowMatrix.makeTranslation(-_lightPositionWorld.x, -_lightPositionWorld.y, -_lightPositionWorld.z);
        _projScreenMatrix.multiplyMatrices(camera.projectionMatrix, camera.matrixWorldInverse);
        this._frustum.setFromProjectionMatrix(_projScreenMatrix);
    }
}
class PointLight extends Light {
    constructor(color, intensity, distance = 0, decay = 2){
        super(color, intensity);
        this.isPointLight = true;
        this.type = "PointLight";
        this.distance = distance;
        this.decay = decay;
        this.shadow = new PointLightShadow();
    }
    get power() {
        // compute the light's luminous power (in lumens) from its intensity (in candela)
        // for an isotropic light source, luminous power (lm) = 4  luminous intensity (cd)
        return this.intensity * 4 * Math.PI;
    }
    set power(power) {
        // set the light's intensity (in candela) from the desired luminous power (in lumens)
        this.intensity = power / (4 * Math.PI);
    }
    dispose() {
        this.shadow.dispose();
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.distance = source.distance;
        this.decay = source.decay;
        this.shadow = source.shadow.clone();
        return this;
    }
}
class DirectionalLightShadow extends LightShadow {
    constructor(){
        super(new OrthographicCamera(-5, 5, 5, -5, 0.5, 500));
        this.isDirectionalLightShadow = true;
    }
}
class DirectionalLight extends Light {
    constructor(color, intensity){
        super(color, intensity);
        this.isDirectionalLight = true;
        this.type = "DirectionalLight";
        this.position.copy(Object3D.DEFAULT_UP);
        this.updateMatrix();
        this.target = new Object3D();
        this.shadow = new DirectionalLightShadow();
    }
    dispose() {
        this.shadow.dispose();
    }
    copy(source) {
        super.copy(source);
        this.target = source.target.clone();
        this.shadow = source.shadow.clone();
        return this;
    }
}
class AmbientLight extends Light {
    constructor(color, intensity){
        super(color, intensity);
        this.isAmbientLight = true;
        this.type = "AmbientLight";
    }
}
class RectAreaLight extends Light {
    constructor(color, intensity, width = 10, height = 10){
        super(color, intensity);
        this.isRectAreaLight = true;
        this.type = "RectAreaLight";
        this.width = width;
        this.height = height;
    }
    get power() {
        // compute the light's luminous power (in lumens) from its intensity (in nits)
        return this.intensity * this.width * this.height * Math.PI;
    }
    set power(power) {
        // set the light's intensity (in nits) from the desired luminous power (in lumens)
        this.intensity = power / (this.width * this.height * Math.PI);
    }
    copy(source) {
        super.copy(source);
        this.width = source.width;
        this.height = source.height;
        return this;
    }
    toJSON(meta) {
        const data = super.toJSON(meta);
        data.object.width = this.width;
        data.object.height = this.height;
        return data;
    }
}
/**
 * Primary reference:
 *   https://graphics.stanford.edu/papers/envmap/envmap.pdf
 *
 * Secondary reference:
 *   https://www.ppsloan.org/publications/StupidSH36.pdf
 */ // 3-band SH defined by 9 coefficients
class SphericalHarmonics3 {
    constructor(){
        this.isSphericalHarmonics3 = true;
        this.coefficients = [];
        for(let i = 0; i < 9; i++)this.coefficients.push(new Vector3());
    }
    set(coefficients) {
        for(let i = 0; i < 9; i++)this.coefficients[i].copy(coefficients[i]);
        return this;
    }
    zero() {
        for(let i = 0; i < 9; i++)this.coefficients[i].set(0, 0, 0);
        return this;
    }
    // get the radiance in the direction of the normal
    // target is a Vector3
    getAt(normal, target) {
        // normal is assumed to be unit length
        const x = normal.x, y = normal.y, z = normal.z;
        const coeff = this.coefficients;
        // band 0
        target.copy(coeff[0]).multiplyScalar(0.282095);
        // band 1
        target.addScaledVector(coeff[1], 0.488603 * y);
        target.addScaledVector(coeff[2], 0.488603 * z);
        target.addScaledVector(coeff[3], 0.488603 * x);
        // band 2
        target.addScaledVector(coeff[4], 1.092548 * (x * y));
        target.addScaledVector(coeff[5], 1.092548 * (y * z));
        target.addScaledVector(coeff[6], 0.315392 * (3.0 * z * z - 1.0));
        target.addScaledVector(coeff[7], 1.092548 * (x * z));
        target.addScaledVector(coeff[8], 0.546274 * (x * x - y * y));
        return target;
    }
    // get the irradiance (radiance convolved with cosine lobe) in the direction of the normal
    // target is a Vector3
    // https://graphics.stanford.edu/papers/envmap/envmap.pdf
    getIrradianceAt(normal, target) {
        // normal is assumed to be unit length
        const x = normal.x, y = normal.y, z = normal.z;
        const coeff = this.coefficients;
        // band 0
        target.copy(coeff[0]).multiplyScalar(0.886227); //  * 0.282095
        // band 1
        target.addScaledVector(coeff[1], 1.023328 * y); // ( 2 *  / 3 ) * 0.488603
        target.addScaledVector(coeff[2], 1.023328 * z);
        target.addScaledVector(coeff[3], 1.023328 * x);
        // band 2
        target.addScaledVector(coeff[4], 0.858086 * x * y); // (  / 4 ) * 1.092548
        target.addScaledVector(coeff[5], 0.858086 * y * z);
        target.addScaledVector(coeff[6], 0.743125 * z * z - 0.247708); // (  / 4 ) * 0.315392 * 3
        target.addScaledVector(coeff[7], 0.858086 * x * z);
        target.addScaledVector(coeff[8], 0.429043 * (x * x - y * y)); // (  / 4 ) * 0.546274
        return target;
    }
    add(sh) {
        for(let i = 0; i < 9; i++)this.coefficients[i].add(sh.coefficients[i]);
        return this;
    }
    addScaledSH(sh, s) {
        for(let i = 0; i < 9; i++)this.coefficients[i].addScaledVector(sh.coefficients[i], s);
        return this;
    }
    scale(s) {
        for(let i = 0; i < 9; i++)this.coefficients[i].multiplyScalar(s);
        return this;
    }
    lerp(sh, alpha) {
        for(let i = 0; i < 9; i++)this.coefficients[i].lerp(sh.coefficients[i], alpha);
        return this;
    }
    equals(sh) {
        for(let i = 0; i < 9; i++){
            if (!this.coefficients[i].equals(sh.coefficients[i])) return false;
        }
        return true;
    }
    copy(sh) {
        return this.set(sh.coefficients);
    }
    clone() {
        return new this.constructor().copy(this);
    }
    fromArray(array, offset = 0) {
        const coefficients = this.coefficients;
        for(let i = 0; i < 9; i++)coefficients[i].fromArray(array, offset + i * 3);
        return this;
    }
    toArray(array = [], offset = 0) {
        const coefficients = this.coefficients;
        for(let i = 0; i < 9; i++)coefficients[i].toArray(array, offset + i * 3);
        return array;
    }
    // evaluate the basis functions
    // shBasis is an Array[ 9 ]
    static getBasisAt(normal, shBasis) {
        // normal is assumed to be unit length
        const x = normal.x, y = normal.y, z = normal.z;
        // band 0
        shBasis[0] = 0.282095;
        // band 1
        shBasis[1] = 0.488603 * y;
        shBasis[2] = 0.488603 * z;
        shBasis[3] = 0.488603 * x;
        // band 2
        shBasis[4] = 1.092548 * x * y;
        shBasis[5] = 1.092548 * y * z;
        shBasis[6] = 0.315392 * (3 * z * z - 1);
        shBasis[7] = 1.092548 * x * z;
        shBasis[8] = 0.546274 * (x * x - y * y);
    }
}
class LightProbe extends Light {
    constructor(sh = new SphericalHarmonics3(), intensity = 1){
        super(undefined, intensity);
        this.isLightProbe = true;
        this.sh = sh;
    }
    copy(source) {
        super.copy(source);
        this.sh.copy(source.sh);
        return this;
    }
    fromJSON(json) {
        this.intensity = json.intensity; // TODO: Move this bit to Light.fromJSON();
        this.sh.fromArray(json.sh);
        return this;
    }
    toJSON(meta) {
        const data = super.toJSON(meta);
        data.object.sh = this.sh.toArray();
        return data;
    }
}
class MaterialLoader extends Loader {
    constructor(manager){
        super(manager);
        this.textures = {};
    }
    load(url, onLoad, onProgress, onError) {
        const scope = this;
        const loader = new FileLoader(scope.manager);
        loader.setPath(scope.path);
        loader.setRequestHeader(scope.requestHeader);
        loader.setWithCredentials(scope.withCredentials);
        loader.load(url, function(text) {
            try {
                onLoad(scope.parse(JSON.parse(text)));
            } catch (e) {
                if (onError) onError(e);
                else console.error(e);
                scope.manager.itemError(url);
            }
        }, onProgress, onError);
    }
    parse(json) {
        const textures = this.textures;
        function getTexture(name) {
            if (textures[name] === undefined) console.warn("THREE.MaterialLoader: Undefined texture", name);
            return textures[name];
        }
        const material = MaterialLoader.createMaterialFromType(json.type);
        if (json.uuid !== undefined) material.uuid = json.uuid;
        if (json.name !== undefined) material.name = json.name;
        if (json.color !== undefined && material.color !== undefined) material.color.setHex(json.color);
        if (json.roughness !== undefined) material.roughness = json.roughness;
        if (json.metalness !== undefined) material.metalness = json.metalness;
        if (json.sheen !== undefined) material.sheen = json.sheen;
        if (json.sheenColor !== undefined) material.sheenColor = new Color().setHex(json.sheenColor);
        if (json.sheenRoughness !== undefined) material.sheenRoughness = json.sheenRoughness;
        if (json.emissive !== undefined && material.emissive !== undefined) material.emissive.setHex(json.emissive);
        if (json.specular !== undefined && material.specular !== undefined) material.specular.setHex(json.specular);
        if (json.specularIntensity !== undefined) material.specularIntensity = json.specularIntensity;
        if (json.specularColor !== undefined && material.specularColor !== undefined) material.specularColor.setHex(json.specularColor);
        if (json.shininess !== undefined) material.shininess = json.shininess;
        if (json.clearcoat !== undefined) material.clearcoat = json.clearcoat;
        if (json.clearcoatRoughness !== undefined) material.clearcoatRoughness = json.clearcoatRoughness;
        if (json.dispersion !== undefined) material.dispersion = json.dispersion;
        if (json.iridescence !== undefined) material.iridescence = json.iridescence;
        if (json.iridescenceIOR !== undefined) material.iridescenceIOR = json.iridescenceIOR;
        if (json.iridescenceThicknessRange !== undefined) material.iridescenceThicknessRange = json.iridescenceThicknessRange;
        if (json.transmission !== undefined) material.transmission = json.transmission;
        if (json.thickness !== undefined) material.thickness = json.thickness;
        if (json.attenuationDistance !== undefined) material.attenuationDistance = json.attenuationDistance;
        if (json.attenuationColor !== undefined && material.attenuationColor !== undefined) material.attenuationColor.setHex(json.attenuationColor);
        if (json.anisotropy !== undefined) material.anisotropy = json.anisotropy;
        if (json.anisotropyRotation !== undefined) material.anisotropyRotation = json.anisotropyRotation;
        if (json.fog !== undefined) material.fog = json.fog;
        if (json.flatShading !== undefined) material.flatShading = json.flatShading;
        if (json.blending !== undefined) material.blending = json.blending;
        if (json.combine !== undefined) material.combine = json.combine;
        if (json.side !== undefined) material.side = json.side;
        if (json.shadowSide !== undefined) material.shadowSide = json.shadowSide;
        if (json.opacity !== undefined) material.opacity = json.opacity;
        if (json.transparent !== undefined) material.transparent = json.transparent;
        if (json.alphaTest !== undefined) material.alphaTest = json.alphaTest;
        if (json.alphaHash !== undefined) material.alphaHash = json.alphaHash;
        if (json.depthFunc !== undefined) material.depthFunc = json.depthFunc;
        if (json.depthTest !== undefined) material.depthTest = json.depthTest;
        if (json.depthWrite !== undefined) material.depthWrite = json.depthWrite;
        if (json.colorWrite !== undefined) material.colorWrite = json.colorWrite;
        if (json.blendSrc !== undefined) material.blendSrc = json.blendSrc;
        if (json.blendDst !== undefined) material.blendDst = json.blendDst;
        if (json.blendEquation !== undefined) material.blendEquation = json.blendEquation;
        if (json.blendSrcAlpha !== undefined) material.blendSrcAlpha = json.blendSrcAlpha;
        if (json.blendDstAlpha !== undefined) material.blendDstAlpha = json.blendDstAlpha;
        if (json.blendEquationAlpha !== undefined) material.blendEquationAlpha = json.blendEquationAlpha;
        if (json.blendColor !== undefined && material.blendColor !== undefined) material.blendColor.setHex(json.blendColor);
        if (json.blendAlpha !== undefined) material.blendAlpha = json.blendAlpha;
        if (json.stencilWriteMask !== undefined) material.stencilWriteMask = json.stencilWriteMask;
        if (json.stencilFunc !== undefined) material.stencilFunc = json.stencilFunc;
        if (json.stencilRef !== undefined) material.stencilRef = json.stencilRef;
        if (json.stencilFuncMask !== undefined) material.stencilFuncMask = json.stencilFuncMask;
        if (json.stencilFail !== undefined) material.stencilFail = json.stencilFail;
        if (json.stencilZFail !== undefined) material.stencilZFail = json.stencilZFail;
        if (json.stencilZPass !== undefined) material.stencilZPass = json.stencilZPass;
        if (json.stencilWrite !== undefined) material.stencilWrite = json.stencilWrite;
        if (json.wireframe !== undefined) material.wireframe = json.wireframe;
        if (json.wireframeLinewidth !== undefined) material.wireframeLinewidth = json.wireframeLinewidth;
        if (json.wireframeLinecap !== undefined) material.wireframeLinecap = json.wireframeLinecap;
        if (json.wireframeLinejoin !== undefined) material.wireframeLinejoin = json.wireframeLinejoin;
        if (json.rotation !== undefined) material.rotation = json.rotation;
        if (json.linewidth !== undefined) material.linewidth = json.linewidth;
        if (json.dashSize !== undefined) material.dashSize = json.dashSize;
        if (json.gapSize !== undefined) material.gapSize = json.gapSize;
        if (json.scale !== undefined) material.scale = json.scale;
        if (json.polygonOffset !== undefined) material.polygonOffset = json.polygonOffset;
        if (json.polygonOffsetFactor !== undefined) material.polygonOffsetFactor = json.polygonOffsetFactor;
        if (json.polygonOffsetUnits !== undefined) material.polygonOffsetUnits = json.polygonOffsetUnits;
        if (json.dithering !== undefined) material.dithering = json.dithering;
        if (json.alphaToCoverage !== undefined) material.alphaToCoverage = json.alphaToCoverage;
        if (json.premultipliedAlpha !== undefined) material.premultipliedAlpha = json.premultipliedAlpha;
        if (json.forceSinglePass !== undefined) material.forceSinglePass = json.forceSinglePass;
        if (json.visible !== undefined) material.visible = json.visible;
        if (json.toneMapped !== undefined) material.toneMapped = json.toneMapped;
        if (json.userData !== undefined) material.userData = json.userData;
        if (json.vertexColors !== undefined) {
            if (typeof json.vertexColors === "number") material.vertexColors = json.vertexColors > 0 ? true : false;
            else material.vertexColors = json.vertexColors;
        }
        // Shader Material
        if (json.uniforms !== undefined) for(const name in json.uniforms){
            const uniform = json.uniforms[name];
            material.uniforms[name] = {};
            switch(uniform.type){
                case "t":
                    material.uniforms[name].value = getTexture(uniform.value);
                    break;
                case "c":
                    material.uniforms[name].value = new Color().setHex(uniform.value);
                    break;
                case "v2":
                    material.uniforms[name].value = new Vector2().fromArray(uniform.value);
                    break;
                case "v3":
                    material.uniforms[name].value = new Vector3().fromArray(uniform.value);
                    break;
                case "v4":
                    material.uniforms[name].value = new Vector4().fromArray(uniform.value);
                    break;
                case "m3":
                    material.uniforms[name].value = new Matrix3().fromArray(uniform.value);
                    break;
                case "m4":
                    material.uniforms[name].value = new Matrix4().fromArray(uniform.value);
                    break;
                default:
                    material.uniforms[name].value = uniform.value;
            }
        }
        if (json.defines !== undefined) material.defines = json.defines;
        if (json.vertexShader !== undefined) material.vertexShader = json.vertexShader;
        if (json.fragmentShader !== undefined) material.fragmentShader = json.fragmentShader;
        if (json.glslVersion !== undefined) material.glslVersion = json.glslVersion;
        if (json.extensions !== undefined) for(const key in json.extensions)material.extensions[key] = json.extensions[key];
        if (json.lights !== undefined) material.lights = json.lights;
        if (json.clipping !== undefined) material.clipping = json.clipping;
        // for PointsMaterial
        if (json.size !== undefined) material.size = json.size;
        if (json.sizeAttenuation !== undefined) material.sizeAttenuation = json.sizeAttenuation;
        // maps
        if (json.map !== undefined) material.map = getTexture(json.map);
        if (json.matcap !== undefined) material.matcap = getTexture(json.matcap);
        if (json.alphaMap !== undefined) material.alphaMap = getTexture(json.alphaMap);
        if (json.bumpMap !== undefined) material.bumpMap = getTexture(json.bumpMap);
        if (json.bumpScale !== undefined) material.bumpScale = json.bumpScale;
        if (json.normalMap !== undefined) material.normalMap = getTexture(json.normalMap);
        if (json.normalMapType !== undefined) material.normalMapType = json.normalMapType;
        if (json.normalScale !== undefined) {
            let normalScale = json.normalScale;
            if (Array.isArray(normalScale) === false) // Blender exporter used to export a scalar. See #7459
            normalScale = [
                normalScale,
                normalScale
            ];
            material.normalScale = new Vector2().fromArray(normalScale);
        }
        if (json.displacementMap !== undefined) material.displacementMap = getTexture(json.displacementMap);
        if (json.displacementScale !== undefined) material.displacementScale = json.displacementScale;
        if (json.displacementBias !== undefined) material.displacementBias = json.displacementBias;
        if (json.roughnessMap !== undefined) material.roughnessMap = getTexture(json.roughnessMap);
        if (json.metalnessMap !== undefined) material.metalnessMap = getTexture(json.metalnessMap);
        if (json.emissiveMap !== undefined) material.emissiveMap = getTexture(json.emissiveMap);
        if (json.emissiveIntensity !== undefined) material.emissiveIntensity = json.emissiveIntensity;
        if (json.specularMap !== undefined) material.specularMap = getTexture(json.specularMap);
        if (json.specularIntensityMap !== undefined) material.specularIntensityMap = getTexture(json.specularIntensityMap);
        if (json.specularColorMap !== undefined) material.specularColorMap = getTexture(json.specularColorMap);
        if (json.envMap !== undefined) material.envMap = getTexture(json.envMap);
        if (json.envMapRotation !== undefined) material.envMapRotation.fromArray(json.envMapRotation);
        if (json.envMapIntensity !== undefined) material.envMapIntensity = json.envMapIntensity;
        if (json.reflectivity !== undefined) material.reflectivity = json.reflectivity;
        if (json.refractionRatio !== undefined) material.refractionRatio = json.refractionRatio;
        if (json.lightMap !== undefined) material.lightMap = getTexture(json.lightMap);
        if (json.lightMapIntensity !== undefined) material.lightMapIntensity = json.lightMapIntensity;
        if (json.aoMap !== undefined) material.aoMap = getTexture(json.aoMap);
        if (json.aoMapIntensity !== undefined) material.aoMapIntensity = json.aoMapIntensity;
        if (json.gradientMap !== undefined) material.gradientMap = getTexture(json.gradientMap);
        if (json.clearcoatMap !== undefined) material.clearcoatMap = getTexture(json.clearcoatMap);
        if (json.clearcoatRoughnessMap !== undefined) material.clearcoatRoughnessMap = getTexture(json.clearcoatRoughnessMap);
        if (json.clearcoatNormalMap !== undefined) material.clearcoatNormalMap = getTexture(json.clearcoatNormalMap);
        if (json.clearcoatNormalScale !== undefined) material.clearcoatNormalScale = new Vector2().fromArray(json.clearcoatNormalScale);
        if (json.iridescenceMap !== undefined) material.iridescenceMap = getTexture(json.iridescenceMap);
        if (json.iridescenceThicknessMap !== undefined) material.iridescenceThicknessMap = getTexture(json.iridescenceThicknessMap);
        if (json.transmissionMap !== undefined) material.transmissionMap = getTexture(json.transmissionMap);
        if (json.thicknessMap !== undefined) material.thicknessMap = getTexture(json.thicknessMap);
        if (json.anisotropyMap !== undefined) material.anisotropyMap = getTexture(json.anisotropyMap);
        if (json.sheenColorMap !== undefined) material.sheenColorMap = getTexture(json.sheenColorMap);
        if (json.sheenRoughnessMap !== undefined) material.sheenRoughnessMap = getTexture(json.sheenRoughnessMap);
        return material;
    }
    setTextures(value) {
        this.textures = value;
        return this;
    }
    static createMaterialFromType(type) {
        const materialLib = {
            ShadowMaterial,
            SpriteMaterial,
            RawShaderMaterial,
            ShaderMaterial,
            PointsMaterial,
            MeshPhysicalMaterial,
            MeshStandardMaterial,
            MeshPhongMaterial,
            MeshToonMaterial,
            MeshNormalMaterial,
            MeshLambertMaterial,
            MeshDepthMaterial,
            MeshDistanceMaterial,
            MeshBasicMaterial,
            MeshMatcapMaterial,
            LineDashedMaterial,
            LineBasicMaterial,
            Material
        };
        return new materialLib[type]();
    }
}
class LoaderUtils {
    static decodeText(array) {
        console.warn("THREE.LoaderUtils: decodeText() has been deprecated with r165 and will be removed with r175. Use TextDecoder instead.");
        if (typeof TextDecoder !== "undefined") return new TextDecoder().decode(array);
        // Avoid the String.fromCharCode.apply(null, array) shortcut, which
        // throws a "maximum call stack size exceeded" error for large arrays.
        let s = "";
        for(let i = 0, il = array.length; i < il; i++)// Implicitly assumes little-endian.
        s += String.fromCharCode(array[i]);
        try {
            // merges multi-byte utf-8 characters.
            return decodeURIComponent(escape(s));
        } catch (e) {
            return s;
        }
    }
    static extractUrlBase(url) {
        const index = url.lastIndexOf("/");
        if (index === -1) return "./";
        return url.slice(0, index + 1);
    }
    static resolveURL(url, path) {
        // Invalid URL
        if (typeof url !== "string" || url === "") return "";
        // Host Relative URL
        if (/^https?:\/\//i.test(path) && /^\//.test(url)) path = path.replace(/(^https?:\/\/[^\/]+).*/i, "$1");
        // Absolute URL http://,https://,//
        if (/^(https?:)?\/\//i.test(url)) return url;
        // Data URI
        if (/^data:.*,.*$/i.test(url)) return url;
        // Blob URL
        if (/^blob:.*$/i.test(url)) return url;
        // Relative URL
        return path + url;
    }
}
class InstancedBufferGeometry extends BufferGeometry {
    constructor(){
        super();
        this.isInstancedBufferGeometry = true;
        this.type = "InstancedBufferGeometry";
        this.instanceCount = Infinity;
    }
    copy(source) {
        super.copy(source);
        this.instanceCount = source.instanceCount;
        return this;
    }
    toJSON() {
        const data = super.toJSON();
        data.instanceCount = this.instanceCount;
        data.isInstancedBufferGeometry = true;
        return data;
    }
}
class BufferGeometryLoader extends Loader {
    constructor(manager){
        super(manager);
    }
    load(url, onLoad, onProgress, onError) {
        const scope = this;
        const loader = new FileLoader(scope.manager);
        loader.setPath(scope.path);
        loader.setRequestHeader(scope.requestHeader);
        loader.setWithCredentials(scope.withCredentials);
        loader.load(url, function(text) {
            try {
                onLoad(scope.parse(JSON.parse(text)));
            } catch (e) {
                if (onError) onError(e);
                else console.error(e);
                scope.manager.itemError(url);
            }
        }, onProgress, onError);
    }
    parse(json) {
        const interleavedBufferMap = {};
        const arrayBufferMap = {};
        function getInterleavedBuffer(json, uuid) {
            if (interleavedBufferMap[uuid] !== undefined) return interleavedBufferMap[uuid];
            const interleavedBuffers = json.interleavedBuffers;
            const interleavedBuffer = interleavedBuffers[uuid];
            const buffer = getArrayBuffer(json, interleavedBuffer.buffer);
            const array = getTypedArray(interleavedBuffer.type, buffer);
            const ib = new InterleavedBuffer(array, interleavedBuffer.stride);
            ib.uuid = interleavedBuffer.uuid;
            interleavedBufferMap[uuid] = ib;
            return ib;
        }
        function getArrayBuffer(json, uuid) {
            if (arrayBufferMap[uuid] !== undefined) return arrayBufferMap[uuid];
            const arrayBuffers = json.arrayBuffers;
            const arrayBuffer = arrayBuffers[uuid];
            const ab = new Uint32Array(arrayBuffer).buffer;
            arrayBufferMap[uuid] = ab;
            return ab;
        }
        const geometry = json.isInstancedBufferGeometry ? new InstancedBufferGeometry() : new BufferGeometry();
        const index = json.data.index;
        if (index !== undefined) {
            const typedArray = getTypedArray(index.type, index.array);
            geometry.setIndex(new BufferAttribute(typedArray, 1));
        }
        const attributes = json.data.attributes;
        for(const key in attributes){
            const attribute = attributes[key];
            let bufferAttribute;
            if (attribute.isInterleavedBufferAttribute) {
                const interleavedBuffer = getInterleavedBuffer(json.data, attribute.data);
                bufferAttribute = new InterleavedBufferAttribute(interleavedBuffer, attribute.itemSize, attribute.offset, attribute.normalized);
            } else {
                const typedArray = getTypedArray(attribute.type, attribute.array);
                const bufferAttributeConstr = attribute.isInstancedBufferAttribute ? InstancedBufferAttribute : BufferAttribute;
                bufferAttribute = new bufferAttributeConstr(typedArray, attribute.itemSize, attribute.normalized);
            }
            if (attribute.name !== undefined) bufferAttribute.name = attribute.name;
            if (attribute.usage !== undefined) bufferAttribute.setUsage(attribute.usage);
            geometry.setAttribute(key, bufferAttribute);
        }
        const morphAttributes = json.data.morphAttributes;
        if (morphAttributes) for(const key in morphAttributes){
            const attributeArray = morphAttributes[key];
            const array = [];
            for(let i = 0, il = attributeArray.length; i < il; i++){
                const attribute = attributeArray[i];
                let bufferAttribute;
                if (attribute.isInterleavedBufferAttribute) {
                    const interleavedBuffer = getInterleavedBuffer(json.data, attribute.data);
                    bufferAttribute = new InterleavedBufferAttribute(interleavedBuffer, attribute.itemSize, attribute.offset, attribute.normalized);
                } else {
                    const typedArray = getTypedArray(attribute.type, attribute.array);
                    bufferAttribute = new BufferAttribute(typedArray, attribute.itemSize, attribute.normalized);
                }
                if (attribute.name !== undefined) bufferAttribute.name = attribute.name;
                array.push(bufferAttribute);
            }
            geometry.morphAttributes[key] = array;
        }
        const morphTargetsRelative = json.data.morphTargetsRelative;
        if (morphTargetsRelative) geometry.morphTargetsRelative = true;
        const groups = json.data.groups || json.data.drawcalls || json.data.offsets;
        if (groups !== undefined) for(let i = 0, n = groups.length; i !== n; ++i){
            const group = groups[i];
            geometry.addGroup(group.start, group.count, group.materialIndex);
        }
        const boundingSphere = json.data.boundingSphere;
        if (boundingSphere !== undefined) {
            const center = new Vector3();
            if (boundingSphere.center !== undefined) center.fromArray(boundingSphere.center);
            geometry.boundingSphere = new Sphere(center, boundingSphere.radius);
        }
        if (json.name) geometry.name = json.name;
        if (json.userData) geometry.userData = json.userData;
        return geometry;
    }
}
class ObjectLoader extends Loader {
    constructor(manager){
        super(manager);
    }
    load(url, onLoad, onProgress, onError) {
        const scope = this;
        const path = this.path === "" ? LoaderUtils.extractUrlBase(url) : this.path;
        this.resourcePath = this.resourcePath || path;
        const loader = new FileLoader(this.manager);
        loader.setPath(this.path);
        loader.setRequestHeader(this.requestHeader);
        loader.setWithCredentials(this.withCredentials);
        loader.load(url, function(text) {
            let json = null;
            try {
                json = JSON.parse(text);
            } catch (error) {
                if (onError !== undefined) onError(error);
                console.error("THREE:ObjectLoader: Can't parse " + url + ".", error.message);
                return;
            }
            const metadata = json.metadata;
            if (metadata === undefined || metadata.type === undefined || metadata.type.toLowerCase() === "geometry") {
                if (onError !== undefined) onError(new Error("THREE.ObjectLoader: Can't load " + url));
                console.error("THREE.ObjectLoader: Can't load " + url);
                return;
            }
            scope.parse(json, onLoad);
        }, onProgress, onError);
    }
    async loadAsync(url, onProgress) {
        const scope = this;
        const path = this.path === "" ? LoaderUtils.extractUrlBase(url) : this.path;
        this.resourcePath = this.resourcePath || path;
        const loader = new FileLoader(this.manager);
        loader.setPath(this.path);
        loader.setRequestHeader(this.requestHeader);
        loader.setWithCredentials(this.withCredentials);
        const text = await loader.loadAsync(url, onProgress);
        const json = JSON.parse(text);
        const metadata = json.metadata;
        if (metadata === undefined || metadata.type === undefined || metadata.type.toLowerCase() === "geometry") throw new Error("THREE.ObjectLoader: Can't load " + url);
        return await scope.parseAsync(json);
    }
    parse(json, onLoad) {
        const animations = this.parseAnimations(json.animations);
        const shapes = this.parseShapes(json.shapes);
        const geometries = this.parseGeometries(json.geometries, shapes);
        const images = this.parseImages(json.images, function() {
            if (onLoad !== undefined) onLoad(object);
        });
        const textures = this.parseTextures(json.textures, images);
        const materials = this.parseMaterials(json.materials, textures);
        const object = this.parseObject(json.object, geometries, materials, textures, animations);
        const skeletons = this.parseSkeletons(json.skeletons, object);
        this.bindSkeletons(object, skeletons);
        this.bindLightTargets(object);
        //
        if (onLoad !== undefined) {
            let hasImages = false;
            for(const uuid in images)if (images[uuid].data instanceof HTMLImageElement) {
                hasImages = true;
                break;
            }
            if (hasImages === false) onLoad(object);
        }
        return object;
    }
    async parseAsync(json) {
        const animations = this.parseAnimations(json.animations);
        const shapes = this.parseShapes(json.shapes);
        const geometries = this.parseGeometries(json.geometries, shapes);
        const images = await this.parseImagesAsync(json.images);
        const textures = this.parseTextures(json.textures, images);
        const materials = this.parseMaterials(json.materials, textures);
        const object = this.parseObject(json.object, geometries, materials, textures, animations);
        const skeletons = this.parseSkeletons(json.skeletons, object);
        this.bindSkeletons(object, skeletons);
        return object;
    }
    parseShapes(json) {
        const shapes = {};
        if (json !== undefined) for(let i = 0, l = json.length; i < l; i++){
            const shape = new Shape().fromJSON(json[i]);
            shapes[shape.uuid] = shape;
        }
        return shapes;
    }
    parseSkeletons(json, object) {
        const skeletons = {};
        const bones = {};
        // generate bone lookup table
        object.traverse(function(child) {
            if (child.isBone) bones[child.uuid] = child;
        });
        // create skeletons
        if (json !== undefined) for(let i = 0, l = json.length; i < l; i++){
            const skeleton = new Skeleton().fromJSON(json[i], bones);
            skeletons[skeleton.uuid] = skeleton;
        }
        return skeletons;
    }
    parseGeometries(json, shapes) {
        const geometries = {};
        if (json !== undefined) {
            const bufferGeometryLoader = new BufferGeometryLoader();
            for(let i = 0, l = json.length; i < l; i++){
                let geometry;
                const data = json[i];
                switch(data.type){
                    case "BufferGeometry":
                    case "InstancedBufferGeometry":
                        geometry = bufferGeometryLoader.parse(data);
                        break;
                    default:
                        if (data.type in Geometries) geometry = Geometries[data.type].fromJSON(data, shapes);
                        else console.warn(`THREE.ObjectLoader: Unsupported geometry type "${data.type}"`);
                }
                geometry.uuid = data.uuid;
                if (data.name !== undefined) geometry.name = data.name;
                if (data.userData !== undefined) geometry.userData = data.userData;
                geometries[data.uuid] = geometry;
            }
        }
        return geometries;
    }
    parseMaterials(json, textures) {
        const cache = {}; // MultiMaterial
        const materials = {};
        if (json !== undefined) {
            const loader = new MaterialLoader();
            loader.setTextures(textures);
            for(let i = 0, l = json.length; i < l; i++){
                const data = json[i];
                if (cache[data.uuid] === undefined) cache[data.uuid] = loader.parse(data);
                materials[data.uuid] = cache[data.uuid];
            }
        }
        return materials;
    }
    parseAnimations(json) {
        const animations = {};
        if (json !== undefined) for(let i = 0; i < json.length; i++){
            const data = json[i];
            const clip = AnimationClip.parse(data);
            animations[clip.uuid] = clip;
        }
        return animations;
    }
    parseImages(json, onLoad) {
        const scope = this;
        const images = {};
        let loader;
        function loadImage(url) {
            scope.manager.itemStart(url);
            return loader.load(url, function() {
                scope.manager.itemEnd(url);
            }, undefined, function() {
                scope.manager.itemError(url);
                scope.manager.itemEnd(url);
            });
        }
        function deserializeImage(image) {
            if (typeof image === "string") {
                const url = image;
                const path = /^(\/\/)|([a-z]+:(\/\/)?)/i.test(url) ? url : scope.resourcePath + url;
                return loadImage(path);
            } else {
                if (image.data) return {
                    data: getTypedArray(image.type, image.data),
                    width: image.width,
                    height: image.height
                };
                else return null;
            }
        }
        if (json !== undefined && json.length > 0) {
            const manager = new LoadingManager(onLoad);
            loader = new ImageLoader(manager);
            loader.setCrossOrigin(this.crossOrigin);
            for(let i = 0, il = json.length; i < il; i++){
                const image = json[i];
                const url = image.url;
                if (Array.isArray(url)) {
                    // load array of images e.g CubeTexture
                    const imageArray = [];
                    for(let j = 0, jl = url.length; j < jl; j++){
                        const currentUrl = url[j];
                        const deserializedImage = deserializeImage(currentUrl);
                        if (deserializedImage !== null) {
                            if (deserializedImage instanceof HTMLImageElement) imageArray.push(deserializedImage);
                            else // special case: handle array of data textures for cube textures
                            imageArray.push(new DataTexture(deserializedImage.data, deserializedImage.width, deserializedImage.height));
                        }
                    }
                    images[image.uuid] = new Source(imageArray);
                } else {
                    // load single image
                    const deserializedImage = deserializeImage(image.url);
                    images[image.uuid] = new Source(deserializedImage);
                }
            }
        }
        return images;
    }
    async parseImagesAsync(json) {
        const scope = this;
        const images = {};
        let loader;
        async function deserializeImage(image) {
            if (typeof image === "string") {
                const url = image;
                const path = /^(\/\/)|([a-z]+:(\/\/)?)/i.test(url) ? url : scope.resourcePath + url;
                return await loader.loadAsync(path);
            } else {
                if (image.data) return {
                    data: getTypedArray(image.type, image.data),
                    width: image.width,
                    height: image.height
                };
                else return null;
            }
        }
        if (json !== undefined && json.length > 0) {
            loader = new ImageLoader(this.manager);
            loader.setCrossOrigin(this.crossOrigin);
            for(let i = 0, il = json.length; i < il; i++){
                const image = json[i];
                const url = image.url;
                if (Array.isArray(url)) {
                    // load array of images e.g CubeTexture
                    const imageArray = [];
                    for(let j = 0, jl = url.length; j < jl; j++){
                        const currentUrl = url[j];
                        const deserializedImage = await deserializeImage(currentUrl);
                        if (deserializedImage !== null) {
                            if (deserializedImage instanceof HTMLImageElement) imageArray.push(deserializedImage);
                            else // special case: handle array of data textures for cube textures
                            imageArray.push(new DataTexture(deserializedImage.data, deserializedImage.width, deserializedImage.height));
                        }
                    }
                    images[image.uuid] = new Source(imageArray);
                } else {
                    // load single image
                    const deserializedImage = await deserializeImage(image.url);
                    images[image.uuid] = new Source(deserializedImage);
                }
            }
        }
        return images;
    }
    parseTextures(json, images) {
        function parseConstant(value, type) {
            if (typeof value === "number") return value;
            console.warn("THREE.ObjectLoader.parseTexture: Constant should be in numeric form.", value);
            return type[value];
        }
        const textures = {};
        if (json !== undefined) for(let i = 0, l = json.length; i < l; i++){
            const data = json[i];
            if (data.image === undefined) console.warn('THREE.ObjectLoader: No "image" specified for', data.uuid);
            if (images[data.image] === undefined) console.warn("THREE.ObjectLoader: Undefined image", data.image);
            const source = images[data.image];
            const image = source.data;
            let texture;
            if (Array.isArray(image)) {
                texture = new CubeTexture();
                if (image.length === 6) texture.needsUpdate = true;
            } else {
                if (image && image.data) texture = new DataTexture();
                else texture = new Texture();
                if (image) texture.needsUpdate = true; // textures can have undefined image data
            }
            texture.source = source;
            texture.uuid = data.uuid;
            if (data.name !== undefined) texture.name = data.name;
            if (data.mapping !== undefined) texture.mapping = parseConstant(data.mapping, TEXTURE_MAPPING);
            if (data.channel !== undefined) texture.channel = data.channel;
            if (data.offset !== undefined) texture.offset.fromArray(data.offset);
            if (data.repeat !== undefined) texture.repeat.fromArray(data.repeat);
            if (data.center !== undefined) texture.center.fromArray(data.center);
            if (data.rotation !== undefined) texture.rotation = data.rotation;
            if (data.wrap !== undefined) {
                texture.wrapS = parseConstant(data.wrap[0], TEXTURE_WRAPPING);
                texture.wrapT = parseConstant(data.wrap[1], TEXTURE_WRAPPING);
            }
            if (data.format !== undefined) texture.format = data.format;
            if (data.internalFormat !== undefined) texture.internalFormat = data.internalFormat;
            if (data.type !== undefined) texture.type = data.type;
            if (data.colorSpace !== undefined) texture.colorSpace = data.colorSpace;
            if (data.minFilter !== undefined) texture.minFilter = parseConstant(data.minFilter, TEXTURE_FILTER);
            if (data.magFilter !== undefined) texture.magFilter = parseConstant(data.magFilter, TEXTURE_FILTER);
            if (data.anisotropy !== undefined) texture.anisotropy = data.anisotropy;
            if (data.flipY !== undefined) texture.flipY = data.flipY;
            if (data.generateMipmaps !== undefined) texture.generateMipmaps = data.generateMipmaps;
            if (data.premultiplyAlpha !== undefined) texture.premultiplyAlpha = data.premultiplyAlpha;
            if (data.unpackAlignment !== undefined) texture.unpackAlignment = data.unpackAlignment;
            if (data.compareFunction !== undefined) texture.compareFunction = data.compareFunction;
            if (data.userData !== undefined) texture.userData = data.userData;
            textures[data.uuid] = texture;
        }
        return textures;
    }
    parseObject(data, geometries, materials, textures, animations) {
        let object;
        function getGeometry(name) {
            if (geometries[name] === undefined) console.warn("THREE.ObjectLoader: Undefined geometry", name);
            return geometries[name];
        }
        function getMaterial(name) {
            if (name === undefined) return undefined;
            if (Array.isArray(name)) {
                const array = [];
                for(let i = 0, l = name.length; i < l; i++){
                    const uuid = name[i];
                    if (materials[uuid] === undefined) console.warn("THREE.ObjectLoader: Undefined material", uuid);
                    array.push(materials[uuid]);
                }
                return array;
            }
            if (materials[name] === undefined) console.warn("THREE.ObjectLoader: Undefined material", name);
            return materials[name];
        }
        function getTexture(uuid) {
            if (textures[uuid] === undefined) console.warn("THREE.ObjectLoader: Undefined texture", uuid);
            return textures[uuid];
        }
        let geometry, material;
        switch(data.type){
            case "Scene":
                object = new Scene();
                if (data.background !== undefined) {
                    if (Number.isInteger(data.background)) object.background = new Color(data.background);
                    else object.background = getTexture(data.background);
                }
                if (data.environment !== undefined) object.environment = getTexture(data.environment);
                if (data.fog !== undefined) {
                    if (data.fog.type === "Fog") object.fog = new Fog(data.fog.color, data.fog.near, data.fog.far);
                    else if (data.fog.type === "FogExp2") object.fog = new FogExp2(data.fog.color, data.fog.density);
                    if (data.fog.name !== "") object.fog.name = data.fog.name;
                }
                if (data.backgroundBlurriness !== undefined) object.backgroundBlurriness = data.backgroundBlurriness;
                if (data.backgroundIntensity !== undefined) object.backgroundIntensity = data.backgroundIntensity;
                if (data.backgroundRotation !== undefined) object.backgroundRotation.fromArray(data.backgroundRotation);
                if (data.environmentIntensity !== undefined) object.environmentIntensity = data.environmentIntensity;
                if (data.environmentRotation !== undefined) object.environmentRotation.fromArray(data.environmentRotation);
                break;
            case "PerspectiveCamera":
                object = new PerspectiveCamera(data.fov, data.aspect, data.near, data.far);
                if (data.focus !== undefined) object.focus = data.focus;
                if (data.zoom !== undefined) object.zoom = data.zoom;
                if (data.filmGauge !== undefined) object.filmGauge = data.filmGauge;
                if (data.filmOffset !== undefined) object.filmOffset = data.filmOffset;
                if (data.view !== undefined) object.view = Object.assign({}, data.view);
                break;
            case "OrthographicCamera":
                object = new OrthographicCamera(data.left, data.right, data.top, data.bottom, data.near, data.far);
                if (data.zoom !== undefined) object.zoom = data.zoom;
                if (data.view !== undefined) object.view = Object.assign({}, data.view);
                break;
            case "AmbientLight":
                object = new AmbientLight(data.color, data.intensity);
                break;
            case "DirectionalLight":
                object = new DirectionalLight(data.color, data.intensity);
                object.target = data.target || "";
                break;
            case "PointLight":
                object = new PointLight(data.color, data.intensity, data.distance, data.decay);
                break;
            case "RectAreaLight":
                object = new RectAreaLight(data.color, data.intensity, data.width, data.height);
                break;
            case "SpotLight":
                object = new SpotLight(data.color, data.intensity, data.distance, data.angle, data.penumbra, data.decay);
                object.target = data.target || "";
                break;
            case "HemisphereLight":
                object = new HemisphereLight(data.color, data.groundColor, data.intensity);
                break;
            case "LightProbe":
                object = new LightProbe().fromJSON(data);
                break;
            case "SkinnedMesh":
                geometry = getGeometry(data.geometry);
                material = getMaterial(data.material);
                object = new SkinnedMesh(geometry, material);
                if (data.bindMode !== undefined) object.bindMode = data.bindMode;
                if (data.bindMatrix !== undefined) object.bindMatrix.fromArray(data.bindMatrix);
                if (data.skeleton !== undefined) object.skeleton = data.skeleton;
                break;
            case "Mesh":
                geometry = getGeometry(data.geometry);
                material = getMaterial(data.material);
                object = new Mesh(geometry, material);
                break;
            case "InstancedMesh":
                geometry = getGeometry(data.geometry);
                material = getMaterial(data.material);
                const count = data.count;
                const instanceMatrix = data.instanceMatrix;
                const instanceColor = data.instanceColor;
                object = new InstancedMesh(geometry, material, count);
                object.instanceMatrix = new InstancedBufferAttribute(new Float32Array(instanceMatrix.array), 16);
                if (instanceColor !== undefined) object.instanceColor = new InstancedBufferAttribute(new Float32Array(instanceColor.array), instanceColor.itemSize);
                break;
            case "BatchedMesh":
                geometry = getGeometry(data.geometry);
                material = getMaterial(data.material);
                object = new BatchedMesh(data.maxInstanceCount, data.maxVertexCount, data.maxIndexCount, material);
                object.geometry = geometry;
                object.perObjectFrustumCulled = data.perObjectFrustumCulled;
                object.sortObjects = data.sortObjects;
                object._drawRanges = data.drawRanges;
                object._reservedRanges = data.reservedRanges;
                object._visibility = data.visibility;
                object._active = data.active;
                object._bounds = data.bounds.map((bound)=>{
                    const box = new Box3();
                    box.min.fromArray(bound.boxMin);
                    box.max.fromArray(bound.boxMax);
                    const sphere = new Sphere();
                    sphere.radius = bound.sphereRadius;
                    sphere.center.fromArray(bound.sphereCenter);
                    return {
                        boxInitialized: bound.boxInitialized,
                        box: box,
                        sphereInitialized: bound.sphereInitialized,
                        sphere: sphere
                    };
                });
                object._maxInstanceCount = data.maxInstanceCount;
                object._maxVertexCount = data.maxVertexCount;
                object._maxIndexCount = data.maxIndexCount;
                object._geometryInitialized = data.geometryInitialized;
                object._geometryCount = data.geometryCount;
                object._matricesTexture = getTexture(data.matricesTexture.uuid);
                if (data.colorsTexture !== undefined) object._colorsTexture = getTexture(data.colorsTexture.uuid);
                break;
            case "LOD":
                object = new LOD();
                break;
            case "Line":
                object = new Line(getGeometry(data.geometry), getMaterial(data.material));
                break;
            case "LineLoop":
                object = new LineLoop(getGeometry(data.geometry), getMaterial(data.material));
                break;
            case "LineSegments":
                object = new LineSegments(getGeometry(data.geometry), getMaterial(data.material));
                break;
            case "PointCloud":
            case "Points":
                object = new Points(getGeometry(data.geometry), getMaterial(data.material));
                break;
            case "Sprite":
                object = new Sprite(getMaterial(data.material));
                break;
            case "Group":
                object = new Group();
                break;
            case "Bone":
                object = new Bone();
                break;
            default:
                object = new Object3D();
        }
        object.uuid = data.uuid;
        if (data.name !== undefined) object.name = data.name;
        if (data.matrix !== undefined) {
            object.matrix.fromArray(data.matrix);
            if (data.matrixAutoUpdate !== undefined) object.matrixAutoUpdate = data.matrixAutoUpdate;
            if (object.matrixAutoUpdate) object.matrix.decompose(object.position, object.quaternion, object.scale);
        } else {
            if (data.position !== undefined) object.position.fromArray(data.position);
            if (data.rotation !== undefined) object.rotation.fromArray(data.rotation);
            if (data.quaternion !== undefined) object.quaternion.fromArray(data.quaternion);
            if (data.scale !== undefined) object.scale.fromArray(data.scale);
        }
        if (data.up !== undefined) object.up.fromArray(data.up);
        if (data.castShadow !== undefined) object.castShadow = data.castShadow;
        if (data.receiveShadow !== undefined) object.receiveShadow = data.receiveShadow;
        if (data.shadow) {
            if (data.shadow.intensity !== undefined) object.shadow.intensity = data.shadow.intensity;
            if (data.shadow.bias !== undefined) object.shadow.bias = data.shadow.bias;
            if (data.shadow.normalBias !== undefined) object.shadow.normalBias = data.shadow.normalBias;
            if (data.shadow.radius !== undefined) object.shadow.radius = data.shadow.radius;
            if (data.shadow.mapSize !== undefined) object.shadow.mapSize.fromArray(data.shadow.mapSize);
            if (data.shadow.camera !== undefined) object.shadow.camera = this.parseObject(data.shadow.camera);
        }
        if (data.visible !== undefined) object.visible = data.visible;
        if (data.frustumCulled !== undefined) object.frustumCulled = data.frustumCulled;
        if (data.renderOrder !== undefined) object.renderOrder = data.renderOrder;
        if (data.userData !== undefined) object.userData = data.userData;
        if (data.layers !== undefined) object.layers.mask = data.layers;
        if (data.children !== undefined) {
            const children = data.children;
            for(let i = 0; i < children.length; i++)object.add(this.parseObject(children[i], geometries, materials, textures, animations));
        }
        if (data.animations !== undefined) {
            const objectAnimations = data.animations;
            for(let i = 0; i < objectAnimations.length; i++){
                const uuid = objectAnimations[i];
                object.animations.push(animations[uuid]);
            }
        }
        if (data.type === "LOD") {
            if (data.autoUpdate !== undefined) object.autoUpdate = data.autoUpdate;
            const levels = data.levels;
            for(let l = 0; l < levels.length; l++){
                const level = levels[l];
                const child = object.getObjectByProperty("uuid", level.object);
                if (child !== undefined) object.addLevel(child, level.distance, level.hysteresis);
            }
        }
        return object;
    }
    bindSkeletons(object, skeletons) {
        if (Object.keys(skeletons).length === 0) return;
        object.traverse(function(child) {
            if (child.isSkinnedMesh === true && child.skeleton !== undefined) {
                const skeleton = skeletons[child.skeleton];
                if (skeleton === undefined) console.warn("THREE.ObjectLoader: No skeleton found with UUID:", child.skeleton);
                else child.bind(skeleton, child.bindMatrix);
            }
        });
    }
    bindLightTargets(object) {
        object.traverse(function(child) {
            if (child.isDirectionalLight || child.isSpotLight) {
                const uuid = child.target;
                const target = object.getObjectByProperty("uuid", uuid);
                if (target !== undefined) child.target = target;
                else child.target = new Object3D();
            }
        });
    }
}
const TEXTURE_MAPPING = {
    UVMapping: UVMapping,
    CubeReflectionMapping: CubeReflectionMapping,
    CubeRefractionMapping: CubeRefractionMapping,
    EquirectangularReflectionMapping: EquirectangularReflectionMapping,
    EquirectangularRefractionMapping: EquirectangularRefractionMapping,
    CubeUVReflectionMapping: CubeUVReflectionMapping
};
const TEXTURE_WRAPPING = {
    RepeatWrapping: RepeatWrapping,
    ClampToEdgeWrapping: ClampToEdgeWrapping,
    MirroredRepeatWrapping: MirroredRepeatWrapping
};
const TEXTURE_FILTER = {
    NearestFilter: NearestFilter,
    NearestMipmapNearestFilter: NearestMipmapNearestFilter,
    NearestMipmapLinearFilter: NearestMipmapLinearFilter,
    LinearFilter: LinearFilter,
    LinearMipmapNearestFilter: LinearMipmapNearestFilter,
    LinearMipmapLinearFilter: LinearMipmapLinearFilter
};
class ImageBitmapLoader extends Loader {
    constructor(manager){
        super(manager);
        this.isImageBitmapLoader = true;
        if (typeof createImageBitmap === "undefined") console.warn("THREE.ImageBitmapLoader: createImageBitmap() not supported.");
        if (typeof fetch === "undefined") console.warn("THREE.ImageBitmapLoader: fetch() not supported.");
        this.options = {
            premultiplyAlpha: "none"
        };
    }
    setOptions(options) {
        this.options = options;
        return this;
    }
    load(url, onLoad, onProgress, onError) {
        if (url === undefined) url = "";
        if (this.path !== undefined) url = this.path + url;
        url = this.manager.resolveURL(url);
        const scope = this;
        const cached = Cache.get(url);
        if (cached !== undefined) {
            scope.manager.itemStart(url);
            // If cached is a promise, wait for it to resolve
            if (cached.then) {
                cached.then((imageBitmap)=>{
                    if (onLoad) onLoad(imageBitmap);
                    scope.manager.itemEnd(url);
                }).catch((e)=>{
                    if (onError) onError(e);
                });
                return;
            }
            // If cached is not a promise (i.e., it's already an imageBitmap)
            setTimeout(function() {
                if (onLoad) onLoad(cached);
                scope.manager.itemEnd(url);
            }, 0);
            return cached;
        }
        const fetchOptions = {};
        fetchOptions.credentials = this.crossOrigin === "anonymous" ? "same-origin" : "include";
        fetchOptions.headers = this.requestHeader;
        const promise = fetch(url, fetchOptions).then(function(res) {
            return res.blob();
        }).then(function(blob) {
            return createImageBitmap(blob, Object.assign(scope.options, {
                colorSpaceConversion: "none"
            }));
        }).then(function(imageBitmap) {
            Cache.add(url, imageBitmap);
            if (onLoad) onLoad(imageBitmap);
            scope.manager.itemEnd(url);
            return imageBitmap;
        }).catch(function(e) {
            if (onError) onError(e);
            Cache.remove(url);
            scope.manager.itemError(url);
            scope.manager.itemEnd(url);
        });
        Cache.add(url, promise);
        scope.manager.itemStart(url);
    }
}
let _context;
class AudioContext {
    static getContext() {
        if (_context === undefined) _context = new (window.AudioContext || window.webkitAudioContext)();
        return _context;
    }
    static setContext(value) {
        _context = value;
    }
}
class AudioLoader extends Loader {
    constructor(manager){
        super(manager);
    }
    load(url, onLoad, onProgress, onError) {
        const scope = this;
        const loader = new FileLoader(this.manager);
        loader.setResponseType("arraybuffer");
        loader.setPath(this.path);
        loader.setRequestHeader(this.requestHeader);
        loader.setWithCredentials(this.withCredentials);
        loader.load(url, function(buffer) {
            try {
                // Create a copy of the buffer. The `decodeAudioData` method
                // detaches the buffer when complete, preventing reuse.
                const bufferCopy = buffer.slice(0);
                const context = AudioContext.getContext();
                context.decodeAudioData(bufferCopy, function(audioBuffer) {
                    onLoad(audioBuffer);
                }).catch(handleError);
            } catch (e) {
                handleError(e);
            }
        }, onProgress, onError);
        function handleError(e) {
            if (onError) onError(e);
            else console.error(e);
            scope.manager.itemError(url);
        }
    }
}
const _eyeRight = /*@__PURE__*/ new Matrix4();
const _eyeLeft = /*@__PURE__*/ new Matrix4();
const _projectionMatrix = /*@__PURE__*/ new Matrix4();
class StereoCamera {
    constructor(){
        this.type = "StereoCamera";
        this.aspect = 1;
        this.eyeSep = 0.064;
        this.cameraL = new PerspectiveCamera();
        this.cameraL.layers.enable(1);
        this.cameraL.matrixAutoUpdate = false;
        this.cameraR = new PerspectiveCamera();
        this.cameraR.layers.enable(2);
        this.cameraR.matrixAutoUpdate = false;
        this._cache = {
            focus: null,
            fov: null,
            aspect: null,
            near: null,
            far: null,
            zoom: null,
            eyeSep: null
        };
    }
    update(camera) {
        const cache = this._cache;
        const needsUpdate = cache.focus !== camera.focus || cache.fov !== camera.fov || cache.aspect !== camera.aspect * this.aspect || cache.near !== camera.near || cache.far !== camera.far || cache.zoom !== camera.zoom || cache.eyeSep !== this.eyeSep;
        if (needsUpdate) {
            cache.focus = camera.focus;
            cache.fov = camera.fov;
            cache.aspect = camera.aspect * this.aspect;
            cache.near = camera.near;
            cache.far = camera.far;
            cache.zoom = camera.zoom;
            cache.eyeSep = this.eyeSep;
            // Off-axis stereoscopic effect based on
            // http://paulbourke.net/stereographics/stereorender/
            _projectionMatrix.copy(camera.projectionMatrix);
            const eyeSepHalf = cache.eyeSep / 2;
            const eyeSepOnProjection = eyeSepHalf * cache.near / cache.focus;
            const ymax = cache.near * Math.tan(DEG2RAD * cache.fov * 0.5) / cache.zoom;
            let xmin, xmax;
            // translate xOffset
            _eyeLeft.elements[12] = -eyeSepHalf;
            _eyeRight.elements[12] = eyeSepHalf;
            // for left eye
            xmin = -ymax * cache.aspect + eyeSepOnProjection;
            xmax = ymax * cache.aspect + eyeSepOnProjection;
            _projectionMatrix.elements[0] = 2 * cache.near / (xmax - xmin);
            _projectionMatrix.elements[8] = (xmax + xmin) / (xmax - xmin);
            this.cameraL.projectionMatrix.copy(_projectionMatrix);
            // for right eye
            xmin = -ymax * cache.aspect - eyeSepOnProjection;
            xmax = ymax * cache.aspect - eyeSepOnProjection;
            _projectionMatrix.elements[0] = 2 * cache.near / (xmax - xmin);
            _projectionMatrix.elements[8] = (xmax + xmin) / (xmax - xmin);
            this.cameraR.projectionMatrix.copy(_projectionMatrix);
        }
        this.cameraL.matrixWorld.copy(camera.matrixWorld).multiply(_eyeLeft);
        this.cameraR.matrixWorld.copy(camera.matrixWorld).multiply(_eyeRight);
    }
}
class Clock {
    constructor(autoStart = true){
        this.autoStart = autoStart;
        this.startTime = 0;
        this.oldTime = 0;
        this.elapsedTime = 0;
        this.running = false;
    }
    start() {
        this.startTime = now();
        this.oldTime = this.startTime;
        this.elapsedTime = 0;
        this.running = true;
    }
    stop() {
        this.getElapsedTime();
        this.running = false;
        this.autoStart = false;
    }
    getElapsedTime() {
        this.getDelta();
        return this.elapsedTime;
    }
    getDelta() {
        let diff = 0;
        if (this.autoStart && !this.running) {
            this.start();
            return 0;
        }
        if (this.running) {
            const newTime = now();
            diff = (newTime - this.oldTime) / 1000;
            this.oldTime = newTime;
            this.elapsedTime += diff;
        }
        return diff;
    }
}
function now() {
    return (typeof performance === "undefined" ? Date : performance).now(); // see #10732
}
const _position$1 = /*@__PURE__*/ new Vector3();
const _quaternion$1 = /*@__PURE__*/ new Quaternion();
const _scale$1 = /*@__PURE__*/ new Vector3();
const _orientation$1 = /*@__PURE__*/ new Vector3();
class AudioListener extends Object3D {
    constructor(){
        super();
        this.type = "AudioListener";
        this.context = AudioContext.getContext();
        this.gain = this.context.createGain();
        this.gain.connect(this.context.destination);
        this.filter = null;
        this.timeDelta = 0;
        // private
        this._clock = new Clock();
    }
    getInput() {
        return this.gain;
    }
    removeFilter() {
        if (this.filter !== null) {
            this.gain.disconnect(this.filter);
            this.filter.disconnect(this.context.destination);
            this.gain.connect(this.context.destination);
            this.filter = null;
        }
        return this;
    }
    getFilter() {
        return this.filter;
    }
    setFilter(value) {
        if (this.filter !== null) {
            this.gain.disconnect(this.filter);
            this.filter.disconnect(this.context.destination);
        } else this.gain.disconnect(this.context.destination);
        this.filter = value;
        this.gain.connect(this.filter);
        this.filter.connect(this.context.destination);
        return this;
    }
    getMasterVolume() {
        return this.gain.gain.value;
    }
    setMasterVolume(value) {
        this.gain.gain.setTargetAtTime(value, this.context.currentTime, 0.01);
        return this;
    }
    updateMatrixWorld(force) {
        super.updateMatrixWorld(force);
        const listener = this.context.listener;
        const up = this.up;
        this.timeDelta = this._clock.getDelta();
        this.matrixWorld.decompose(_position$1, _quaternion$1, _scale$1);
        _orientation$1.set(0, 0, -1).applyQuaternion(_quaternion$1);
        if (listener.positionX) {
            // code path for Chrome (see #14393)
            const endTime = this.context.currentTime + this.timeDelta;
            listener.positionX.linearRampToValueAtTime(_position$1.x, endTime);
            listener.positionY.linearRampToValueAtTime(_position$1.y, endTime);
            listener.positionZ.linearRampToValueAtTime(_position$1.z, endTime);
            listener.forwardX.linearRampToValueAtTime(_orientation$1.x, endTime);
            listener.forwardY.linearRampToValueAtTime(_orientation$1.y, endTime);
            listener.forwardZ.linearRampToValueAtTime(_orientation$1.z, endTime);
            listener.upX.linearRampToValueAtTime(up.x, endTime);
            listener.upY.linearRampToValueAtTime(up.y, endTime);
            listener.upZ.linearRampToValueAtTime(up.z, endTime);
        } else {
            listener.setPosition(_position$1.x, _position$1.y, _position$1.z);
            listener.setOrientation(_orientation$1.x, _orientation$1.y, _orientation$1.z, up.x, up.y, up.z);
        }
    }
}
class Audio extends Object3D {
    constructor(listener){
        super();
        this.type = "Audio";
        this.listener = listener;
        this.context = listener.context;
        this.gain = this.context.createGain();
        this.gain.connect(listener.getInput());
        this.autoplay = false;
        this.buffer = null;
        this.detune = 0;
        this.loop = false;
        this.loopStart = 0;
        this.loopEnd = 0;
        this.offset = 0;
        this.duration = undefined;
        this.playbackRate = 1;
        this.isPlaying = false;
        this.hasPlaybackControl = true;
        this.source = null;
        this.sourceType = "empty";
        this._startedAt = 0;
        this._progress = 0;
        this._connected = false;
        this.filters = [];
    }
    getOutput() {
        return this.gain;
    }
    setNodeSource(audioNode) {
        this.hasPlaybackControl = false;
        this.sourceType = "audioNode";
        this.source = audioNode;
        this.connect();
        return this;
    }
    setMediaElementSource(mediaElement) {
        this.hasPlaybackControl = false;
        this.sourceType = "mediaNode";
        this.source = this.context.createMediaElementSource(mediaElement);
        this.connect();
        return this;
    }
    setMediaStreamSource(mediaStream) {
        this.hasPlaybackControl = false;
        this.sourceType = "mediaStreamNode";
        this.source = this.context.createMediaStreamSource(mediaStream);
        this.connect();
        return this;
    }
    setBuffer(audioBuffer) {
        this.buffer = audioBuffer;
        this.sourceType = "buffer";
        if (this.autoplay) this.play();
        return this;
    }
    play(delay = 0) {
        if (this.isPlaying === true) {
            console.warn("THREE.Audio: Audio is already playing.");
            return;
        }
        if (this.hasPlaybackControl === false) {
            console.warn("THREE.Audio: this Audio has no playback control.");
            return;
        }
        this._startedAt = this.context.currentTime + delay;
        const source = this.context.createBufferSource();
        source.buffer = this.buffer;
        source.loop = this.loop;
        source.loopStart = this.loopStart;
        source.loopEnd = this.loopEnd;
        source.onended = this.onEnded.bind(this);
        source.start(this._startedAt, this._progress + this.offset, this.duration);
        this.isPlaying = true;
        this.source = source;
        this.setDetune(this.detune);
        this.setPlaybackRate(this.playbackRate);
        return this.connect();
    }
    pause() {
        if (this.hasPlaybackControl === false) {
            console.warn("THREE.Audio: this Audio has no playback control.");
            return;
        }
        if (this.isPlaying === true) {
            // update current progress
            this._progress += Math.max(this.context.currentTime - this._startedAt, 0) * this.playbackRate;
            if (this.loop === true) // ensure _progress does not exceed duration with looped audios
            this._progress = this._progress % (this.duration || this.buffer.duration);
            this.source.stop();
            this.source.onended = null;
            this.isPlaying = false;
        }
        return this;
    }
    stop() {
        if (this.hasPlaybackControl === false) {
            console.warn("THREE.Audio: this Audio has no playback control.");
            return;
        }
        this._progress = 0;
        if (this.source !== null) {
            this.source.stop();
            this.source.onended = null;
        }
        this.isPlaying = false;
        return this;
    }
    connect() {
        if (this.filters.length > 0) {
            this.source.connect(this.filters[0]);
            for(let i = 1, l = this.filters.length; i < l; i++)this.filters[i - 1].connect(this.filters[i]);
            this.filters[this.filters.length - 1].connect(this.getOutput());
        } else this.source.connect(this.getOutput());
        this._connected = true;
        return this;
    }
    disconnect() {
        if (this._connected === false) return;
        if (this.filters.length > 0) {
            this.source.disconnect(this.filters[0]);
            for(let i = 1, l = this.filters.length; i < l; i++)this.filters[i - 1].disconnect(this.filters[i]);
            this.filters[this.filters.length - 1].disconnect(this.getOutput());
        } else this.source.disconnect(this.getOutput());
        this._connected = false;
        return this;
    }
    getFilters() {
        return this.filters;
    }
    setFilters(value) {
        if (!value) value = [];
        if (this._connected === true) {
            this.disconnect();
            this.filters = value.slice();
            this.connect();
        } else this.filters = value.slice();
        return this;
    }
    setDetune(value) {
        this.detune = value;
        if (this.isPlaying === true && this.source.detune !== undefined) this.source.detune.setTargetAtTime(this.detune, this.context.currentTime, 0.01);
        return this;
    }
    getDetune() {
        return this.detune;
    }
    getFilter() {
        return this.getFilters()[0];
    }
    setFilter(filter) {
        return this.setFilters(filter ? [
            filter
        ] : []);
    }
    setPlaybackRate(value) {
        if (this.hasPlaybackControl === false) {
            console.warn("THREE.Audio: this Audio has no playback control.");
            return;
        }
        this.playbackRate = value;
        if (this.isPlaying === true) this.source.playbackRate.setTargetAtTime(this.playbackRate, this.context.currentTime, 0.01);
        return this;
    }
    getPlaybackRate() {
        return this.playbackRate;
    }
    onEnded() {
        this.isPlaying = false;
    }
    getLoop() {
        if (this.hasPlaybackControl === false) {
            console.warn("THREE.Audio: this Audio has no playback control.");
            return false;
        }
        return this.loop;
    }
    setLoop(value) {
        if (this.hasPlaybackControl === false) {
            console.warn("THREE.Audio: this Audio has no playback control.");
            return;
        }
        this.loop = value;
        if (this.isPlaying === true) this.source.loop = this.loop;
        return this;
    }
    setLoopStart(value) {
        this.loopStart = value;
        return this;
    }
    setLoopEnd(value) {
        this.loopEnd = value;
        return this;
    }
    getVolume() {
        return this.gain.gain.value;
    }
    setVolume(value) {
        this.gain.gain.setTargetAtTime(value, this.context.currentTime, 0.01);
        return this;
    }
}
const _position = /*@__PURE__*/ new Vector3();
const _quaternion = /*@__PURE__*/ new Quaternion();
const _scale = /*@__PURE__*/ new Vector3();
const _orientation = /*@__PURE__*/ new Vector3();
class PositionalAudio extends Audio {
    constructor(listener){
        super(listener);
        this.panner = this.context.createPanner();
        this.panner.panningModel = "HRTF";
        this.panner.connect(this.gain);
    }
    connect() {
        super.connect();
        this.panner.connect(this.gain);
    }
    disconnect() {
        super.disconnect();
        this.panner.disconnect(this.gain);
    }
    getOutput() {
        return this.panner;
    }
    getRefDistance() {
        return this.panner.refDistance;
    }
    setRefDistance(value) {
        this.panner.refDistance = value;
        return this;
    }
    getRolloffFactor() {
        return this.panner.rolloffFactor;
    }
    setRolloffFactor(value) {
        this.panner.rolloffFactor = value;
        return this;
    }
    getDistanceModel() {
        return this.panner.distanceModel;
    }
    setDistanceModel(value) {
        this.panner.distanceModel = value;
        return this;
    }
    getMaxDistance() {
        return this.panner.maxDistance;
    }
    setMaxDistance(value) {
        this.panner.maxDistance = value;
        return this;
    }
    setDirectionalCone(coneInnerAngle, coneOuterAngle, coneOuterGain) {
        this.panner.coneInnerAngle = coneInnerAngle;
        this.panner.coneOuterAngle = coneOuterAngle;
        this.panner.coneOuterGain = coneOuterGain;
        return this;
    }
    updateMatrixWorld(force) {
        super.updateMatrixWorld(force);
        if (this.hasPlaybackControl === true && this.isPlaying === false) return;
        this.matrixWorld.decompose(_position, _quaternion, _scale);
        _orientation.set(0, 0, 1).applyQuaternion(_quaternion);
        const panner = this.panner;
        if (panner.positionX) {
            // code path for Chrome and Firefox (see #14393)
            const endTime = this.context.currentTime + this.listener.timeDelta;
            panner.positionX.linearRampToValueAtTime(_position.x, endTime);
            panner.positionY.linearRampToValueAtTime(_position.y, endTime);
            panner.positionZ.linearRampToValueAtTime(_position.z, endTime);
            panner.orientationX.linearRampToValueAtTime(_orientation.x, endTime);
            panner.orientationY.linearRampToValueAtTime(_orientation.y, endTime);
            panner.orientationZ.linearRampToValueAtTime(_orientation.z, endTime);
        } else {
            panner.setPosition(_position.x, _position.y, _position.z);
            panner.setOrientation(_orientation.x, _orientation.y, _orientation.z);
        }
    }
}
class AudioAnalyser {
    constructor(audio, fftSize = 2048){
        this.analyser = audio.context.createAnalyser();
        this.analyser.fftSize = fftSize;
        this.data = new Uint8Array(this.analyser.frequencyBinCount);
        audio.getOutput().connect(this.analyser);
    }
    getFrequencyData() {
        this.analyser.getByteFrequencyData(this.data);
        return this.data;
    }
    getAverageFrequency() {
        let value = 0;
        const data = this.getFrequencyData();
        for(let i = 0; i < data.length; i++)value += data[i];
        return value / data.length;
    }
}
class PropertyMixer {
    constructor(binding, typeName, valueSize){
        this.binding = binding;
        this.valueSize = valueSize;
        let mixFunction, mixFunctionAdditive, setIdentity;
        // buffer layout: [ incoming | accu0 | accu1 | orig | addAccu | (optional work) ]
        //
        // interpolators can use .buffer as their .result
        // the data then goes to 'incoming'
        //
        // 'accu0' and 'accu1' are used frame-interleaved for
        // the cumulative result and are compared to detect
        // changes
        //
        // 'orig' stores the original state of the property
        //
        // 'add' is used for additive cumulative results
        //
        // 'work' is optional and is only present for quaternion types. It is used
        // to store intermediate quaternion multiplication results
        switch(typeName){
            case "quaternion":
                mixFunction = this._slerp;
                mixFunctionAdditive = this._slerpAdditive;
                setIdentity = this._setAdditiveIdentityQuaternion;
                this.buffer = new Float64Array(valueSize * 6);
                this._workIndex = 5;
                break;
            case "string":
            case "bool":
                mixFunction = this._select;
                // Use the regular mix function and for additive on these types,
                // additive is not relevant for non-numeric types
                mixFunctionAdditive = this._select;
                setIdentity = this._setAdditiveIdentityOther;
                this.buffer = new Array(valueSize * 5);
                break;
            default:
                mixFunction = this._lerp;
                mixFunctionAdditive = this._lerpAdditive;
                setIdentity = this._setAdditiveIdentityNumeric;
                this.buffer = new Float64Array(valueSize * 5);
        }
        this._mixBufferRegion = mixFunction;
        this._mixBufferRegionAdditive = mixFunctionAdditive;
        this._setIdentity = setIdentity;
        this._origIndex = 3;
        this._addIndex = 4;
        this.cumulativeWeight = 0;
        this.cumulativeWeightAdditive = 0;
        this.useCount = 0;
        this.referenceCount = 0;
    }
    // accumulate data in the 'incoming' region into 'accu<i>'
    accumulate(accuIndex, weight) {
        // note: happily accumulating nothing when weight = 0, the caller knows
        // the weight and shouldn't have made the call in the first place
        const buffer = this.buffer, stride = this.valueSize, offset = accuIndex * stride + stride;
        let currentWeight = this.cumulativeWeight;
        if (currentWeight === 0) {
            // accuN := incoming * weight
            for(let i = 0; i !== stride; ++i)buffer[offset + i] = buffer[i];
            currentWeight = weight;
        } else {
            // accuN := accuN + incoming * weight
            currentWeight += weight;
            const mix = weight / currentWeight;
            this._mixBufferRegion(buffer, offset, 0, mix, stride);
        }
        this.cumulativeWeight = currentWeight;
    }
    // accumulate data in the 'incoming' region into 'add'
    accumulateAdditive(weight) {
        const buffer = this.buffer, stride = this.valueSize, offset = stride * this._addIndex;
        if (this.cumulativeWeightAdditive === 0) // add = identity
        this._setIdentity();
        // add := add + incoming * weight
        this._mixBufferRegionAdditive(buffer, offset, 0, weight, stride);
        this.cumulativeWeightAdditive += weight;
    }
    // apply the state of 'accu<i>' to the binding when accus differ
    apply(accuIndex) {
        const stride = this.valueSize, buffer = this.buffer, offset = accuIndex * stride + stride, weight = this.cumulativeWeight, weightAdditive = this.cumulativeWeightAdditive, binding = this.binding;
        this.cumulativeWeight = 0;
        this.cumulativeWeightAdditive = 0;
        if (weight < 1) {
            // accuN := accuN + original * ( 1 - cumulativeWeight )
            const originalValueOffset = stride * this._origIndex;
            this._mixBufferRegion(buffer, offset, originalValueOffset, 1 - weight, stride);
        }
        if (weightAdditive > 0) // accuN := accuN + additive accuN
        this._mixBufferRegionAdditive(buffer, offset, this._addIndex * stride, 1, stride);
        for(let i = stride, e = stride + stride; i !== e; ++i)if (buffer[i] !== buffer[i + stride]) {
            // value has changed -> update scene graph
            binding.setValue(buffer, offset);
            break;
        }
    }
    // remember the state of the bound property and copy it to both accus
    saveOriginalState() {
        const binding = this.binding;
        const buffer = this.buffer, stride = this.valueSize, originalValueOffset = stride * this._origIndex;
        binding.getValue(buffer, originalValueOffset);
        // accu[0..1] := orig -- initially detect changes against the original
        for(let i = stride, e = originalValueOffset; i !== e; ++i)buffer[i] = buffer[originalValueOffset + i % stride];
        // Add to identity for additive
        this._setIdentity();
        this.cumulativeWeight = 0;
        this.cumulativeWeightAdditive = 0;
    }
    // apply the state previously taken via 'saveOriginalState' to the binding
    restoreOriginalState() {
        const originalValueOffset = this.valueSize * 3;
        this.binding.setValue(this.buffer, originalValueOffset);
    }
    _setAdditiveIdentityNumeric() {
        const startIndex = this._addIndex * this.valueSize;
        const endIndex = startIndex + this.valueSize;
        for(let i = startIndex; i < endIndex; i++)this.buffer[i] = 0;
    }
    _setAdditiveIdentityQuaternion() {
        this._setAdditiveIdentityNumeric();
        this.buffer[this._addIndex * this.valueSize + 3] = 1;
    }
    _setAdditiveIdentityOther() {
        const startIndex = this._origIndex * this.valueSize;
        const targetIndex = this._addIndex * this.valueSize;
        for(let i = 0; i < this.valueSize; i++)this.buffer[targetIndex + i] = this.buffer[startIndex + i];
    }
    // mix functions
    _select(buffer, dstOffset, srcOffset, t, stride) {
        if (t >= 0.5) for(let i = 0; i !== stride; ++i)buffer[dstOffset + i] = buffer[srcOffset + i];
    }
    _slerp(buffer, dstOffset, srcOffset, t) {
        Quaternion.slerpFlat(buffer, dstOffset, buffer, dstOffset, buffer, srcOffset, t);
    }
    _slerpAdditive(buffer, dstOffset, srcOffset, t, stride) {
        const workOffset = this._workIndex * stride;
        // Store result in intermediate buffer offset
        Quaternion.multiplyQuaternionsFlat(buffer, workOffset, buffer, dstOffset, buffer, srcOffset);
        // Slerp to the intermediate result
        Quaternion.slerpFlat(buffer, dstOffset, buffer, dstOffset, buffer, workOffset, t);
    }
    _lerp(buffer, dstOffset, srcOffset, t, stride) {
        const s = 1 - t;
        for(let i = 0; i !== stride; ++i){
            const j = dstOffset + i;
            buffer[j] = buffer[j] * s + buffer[srcOffset + i] * t;
        }
    }
    _lerpAdditive(buffer, dstOffset, srcOffset, t, stride) {
        for(let i = 0; i !== stride; ++i){
            const j = dstOffset + i;
            buffer[j] = buffer[j] + buffer[srcOffset + i] * t;
        }
    }
}
// Characters [].:/ are reserved for track binding syntax.
const _RESERVED_CHARS_RE = "\\[\\]\\.:\\/";
const _reservedRe = new RegExp("[" + _RESERVED_CHARS_RE + "]", "g");
// Attempts to allow node names from any language. ES5's `\w` regexp matches
// only latin characters, and the unicode \p{L} is not yet supported. So
// instead, we exclude reserved characters and match everything else.
const _wordChar = "[^" + _RESERVED_CHARS_RE + "]";
const _wordCharOrDot = "[^" + _RESERVED_CHARS_RE.replace("\\.", "") + "]";
// Parent directories, delimited by '/' or ':'. Currently unused, but must
// be matched to parse the rest of the track name.
const _directoryRe = /*@__PURE__*/ /((?:WC+[\/:])*)/.source.replace("WC", _wordChar);
// Target node. May contain word characters (a-zA-Z0-9_) and '.' or '-'.
const _nodeRe = /*@__PURE__*/ /(WCOD+)?/.source.replace("WCOD", _wordCharOrDot);
// Object on target node, and accessor. May not contain reserved
// characters. Accessor may contain any character except closing bracket.
const _objectRe = /*@__PURE__*/ /(?:\.(WC+)(?:\[(.+)\])?)?/.source.replace("WC", _wordChar);
// Property and accessor. May not contain reserved characters. Accessor may
// contain any non-bracket characters.
const _propertyRe = /*@__PURE__*/ /\.(WC+)(?:\[(.+)\])?/.source.replace("WC", _wordChar);
const _trackRe = new RegExp("^" + _directoryRe + _nodeRe + _objectRe + _propertyRe + "$");
const _supportedObjectNames = [
    "material",
    "materials",
    "bones",
    "map"
];
class Composite {
    constructor(targetGroup, path, optionalParsedPath){
        const parsedPath = optionalParsedPath || PropertyBinding.parseTrackName(path);
        this._targetGroup = targetGroup;
        this._bindings = targetGroup.subscribe_(path, parsedPath);
    }
    getValue(array, offset) {
        this.bind(); // bind all binding
        const firstValidIndex = this._targetGroup.nCachedObjects_, binding = this._bindings[firstValidIndex];
        // and only call .getValue on the first
        if (binding !== undefined) binding.getValue(array, offset);
    }
    setValue(array, offset) {
        const bindings = this._bindings;
        for(let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++i)bindings[i].setValue(array, offset);
    }
    bind() {
        const bindings = this._bindings;
        for(let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++i)bindings[i].bind();
    }
    unbind() {
        const bindings = this._bindings;
        for(let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++i)bindings[i].unbind();
    }
}
// Note: This class uses a State pattern on a per-method basis:
// 'bind' sets 'this.getValue' / 'setValue' and shadows the
// prototype version of these methods with one that represents
// the bound state. When the property is not found, the methods
// become no-ops.
class PropertyBinding {
    constructor(rootNode, path, parsedPath){
        this.path = path;
        this.parsedPath = parsedPath || PropertyBinding.parseTrackName(path);
        this.node = PropertyBinding.findNode(rootNode, this.parsedPath.nodeName);
        this.rootNode = rootNode;
        // initial state of these methods that calls 'bind'
        this.getValue = this._getValue_unbound;
        this.setValue = this._setValue_unbound;
    }
    static create(root, path, parsedPath) {
        if (!(root && root.isAnimationObjectGroup)) return new PropertyBinding(root, path, parsedPath);
        else return new PropertyBinding.Composite(root, path, parsedPath);
    }
    /**
	 * Replaces spaces with underscores and removes unsupported characters from
	 * node names, to ensure compatibility with parseTrackName().
	 *
	 * @param {string} name Node name to be sanitized.
	 * @return {string}
	 */ static sanitizeNodeName(name) {
        return name.replace(/\s/g, "_").replace(_reservedRe, "");
    }
    static parseTrackName(trackName) {
        const matches = _trackRe.exec(trackName);
        if (matches === null) throw new Error("PropertyBinding: Cannot parse trackName: " + trackName);
        const results = {
            // directoryName: matches[ 1 ], // (tschw) currently unused
            nodeName: matches[2],
            objectName: matches[3],
            objectIndex: matches[4],
            propertyName: matches[5],
            propertyIndex: matches[6]
        };
        const lastDot = results.nodeName && results.nodeName.lastIndexOf(".");
        if (lastDot !== undefined && lastDot !== -1) {
            const objectName = results.nodeName.substring(lastDot + 1);
            // Object names must be checked against an allowlist. Otherwise, there
            // is no way to parse 'foo.bar.baz': 'baz' must be a property, but
            // 'bar' could be the objectName, or part of a nodeName (which can
            // include '.' characters).
            if (_supportedObjectNames.indexOf(objectName) !== -1) {
                results.nodeName = results.nodeName.substring(0, lastDot);
                results.objectName = objectName;
            }
        }
        if (results.propertyName === null || results.propertyName.length === 0) throw new Error("PropertyBinding: can not parse propertyName from trackName: " + trackName);
        return results;
    }
    static findNode(root, nodeName) {
        if (nodeName === undefined || nodeName === "" || nodeName === "." || nodeName === -1 || nodeName === root.name || nodeName === root.uuid) return root;
        // search into skeleton bones.
        if (root.skeleton) {
            const bone = root.skeleton.getBoneByName(nodeName);
            if (bone !== undefined) return bone;
        }
        // search into node subtree.
        if (root.children) {
            const searchNodeSubtree = function(children) {
                for(let i = 0; i < children.length; i++){
                    const childNode = children[i];
                    if (childNode.name === nodeName || childNode.uuid === nodeName) return childNode;
                    const result = searchNodeSubtree(childNode.children);
                    if (result) return result;
                }
                return null;
            };
            const subTreeNode = searchNodeSubtree(root.children);
            if (subTreeNode) return subTreeNode;
        }
        return null;
    }
    // these are used to "bind" a nonexistent property
    _getValue_unavailable() {}
    _setValue_unavailable() {}
    // Getters
    _getValue_direct(buffer, offset) {
        buffer[offset] = this.targetObject[this.propertyName];
    }
    _getValue_array(buffer, offset) {
        const source = this.resolvedProperty;
        for(let i = 0, n = source.length; i !== n; ++i)buffer[offset++] = source[i];
    }
    _getValue_arrayElement(buffer, offset) {
        buffer[offset] = this.resolvedProperty[this.propertyIndex];
    }
    _getValue_toArray(buffer, offset) {
        this.resolvedProperty.toArray(buffer, offset);
    }
    // Direct
    _setValue_direct(buffer, offset) {
        this.targetObject[this.propertyName] = buffer[offset];
    }
    _setValue_direct_setNeedsUpdate(buffer, offset) {
        this.targetObject[this.propertyName] = buffer[offset];
        this.targetObject.needsUpdate = true;
    }
    _setValue_direct_setMatrixWorldNeedsUpdate(buffer, offset) {
        this.targetObject[this.propertyName] = buffer[offset];
        this.targetObject.matrixWorldNeedsUpdate = true;
    }
    // EntireArray
    _setValue_array(buffer, offset) {
        const dest = this.resolvedProperty;
        for(let i = 0, n = dest.length; i !== n; ++i)dest[i] = buffer[offset++];
    }
    _setValue_array_setNeedsUpdate(buffer, offset) {
        const dest = this.resolvedProperty;
        for(let i = 0, n = dest.length; i !== n; ++i)dest[i] = buffer[offset++];
        this.targetObject.needsUpdate = true;
    }
    _setValue_array_setMatrixWorldNeedsUpdate(buffer, offset) {
        const dest = this.resolvedProperty;
        for(let i = 0, n = dest.length; i !== n; ++i)dest[i] = buffer[offset++];
        this.targetObject.matrixWorldNeedsUpdate = true;
    }
    // ArrayElement
    _setValue_arrayElement(buffer, offset) {
        this.resolvedProperty[this.propertyIndex] = buffer[offset];
    }
    _setValue_arrayElement_setNeedsUpdate(buffer, offset) {
        this.resolvedProperty[this.propertyIndex] = buffer[offset];
        this.targetObject.needsUpdate = true;
    }
    _setValue_arrayElement_setMatrixWorldNeedsUpdate(buffer, offset) {
        this.resolvedProperty[this.propertyIndex] = buffer[offset];
        this.targetObject.matrixWorldNeedsUpdate = true;
    }
    // HasToFromArray
    _setValue_fromArray(buffer, offset) {
        this.resolvedProperty.fromArray(buffer, offset);
    }
    _setValue_fromArray_setNeedsUpdate(buffer, offset) {
        this.resolvedProperty.fromArray(buffer, offset);
        this.targetObject.needsUpdate = true;
    }
    _setValue_fromArray_setMatrixWorldNeedsUpdate(buffer, offset) {
        this.resolvedProperty.fromArray(buffer, offset);
        this.targetObject.matrixWorldNeedsUpdate = true;
    }
    _getValue_unbound(targetArray, offset) {
        this.bind();
        this.getValue(targetArray, offset);
    }
    _setValue_unbound(sourceArray, offset) {
        this.bind();
        this.setValue(sourceArray, offset);
    }
    // create getter / setter pair for a property in the scene graph
    bind() {
        let targetObject = this.node;
        const parsedPath = this.parsedPath;
        const objectName = parsedPath.objectName;
        const propertyName = parsedPath.propertyName;
        let propertyIndex = parsedPath.propertyIndex;
        if (!targetObject) {
            targetObject = PropertyBinding.findNode(this.rootNode, parsedPath.nodeName);
            this.node = targetObject;
        }
        // set fail state so we can just 'return' on error
        this.getValue = this._getValue_unavailable;
        this.setValue = this._setValue_unavailable;
        // ensure there is a value node
        if (!targetObject) {
            console.warn("THREE.PropertyBinding: No target node found for track: " + this.path + ".");
            return;
        }
        if (objectName) {
            let objectIndex = parsedPath.objectIndex;
            // special cases were we need to reach deeper into the hierarchy to get the face materials....
            switch(objectName){
                case "materials":
                    if (!targetObject.material) {
                        console.error("THREE.PropertyBinding: Can not bind to material as node does not have a material.", this);
                        return;
                    }
                    if (!targetObject.material.materials) {
                        console.error("THREE.PropertyBinding: Can not bind to material.materials as node.material does not have a materials array.", this);
                        return;
                    }
                    targetObject = targetObject.material.materials;
                    break;
                case "bones":
                    if (!targetObject.skeleton) {
                        console.error("THREE.PropertyBinding: Can not bind to bones as node does not have a skeleton.", this);
                        return;
                    }
                    // potential future optimization: skip this if propertyIndex is already an integer
                    // and convert the integer string to a true integer.
                    targetObject = targetObject.skeleton.bones;
                    // support resolving morphTarget names into indices.
                    for(let i = 0; i < targetObject.length; i++)if (targetObject[i].name === objectIndex) {
                        objectIndex = i;
                        break;
                    }
                    break;
                case "map":
                    if ("map" in targetObject) {
                        targetObject = targetObject.map;
                        break;
                    }
                    if (!targetObject.material) {
                        console.error("THREE.PropertyBinding: Can not bind to material as node does not have a material.", this);
                        return;
                    }
                    if (!targetObject.material.map) {
                        console.error("THREE.PropertyBinding: Can not bind to material.map as node.material does not have a map.", this);
                        return;
                    }
                    targetObject = targetObject.material.map;
                    break;
                default:
                    if (targetObject[objectName] === undefined) {
                        console.error("THREE.PropertyBinding: Can not bind to objectName of node undefined.", this);
                        return;
                    }
                    targetObject = targetObject[objectName];
            }
            if (objectIndex !== undefined) {
                if (targetObject[objectIndex] === undefined) {
                    console.error("THREE.PropertyBinding: Trying to bind to objectIndex of objectName, but is undefined.", this, targetObject);
                    return;
                }
                targetObject = targetObject[objectIndex];
            }
        }
        // resolve property
        const nodeProperty = targetObject[propertyName];
        if (nodeProperty === undefined) {
            const nodeName = parsedPath.nodeName;
            console.error("THREE.PropertyBinding: Trying to update property for track: " + nodeName + "." + propertyName + " but it wasn't found.", targetObject);
            return;
        }
        // determine versioning scheme
        let versioning = this.Versioning.None;
        this.targetObject = targetObject;
        if (targetObject.needsUpdate !== undefined) versioning = this.Versioning.NeedsUpdate;
        else if (targetObject.matrixWorldNeedsUpdate !== undefined) versioning = this.Versioning.MatrixWorldNeedsUpdate;
        // determine how the property gets bound
        let bindingType = this.BindingType.Direct;
        if (propertyIndex !== undefined) {
            // access a sub element of the property array (only primitives are supported right now)
            if (propertyName === "morphTargetInfluences") {
                // potential optimization, skip this if propertyIndex is already an integer, and convert the integer string to a true integer.
                // support resolving morphTarget names into indices.
                if (!targetObject.geometry) {
                    console.error("THREE.PropertyBinding: Can not bind to morphTargetInfluences because node does not have a geometry.", this);
                    return;
                }
                if (!targetObject.geometry.morphAttributes) {
                    console.error("THREE.PropertyBinding: Can not bind to morphTargetInfluences because node does not have a geometry.morphAttributes.", this);
                    return;
                }
                if (targetObject.morphTargetDictionary[propertyIndex] !== undefined) propertyIndex = targetObject.morphTargetDictionary[propertyIndex];
            }
            bindingType = this.BindingType.ArrayElement;
            this.resolvedProperty = nodeProperty;
            this.propertyIndex = propertyIndex;
        } else if (nodeProperty.fromArray !== undefined && nodeProperty.toArray !== undefined) {
            // must use copy for Object3D.Euler/Quaternion
            bindingType = this.BindingType.HasFromToArray;
            this.resolvedProperty = nodeProperty;
        } else if (Array.isArray(nodeProperty)) {
            bindingType = this.BindingType.EntireArray;
            this.resolvedProperty = nodeProperty;
        } else this.propertyName = propertyName;
        // select getter / setter
        this.getValue = this.GetterByBindingType[bindingType];
        this.setValue = this.SetterByBindingTypeAndVersioning[bindingType][versioning];
    }
    unbind() {
        this.node = null;
        // back to the prototype version of getValue / setValue
        // note: avoiding to mutate the shape of 'this' via 'delete'
        this.getValue = this._getValue_unbound;
        this.setValue = this._setValue_unbound;
    }
}
PropertyBinding.Composite = Composite;
PropertyBinding.prototype.BindingType = {
    Direct: 0,
    EntireArray: 1,
    ArrayElement: 2,
    HasFromToArray: 3
};
PropertyBinding.prototype.Versioning = {
    None: 0,
    NeedsUpdate: 1,
    MatrixWorldNeedsUpdate: 2
};
PropertyBinding.prototype.GetterByBindingType = [
    PropertyBinding.prototype._getValue_direct,
    PropertyBinding.prototype._getValue_array,
    PropertyBinding.prototype._getValue_arrayElement,
    PropertyBinding.prototype._getValue_toArray
];
PropertyBinding.prototype.SetterByBindingTypeAndVersioning = [
    [
        // Direct
        PropertyBinding.prototype._setValue_direct,
        PropertyBinding.prototype._setValue_direct_setNeedsUpdate,
        PropertyBinding.prototype._setValue_direct_setMatrixWorldNeedsUpdate
    ],
    [
        // EntireArray
        PropertyBinding.prototype._setValue_array,
        PropertyBinding.prototype._setValue_array_setNeedsUpdate,
        PropertyBinding.prototype._setValue_array_setMatrixWorldNeedsUpdate
    ],
    [
        // ArrayElement
        PropertyBinding.prototype._setValue_arrayElement,
        PropertyBinding.prototype._setValue_arrayElement_setNeedsUpdate,
        PropertyBinding.prototype._setValue_arrayElement_setMatrixWorldNeedsUpdate
    ],
    [
        // HasToFromArray
        PropertyBinding.prototype._setValue_fromArray,
        PropertyBinding.prototype._setValue_fromArray_setNeedsUpdate,
        PropertyBinding.prototype._setValue_fromArray_setMatrixWorldNeedsUpdate
    ]
];
/**
 *
 * A group of objects that receives a shared animation state.
 *
 * Usage:
 *
 *  - Add objects you would otherwise pass as 'root' to the
 *    constructor or the .clipAction method of AnimationMixer.
 *
 *  - Instead pass this object as 'root'.
 *
 *  - You can also add and remove objects later when the mixer
 *    is running.
 *
 * Note:
 *
 *    Objects of this class appear as one object to the mixer,
 *    so cache control of the individual objects must be done
 *    on the group.
 *
 * Limitation:
 *
 *  - The animated properties must be compatible among the
 *    all objects in the group.
 *
 *  - A single property can either be controlled through a
 *    target group or directly, but not both.
 */ class AnimationObjectGroup {
    constructor(){
        this.isAnimationObjectGroup = true;
        this.uuid = generateUUID();
        // cached objects followed by the active ones
        this._objects = Array.prototype.slice.call(arguments);
        this.nCachedObjects_ = 0; // threshold
        // note: read by PropertyBinding.Composite
        const indices = {};
        this._indicesByUUID = indices; // for bookkeeping
        for(let i = 0, n = arguments.length; i !== n; ++i)indices[arguments[i].uuid] = i;
        this._paths = []; // inside: string
        this._parsedPaths = []; // inside: { we don't care, here }
        this._bindings = []; // inside: Array< PropertyBinding >
        this._bindingsIndicesByPath = {}; // inside: indices in these arrays
        const scope = this;
        this.stats = {
            objects: {
                get total () {
                    return scope._objects.length;
                },
                get inUse () {
                    return this.total - scope.nCachedObjects_;
                }
            },
            get bindingsPerObject () {
                return scope._bindings.length;
            }
        };
    }
    add() {
        const objects = this._objects, indicesByUUID = this._indicesByUUID, paths = this._paths, parsedPaths = this._parsedPaths, bindings = this._bindings, nBindings = bindings.length;
        let knownObject = undefined, nObjects = objects.length, nCachedObjects = this.nCachedObjects_;
        for(let i = 0, n = arguments.length; i !== n; ++i){
            const object = arguments[i], uuid = object.uuid;
            let index = indicesByUUID[uuid];
            if (index === undefined) {
                // unknown object -> add it to the ACTIVE region
                index = nObjects++;
                indicesByUUID[uuid] = index;
                objects.push(object);
                // accounting is done, now do the same for all bindings
                for(let j = 0, m = nBindings; j !== m; ++j)bindings[j].push(new PropertyBinding(object, paths[j], parsedPaths[j]));
            } else if (index < nCachedObjects) {
                knownObject = objects[index];
                // move existing object to the ACTIVE region
                const firstActiveIndex = --nCachedObjects, lastCachedObject = objects[firstActiveIndex];
                indicesByUUID[lastCachedObject.uuid] = index;
                objects[index] = lastCachedObject;
                indicesByUUID[uuid] = firstActiveIndex;
                objects[firstActiveIndex] = object;
                // accounting is done, now do the same for all bindings
                for(let j = 0, m = nBindings; j !== m; ++j){
                    const bindingsForPath = bindings[j], lastCached = bindingsForPath[firstActiveIndex];
                    let binding = bindingsForPath[index];
                    bindingsForPath[index] = lastCached;
                    if (binding === undefined) // since we do not bother to create new bindings
                    // for objects that are cached, the binding may
                    // or may not exist
                    binding = new PropertyBinding(object, paths[j], parsedPaths[j]);
                    bindingsForPath[firstActiveIndex] = binding;
                }
            } else if (objects[index] !== knownObject) console.error("THREE.AnimationObjectGroup: Different objects with the same UUID detected. Clean the caches or recreate your infrastructure when reloading scenes.");
             // else the object is already where we want it to be
        } // for arguments
        this.nCachedObjects_ = nCachedObjects;
    }
    remove() {
        const objects = this._objects, indicesByUUID = this._indicesByUUID, bindings = this._bindings, nBindings = bindings.length;
        let nCachedObjects = this.nCachedObjects_;
        for(let i = 0, n = arguments.length; i !== n; ++i){
            const object = arguments[i], uuid = object.uuid, index = indicesByUUID[uuid];
            if (index !== undefined && index >= nCachedObjects) {
                // move existing object into the CACHED region
                const lastCachedIndex = nCachedObjects++, firstActiveObject = objects[lastCachedIndex];
                indicesByUUID[firstActiveObject.uuid] = index;
                objects[index] = firstActiveObject;
                indicesByUUID[uuid] = lastCachedIndex;
                objects[lastCachedIndex] = object;
                // accounting is done, now do the same for all bindings
                for(let j = 0, m = nBindings; j !== m; ++j){
                    const bindingsForPath = bindings[j], firstActive = bindingsForPath[lastCachedIndex], binding = bindingsForPath[index];
                    bindingsForPath[index] = firstActive;
                    bindingsForPath[lastCachedIndex] = binding;
                }
            }
        } // for arguments
        this.nCachedObjects_ = nCachedObjects;
    }
    // remove & forget
    uncache() {
        const objects = this._objects, indicesByUUID = this._indicesByUUID, bindings = this._bindings, nBindings = bindings.length;
        let nCachedObjects = this.nCachedObjects_, nObjects = objects.length;
        for(let i = 0, n = arguments.length; i !== n; ++i){
            const object = arguments[i], uuid = object.uuid, index = indicesByUUID[uuid];
            if (index !== undefined) {
                delete indicesByUUID[uuid];
                if (index < nCachedObjects) {
                    // object is cached, shrink the CACHED region
                    const firstActiveIndex = --nCachedObjects, lastCachedObject = objects[firstActiveIndex], lastIndex = --nObjects, lastObject = objects[lastIndex];
                    // last cached object takes this object's place
                    indicesByUUID[lastCachedObject.uuid] = index;
                    objects[index] = lastCachedObject;
                    // last object goes to the activated slot and pop
                    indicesByUUID[lastObject.uuid] = firstActiveIndex;
                    objects[firstActiveIndex] = lastObject;
                    objects.pop();
                    // accounting is done, now do the same for all bindings
                    for(let j = 0, m = nBindings; j !== m; ++j){
                        const bindingsForPath = bindings[j], lastCached = bindingsForPath[firstActiveIndex], last = bindingsForPath[lastIndex];
                        bindingsForPath[index] = lastCached;
                        bindingsForPath[firstActiveIndex] = last;
                        bindingsForPath.pop();
                    }
                } else {
                    // object is active, just swap with the last and pop
                    const lastIndex = --nObjects, lastObject = objects[lastIndex];
                    if (lastIndex > 0) indicesByUUID[lastObject.uuid] = index;
                    objects[index] = lastObject;
                    objects.pop();
                    // accounting is done, now do the same for all bindings
                    for(let j = 0, m = nBindings; j !== m; ++j){
                        const bindingsForPath = bindings[j];
                        bindingsForPath[index] = bindingsForPath[lastIndex];
                        bindingsForPath.pop();
                    }
                } // cached or active
            } // if object is known
        } // for arguments
        this.nCachedObjects_ = nCachedObjects;
    }
    // Internal interface used by befriended PropertyBinding.Composite:
    subscribe_(path, parsedPath) {
        // returns an array of bindings for the given path that is changed
        // according to the contained objects in the group
        const indicesByPath = this._bindingsIndicesByPath;
        let index = indicesByPath[path];
        const bindings = this._bindings;
        if (index !== undefined) return bindings[index];
        const paths = this._paths, parsedPaths = this._parsedPaths, objects = this._objects, nObjects = objects.length, nCachedObjects = this.nCachedObjects_, bindingsForPath = new Array(nObjects);
        index = bindings.length;
        indicesByPath[path] = index;
        paths.push(path);
        parsedPaths.push(parsedPath);
        bindings.push(bindingsForPath);
        for(let i = nCachedObjects, n = objects.length; i !== n; ++i){
            const object = objects[i];
            bindingsForPath[i] = new PropertyBinding(object, path, parsedPath);
        }
        return bindingsForPath;
    }
    unsubscribe_(path) {
        // tells the group to forget about a property path and no longer
        // update the array previously obtained with 'subscribe_'
        const indicesByPath = this._bindingsIndicesByPath, index = indicesByPath[path];
        if (index !== undefined) {
            const paths = this._paths, parsedPaths = this._parsedPaths, bindings = this._bindings, lastBindingsIndex = bindings.length - 1, lastBindings = bindings[lastBindingsIndex], lastBindingsPath = path[lastBindingsIndex];
            indicesByPath[lastBindingsPath] = index;
            bindings[index] = lastBindings;
            bindings.pop();
            parsedPaths[index] = parsedPaths[lastBindingsIndex];
            parsedPaths.pop();
            paths[index] = paths[lastBindingsIndex];
            paths.pop();
        }
    }
}
class AnimationAction {
    constructor(mixer, clip, localRoot = null, blendMode = clip.blendMode){
        this._mixer = mixer;
        this._clip = clip;
        this._localRoot = localRoot;
        this.blendMode = blendMode;
        const tracks = clip.tracks, nTracks = tracks.length, interpolants = new Array(nTracks);
        const interpolantSettings = {
            endingStart: ZeroCurvatureEnding,
            endingEnd: ZeroCurvatureEnding
        };
        for(let i = 0; i !== nTracks; ++i){
            const interpolant = tracks[i].createInterpolant(null);
            interpolants[i] = interpolant;
            interpolant.settings = interpolantSettings;
        }
        this._interpolantSettings = interpolantSettings;
        this._interpolants = interpolants; // bound by the mixer
        // inside: PropertyMixer (managed by the mixer)
        this._propertyBindings = new Array(nTracks);
        this._cacheIndex = null; // for the memory manager
        this._byClipCacheIndex = null; // for the memory manager
        this._timeScaleInterpolant = null;
        this._weightInterpolant = null;
        this.loop = LoopRepeat;
        this._loopCount = -1;
        // global mixer time when the action is to be started
        // it's set back to 'null' upon start of the action
        this._startTime = null;
        // scaled local time of the action
        // gets clamped or wrapped to 0..clip.duration according to loop
        this.time = 0;
        this.timeScale = 1;
        this._effectiveTimeScale = 1;
        this.weight = 1;
        this._effectiveWeight = 1;
        this.repetitions = Infinity; // no. of repetitions when looping
        this.paused = false; // true -> zero effective time scale
        this.enabled = true; // false -> zero effective weight
        this.clampWhenFinished = false; // keep feeding the last frame?
        this.zeroSlopeAtStart = true; // for smooth interpolation w/o separate
        this.zeroSlopeAtEnd = true; // clips for start, loop and end
    }
    // State & Scheduling
    play() {
        this._mixer._activateAction(this);
        return this;
    }
    stop() {
        this._mixer._deactivateAction(this);
        return this.reset();
    }
    reset() {
        this.paused = false;
        this.enabled = true;
        this.time = 0; // restart clip
        this._loopCount = -1; // forget previous loops
        this._startTime = null; // forget scheduling
        return this.stopFading().stopWarping();
    }
    isRunning() {
        return this.enabled && !this.paused && this.timeScale !== 0 && this._startTime === null && this._mixer._isActiveAction(this);
    }
    // return true when play has been called
    isScheduled() {
        return this._mixer._isActiveAction(this);
    }
    startAt(time) {
        this._startTime = time;
        return this;
    }
    setLoop(mode, repetitions) {
        this.loop = mode;
        this.repetitions = repetitions;
        return this;
    }
    // Weight
    // set the weight stopping any scheduled fading
    // although .enabled = false yields an effective weight of zero, this
    // method does *not* change .enabled, because it would be confusing
    setEffectiveWeight(weight) {
        this.weight = weight;
        // note: same logic as when updated at runtime
        this._effectiveWeight = this.enabled ? weight : 0;
        return this.stopFading();
    }
    // return the weight considering fading and .enabled
    getEffectiveWeight() {
        return this._effectiveWeight;
    }
    fadeIn(duration) {
        return this._scheduleFading(duration, 0, 1);
    }
    fadeOut(duration) {
        return this._scheduleFading(duration, 1, 0);
    }
    crossFadeFrom(fadeOutAction, duration, warp) {
        fadeOutAction.fadeOut(duration);
        this.fadeIn(duration);
        if (warp) {
            const fadeInDuration = this._clip.duration, fadeOutDuration = fadeOutAction._clip.duration, startEndRatio = fadeOutDuration / fadeInDuration, endStartRatio = fadeInDuration / fadeOutDuration;
            fadeOutAction.warp(1.0, startEndRatio, duration);
            this.warp(endStartRatio, 1.0, duration);
        }
        return this;
    }
    crossFadeTo(fadeInAction, duration, warp) {
        return fadeInAction.crossFadeFrom(this, duration, warp);
    }
    stopFading() {
        const weightInterpolant = this._weightInterpolant;
        if (weightInterpolant !== null) {
            this._weightInterpolant = null;
            this._mixer._takeBackControlInterpolant(weightInterpolant);
        }
        return this;
    }
    // Time Scale Control
    // set the time scale stopping any scheduled warping
    // although .paused = true yields an effective time scale of zero, this
    // method does *not* change .paused, because it would be confusing
    setEffectiveTimeScale(timeScale) {
        this.timeScale = timeScale;
        this._effectiveTimeScale = this.paused ? 0 : timeScale;
        return this.stopWarping();
    }
    // return the time scale considering warping and .paused
    getEffectiveTimeScale() {
        return this._effectiveTimeScale;
    }
    setDuration(duration) {
        this.timeScale = this._clip.duration / duration;
        return this.stopWarping();
    }
    syncWith(action) {
        this.time = action.time;
        this.timeScale = action.timeScale;
        return this.stopWarping();
    }
    halt(duration) {
        return this.warp(this._effectiveTimeScale, 0, duration);
    }
    warp(startTimeScale, endTimeScale, duration) {
        const mixer = this._mixer, now = mixer.time, timeScale = this.timeScale;
        let interpolant = this._timeScaleInterpolant;
        if (interpolant === null) {
            interpolant = mixer._lendControlInterpolant();
            this._timeScaleInterpolant = interpolant;
        }
        const times = interpolant.parameterPositions, values = interpolant.sampleValues;
        times[0] = now;
        times[1] = now + duration;
        values[0] = startTimeScale / timeScale;
        values[1] = endTimeScale / timeScale;
        return this;
    }
    stopWarping() {
        const timeScaleInterpolant = this._timeScaleInterpolant;
        if (timeScaleInterpolant !== null) {
            this._timeScaleInterpolant = null;
            this._mixer._takeBackControlInterpolant(timeScaleInterpolant);
        }
        return this;
    }
    // Object Accessors
    getMixer() {
        return this._mixer;
    }
    getClip() {
        return this._clip;
    }
    getRoot() {
        return this._localRoot || this._mixer._root;
    }
    // Interna
    _update(time, deltaTime, timeDirection, accuIndex) {
        // called by the mixer
        if (!this.enabled) {
            // call ._updateWeight() to update ._effectiveWeight
            this._updateWeight(time);
            return;
        }
        const startTime = this._startTime;
        if (startTime !== null) {
            // check for scheduled start of action
            const timeRunning = (time - startTime) * timeDirection;
            if (timeRunning < 0 || timeDirection === 0) deltaTime = 0;
            else {
                this._startTime = null; // unschedule
                deltaTime = timeDirection * timeRunning;
            }
        }
        // apply time scale and advance time
        deltaTime *= this._updateTimeScale(time);
        const clipTime = this._updateTime(deltaTime);
        // note: _updateTime may disable the action resulting in
        // an effective weight of 0
        const weight = this._updateWeight(time);
        if (weight > 0) {
            const interpolants = this._interpolants;
            const propertyMixers = this._propertyBindings;
            switch(this.blendMode){
                case AdditiveAnimationBlendMode:
                    for(let j = 0, m = interpolants.length; j !== m; ++j){
                        interpolants[j].evaluate(clipTime);
                        propertyMixers[j].accumulateAdditive(weight);
                    }
                    break;
                case NormalAnimationBlendMode:
                default:
                    for(let j = 0, m = interpolants.length; j !== m; ++j){
                        interpolants[j].evaluate(clipTime);
                        propertyMixers[j].accumulate(accuIndex, weight);
                    }
            }
        }
    }
    _updateWeight(time) {
        let weight = 0;
        if (this.enabled) {
            weight = this.weight;
            const interpolant = this._weightInterpolant;
            if (interpolant !== null) {
                const interpolantValue = interpolant.evaluate(time)[0];
                weight *= interpolantValue;
                if (time > interpolant.parameterPositions[1]) {
                    this.stopFading();
                    if (interpolantValue === 0) // faded out, disable
                    this.enabled = false;
                }
            }
        }
        this._effectiveWeight = weight;
        return weight;
    }
    _updateTimeScale(time) {
        let timeScale = 0;
        if (!this.paused) {
            timeScale = this.timeScale;
            const interpolant = this._timeScaleInterpolant;
            if (interpolant !== null) {
                const interpolantValue = interpolant.evaluate(time)[0];
                timeScale *= interpolantValue;
                if (time > interpolant.parameterPositions[1]) {
                    this.stopWarping();
                    if (timeScale === 0) // motion has halted, pause
                    this.paused = true;
                    else // warp done - apply final time scale
                    this.timeScale = timeScale;
                }
            }
        }
        this._effectiveTimeScale = timeScale;
        return timeScale;
    }
    _updateTime(deltaTime) {
        const duration = this._clip.duration;
        const loop = this.loop;
        let time = this.time + deltaTime;
        let loopCount = this._loopCount;
        const pingPong = loop === LoopPingPong;
        if (deltaTime === 0) {
            if (loopCount === -1) return time;
            return pingPong && (loopCount & 1) === 1 ? duration - time : time;
        }
        if (loop === LoopOnce) {
            if (loopCount === -1) {
                // just started
                this._loopCount = 0;
                this._setEndings(true, true, false);
            }
            handle_stop: {
                if (time >= duration) time = duration;
                else if (time < 0) time = 0;
                else {
                    this.time = time;
                    break handle_stop;
                }
                if (this.clampWhenFinished) this.paused = true;
                else this.enabled = false;
                this.time = time;
                this._mixer.dispatchEvent({
                    type: "finished",
                    action: this,
                    direction: deltaTime < 0 ? -1 : 1
                });
            }
        } else {
            if (loopCount === -1) {
                // just started
                if (deltaTime >= 0) {
                    loopCount = 0;
                    this._setEndings(true, this.repetitions === 0, pingPong);
                } else // when looping in reverse direction, the initial
                // transition through zero counts as a repetition,
                // so leave loopCount at -1
                this._setEndings(this.repetitions === 0, true, pingPong);
            }
            if (time >= duration || time < 0) {
                // wrap around
                const loopDelta = Math.floor(time / duration); // signed
                time -= duration * loopDelta;
                loopCount += Math.abs(loopDelta);
                const pending = this.repetitions - loopCount;
                if (pending <= 0) {
                    // have to stop (switch state, clamp time, fire event)
                    if (this.clampWhenFinished) this.paused = true;
                    else this.enabled = false;
                    time = deltaTime > 0 ? duration : 0;
                    this.time = time;
                    this._mixer.dispatchEvent({
                        type: "finished",
                        action: this,
                        direction: deltaTime > 0 ? 1 : -1
                    });
                } else {
                    // keep running
                    if (pending === 1) {
                        // entering the last round
                        const atStart = deltaTime < 0;
                        this._setEndings(atStart, !atStart, pingPong);
                    } else this._setEndings(false, false, pingPong);
                    this._loopCount = loopCount;
                    this.time = time;
                    this._mixer.dispatchEvent({
                        type: "loop",
                        action: this,
                        loopDelta: loopDelta
                    });
                }
            } else this.time = time;
            if (pingPong && (loopCount & 1) === 1) // invert time for the "pong round"
            return duration - time;
        }
        return time;
    }
    _setEndings(atStart, atEnd, pingPong) {
        const settings = this._interpolantSettings;
        if (pingPong) {
            settings.endingStart = ZeroSlopeEnding;
            settings.endingEnd = ZeroSlopeEnding;
        } else {
            // assuming for LoopOnce atStart == atEnd == true
            if (atStart) settings.endingStart = this.zeroSlopeAtStart ? ZeroSlopeEnding : ZeroCurvatureEnding;
            else settings.endingStart = WrapAroundEnding;
            if (atEnd) settings.endingEnd = this.zeroSlopeAtEnd ? ZeroSlopeEnding : ZeroCurvatureEnding;
            else settings.endingEnd = WrapAroundEnding;
        }
    }
    _scheduleFading(duration, weightNow, weightThen) {
        const mixer = this._mixer, now = mixer.time;
        let interpolant = this._weightInterpolant;
        if (interpolant === null) {
            interpolant = mixer._lendControlInterpolant();
            this._weightInterpolant = interpolant;
        }
        const times = interpolant.parameterPositions, values = interpolant.sampleValues;
        times[0] = now;
        values[0] = weightNow;
        times[1] = now + duration;
        values[1] = weightThen;
        return this;
    }
}
const _controlInterpolantsResultBuffer = new Float32Array(1);
class AnimationMixer extends EventDispatcher {
    constructor(root){
        super();
        this._root = root;
        this._initMemoryManager();
        this._accuIndex = 0;
        this.time = 0;
        this.timeScale = 1.0;
    }
    _bindAction(action, prototypeAction) {
        const root = action._localRoot || this._root, tracks = action._clip.tracks, nTracks = tracks.length, bindings = action._propertyBindings, interpolants = action._interpolants, rootUuid = root.uuid, bindingsByRoot = this._bindingsByRootAndName;
        let bindingsByName = bindingsByRoot[rootUuid];
        if (bindingsByName === undefined) {
            bindingsByName = {};
            bindingsByRoot[rootUuid] = bindingsByName;
        }
        for(let i = 0; i !== nTracks; ++i){
            const track = tracks[i], trackName = track.name;
            let binding = bindingsByName[trackName];
            if (binding !== undefined) {
                ++binding.referenceCount;
                bindings[i] = binding;
            } else {
                binding = bindings[i];
                if (binding !== undefined) {
                    // existing binding, make sure the cache knows
                    if (binding._cacheIndex === null) {
                        ++binding.referenceCount;
                        this._addInactiveBinding(binding, rootUuid, trackName);
                    }
                    continue;
                }
                const path = prototypeAction && prototypeAction._propertyBindings[i].binding.parsedPath;
                binding = new PropertyMixer(PropertyBinding.create(root, trackName, path), track.ValueTypeName, track.getValueSize());
                ++binding.referenceCount;
                this._addInactiveBinding(binding, rootUuid, trackName);
                bindings[i] = binding;
            }
            interpolants[i].resultBuffer = binding.buffer;
        }
    }
    _activateAction(action) {
        if (!this._isActiveAction(action)) {
            if (action._cacheIndex === null) {
                // this action has been forgotten by the cache, but the user
                // appears to be still using it -> rebind
                const rootUuid = (action._localRoot || this._root).uuid, clipUuid = action._clip.uuid, actionsForClip = this._actionsByClip[clipUuid];
                this._bindAction(action, actionsForClip && actionsForClip.knownActions[0]);
                this._addInactiveAction(action, clipUuid, rootUuid);
            }
            const bindings = action._propertyBindings;
            // increment reference counts / sort out state
            for(let i = 0, n = bindings.length; i !== n; ++i){
                const binding = bindings[i];
                if (binding.useCount++ === 0) {
                    this._lendBinding(binding);
                    binding.saveOriginalState();
                }
            }
            this._lendAction(action);
        }
    }
    _deactivateAction(action) {
        if (this._isActiveAction(action)) {
            const bindings = action._propertyBindings;
            // decrement reference counts / sort out state
            for(let i = 0, n = bindings.length; i !== n; ++i){
                const binding = bindings[i];
                if (--binding.useCount === 0) {
                    binding.restoreOriginalState();
                    this._takeBackBinding(binding);
                }
            }
            this._takeBackAction(action);
        }
    }
    // Memory manager
    _initMemoryManager() {
        this._actions = []; // 'nActiveActions' followed by inactive ones
        this._nActiveActions = 0;
        this._actionsByClip = {};
        // inside:
        // {
        // 	knownActions: Array< AnimationAction > - used as prototypes
        // 	actionByRoot: AnimationAction - lookup
        // }
        this._bindings = []; // 'nActiveBindings' followed by inactive ones
        this._nActiveBindings = 0;
        this._bindingsByRootAndName = {}; // inside: Map< name, PropertyMixer >
        this._controlInterpolants = []; // same game as above
        this._nActiveControlInterpolants = 0;
        const scope = this;
        this.stats = {
            actions: {
                get total () {
                    return scope._actions.length;
                },
                get inUse () {
                    return scope._nActiveActions;
                }
            },
            bindings: {
                get total () {
                    return scope._bindings.length;
                },
                get inUse () {
                    return scope._nActiveBindings;
                }
            },
            controlInterpolants: {
                get total () {
                    return scope._controlInterpolants.length;
                },
                get inUse () {
                    return scope._nActiveControlInterpolants;
                }
            }
        };
    }
    // Memory management for AnimationAction objects
    _isActiveAction(action) {
        const index = action._cacheIndex;
        return index !== null && index < this._nActiveActions;
    }
    _addInactiveAction(action, clipUuid, rootUuid) {
        const actions = this._actions, actionsByClip = this._actionsByClip;
        let actionsForClip = actionsByClip[clipUuid];
        if (actionsForClip === undefined) {
            actionsForClip = {
                knownActions: [
                    action
                ],
                actionByRoot: {}
            };
            action._byClipCacheIndex = 0;
            actionsByClip[clipUuid] = actionsForClip;
        } else {
            const knownActions = actionsForClip.knownActions;
            action._byClipCacheIndex = knownActions.length;
            knownActions.push(action);
        }
        action._cacheIndex = actions.length;
        actions.push(action);
        actionsForClip.actionByRoot[rootUuid] = action;
    }
    _removeInactiveAction(action) {
        const actions = this._actions, lastInactiveAction = actions[actions.length - 1], cacheIndex = action._cacheIndex;
        lastInactiveAction._cacheIndex = cacheIndex;
        actions[cacheIndex] = lastInactiveAction;
        actions.pop();
        action._cacheIndex = null;
        const clipUuid = action._clip.uuid, actionsByClip = this._actionsByClip, actionsForClip = actionsByClip[clipUuid], knownActionsForClip = actionsForClip.knownActions, lastKnownAction = knownActionsForClip[knownActionsForClip.length - 1], byClipCacheIndex = action._byClipCacheIndex;
        lastKnownAction._byClipCacheIndex = byClipCacheIndex;
        knownActionsForClip[byClipCacheIndex] = lastKnownAction;
        knownActionsForClip.pop();
        action._byClipCacheIndex = null;
        const actionByRoot = actionsForClip.actionByRoot, rootUuid = (action._localRoot || this._root).uuid;
        delete actionByRoot[rootUuid];
        if (knownActionsForClip.length === 0) delete actionsByClip[clipUuid];
        this._removeInactiveBindingsForAction(action);
    }
    _removeInactiveBindingsForAction(action) {
        const bindings = action._propertyBindings;
        for(let i = 0, n = bindings.length; i !== n; ++i){
            const binding = bindings[i];
            if (--binding.referenceCount === 0) this._removeInactiveBinding(binding);
        }
    }
    _lendAction(action) {
        // [ active actions |  inactive actions  ]
        // [  active actions >| inactive actions ]
        //                 s        a
        //                  <-swap->
        //                 a        s
        const actions = this._actions, prevIndex = action._cacheIndex, lastActiveIndex = this._nActiveActions++, firstInactiveAction = actions[lastActiveIndex];
        action._cacheIndex = lastActiveIndex;
        actions[lastActiveIndex] = action;
        firstInactiveAction._cacheIndex = prevIndex;
        actions[prevIndex] = firstInactiveAction;
    }
    _takeBackAction(action) {
        // [  active actions  | inactive actions ]
        // [ active actions |< inactive actions  ]
        //        a        s
        //         <-swap->
        //        s        a
        const actions = this._actions, prevIndex = action._cacheIndex, firstInactiveIndex = --this._nActiveActions, lastActiveAction = actions[firstInactiveIndex];
        action._cacheIndex = firstInactiveIndex;
        actions[firstInactiveIndex] = action;
        lastActiveAction._cacheIndex = prevIndex;
        actions[prevIndex] = lastActiveAction;
    }
    // Memory management for PropertyMixer objects
    _addInactiveBinding(binding, rootUuid, trackName) {
        const bindingsByRoot = this._bindingsByRootAndName, bindings = this._bindings;
        let bindingByName = bindingsByRoot[rootUuid];
        if (bindingByName === undefined) {
            bindingByName = {};
            bindingsByRoot[rootUuid] = bindingByName;
        }
        bindingByName[trackName] = binding;
        binding._cacheIndex = bindings.length;
        bindings.push(binding);
    }
    _removeInactiveBinding(binding) {
        const bindings = this._bindings, propBinding = binding.binding, rootUuid = propBinding.rootNode.uuid, trackName = propBinding.path, bindingsByRoot = this._bindingsByRootAndName, bindingByName = bindingsByRoot[rootUuid], lastInactiveBinding = bindings[bindings.length - 1], cacheIndex = binding._cacheIndex;
        lastInactiveBinding._cacheIndex = cacheIndex;
        bindings[cacheIndex] = lastInactiveBinding;
        bindings.pop();
        delete bindingByName[trackName];
        if (Object.keys(bindingByName).length === 0) delete bindingsByRoot[rootUuid];
    }
    _lendBinding(binding) {
        const bindings = this._bindings, prevIndex = binding._cacheIndex, lastActiveIndex = this._nActiveBindings++, firstInactiveBinding = bindings[lastActiveIndex];
        binding._cacheIndex = lastActiveIndex;
        bindings[lastActiveIndex] = binding;
        firstInactiveBinding._cacheIndex = prevIndex;
        bindings[prevIndex] = firstInactiveBinding;
    }
    _takeBackBinding(binding) {
        const bindings = this._bindings, prevIndex = binding._cacheIndex, firstInactiveIndex = --this._nActiveBindings, lastActiveBinding = bindings[firstInactiveIndex];
        binding._cacheIndex = firstInactiveIndex;
        bindings[firstInactiveIndex] = binding;
        lastActiveBinding._cacheIndex = prevIndex;
        bindings[prevIndex] = lastActiveBinding;
    }
    // Memory management of Interpolants for weight and time scale
    _lendControlInterpolant() {
        const interpolants = this._controlInterpolants, lastActiveIndex = this._nActiveControlInterpolants++;
        let interpolant = interpolants[lastActiveIndex];
        if (interpolant === undefined) {
            interpolant = new LinearInterpolant(new Float32Array(2), new Float32Array(2), 1, _controlInterpolantsResultBuffer);
            interpolant.__cacheIndex = lastActiveIndex;
            interpolants[lastActiveIndex] = interpolant;
        }
        return interpolant;
    }
    _takeBackControlInterpolant(interpolant) {
        const interpolants = this._controlInterpolants, prevIndex = interpolant.__cacheIndex, firstInactiveIndex = --this._nActiveControlInterpolants, lastActiveInterpolant = interpolants[firstInactiveIndex];
        interpolant.__cacheIndex = firstInactiveIndex;
        interpolants[firstInactiveIndex] = interpolant;
        lastActiveInterpolant.__cacheIndex = prevIndex;
        interpolants[prevIndex] = lastActiveInterpolant;
    }
    // return an action for a clip optionally using a custom root target
    // object (this method allocates a lot of dynamic memory in case a
    // previously unknown clip/root combination is specified)
    clipAction(clip, optionalRoot, blendMode) {
        const root = optionalRoot || this._root, rootUuid = root.uuid;
        let clipObject = typeof clip === "string" ? AnimationClip.findByName(root, clip) : clip;
        const clipUuid = clipObject !== null ? clipObject.uuid : clip;
        const actionsForClip = this._actionsByClip[clipUuid];
        let prototypeAction = null;
        if (blendMode === undefined) {
            if (clipObject !== null) blendMode = clipObject.blendMode;
            else blendMode = NormalAnimationBlendMode;
        }
        if (actionsForClip !== undefined) {
            const existingAction = actionsForClip.actionByRoot[rootUuid];
            if (existingAction !== undefined && existingAction.blendMode === blendMode) return existingAction;
            // we know the clip, so we don't have to parse all
            // the bindings again but can just copy
            prototypeAction = actionsForClip.knownActions[0];
            // also, take the clip from the prototype action
            if (clipObject === null) clipObject = prototypeAction._clip;
        }
        // clip must be known when specified via string
        if (clipObject === null) return null;
        // allocate all resources required to run it
        const newAction = new AnimationAction(this, clipObject, optionalRoot, blendMode);
        this._bindAction(newAction, prototypeAction);
        // and make the action known to the memory manager
        this._addInactiveAction(newAction, clipUuid, rootUuid);
        return newAction;
    }
    // get an existing action
    existingAction(clip, optionalRoot) {
        const root = optionalRoot || this._root, rootUuid = root.uuid, clipObject = typeof clip === "string" ? AnimationClip.findByName(root, clip) : clip, clipUuid = clipObject ? clipObject.uuid : clip, actionsForClip = this._actionsByClip[clipUuid];
        if (actionsForClip !== undefined) return actionsForClip.actionByRoot[rootUuid] || null;
        return null;
    }
    // deactivates all previously scheduled actions
    stopAllAction() {
        const actions = this._actions, nActions = this._nActiveActions;
        for(let i = nActions - 1; i >= 0; --i)actions[i].stop();
        return this;
    }
    // advance the time and update apply the animation
    update(deltaTime) {
        deltaTime *= this.timeScale;
        const actions = this._actions, nActions = this._nActiveActions, time = this.time += deltaTime, timeDirection = Math.sign(deltaTime), accuIndex = this._accuIndex ^= 1;
        // run active actions
        for(let i = 0; i !== nActions; ++i){
            const action = actions[i];
            action._update(time, deltaTime, timeDirection, accuIndex);
        }
        // update scene graph
        const bindings = this._bindings, nBindings = this._nActiveBindings;
        for(let i = 0; i !== nBindings; ++i)bindings[i].apply(accuIndex);
        return this;
    }
    // Allows you to seek to a specific time in an animation.
    setTime(timeInSeconds) {
        this.time = 0; // Zero out time attribute for AnimationMixer object;
        for(let i = 0; i < this._actions.length; i++)this._actions[i].time = 0; // Zero out time attribute for all associated AnimationAction objects.
        return this.update(timeInSeconds); // Update used to set exact time. Returns "this" AnimationMixer object.
    }
    // return this mixer's root target object
    getRoot() {
        return this._root;
    }
    // free all resources specific to a particular clip
    uncacheClip(clip) {
        const actions = this._actions, clipUuid = clip.uuid, actionsByClip = this._actionsByClip, actionsForClip = actionsByClip[clipUuid];
        if (actionsForClip !== undefined) {
            // note: just calling _removeInactiveAction would mess up the
            // iteration state and also require updating the state we can
            // just throw away
            const actionsToRemove = actionsForClip.knownActions;
            for(let i = 0, n = actionsToRemove.length; i !== n; ++i){
                const action = actionsToRemove[i];
                this._deactivateAction(action);
                const cacheIndex = action._cacheIndex, lastInactiveAction = actions[actions.length - 1];
                action._cacheIndex = null;
                action._byClipCacheIndex = null;
                lastInactiveAction._cacheIndex = cacheIndex;
                actions[cacheIndex] = lastInactiveAction;
                actions.pop();
                this._removeInactiveBindingsForAction(action);
            }
            delete actionsByClip[clipUuid];
        }
    }
    // free all resources specific to a particular root target object
    uncacheRoot(root) {
        const rootUuid = root.uuid, actionsByClip = this._actionsByClip;
        for(const clipUuid in actionsByClip){
            const actionByRoot = actionsByClip[clipUuid].actionByRoot, action = actionByRoot[rootUuid];
            if (action !== undefined) {
                this._deactivateAction(action);
                this._removeInactiveAction(action);
            }
        }
        const bindingsByRoot = this._bindingsByRootAndName, bindingByName = bindingsByRoot[rootUuid];
        if (bindingByName !== undefined) for(const trackName in bindingByName){
            const binding = bindingByName[trackName];
            binding.restoreOriginalState();
            this._removeInactiveBinding(binding);
        }
    }
    // remove a targeted clip from the cache
    uncacheAction(clip, optionalRoot) {
        const action = this.existingAction(clip, optionalRoot);
        if (action !== null) {
            this._deactivateAction(action);
            this._removeInactiveAction(action);
        }
    }
}
class Uniform {
    constructor(value){
        this.value = value;
    }
    clone() {
        return new Uniform(this.value.clone === undefined ? this.value : this.value.clone());
    }
}
let _id = 0;
class UniformsGroup extends EventDispatcher {
    constructor(){
        super();
        this.isUniformsGroup = true;
        Object.defineProperty(this, "id", {
            value: _id++
        });
        this.name = "";
        this.usage = StaticDrawUsage;
        this.uniforms = [];
    }
    add(uniform) {
        this.uniforms.push(uniform);
        return this;
    }
    remove(uniform) {
        const index = this.uniforms.indexOf(uniform);
        if (index !== -1) this.uniforms.splice(index, 1);
        return this;
    }
    setName(name) {
        this.name = name;
        return this;
    }
    setUsage(value) {
        this.usage = value;
        return this;
    }
    dispose() {
        this.dispatchEvent({
            type: "dispose"
        });
        return this;
    }
    copy(source) {
        this.name = source.name;
        this.usage = source.usage;
        const uniformsSource = source.uniforms;
        this.uniforms.length = 0;
        for(let i = 0, l = uniformsSource.length; i < l; i++){
            const uniforms = Array.isArray(uniformsSource[i]) ? uniformsSource[i] : [
                uniformsSource[i]
            ];
            for(let j = 0; j < uniforms.length; j++)this.uniforms.push(uniforms[j].clone());
        }
        return this;
    }
    clone() {
        return new this.constructor().copy(this);
    }
}
class InstancedInterleavedBuffer extends InterleavedBuffer {
    constructor(array, stride, meshPerAttribute = 1){
        super(array, stride);
        this.isInstancedInterleavedBuffer = true;
        this.meshPerAttribute = meshPerAttribute;
    }
    copy(source) {
        super.copy(source);
        this.meshPerAttribute = source.meshPerAttribute;
        return this;
    }
    clone(data) {
        const ib = super.clone(data);
        ib.meshPerAttribute = this.meshPerAttribute;
        return ib;
    }
    toJSON(data) {
        const json = super.toJSON(data);
        json.isInstancedInterleavedBuffer = true;
        json.meshPerAttribute = this.meshPerAttribute;
        return json;
    }
}
class GLBufferAttribute {
    constructor(buffer, type, itemSize, elementSize, count){
        this.isGLBufferAttribute = true;
        this.name = "";
        this.buffer = buffer;
        this.type = type;
        this.itemSize = itemSize;
        this.elementSize = elementSize;
        this.count = count;
        this.version = 0;
    }
    set needsUpdate(value) {
        if (value === true) this.version++;
    }
    setBuffer(buffer) {
        this.buffer = buffer;
        return this;
    }
    setType(type, elementSize) {
        this.type = type;
        this.elementSize = elementSize;
        return this;
    }
    setItemSize(itemSize) {
        this.itemSize = itemSize;
        return this;
    }
    setCount(count) {
        this.count = count;
        return this;
    }
}
const _matrix = /*@__PURE__*/ new Matrix4();
class Raycaster {
    constructor(origin, direction, near = 0, far = Infinity){
        this.ray = new Ray(origin, direction);
        // direction is assumed to be normalized (for accurate distance calculations)
        this.near = near;
        this.far = far;
        this.camera = null;
        this.layers = new Layers();
        this.params = {
            Mesh: {},
            Line: {
                threshold: 1
            },
            LOD: {},
            Points: {
                threshold: 1
            },
            Sprite: {}
        };
    }
    set(origin, direction) {
        // direction is assumed to be normalized (for accurate distance calculations)
        this.ray.set(origin, direction);
    }
    setFromCamera(coords, camera) {
        if (camera.isPerspectiveCamera) {
            this.ray.origin.setFromMatrixPosition(camera.matrixWorld);
            this.ray.direction.set(coords.x, coords.y, 0.5).unproject(camera).sub(this.ray.origin).normalize();
            this.camera = camera;
        } else if (camera.isOrthographicCamera) {
            this.ray.origin.set(coords.x, coords.y, (camera.near + camera.far) / (camera.near - camera.far)).unproject(camera); // set origin in plane of camera
            this.ray.direction.set(0, 0, -1).transformDirection(camera.matrixWorld);
            this.camera = camera;
        } else console.error("THREE.Raycaster: Unsupported camera type: " + camera.type);
    }
    setFromXRController(controller) {
        _matrix.identity().extractRotation(controller.matrixWorld);
        this.ray.origin.setFromMatrixPosition(controller.matrixWorld);
        this.ray.direction.set(0, 0, -1).applyMatrix4(_matrix);
        return this;
    }
    intersectObject(object, recursive = true, intersects = []) {
        intersect(object, this, intersects, recursive);
        intersects.sort(ascSort);
        return intersects;
    }
    intersectObjects(objects, recursive = true, intersects = []) {
        for(let i = 0, l = objects.length; i < l; i++)intersect(objects[i], this, intersects, recursive);
        intersects.sort(ascSort);
        return intersects;
    }
}
function ascSort(a, b) {
    return a.distance - b.distance;
}
function intersect(object, raycaster, intersects, recursive) {
    let propagate = true;
    if (object.layers.test(raycaster.layers)) {
        const result = object.raycast(raycaster, intersects);
        if (result === false) propagate = false;
    }
    if (propagate === true && recursive === true) {
        const children = object.children;
        for(let i = 0, l = children.length; i < l; i++)intersect(children[i], raycaster, intersects, true);
    }
}
/**
 * Ref: https://en.wikipedia.org/wiki/Spherical_coordinate_system
 *
 * phi (the polar angle) is measured from the positive y-axis. The positive y-axis is up.
 * theta (the azimuthal angle) is measured from the positive z-axis.
 */ class Spherical {
    constructor(radius = 1, phi = 0, theta = 0){
        this.radius = radius;
        this.phi = phi; // polar angle
        this.theta = theta; // azimuthal angle
        return this;
    }
    set(radius, phi, theta) {
        this.radius = radius;
        this.phi = phi;
        this.theta = theta;
        return this;
    }
    copy(other) {
        this.radius = other.radius;
        this.phi = other.phi;
        this.theta = other.theta;
        return this;
    }
    // restrict phi to be between EPS and PI-EPS
    makeSafe() {
        const EPS = 0.000001;
        this.phi = Math.max(EPS, Math.min(Math.PI - EPS, this.phi));
        return this;
    }
    setFromVector3(v) {
        return this.setFromCartesianCoords(v.x, v.y, v.z);
    }
    setFromCartesianCoords(x, y, z) {
        this.radius = Math.sqrt(x * x + y * y + z * z);
        if (this.radius === 0) {
            this.theta = 0;
            this.phi = 0;
        } else {
            this.theta = Math.atan2(x, z);
            this.phi = Math.acos(clamp(y / this.radius, -1, 1));
        }
        return this;
    }
    clone() {
        return new this.constructor().copy(this);
    }
}
/**
 * Ref: https://en.wikipedia.org/wiki/Cylindrical_coordinate_system
 */ class Cylindrical {
    constructor(radius = 1, theta = 0, y = 0){
        this.radius = radius; // distance from the origin to a point in the x-z plane
        this.theta = theta; // counterclockwise angle in the x-z plane measured in radians from the positive z-axis
        this.y = y; // height above the x-z plane
        return this;
    }
    set(radius, theta, y) {
        this.radius = radius;
        this.theta = theta;
        this.y = y;
        return this;
    }
    copy(other) {
        this.radius = other.radius;
        this.theta = other.theta;
        this.y = other.y;
        return this;
    }
    setFromVector3(v) {
        return this.setFromCartesianCoords(v.x, v.y, v.z);
    }
    setFromCartesianCoords(x, y, z) {
        this.radius = Math.sqrt(x * x + z * z);
        this.theta = Math.atan2(x, z);
        this.y = y;
        return this;
    }
    clone() {
        return new this.constructor().copy(this);
    }
}
const _vector$4 = /*@__PURE__*/ new Vector2();
class Box2 {
    constructor(min = new Vector2(Infinity, Infinity), max = new Vector2(-Infinity, -Infinity)){
        this.isBox2 = true;
        this.min = min;
        this.max = max;
    }
    set(min, max) {
        this.min.copy(min);
        this.max.copy(max);
        return this;
    }
    setFromPoints(points) {
        this.makeEmpty();
        for(let i = 0, il = points.length; i < il; i++)this.expandByPoint(points[i]);
        return this;
    }
    setFromCenterAndSize(center, size) {
        const halfSize = _vector$4.copy(size).multiplyScalar(0.5);
        this.min.copy(center).sub(halfSize);
        this.max.copy(center).add(halfSize);
        return this;
    }
    clone() {
        return new this.constructor().copy(this);
    }
    copy(box) {
        this.min.copy(box.min);
        this.max.copy(box.max);
        return this;
    }
    makeEmpty() {
        this.min.x = this.min.y = Infinity;
        this.max.x = this.max.y = -Infinity;
        return this;
    }
    isEmpty() {
        // this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes
        return this.max.x < this.min.x || this.max.y < this.min.y;
    }
    getCenter(target) {
        return this.isEmpty() ? target.set(0, 0) : target.addVectors(this.min, this.max).multiplyScalar(0.5);
    }
    getSize(target) {
        return this.isEmpty() ? target.set(0, 0) : target.subVectors(this.max, this.min);
    }
    expandByPoint(point) {
        this.min.min(point);
        this.max.max(point);
        return this;
    }
    expandByVector(vector) {
        this.min.sub(vector);
        this.max.add(vector);
        return this;
    }
    expandByScalar(scalar) {
        this.min.addScalar(-scalar);
        this.max.addScalar(scalar);
        return this;
    }
    containsPoint(point) {
        return point.x < this.min.x || point.x > this.max.x || point.y < this.min.y || point.y > this.max.y ? false : true;
    }
    containsBox(box) {
        return this.min.x <= box.min.x && box.max.x <= this.max.x && this.min.y <= box.min.y && box.max.y <= this.max.y;
    }
    getParameter(point, target) {
        // This can potentially have a divide by zero if the box
        // has a size dimension of 0.
        return target.set((point.x - this.min.x) / (this.max.x - this.min.x), (point.y - this.min.y) / (this.max.y - this.min.y));
    }
    intersectsBox(box) {
        // using 4 splitting planes to rule out intersections
        return box.max.x < this.min.x || box.min.x > this.max.x || box.max.y < this.min.y || box.min.y > this.max.y ? false : true;
    }
    clampPoint(point, target) {
        return target.copy(point).clamp(this.min, this.max);
    }
    distanceToPoint(point) {
        return this.clampPoint(point, _vector$4).distanceTo(point);
    }
    intersect(box) {
        this.min.max(box.min);
        this.max.min(box.max);
        if (this.isEmpty()) this.makeEmpty();
        return this;
    }
    union(box) {
        this.min.min(box.min);
        this.max.max(box.max);
        return this;
    }
    translate(offset) {
        this.min.add(offset);
        this.max.add(offset);
        return this;
    }
    equals(box) {
        return box.min.equals(this.min) && box.max.equals(this.max);
    }
}
const _startP = /*@__PURE__*/ new Vector3();
const _startEnd = /*@__PURE__*/ new Vector3();
class Line3 {
    constructor(start = new Vector3(), end = new Vector3()){
        this.start = start;
        this.end = end;
    }
    set(start, end) {
        this.start.copy(start);
        this.end.copy(end);
        return this;
    }
    copy(line) {
        this.start.copy(line.start);
        this.end.copy(line.end);
        return this;
    }
    getCenter(target) {
        return target.addVectors(this.start, this.end).multiplyScalar(0.5);
    }
    delta(target) {
        return target.subVectors(this.end, this.start);
    }
    distanceSq() {
        return this.start.distanceToSquared(this.end);
    }
    distance() {
        return this.start.distanceTo(this.end);
    }
    at(t, target) {
        return this.delta(target).multiplyScalar(t).add(this.start);
    }
    closestPointToPointParameter(point, clampToLine) {
        _startP.subVectors(point, this.start);
        _startEnd.subVectors(this.end, this.start);
        const startEnd2 = _startEnd.dot(_startEnd);
        const startEnd_startP = _startEnd.dot(_startP);
        let t = startEnd_startP / startEnd2;
        if (clampToLine) t = clamp(t, 0, 1);
        return t;
    }
    closestPointToPoint(point, clampToLine, target) {
        const t = this.closestPointToPointParameter(point, clampToLine);
        return this.delta(target).multiplyScalar(t).add(this.start);
    }
    applyMatrix4(matrix) {
        this.start.applyMatrix4(matrix);
        this.end.applyMatrix4(matrix);
        return this;
    }
    equals(line) {
        return line.start.equals(this.start) && line.end.equals(this.end);
    }
    clone() {
        return new this.constructor().copy(this);
    }
}
const _vector$3 = /*@__PURE__*/ new Vector3();
class SpotLightHelper extends Object3D {
    constructor(light, color){
        super();
        this.light = light;
        this.matrixAutoUpdate = false;
        this.color = color;
        this.type = "SpotLightHelper";
        const geometry = new BufferGeometry();
        const positions = [
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            -1,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            1,
            0,
            0,
            0,
            0,
            -1,
            1
        ];
        for(let i = 0, j = 1, l = 32; i < l; i++, j++){
            const p1 = i / l * Math.PI * 2;
            const p2 = j / l * Math.PI * 2;
            positions.push(Math.cos(p1), Math.sin(p1), 1, Math.cos(p2), Math.sin(p2), 1);
        }
        geometry.setAttribute("position", new Float32BufferAttribute(positions, 3));
        const material = new LineBasicMaterial({
            fog: false,
            toneMapped: false
        });
        this.cone = new LineSegments(geometry, material);
        this.add(this.cone);
        this.update();
    }
    dispose() {
        this.cone.geometry.dispose();
        this.cone.material.dispose();
    }
    update() {
        this.light.updateWorldMatrix(true, false);
        this.light.target.updateWorldMatrix(true, false);
        // update the local matrix based on the parent and light target transforms
        if (this.parent) {
            this.parent.updateWorldMatrix(true);
            this.matrix.copy(this.parent.matrixWorld).invert().multiply(this.light.matrixWorld);
        } else this.matrix.copy(this.light.matrixWorld);
        this.matrixWorld.copy(this.light.matrixWorld);
        const coneLength = this.light.distance ? this.light.distance : 1000;
        const coneWidth = coneLength * Math.tan(this.light.angle);
        this.cone.scale.set(coneWidth, coneWidth, coneLength);
        _vector$3.setFromMatrixPosition(this.light.target.matrixWorld);
        this.cone.lookAt(_vector$3);
        if (this.color !== undefined) this.cone.material.color.set(this.color);
        else this.cone.material.color.copy(this.light.color);
    }
}
const _vector$2 = /*@__PURE__*/ new Vector3();
const _boneMatrix = /*@__PURE__*/ new Matrix4();
const _matrixWorldInv = /*@__PURE__*/ new Matrix4();
class SkeletonHelper extends LineSegments {
    constructor(object){
        const bones = getBoneList(object);
        const geometry = new BufferGeometry();
        const vertices = [];
        const colors = [];
        const color1 = new Color(0, 0, 1);
        const color2 = new Color(0, 1, 0);
        for(let i = 0; i < bones.length; i++){
            const bone = bones[i];
            if (bone.parent && bone.parent.isBone) {
                vertices.push(0, 0, 0);
                vertices.push(0, 0, 0);
                colors.push(color1.r, color1.g, color1.b);
                colors.push(color2.r, color2.g, color2.b);
            }
        }
        geometry.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        geometry.setAttribute("color", new Float32BufferAttribute(colors, 3));
        const material = new LineBasicMaterial({
            vertexColors: true,
            depthTest: false,
            depthWrite: false,
            toneMapped: false,
            transparent: true
        });
        super(geometry, material);
        this.isSkeletonHelper = true;
        this.type = "SkeletonHelper";
        this.root = object;
        this.bones = bones;
        this.matrix = object.matrixWorld;
        this.matrixAutoUpdate = false;
    }
    updateMatrixWorld(force) {
        const bones = this.bones;
        const geometry = this.geometry;
        const position = geometry.getAttribute("position");
        _matrixWorldInv.copy(this.root.matrixWorld).invert();
        for(let i = 0, j = 0; i < bones.length; i++){
            const bone = bones[i];
            if (bone.parent && bone.parent.isBone) {
                _boneMatrix.multiplyMatrices(_matrixWorldInv, bone.matrixWorld);
                _vector$2.setFromMatrixPosition(_boneMatrix);
                position.setXYZ(j, _vector$2.x, _vector$2.y, _vector$2.z);
                _boneMatrix.multiplyMatrices(_matrixWorldInv, bone.parent.matrixWorld);
                _vector$2.setFromMatrixPosition(_boneMatrix);
                position.setXYZ(j + 1, _vector$2.x, _vector$2.y, _vector$2.z);
                j += 2;
            }
        }
        geometry.getAttribute("position").needsUpdate = true;
        super.updateMatrixWorld(force);
    }
    dispose() {
        this.geometry.dispose();
        this.material.dispose();
    }
}
function getBoneList(object) {
    const boneList = [];
    if (object.isBone === true) boneList.push(object);
    for(let i = 0; i < object.children.length; i++)boneList.push.apply(boneList, getBoneList(object.children[i]));
    return boneList;
}
class PointLightHelper extends Mesh {
    constructor(light, sphereSize, color){
        const geometry = new SphereGeometry(sphereSize, 4, 2);
        const material = new MeshBasicMaterial({
            wireframe: true,
            fog: false,
            toneMapped: false
        });
        super(geometry, material);
        this.light = light;
        this.color = color;
        this.type = "PointLightHelper";
        this.matrix = this.light.matrixWorld;
        this.matrixAutoUpdate = false;
        this.update();
    /*
	// TODO: delete this comment?
	const distanceGeometry = new THREE.IcosahedronGeometry( 1, 2 );
	const distanceMaterial = new THREE.MeshBasicMaterial( { color: hexColor, fog: false, wireframe: true, opacity: 0.1, transparent: true } );

	this.lightSphere = new THREE.Mesh( bulbGeometry, bulbMaterial );
	this.lightDistance = new THREE.Mesh( distanceGeometry, distanceMaterial );

	const d = light.distance;

	if ( d === 0.0 ) {

		this.lightDistance.visible = false;

	} else {

		this.lightDistance.scale.set( d, d, d );

	}

	this.add( this.lightDistance );
	*/ }
    dispose() {
        this.geometry.dispose();
        this.material.dispose();
    }
    update() {
        this.light.updateWorldMatrix(true, false);
        if (this.color !== undefined) this.material.color.set(this.color);
        else this.material.color.copy(this.light.color);
    /*
		const d = this.light.distance;

		if ( d === 0.0 ) {

			this.lightDistance.visible = false;

		} else {

			this.lightDistance.visible = true;
			this.lightDistance.scale.set( d, d, d );

		}
		*/ }
}
const _vector$1 = /*@__PURE__*/ new Vector3();
const _color1 = /*@__PURE__*/ new Color();
const _color2 = /*@__PURE__*/ new Color();
class HemisphereLightHelper extends Object3D {
    constructor(light, size, color){
        super();
        this.light = light;
        this.matrix = light.matrixWorld;
        this.matrixAutoUpdate = false;
        this.color = color;
        this.type = "HemisphereLightHelper";
        const geometry = new OctahedronGeometry(size);
        geometry.rotateY(Math.PI * 0.5);
        this.material = new MeshBasicMaterial({
            wireframe: true,
            fog: false,
            toneMapped: false
        });
        if (this.color === undefined) this.material.vertexColors = true;
        const position = geometry.getAttribute("position");
        const colors = new Float32Array(position.count * 3);
        geometry.setAttribute("color", new BufferAttribute(colors, 3));
        this.add(new Mesh(geometry, this.material));
        this.update();
    }
    dispose() {
        this.children[0].geometry.dispose();
        this.children[0].material.dispose();
    }
    update() {
        const mesh = this.children[0];
        if (this.color !== undefined) this.material.color.set(this.color);
        else {
            const colors = mesh.geometry.getAttribute("color");
            _color1.copy(this.light.color);
            _color2.copy(this.light.groundColor);
            for(let i = 0, l = colors.count; i < l; i++){
                const color = i < l / 2 ? _color1 : _color2;
                colors.setXYZ(i, color.r, color.g, color.b);
            }
            colors.needsUpdate = true;
        }
        this.light.updateWorldMatrix(true, false);
        mesh.lookAt(_vector$1.setFromMatrixPosition(this.light.matrixWorld).negate());
    }
}
class GridHelper extends LineSegments {
    constructor(size = 10, divisions = 10, color1 = 0x444444, color2 = 0x888888){
        color1 = new Color(color1);
        color2 = new Color(color2);
        const center = divisions / 2;
        const step = size / divisions;
        const halfSize = size / 2;
        const vertices = [], colors = [];
        for(let i = 0, j = 0, k = -halfSize; i <= divisions; i++, k += step){
            vertices.push(-halfSize, 0, k, halfSize, 0, k);
            vertices.push(k, 0, -halfSize, k, 0, halfSize);
            const color = i === center ? color1 : color2;
            color.toArray(colors, j);
            j += 3;
            color.toArray(colors, j);
            j += 3;
            color.toArray(colors, j);
            j += 3;
            color.toArray(colors, j);
            j += 3;
        }
        const geometry = new BufferGeometry();
        geometry.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        geometry.setAttribute("color", new Float32BufferAttribute(colors, 3));
        const material = new LineBasicMaterial({
            vertexColors: true,
            toneMapped: false
        });
        super(geometry, material);
        this.type = "GridHelper";
    }
    dispose() {
        this.geometry.dispose();
        this.material.dispose();
    }
}
class PolarGridHelper extends LineSegments {
    constructor(radius = 10, sectors = 16, rings = 8, divisions = 64, color1 = 0x444444, color2 = 0x888888){
        color1 = new Color(color1);
        color2 = new Color(color2);
        const vertices = [];
        const colors = [];
        // create the sectors
        if (sectors > 1) for(let i = 0; i < sectors; i++){
            const v = i / sectors * (Math.PI * 2);
            const x = Math.sin(v) * radius;
            const z = Math.cos(v) * radius;
            vertices.push(0, 0, 0);
            vertices.push(x, 0, z);
            const color = i & 1 ? color1 : color2;
            colors.push(color.r, color.g, color.b);
            colors.push(color.r, color.g, color.b);
        }
        // create the rings
        for(let i = 0; i < rings; i++){
            const color = i & 1 ? color1 : color2;
            const r = radius - radius / rings * i;
            for(let j = 0; j < divisions; j++){
                // first vertex
                let v = j / divisions * (Math.PI * 2);
                let x = Math.sin(v) * r;
                let z = Math.cos(v) * r;
                vertices.push(x, 0, z);
                colors.push(color.r, color.g, color.b);
                // second vertex
                v = (j + 1) / divisions * (Math.PI * 2);
                x = Math.sin(v) * r;
                z = Math.cos(v) * r;
                vertices.push(x, 0, z);
                colors.push(color.r, color.g, color.b);
            }
        }
        const geometry = new BufferGeometry();
        geometry.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        geometry.setAttribute("color", new Float32BufferAttribute(colors, 3));
        const material = new LineBasicMaterial({
            vertexColors: true,
            toneMapped: false
        });
        super(geometry, material);
        this.type = "PolarGridHelper";
    }
    dispose() {
        this.geometry.dispose();
        this.material.dispose();
    }
}
const _v1 = /*@__PURE__*/ new Vector3();
const _v2 = /*@__PURE__*/ new Vector3();
const _v3 = /*@__PURE__*/ new Vector3();
class DirectionalLightHelper extends Object3D {
    constructor(light, size, color){
        super();
        this.light = light;
        this.matrix = light.matrixWorld;
        this.matrixAutoUpdate = false;
        this.color = color;
        this.type = "DirectionalLightHelper";
        if (size === undefined) size = 1;
        let geometry = new BufferGeometry();
        geometry.setAttribute("position", new Float32BufferAttribute([
            -size,
            size,
            0,
            size,
            size,
            0,
            size,
            -size,
            0,
            -size,
            -size,
            0,
            -size,
            size,
            0
        ], 3));
        const material = new LineBasicMaterial({
            fog: false,
            toneMapped: false
        });
        this.lightPlane = new Line(geometry, material);
        this.add(this.lightPlane);
        geometry = new BufferGeometry();
        geometry.setAttribute("position", new Float32BufferAttribute([
            0,
            0,
            0,
            0,
            0,
            1
        ], 3));
        this.targetLine = new Line(geometry, material);
        this.add(this.targetLine);
        this.update();
    }
    dispose() {
        this.lightPlane.geometry.dispose();
        this.lightPlane.material.dispose();
        this.targetLine.geometry.dispose();
        this.targetLine.material.dispose();
    }
    update() {
        this.light.updateWorldMatrix(true, false);
        this.light.target.updateWorldMatrix(true, false);
        _v1.setFromMatrixPosition(this.light.matrixWorld);
        _v2.setFromMatrixPosition(this.light.target.matrixWorld);
        _v3.subVectors(_v2, _v1);
        this.lightPlane.lookAt(_v2);
        if (this.color !== undefined) {
            this.lightPlane.material.color.set(this.color);
            this.targetLine.material.color.set(this.color);
        } else {
            this.lightPlane.material.color.copy(this.light.color);
            this.targetLine.material.color.copy(this.light.color);
        }
        this.targetLine.lookAt(_v2);
        this.targetLine.scale.z = _v3.length();
    }
}
const _vector = /*@__PURE__*/ new Vector3();
const _camera = /*@__PURE__*/ new Camera();
/**
 *	- shows frustum, line of sight and up of the camera
 *	- suitable for fast updates
 * 	- based on frustum visualization in lightgl.js shadowmap example
 *		https://github.com/evanw/lightgl.js/blob/master/tests/shadowmap.html
 */ class CameraHelper extends LineSegments {
    constructor(camera){
        const geometry = new BufferGeometry();
        const material = new LineBasicMaterial({
            color: 0xffffff,
            vertexColors: true,
            toneMapped: false
        });
        const vertices = [];
        const colors = [];
        const pointMap = {};
        // near
        addLine("n1", "n2");
        addLine("n2", "n4");
        addLine("n4", "n3");
        addLine("n3", "n1");
        // far
        addLine("f1", "f2");
        addLine("f2", "f4");
        addLine("f4", "f3");
        addLine("f3", "f1");
        // sides
        addLine("n1", "f1");
        addLine("n2", "f2");
        addLine("n3", "f3");
        addLine("n4", "f4");
        // cone
        addLine("p", "n1");
        addLine("p", "n2");
        addLine("p", "n3");
        addLine("p", "n4");
        // up
        addLine("u1", "u2");
        addLine("u2", "u3");
        addLine("u3", "u1");
        // target
        addLine("c", "t");
        addLine("p", "c");
        // cross
        addLine("cn1", "cn2");
        addLine("cn3", "cn4");
        addLine("cf1", "cf2");
        addLine("cf3", "cf4");
        function addLine(a, b) {
            addPoint(a);
            addPoint(b);
        }
        function addPoint(id) {
            vertices.push(0, 0, 0);
            colors.push(0, 0, 0);
            if (pointMap[id] === undefined) pointMap[id] = [];
            pointMap[id].push(vertices.length / 3 - 1);
        }
        geometry.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        geometry.setAttribute("color", new Float32BufferAttribute(colors, 3));
        super(geometry, material);
        this.type = "CameraHelper";
        this.camera = camera;
        if (this.camera.updateProjectionMatrix) this.camera.updateProjectionMatrix();
        this.matrix = camera.matrixWorld;
        this.matrixAutoUpdate = false;
        this.pointMap = pointMap;
        this.update();
        // colors
        const colorFrustum = new Color(0xffaa00);
        const colorCone = new Color(0xff0000);
        const colorUp = new Color(0x00aaff);
        const colorTarget = new Color(0xffffff);
        const colorCross = new Color(0x333333);
        this.setColors(colorFrustum, colorCone, colorUp, colorTarget, colorCross);
    }
    setColors(frustum, cone, up, target, cross) {
        const geometry = this.geometry;
        const colorAttribute = geometry.getAttribute("color");
        // near
        colorAttribute.setXYZ(0, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(1, frustum.r, frustum.g, frustum.b); // n1, n2
        colorAttribute.setXYZ(2, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(3, frustum.r, frustum.g, frustum.b); // n2, n4
        colorAttribute.setXYZ(4, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(5, frustum.r, frustum.g, frustum.b); // n4, n3
        colorAttribute.setXYZ(6, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(7, frustum.r, frustum.g, frustum.b); // n3, n1
        // far
        colorAttribute.setXYZ(8, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(9, frustum.r, frustum.g, frustum.b); // f1, f2
        colorAttribute.setXYZ(10, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(11, frustum.r, frustum.g, frustum.b); // f2, f4
        colorAttribute.setXYZ(12, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(13, frustum.r, frustum.g, frustum.b); // f4, f3
        colorAttribute.setXYZ(14, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(15, frustum.r, frustum.g, frustum.b); // f3, f1
        // sides
        colorAttribute.setXYZ(16, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(17, frustum.r, frustum.g, frustum.b); // n1, f1
        colorAttribute.setXYZ(18, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(19, frustum.r, frustum.g, frustum.b); // n2, f2
        colorAttribute.setXYZ(20, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(21, frustum.r, frustum.g, frustum.b); // n3, f3
        colorAttribute.setXYZ(22, frustum.r, frustum.g, frustum.b);
        colorAttribute.setXYZ(23, frustum.r, frustum.g, frustum.b); // n4, f4
        // cone
        colorAttribute.setXYZ(24, cone.r, cone.g, cone.b);
        colorAttribute.setXYZ(25, cone.r, cone.g, cone.b); // p, n1
        colorAttribute.setXYZ(26, cone.r, cone.g, cone.b);
        colorAttribute.setXYZ(27, cone.r, cone.g, cone.b); // p, n2
        colorAttribute.setXYZ(28, cone.r, cone.g, cone.b);
        colorAttribute.setXYZ(29, cone.r, cone.g, cone.b); // p, n3
        colorAttribute.setXYZ(30, cone.r, cone.g, cone.b);
        colorAttribute.setXYZ(31, cone.r, cone.g, cone.b); // p, n4
        // up
        colorAttribute.setXYZ(32, up.r, up.g, up.b);
        colorAttribute.setXYZ(33, up.r, up.g, up.b); // u1, u2
        colorAttribute.setXYZ(34, up.r, up.g, up.b);
        colorAttribute.setXYZ(35, up.r, up.g, up.b); // u2, u3
        colorAttribute.setXYZ(36, up.r, up.g, up.b);
        colorAttribute.setXYZ(37, up.r, up.g, up.b); // u3, u1
        // target
        colorAttribute.setXYZ(38, target.r, target.g, target.b);
        colorAttribute.setXYZ(39, target.r, target.g, target.b); // c, t
        colorAttribute.setXYZ(40, cross.r, cross.g, cross.b);
        colorAttribute.setXYZ(41, cross.r, cross.g, cross.b); // p, c
        // cross
        colorAttribute.setXYZ(42, cross.r, cross.g, cross.b);
        colorAttribute.setXYZ(43, cross.r, cross.g, cross.b); // cn1, cn2
        colorAttribute.setXYZ(44, cross.r, cross.g, cross.b);
        colorAttribute.setXYZ(45, cross.r, cross.g, cross.b); // cn3, cn4
        colorAttribute.setXYZ(46, cross.r, cross.g, cross.b);
        colorAttribute.setXYZ(47, cross.r, cross.g, cross.b); // cf1, cf2
        colorAttribute.setXYZ(48, cross.r, cross.g, cross.b);
        colorAttribute.setXYZ(49, cross.r, cross.g, cross.b); // cf3, cf4
        colorAttribute.needsUpdate = true;
    }
    update() {
        const geometry = this.geometry;
        const pointMap = this.pointMap;
        const w = 1, h = 1;
        // we need just camera projection matrix inverse
        // world matrix must be identity
        _camera.projectionMatrixInverse.copy(this.camera.projectionMatrixInverse);
        // center / target
        setPoint("c", pointMap, geometry, _camera, 0, 0, -1);
        setPoint("t", pointMap, geometry, _camera, 0, 0, 1);
        // near
        setPoint("n1", pointMap, geometry, _camera, -w, -h, -1);
        setPoint("n2", pointMap, geometry, _camera, w, -h, -1);
        setPoint("n3", pointMap, geometry, _camera, -w, h, -1);
        setPoint("n4", pointMap, geometry, _camera, w, h, -1);
        // far
        setPoint("f1", pointMap, geometry, _camera, -w, -h, 1);
        setPoint("f2", pointMap, geometry, _camera, w, -h, 1);
        setPoint("f3", pointMap, geometry, _camera, -w, h, 1);
        setPoint("f4", pointMap, geometry, _camera, w, h, 1);
        // up
        setPoint("u1", pointMap, geometry, _camera, w * 0.7, h * 1.1, -1);
        setPoint("u2", pointMap, geometry, _camera, -w * 0.7, h * 1.1, -1);
        setPoint("u3", pointMap, geometry, _camera, 0, h * 2, -1);
        // cross
        setPoint("cf1", pointMap, geometry, _camera, -w, 0, 1);
        setPoint("cf2", pointMap, geometry, _camera, w, 0, 1);
        setPoint("cf3", pointMap, geometry, _camera, 0, -h, 1);
        setPoint("cf4", pointMap, geometry, _camera, 0, h, 1);
        setPoint("cn1", pointMap, geometry, _camera, -w, 0, -1);
        setPoint("cn2", pointMap, geometry, _camera, w, 0, -1);
        setPoint("cn3", pointMap, geometry, _camera, 0, -h, -1);
        setPoint("cn4", pointMap, geometry, _camera, 0, h, -1);
        geometry.getAttribute("position").needsUpdate = true;
    }
    dispose() {
        this.geometry.dispose();
        this.material.dispose();
    }
}
function setPoint(point, pointMap, geometry, camera, x, y, z) {
    _vector.set(x, y, z).unproject(camera);
    const points = pointMap[point];
    if (points !== undefined) {
        const position = geometry.getAttribute("position");
        for(let i = 0, l = points.length; i < l; i++)position.setXYZ(points[i], _vector.x, _vector.y, _vector.z);
    }
}
const _box = /*@__PURE__*/ new Box3();
class BoxHelper extends LineSegments {
    constructor(object, color = 0xffff00){
        const indices = new Uint16Array([
            0,
            1,
            1,
            2,
            2,
            3,
            3,
            0,
            4,
            5,
            5,
            6,
            6,
            7,
            7,
            4,
            0,
            4,
            1,
            5,
            2,
            6,
            3,
            7
        ]);
        const positions = new Float32Array(24);
        const geometry = new BufferGeometry();
        geometry.setIndex(new BufferAttribute(indices, 1));
        geometry.setAttribute("position", new BufferAttribute(positions, 3));
        super(geometry, new LineBasicMaterial({
            color: color,
            toneMapped: false
        }));
        this.object = object;
        this.type = "BoxHelper";
        this.matrixAutoUpdate = false;
        this.update();
    }
    update(object) {
        if (object !== undefined) console.warn("THREE.BoxHelper: .update() has no longer arguments.");
        if (this.object !== undefined) _box.setFromObject(this.object);
        if (_box.isEmpty()) return;
        const min = _box.min;
        const max = _box.max;
        /*
			5____4
		1/___0/|
		| 6__|_7
		2/___3/

		0: max.x, max.y, max.z
		1: min.x, max.y, max.z
		2: min.x, min.y, max.z
		3: max.x, min.y, max.z
		4: max.x, max.y, min.z
		5: min.x, max.y, min.z
		6: min.x, min.y, min.z
		7: max.x, min.y, min.z
		*/ const position = this.geometry.attributes.position;
        const array = position.array;
        array[0] = max.x;
        array[1] = max.y;
        array[2] = max.z;
        array[3] = min.x;
        array[4] = max.y;
        array[5] = max.z;
        array[6] = min.x;
        array[7] = min.y;
        array[8] = max.z;
        array[9] = max.x;
        array[10] = min.y;
        array[11] = max.z;
        array[12] = max.x;
        array[13] = max.y;
        array[14] = min.z;
        array[15] = min.x;
        array[16] = max.y;
        array[17] = min.z;
        array[18] = min.x;
        array[19] = min.y;
        array[20] = min.z;
        array[21] = max.x;
        array[22] = min.y;
        array[23] = min.z;
        position.needsUpdate = true;
        this.geometry.computeBoundingSphere();
    }
    setFromObject(object) {
        this.object = object;
        this.update();
        return this;
    }
    copy(source, recursive) {
        super.copy(source, recursive);
        this.object = source.object;
        return this;
    }
    dispose() {
        this.geometry.dispose();
        this.material.dispose();
    }
}
class Box3Helper extends LineSegments {
    constructor(box, color = 0xffff00){
        const indices = new Uint16Array([
            0,
            1,
            1,
            2,
            2,
            3,
            3,
            0,
            4,
            5,
            5,
            6,
            6,
            7,
            7,
            4,
            0,
            4,
            1,
            5,
            2,
            6,
            3,
            7
        ]);
        const positions = [
            1,
            1,
            1,
            -1,
            1,
            1,
            -1,
            -1,
            1,
            1,
            -1,
            1,
            1,
            1,
            -1,
            -1,
            1,
            -1,
            -1,
            -1,
            -1,
            1,
            -1,
            -1
        ];
        const geometry = new BufferGeometry();
        geometry.setIndex(new BufferAttribute(indices, 1));
        geometry.setAttribute("position", new Float32BufferAttribute(positions, 3));
        super(geometry, new LineBasicMaterial({
            color: color,
            toneMapped: false
        }));
        this.box = box;
        this.type = "Box3Helper";
        this.geometry.computeBoundingSphere();
    }
    updateMatrixWorld(force) {
        const box = this.box;
        if (box.isEmpty()) return;
        box.getCenter(this.position);
        box.getSize(this.scale);
        this.scale.multiplyScalar(0.5);
        super.updateMatrixWorld(force);
    }
    dispose() {
        this.geometry.dispose();
        this.material.dispose();
    }
}
class PlaneHelper extends Line {
    constructor(plane, size = 1, hex = 0xffff00){
        const color = hex;
        const positions = [
            1,
            -1,
            0,
            -1,
            1,
            0,
            -1,
            -1,
            0,
            1,
            1,
            0,
            -1,
            1,
            0,
            -1,
            -1,
            0,
            1,
            -1,
            0,
            1,
            1,
            0
        ];
        const geometry = new BufferGeometry();
        geometry.setAttribute("position", new Float32BufferAttribute(positions, 3));
        geometry.computeBoundingSphere();
        super(geometry, new LineBasicMaterial({
            color: color,
            toneMapped: false
        }));
        this.type = "PlaneHelper";
        this.plane = plane;
        this.size = size;
        const positions2 = [
            1,
            1,
            0,
            -1,
            1,
            0,
            -1,
            -1,
            0,
            1,
            1,
            0,
            -1,
            -1,
            0,
            1,
            -1,
            0
        ];
        const geometry2 = new BufferGeometry();
        geometry2.setAttribute("position", new Float32BufferAttribute(positions2, 3));
        geometry2.computeBoundingSphere();
        this.add(new Mesh(geometry2, new MeshBasicMaterial({
            color: color,
            opacity: 0.2,
            transparent: true,
            depthWrite: false,
            toneMapped: false
        })));
    }
    updateMatrixWorld(force) {
        this.position.set(0, 0, 0);
        this.scale.set(0.5 * this.size, 0.5 * this.size, 1);
        this.lookAt(this.plane.normal);
        this.translateZ(-this.plane.constant);
        super.updateMatrixWorld(force);
    }
    dispose() {
        this.geometry.dispose();
        this.material.dispose();
        this.children[0].geometry.dispose();
        this.children[0].material.dispose();
    }
}
const _axis = /*@__PURE__*/ new Vector3();
let _lineGeometry, _coneGeometry;
class ArrowHelper extends Object3D {
    // dir is assumed to be normalized
    constructor(dir = new Vector3(0, 0, 1), origin = new Vector3(0, 0, 0), length = 1, color = 0xffff00, headLength = length * 0.2, headWidth = headLength * 0.2){
        super();
        this.type = "ArrowHelper";
        if (_lineGeometry === undefined) {
            _lineGeometry = new BufferGeometry();
            _lineGeometry.setAttribute("position", new Float32BufferAttribute([
                0,
                0,
                0,
                0,
                1,
                0
            ], 3));
            _coneGeometry = new CylinderGeometry(0, 0.5, 1, 5, 1);
            _coneGeometry.translate(0, -0.5, 0);
        }
        this.position.copy(origin);
        this.line = new Line(_lineGeometry, new LineBasicMaterial({
            color: color,
            toneMapped: false
        }));
        this.line.matrixAutoUpdate = false;
        this.add(this.line);
        this.cone = new Mesh(_coneGeometry, new MeshBasicMaterial({
            color: color,
            toneMapped: false
        }));
        this.cone.matrixAutoUpdate = false;
        this.add(this.cone);
        this.setDirection(dir);
        this.setLength(length, headLength, headWidth);
    }
    setDirection(dir) {
        // dir is assumed to be normalized
        if (dir.y > 0.99999) this.quaternion.set(0, 0, 0, 1);
        else if (dir.y < -0.99999) this.quaternion.set(1, 0, 0, 0);
        else {
            _axis.set(dir.z, 0, -dir.x).normalize();
            const radians = Math.acos(dir.y);
            this.quaternion.setFromAxisAngle(_axis, radians);
        }
    }
    setLength(length, headLength = length * 0.2, headWidth = headLength * 0.2) {
        this.line.scale.set(1, Math.max(0.0001, length - headLength), 1); // see #17458
        this.line.updateMatrix();
        this.cone.scale.set(headWidth, headLength, headWidth);
        this.cone.position.y = length;
        this.cone.updateMatrix();
    }
    setColor(color) {
        this.line.material.color.set(color);
        this.cone.material.color.set(color);
    }
    copy(source) {
        super.copy(source, false);
        this.line.copy(source.line);
        this.cone.copy(source.cone);
        return this;
    }
    dispose() {
        this.line.geometry.dispose();
        this.line.material.dispose();
        this.cone.geometry.dispose();
        this.cone.material.dispose();
    }
}
class AxesHelper extends LineSegments {
    constructor(size = 1){
        const vertices = [
            0,
            0,
            0,
            size,
            0,
            0,
            0,
            0,
            0,
            0,
            size,
            0,
            0,
            0,
            0,
            0,
            0,
            size
        ];
        const colors = [
            1,
            0,
            0,
            1,
            0.6,
            0,
            0,
            1,
            0,
            0.6,
            1,
            0,
            0,
            0,
            1,
            0,
            0.6,
            1
        ];
        const geometry = new BufferGeometry();
        geometry.setAttribute("position", new Float32BufferAttribute(vertices, 3));
        geometry.setAttribute("color", new Float32BufferAttribute(colors, 3));
        const material = new LineBasicMaterial({
            vertexColors: true,
            toneMapped: false
        });
        super(geometry, material);
        this.type = "AxesHelper";
    }
    setColors(xAxisColor, yAxisColor, zAxisColor) {
        const color = new Color();
        const array = this.geometry.attributes.color.array;
        color.set(xAxisColor);
        color.toArray(array, 0);
        color.toArray(array, 3);
        color.set(yAxisColor);
        color.toArray(array, 6);
        color.toArray(array, 9);
        color.set(zAxisColor);
        color.toArray(array, 12);
        color.toArray(array, 15);
        this.geometry.attributes.color.needsUpdate = true;
        return this;
    }
    dispose() {
        this.geometry.dispose();
        this.material.dispose();
    }
}
class ShapePath {
    constructor(){
        this.type = "ShapePath";
        this.color = new Color();
        this.subPaths = [];
        this.currentPath = null;
    }
    moveTo(x, y) {
        this.currentPath = new Path();
        this.subPaths.push(this.currentPath);
        this.currentPath.moveTo(x, y);
        return this;
    }
    lineTo(x, y) {
        this.currentPath.lineTo(x, y);
        return this;
    }
    quadraticCurveTo(aCPx, aCPy, aX, aY) {
        this.currentPath.quadraticCurveTo(aCPx, aCPy, aX, aY);
        return this;
    }
    bezierCurveTo(aCP1x, aCP1y, aCP2x, aCP2y, aX, aY) {
        this.currentPath.bezierCurveTo(aCP1x, aCP1y, aCP2x, aCP2y, aX, aY);
        return this;
    }
    splineThru(pts) {
        this.currentPath.splineThru(pts);
        return this;
    }
    toShapes(isCCW) {
        function toShapesNoHoles(inSubpaths) {
            const shapes = [];
            for(let i = 0, l = inSubpaths.length; i < l; i++){
                const tmpPath = inSubpaths[i];
                const tmpShape = new Shape();
                tmpShape.curves = tmpPath.curves;
                shapes.push(tmpShape);
            }
            return shapes;
        }
        function isPointInsidePolygon(inPt, inPolygon) {
            const polyLen = inPolygon.length;
            // inPt on polygon contour => immediate success    or
            // toggling of inside/outside at every single! intersection point of an edge
            //  with the horizontal line through inPt, left of inPt
            //  not counting lowerY endpoints of edges and whole edges on that line
            let inside = false;
            for(let p = polyLen - 1, q = 0; q < polyLen; p = q++){
                let edgeLowPt = inPolygon[p];
                let edgeHighPt = inPolygon[q];
                let edgeDx = edgeHighPt.x - edgeLowPt.x;
                let edgeDy = edgeHighPt.y - edgeLowPt.y;
                if (Math.abs(edgeDy) > Number.EPSILON) {
                    // not parallel
                    if (edgeDy < 0) {
                        edgeLowPt = inPolygon[q];
                        edgeDx = -edgeDx;
                        edgeHighPt = inPolygon[p];
                        edgeDy = -edgeDy;
                    }
                    if (inPt.y < edgeLowPt.y || inPt.y > edgeHighPt.y) continue;
                    if (inPt.y === edgeLowPt.y) {
                        if (inPt.x === edgeLowPt.x) return true; // inPt is on contour ?
                    // continue;				// no intersection or edgeLowPt => doesn't count !!!
                    } else {
                        const perpEdge = edgeDy * (inPt.x - edgeLowPt.x) - edgeDx * (inPt.y - edgeLowPt.y);
                        if (perpEdge === 0) return true; // inPt is on contour ?
                        if (perpEdge < 0) continue;
                        inside = !inside; // true intersection left of inPt
                    }
                } else {
                    // parallel or collinear
                    if (inPt.y !== edgeLowPt.y) continue; // parallel
                    // edge lies on the same horizontal line as inPt
                    if (edgeHighPt.x <= inPt.x && inPt.x <= edgeLowPt.x || edgeLowPt.x <= inPt.x && inPt.x <= edgeHighPt.x) return true; // inPt: Point on contour !
                // continue;
                }
            }
            return inside;
        }
        const isClockWise = ShapeUtils.isClockWise;
        const subPaths = this.subPaths;
        if (subPaths.length === 0) return [];
        let solid, tmpPath, tmpShape;
        const shapes = [];
        if (subPaths.length === 1) {
            tmpPath = subPaths[0];
            tmpShape = new Shape();
            tmpShape.curves = tmpPath.curves;
            shapes.push(tmpShape);
            return shapes;
        }
        let holesFirst = !isClockWise(subPaths[0].getPoints());
        holesFirst = isCCW ? !holesFirst : holesFirst;
        // console.log("Holes first", holesFirst);
        const betterShapeHoles = [];
        const newShapes = [];
        let newShapeHoles = [];
        let mainIdx = 0;
        let tmpPoints;
        newShapes[mainIdx] = undefined;
        newShapeHoles[mainIdx] = [];
        for(let i = 0, l = subPaths.length; i < l; i++){
            tmpPath = subPaths[i];
            tmpPoints = tmpPath.getPoints();
            solid = isClockWise(tmpPoints);
            solid = isCCW ? !solid : solid;
            if (solid) {
                if (!holesFirst && newShapes[mainIdx]) mainIdx++;
                newShapes[mainIdx] = {
                    s: new Shape(),
                    p: tmpPoints
                };
                newShapes[mainIdx].s.curves = tmpPath.curves;
                if (holesFirst) mainIdx++;
                newShapeHoles[mainIdx] = [];
            //console.log('cw', i);
            } else newShapeHoles[mainIdx].push({
                h: tmpPath,
                p: tmpPoints[0]
            });
        }
        // only Holes? -> probably all Shapes with wrong orientation
        if (!newShapes[0]) return toShapesNoHoles(subPaths);
        if (newShapes.length > 1) {
            let ambiguous = false;
            let toChange = 0;
            for(let sIdx = 0, sLen = newShapes.length; sIdx < sLen; sIdx++)betterShapeHoles[sIdx] = [];
            for(let sIdx = 0, sLen = newShapes.length; sIdx < sLen; sIdx++){
                const sho = newShapeHoles[sIdx];
                for(let hIdx = 0; hIdx < sho.length; hIdx++){
                    const ho = sho[hIdx];
                    let hole_unassigned = true;
                    for(let s2Idx = 0; s2Idx < newShapes.length; s2Idx++)if (isPointInsidePolygon(ho.p, newShapes[s2Idx].p)) {
                        if (sIdx !== s2Idx) toChange++;
                        if (hole_unassigned) {
                            hole_unassigned = false;
                            betterShapeHoles[s2Idx].push(ho);
                        } else ambiguous = true;
                    }
                    if (hole_unassigned) betterShapeHoles[sIdx].push(ho);
                }
            }
            if (toChange > 0 && ambiguous === false) newShapeHoles = betterShapeHoles;
        }
        let tmpHoles;
        for(let i = 0, il = newShapes.length; i < il; i++){
            tmpShape = newShapes[i].s;
            shapes.push(tmpShape);
            tmpHoles = newShapeHoles[i];
            for(let j = 0, jl = tmpHoles.length; j < jl; j++)tmpShape.holes.push(tmpHoles[j].h);
        }
        //console.log("shape", shapes);
        return shapes;
    }
}
class WebGLMultipleRenderTargets extends WebGLRenderTarget {
    constructor(width = 1, height = 1, count = 1, options = {}){
        console.warn('THREE.WebGLMultipleRenderTargets has been deprecated and will be removed in r172. Use THREE.WebGLRenderTarget and set the "count" parameter to enable MRT.');
        super(width, height, {
            ...options,
            count
        });
        this.isWebGLMultipleRenderTargets = true;
    }
    get texture() {
        return this.textures;
    }
}
if (typeof __THREE_DEVTOOLS__ !== "undefined") __THREE_DEVTOOLS__.dispatchEvent(new CustomEvent("register", {
    detail: {
        revision: REVISION
    }
}));
if (typeof window !== "undefined") {
    if (window.__THREE__) console.warn("WARNING: Multiple instances of Three.js being imported.");
    else window.__THREE__ = REVISION;
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gkKU3":[function(require,module,exports) {
exports.interopDefault = function(a) {
    return a && a.__esModule ? a : {
        default: a
    };
};
exports.defineInteropFlag = function(a) {
    Object.defineProperty(a, "__esModule", {
        value: true
    });
};
exports.exportAll = function(source, dest) {
    Object.keys(source).forEach(function(key) {
        if (key === "default" || key === "__esModule" || Object.prototype.hasOwnProperty.call(dest, key)) return;
        Object.defineProperty(dest, key, {
            enumerable: true,
            get: function() {
                return source[key];
            }
        });
    });
    return dest;
};
exports.export = function(dest, destName, get) {
    Object.defineProperty(dest, destName, {
        enumerable: true,
        get: get
    });
};

},{}],"2tCfN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getContext", ()=>(0, _globalJs.getContext));
parcelHelpers.export(exports, "setContext", ()=>(0, _globalJs.setContext));
parcelHelpers.export(exports, "start", ()=>(0, _globalJs.start));
parcelHelpers.export(exports, "supported", ()=>(0, _audioContextJs.supported));
/**
 * The current audio context time of the global {@link BaseContext}.
 * @see {@link Context.now}
 * @category Core
 */ parcelHelpers.export(exports, "now", ()=>now);
/**
 * The current audio context time of the global {@link Context} without the {@link Context.lookAhead}
 * @see {@link Context.immediate}
 * @category Core
 */ parcelHelpers.export(exports, "immediate", ()=>immediate);
parcelHelpers.export(exports, "Transport", ()=>Transport);
/**
 * The Transport object belonging to the global Tone.js Context.
 * @see {@link TransportClass}
 * @category Core
 */ parcelHelpers.export(exports, "getTransport", ()=>getTransport);
parcelHelpers.export(exports, "Destination", ()=>Destination);
parcelHelpers.export(exports, "Master", ()=>Master);
/**
 * The Destination (output) belonging to the global Tone.js Context.
 * @see {@link DestinationClass}
 * @category Core
 */ parcelHelpers.export(exports, "getDestination", ()=>getDestination);
parcelHelpers.export(exports, "Listener", ()=>Listener);
/**
 * The {@link ListenerClass} belonging to the global Tone.js Context.
 * @category Core
 */ parcelHelpers.export(exports, "getListener", ()=>getListener);
parcelHelpers.export(exports, "Draw", ()=>Draw);
/**
 * Get the singleton attached to the global context.
 * Draw is used to synchronize the draw frame with the Transport's callbacks.
 * @see {@link DrawClass}
 * @category Core
 */ parcelHelpers.export(exports, "getDraw", ()=>getDraw);
parcelHelpers.export(exports, "context", ()=>context);
/**
 * Promise which resolves when all of the loading promises are resolved.
 * Alias for static {@link ToneAudioBuffer.loaded} method.
 * @category Core
 */ parcelHelpers.export(exports, "loaded", ()=>loaded);
parcelHelpers.export(exports, "Buffer", ()=>Buffer);
parcelHelpers.export(exports, "Buffers", ()=>Buffers);
parcelHelpers.export(exports, "BufferSource", ()=>BufferSource);
var _globalJs = require("./core/Global.js");
var _classesJs = require("./classes.js");
parcelHelpers.exportAll(_classesJs, exports);
var _versionJs = require("./version.js");
parcelHelpers.exportAll(_versionJs, exports);
var _toneAudioBufferJs = require("./core/context/ToneAudioBuffer.js");
var _audioContextJs = require("./core/context/AudioContext.js");
// this fills in name changes from 13.x to 14.x
var _toneAudioBuffersJs = require("./core/context/ToneAudioBuffers.js");
var _toneBufferSourceJs = require("./source/buffer/ToneBufferSource.js");
function now() {
    return (0, _globalJs.getContext)().now();
}
function immediate() {
    return (0, _globalJs.getContext)().immediate();
}
const Transport = (0, _globalJs.getContext)().transport;
function getTransport() {
    return (0, _globalJs.getContext)().transport;
}
const Destination = (0, _globalJs.getContext)().destination;
const Master = (0, _globalJs.getContext)().destination;
function getDestination() {
    return (0, _globalJs.getContext)().destination;
}
const Listener = (0, _globalJs.getContext)().listener;
function getListener() {
    return (0, _globalJs.getContext)().listener;
}
const Draw = (0, _globalJs.getContext)().draw;
function getDraw() {
    return (0, _globalJs.getContext)().draw;
}
const context = (0, _globalJs.getContext)();
function loaded() {
    return (0, _toneAudioBufferJs.ToneAudioBuffer).loaded();
}
const Buffer = (0, _toneAudioBufferJs.ToneAudioBuffer);
const Buffers = (0, _toneAudioBuffersJs.ToneAudioBuffers);
const BufferSource = (0, _toneBufferSourceJs.ToneBufferSource);

},{"./core/Global.js":"79THw","./classes.js":"bbfCi","./version.js":"kWqOI","./core/context/ToneAudioBuffer.js":"8aSPC","./core/context/AudioContext.js":"1NjF0","./core/context/ToneAudioBuffers.js":"8zO1I","./source/buffer/ToneBufferSource.js":"9FxEt","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"79THw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Returns the default system-wide {@link Context}
 * @category Core
 */ parcelHelpers.export(exports, "getContext", ()=>getContext);
/**
 * Set the default audio context
 * @param context
 * @param disposeOld Pass `true` if you don't need the old context to dispose it.
 * @category Core
 */ parcelHelpers.export(exports, "setContext", ()=>setContext);
/**
 * Most browsers will not play _any_ audio until a user
 * clicks something (like a play button). Invoke this method
 * on a click or keypress event handler to start the audio context.
 * More about the Autoplay policy
 * [here](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)
 * @example
 * document.querySelector("button").addEventListener("click", async () => {
 * 	await Tone.start();
 * 	console.log("context started");
 * });
 * @category Core
 */ parcelHelpers.export(exports, "start", ()=>start);
var _versionJs = require("../version.js");
var _audioContextJs = require("./context/AudioContext.js");
var _contextJs = require("./context/Context.js");
var _dummyContextJs = require("./context/DummyContext.js");
var _offlineContextJs = require("./context/OfflineContext.js");
var _advancedTypeCheckJs = require("./util/AdvancedTypeCheck.js");
/**
 * This dummy context is used to avoid throwing immediate errors when importing in Node.js
 */ const dummyContext = new (0, _dummyContextJs.DummyContext)();
/**
 * The global audio context which is getable and assignable through
 * getContext and setContext
 */ let globalContext = dummyContext;
function getContext() {
    if (globalContext === dummyContext && (0, _audioContextJs.hasAudioContext)) setContext(new (0, _contextJs.Context)());
    return globalContext;
}
function setContext(context, disposeOld = false) {
    if (disposeOld) globalContext.dispose();
    if ((0, _advancedTypeCheckJs.isAudioContext)(context)) globalContext = new (0, _contextJs.Context)(context);
    else if ((0, _advancedTypeCheckJs.isOfflineAudioContext)(context)) globalContext = new (0, _offlineContextJs.OfflineContext)(context);
    else globalContext = context;
}
function start() {
    return globalContext.resume();
}
/**
 * Log Tone.js + version in the console.
 */ if ((0, _audioContextJs.theWindow) && !(0, _audioContextJs.theWindow).TONE_SILENCE_LOGGING) {
    let prefix = "v";
    if ((0, _versionJs.version) === "dev") prefix = "";
    const printString = ` * Tone.js ${prefix}${(0, _versionJs.version)} * `;
    // eslint-disable-next-line no-console
    console.log(`%c${printString}`, "background: #000; color: #fff");
}

},{"../version.js":"kWqOI","./context/AudioContext.js":"1NjF0","./context/Context.js":"1CuCx","./context/DummyContext.js":"lf5qO","./context/OfflineContext.js":"8VnAL","./util/AdvancedTypeCheck.js":"gKVc7","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kWqOI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "version", ()=>version);
const version = "15.0.4";

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1NjF0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * This promise resolves to a boolean which indicates if the
 * functionality is supported within the currently used browse.
 * Taken from [standardized-audio-context](https://github.com/chrisguttandin/standardized-audio-context#issupported)
 */ parcelHelpers.export(exports, "supported", ()=>(0, _standardizedAudioContext.isSupported));
/**
 * Create a new AudioContext
 */ parcelHelpers.export(exports, "createAudioContext", ()=>createAudioContext);
/**
 * Create a new OfflineAudioContext
 */ parcelHelpers.export(exports, "createOfflineAudioContext", ()=>createOfflineAudioContext);
parcelHelpers.export(exports, "theWindow", ()=>theWindow);
parcelHelpers.export(exports, "hasAudioContext", ()=>hasAudioContext);
parcelHelpers.export(exports, "createAudioWorkletNode", ()=>createAudioWorkletNode);
var _standardizedAudioContext = require("standardized-audio-context");
var _debugJs = require("../util/Debug.js");
var _typeCheckJs = require("../util/TypeCheck.js");
function createAudioContext(options) {
    return new (0, _standardizedAudioContext.AudioContext)(options);
}
function createOfflineAudioContext(channels, length, sampleRate) {
    return new (0, _standardizedAudioContext.OfflineAudioContext)(channels, length, sampleRate);
}
const theWindow = typeof self === "object" ? self : null;
const hasAudioContext = theWindow && (theWindow.hasOwnProperty("AudioContext") || theWindow.hasOwnProperty("webkitAudioContext"));
function createAudioWorkletNode(context, name, options) {
    (0, _debugJs.assert)((0, _typeCheckJs.isDefined)((0, _standardizedAudioContext.AudioWorkletNode)), "AudioWorkletNode only works in a secure context (https or localhost)");
    return new (context instanceof (theWindow === null || theWindow === void 0 ? void 0 : theWindow.BaseAudioContext) ? theWindow === null || theWindow === void 0 ? void 0 : theWindow.AudioWorkletNode : (0, _standardizedAudioContext.AudioWorkletNode))(context, name, options);
}

},{"standardized-audio-context":"J0Z3v","../util/Debug.js":"2lOIQ","../util/TypeCheck.js":"eMH5A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"J0Z3v":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AnalyserNode", ()=>analyserNodeConstructor);
parcelHelpers.export(exports, "AudioBuffer", ()=>audioBufferConstructor);
parcelHelpers.export(exports, "AudioBufferSourceNode", ()=>audioBufferSourceNodeConstructor);
parcelHelpers.export(exports, "addAudioWorkletModule", ()=>addAudioWorkletModule);
parcelHelpers.export(exports, "decodeAudioData", ()=>decodeAudioData);
parcelHelpers.export(exports, "AudioContext", ()=>audioContextConstructor);
parcelHelpers.export(exports, "AudioWorkletNode", ()=>audioWorkletNodeConstructor);
parcelHelpers.export(exports, "BiquadFilterNode", ()=>biquadFilterNodeConstructor);
parcelHelpers.export(exports, "ChannelMergerNode", ()=>channelMergerNodeConstructor);
parcelHelpers.export(exports, "ChannelSplitterNode", ()=>channelSplitterNodeConstructor);
parcelHelpers.export(exports, "ConvolverNode", ()=>convolverNodeConstructor);
parcelHelpers.export(exports, "ConstantSourceNode", ()=>constantSourceNodeConstructor);
parcelHelpers.export(exports, "DelayNode", ()=>delayNodeConstructor);
parcelHelpers.export(exports, "DynamicsCompressorNode", ()=>dynamicsCompressorNodeConstructor);
parcelHelpers.export(exports, "GainNode", ()=>gainNodeConstructor);
parcelHelpers.export(exports, "IIRFilterNode", ()=>iIRFilterNodeConstructor);
parcelHelpers.export(exports, "MediaElementAudioSourceNode", ()=>mediaElementAudioSourceNodeConstructor);
parcelHelpers.export(exports, "MediaStreamAudioDestinationNode", ()=>mediaStreamAudioDestinationNodeConstructor);
parcelHelpers.export(exports, "MediaStreamAudioSourceNode", ()=>mediaStreamAudioSourceNodeConstructor);
parcelHelpers.export(exports, "MediaStreamTrackAudioSourceNode", ()=>mediaStreamTrackAudioSourceNodeConstructor);
parcelHelpers.export(exports, "MinimalAudioContext", ()=>minimalAudioContextConstructor);
parcelHelpers.export(exports, "MinimalOfflineAudioContext", ()=>minimalOfflineAudioContextConstructor);
parcelHelpers.export(exports, "OfflineAudioContext", ()=>offlineAudioContextConstructor);
parcelHelpers.export(exports, "OscillatorNode", ()=>oscillatorNodeConstructor);
parcelHelpers.export(exports, "PannerNode", ()=>pannerNodeConstructor);
parcelHelpers.export(exports, "PeriodicWave", ()=>periodicWaveConstructor);
parcelHelpers.export(exports, "StereoPannerNode", ()=>stereoPannerNodeConstructor);
parcelHelpers.export(exports, "WaveShaperNode", ()=>waveShaperNodeConstructor);
parcelHelpers.export(exports, "isAnyAudioContext", ()=>isAnyAudioContext);
parcelHelpers.export(exports, "isAnyAudioNode", ()=>isAnyAudioNode);
parcelHelpers.export(exports, "isAnyAudioParam", ()=>isAnyAudioParam);
parcelHelpers.export(exports, "isAnyOfflineAudioContext", ()=>isAnyOfflineAudioContext);
parcelHelpers.export(exports, "isSupported", ()=>isSupported);
var _automationEvents = require("automation-events");
var _abortError = require("./factories/abort-error");
var _addActiveInputConnectionToAudioNode = require("./factories/add-active-input-connection-to-audio-node");
var _addAudioNodeConnections = require("./factories/add-audio-node-connections");
var _addAudioParamConnections = require("./factories/add-audio-param-connections");
var _addAudioWorkletModule = require("./factories/add-audio-worklet-module");
var _addConnectionToAudioNode = require("./factories/add-connection-to-audio-node");
var _addPassiveInputConnectionToAudioNode = require("./factories/add-passive-input-connection-to-audio-node");
var _addSilentConnection = require("./factories/add-silent-connection");
var _addUnrenderedAudioWorkletNode = require("./factories/add-unrendered-audio-worklet-node");
var _analyserNodeConstructor = require("./factories/analyser-node-constructor");
var _analyserNodeRendererFactory = require("./factories/analyser-node-renderer-factory");
var _audioBufferConstructor = require("./factories/audio-buffer-constructor");
var _audioBufferSourceNodeConstructor = require("./factories/audio-buffer-source-node-constructor");
var _audioBufferSourceNodeRendererFactory = require("./factories/audio-buffer-source-node-renderer-factory");
var _audioContextConstructor = require("./factories/audio-context-constructor");
var _audioDestinationNodeConstructor = require("./factories/audio-destination-node-constructor");
var _audioDestinationNodeRendererFactory = require("./factories/audio-destination-node-renderer-factory");
var _audioListenerFactory = require("./factories/audio-listener-factory");
var _audioNodeConstructor = require("./factories/audio-node-constructor");
var _audioParamFactory = require("./factories/audio-param-factory");
var _audioParamRenderer = require("./factories/audio-param-renderer");
var _audioWorkletNodeConstructor = require("./factories/audio-worklet-node-constructor");
var _audioWorkletNodeRendererFactory = require("./factories/audio-worklet-node-renderer-factory");
var _baseAudioContextConstructor = require("./factories/base-audio-context-constructor");
var _biquadFilterNodeConstructor = require("./factories/biquad-filter-node-constructor");
var _biquadFilterNodeRendererFactory = require("./factories/biquad-filter-node-renderer-factory");
var _cacheTestResult = require("./factories/cache-test-result");
var _channelMergerNodeConstructor = require("./factories/channel-merger-node-constructor");
var _channelMergerNodeRendererFactory = require("./factories/channel-merger-node-renderer-factory");
var _channelSplitterNodeConstructor = require("./factories/channel-splitter-node-constructor");
var _channelSplitterNodeRendererFactory = require("./factories/channel-splitter-node-renderer-factory");
var _connectAudioParam = require("./factories/connect-audio-param");
var _connectMultipleOutputs = require("./factories/connect-multiple-outputs");
var _connectedNativeAudioBufferSourceNodeFactory = require("./factories/connected-native-audio-buffer-source-node-factory");
var _constantSourceNodeConstructor = require("./factories/constant-source-node-constructor");
var _constantSourceNodeRendererFactory = require("./factories/constant-source-node-renderer-factory");
var _convertNumberToUnsignedLong = require("./factories/convert-number-to-unsigned-long");
var _convolverNodeConstructor = require("./factories/convolver-node-constructor");
var _convolverNodeRendererFactory = require("./factories/convolver-node-renderer-factory");
var _createNativeOfflineAudioContext = require("./factories/create-native-offline-audio-context");
var _dataCloneError = require("./factories/data-clone-error");
var _decodeAudioData = require("./factories/decode-audio-data");
var _decrementCycleCounter = require("./factories/decrement-cycle-counter");
var _delayNodeConstructor = require("./factories/delay-node-constructor");
var _delayNodeRendererFactory = require("./factories/delay-node-renderer-factory");
var _deleteActiveInputConnectionToAudioNode = require("./factories/delete-active-input-connection-to-audio-node");
var _deleteUnrenderedAudioWorkletNode = require("./factories/delete-unrendered-audio-worklet-node");
var _detectCycles = require("./factories/detect-cycles");
var _disconnectMultipleOutputs = require("./factories/disconnect-multiple-outputs");
var _dynamicsCompressorNodeConstructor = require("./factories/dynamics-compressor-node-constructor");
var _dynamicsCompressorNodeRendererFactory = require("./factories/dynamics-compressor-node-renderer-factory");
var _encodingError = require("./factories/encoding-error");
var _evaluateSource = require("./factories/evaluate-source");
var _eventTargetConstructor = require("./factories/event-target-constructor");
var _exposeCurrentFrameAndCurrentTime = require("./factories/expose-current-frame-and-current-time");
var _fetchSource = require("./factories/fetch-source");
var _gainNodeConstructor = require("./factories/gain-node-constructor");
var _gainNodeRendererFactory = require("./factories/gain-node-renderer-factory");
var _getActiveAudioWorkletNodeInputs = require("./factories/get-active-audio-worklet-node-inputs");
var _getAudioNodeRenderer = require("./factories/get-audio-node-renderer");
var _getAudioNodeTailTime = require("./factories/get-audio-node-tail-time");
var _getAudioParamRenderer = require("./factories/get-audio-param-renderer");
var _getBackupOfflineAudioContext = require("./factories/get-backup-offline-audio-context");
var _getNativeContext = require("./factories/get-native-context");
var _getOrCreateBackupOfflineAudioContext = require("./factories/get-or-create-backup-offline-audio-context");
var _getUnrenderedAudioWorkletNodes = require("./factories/get-unrendered-audio-worklet-nodes");
var _iirFilterNodeConstructor = require("./factories/iir-filter-node-constructor");
var _iirFilterNodeRendererFactory = require("./factories/iir-filter-node-renderer-factory");
var _incrementCycleCounterFactory = require("./factories/increment-cycle-counter-factory");
var _indexSizeError = require("./factories/index-size-error");
var _invalidAccessError = require("./factories/invalid-access-error");
var _invalidStateError = require("./factories/invalid-state-error");
var _isAnyAudioContext = require("./factories/is-any-audio-context");
var _isAnyAudioNode = require("./factories/is-any-audio-node");
var _isAnyAudioParam = require("./factories/is-any-audio-param");
var _isAnyOfflineAudioContext = require("./factories/is-any-offline-audio-context");
var _isNativeAudioContext = require("./factories/is-native-audio-context");
var _isNativeAudioNode = require("./factories/is-native-audio-node");
var _isNativeAudioParam = require("./factories/is-native-audio-param");
var _isNativeContext = require("./factories/is-native-context");
var _isNativeOfflineAudioContext = require("./factories/is-native-offline-audio-context");
var _isSecureContext = require("./factories/is-secure-context");
var _isSupportedPromise = require("./factories/is-supported-promise");
var _mediaElementAudioSourceNodeConstructor = require("./factories/media-element-audio-source-node-constructor");
var _mediaStreamAudioDestinationNodeConstructor = require("./factories/media-stream-audio-destination-node-constructor");
var _mediaStreamAudioSourceNodeConstructor = require("./factories/media-stream-audio-source-node-constructor");
var _mediaStreamTrackAudioSourceNodeConstructor = require("./factories/media-stream-track-audio-source-node-constructor");
var _minimalAudioContextConstructor = require("./factories/minimal-audio-context-constructor");
var _minimalBaseAudioContextConstructor = require("./factories/minimal-base-audio-context-constructor");
var _minimalOfflineAudioContextConstructor = require("./factories/minimal-offline-audio-context-constructor");
var _monitorConnections = require("./factories/monitor-connections");
var _nativeAnalyserNodeFactory = require("./factories/native-analyser-node-factory");
var _nativeAudioBufferConstructor = require("./factories/native-audio-buffer-constructor");
var _nativeAudioBufferSourceNodeFactory = require("./factories/native-audio-buffer-source-node-factory");
var _nativeAudioContextConstructor = require("./factories/native-audio-context-constructor");
var _nativeAudioDestinationNode = require("./factories/native-audio-destination-node");
var _nativeAudioWorkletNodeConstructor = require("./factories/native-audio-worklet-node-constructor");
var _nativeAudioWorkletNodeFactory = require("./factories/native-audio-worklet-node-factory");
var _nativeAudioWorkletNodeFakerFactory = require("./factories/native-audio-worklet-node-faker-factory");
var _nativeBiquadFilterNode = require("./factories/native-biquad-filter-node");
var _nativeChannelMergerNodeFactory = require("./factories/native-channel-merger-node-factory");
var _nativeChannelSplitterNode = require("./factories/native-channel-splitter-node");
var _nativeConstantSourceNodeFactory = require("./factories/native-constant-source-node-factory");
var _nativeConstantSourceNodeFakerFactory = require("./factories/native-constant-source-node-faker-factory");
var _nativeConvolverNodeFactory = require("./factories/native-convolver-node-factory");
var _nativeDelayNode = require("./factories/native-delay-node");
var _nativeDynamicsCompressorNodeFactory = require("./factories/native-dynamics-compressor-node-factory");
var _nativeGainNode = require("./factories/native-gain-node");
var _nativeIirFilterNodeFactory = require("./factories/native-iir-filter-node-factory");
var _nativeIirFilterNodeFakerFactory = require("./factories/native-iir-filter-node-faker-factory");
var _nativeMediaElementAudioSourceNode = require("./factories/native-media-element-audio-source-node");
var _nativeMediaStreamAudioDestinationNode = require("./factories/native-media-stream-audio-destination-node");
var _nativeMediaStreamAudioSourceNode = require("./factories/native-media-stream-audio-source-node");
var _nativeMediaStreamTrackAudioSourceNodeFactory = require("./factories/native-media-stream-track-audio-source-node-factory");
var _nativeOfflineAudioContextConstructor = require("./factories/native-offline-audio-context-constructor");
var _nativeOscillatorNodeFactory = require("./factories/native-oscillator-node-factory");
var _nativePannerNodeFactory = require("./factories/native-panner-node-factory");
var _nativePannerNodeFakerFactory = require("./factories/native-panner-node-faker-factory");
var _nativePeriodicWaveFactory = require("./factories/native-periodic-wave-factory");
var _nativeScriptProcessorNode = require("./factories/native-script-processor-node");
var _nativeStereoPannerNodeFactory = require("./factories/native-stereo-panner-node-factory");
var _nativeStereoPannerNodeFakerFactory = require("./factories/native-stereo-panner-node-faker-factory");
var _nativeWaveShaperNodeFactory = require("./factories/native-wave-shaper-node-factory");
var _nativeWaveShaperNodeFakerFactory = require("./factories/native-wave-shaper-node-faker-factory");
var _notSupportedError = require("./factories/not-supported-error");
var _offlineAudioContextConstructor = require("./factories/offline-audio-context-constructor");
var _oscillatorNodeConstructor = require("./factories/oscillator-node-constructor");
var _oscillatorNodeRendererFactory = require("./factories/oscillator-node-renderer-factory");
var _pannerNodeConstructor = require("./factories/panner-node-constructor");
var _pannerNodeRendererFactory = require("./factories/panner-node-renderer-factory");
var _periodicWaveConstructor = require("./factories/periodic-wave-constructor");
var _renderAutomation = require("./factories/render-automation");
var _renderInputsOfAudioNode = require("./factories/render-inputs-of-audio-node");
var _renderInputsOfAudioParam = require("./factories/render-inputs-of-audio-param");
var _renderNativeOfflineAudioContext = require("./factories/render-native-offline-audio-context");
var _setActiveAudioWorkletNodeInputs = require("./factories/set-active-audio-worklet-node-inputs");
var _setAudioNodeTailTime = require("./factories/set-audio-node-tail-time");
var _startRendering = require("./factories/start-rendering");
var _stereoPannerNodeConstructor = require("./factories/stereo-panner-node-constructor");
var _stereoPannerNodeRendererFactory = require("./factories/stereo-panner-node-renderer-factory");
var _testAudioBufferConstructorSupport = require("./factories/test-audio-buffer-constructor-support");
var _testAudioBufferCopyChannelMethodsSubarraySupport = require("./factories/test-audio-buffer-copy-channel-methods-subarray-support");
var _testAudioContextCloseMethodSupport = require("./factories/test-audio-context-close-method-support");
var _testAudioContextDecodeAudioDataMethodTypeErrorSupport = require("./factories/test-audio-context-decode-audio-data-method-type-error-support");
var _testAudioContextOptionsSupport = require("./factories/test-audio-context-options-support");
var _testAudioNodeConnectMethodSupport = require("./factories/test-audio-node-connect-method-support");
var _testAudioWorkletProcessorNoOutputsSupport = require("./factories/test-audio-worklet-processor-no-outputs-support");
var _testAudioWorkletProcessorPostMessageSupport = require("./factories/test-audio-worklet-processor-post-message-support");
var _testChannelMergerNodeChannelCountSupport = require("./factories/test-channel-merger-node-channel-count-support");
var _testConstantSourceNodeAccurateSchedulingSupport = require("./factories/test-constant-source-node-accurate-scheduling-support");
var _testConvolverNodeBufferReassignabilitySupport = require("./factories/test-convolver-node-buffer-reassignability-support");
var _testConvolverNodeChannelCountSupport = require("./factories/test-convolver-node-channel-count-support");
var _testIsSecureContextSupport = require("./factories/test-is-secure-context-support");
var _testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport = require("./factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support");
var _testOfflineAudioContextCurrentTimeSupport = require("./factories/test-offline-audio-context-current-time-support");
var _testStereoPannerNodeDefaultValueSupport = require("./factories/test-stereo-panner-node-default-value-support");
var _unknownError = require("./factories/unknown-error");
var _waveShaperNodeConstructor = require("./factories/wave-shaper-node-constructor");
var _waveShaperNodeRendererFactory = require("./factories/wave-shaper-node-renderer-factory");
var _window = require("./factories/window");
var _wrapAudioBufferCopyChannelMethods = require("./factories/wrap-audio-buffer-copy-channel-methods");
var _wrapAudioBufferCopyChannelMethodsOutOfBounds = require("./factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds");
var _wrapAudioBufferSourceNodeStopMethodNullifiedBuffer = require("./factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer");
var _wrapChannelMergerNode = require("./factories/wrap-channel-merger-node");
var _globals = require("./globals");
var _connectNativeAudioNodeToNativeAudioNode = require("./helpers/connect-native-audio-node-to-native-audio-node");
var _disconnectNativeAudioNodeFromNativeAudioNode = require("./helpers/disconnect-native-audio-node-from-native-audio-node");
var _getAudioNodeConnections = require("./helpers/get-audio-node-connections");
var _getAudioParamConnections = require("./helpers/get-audio-param-connections");
var _getEventListenersOfAudioNode = require("./helpers/get-event-listeners-of-audio-node");
var _getFirstSample = require("./helpers/get-first-sample");
var _getNativeAudioNode = require("./helpers/get-native-audio-node");
var _getNativeAudioParam = require("./helpers/get-native-audio-param");
var _getValueForKey = require("./helpers/get-value-for-key");
var _insertElementInSet = require("./helpers/insert-element-in-set");
var _isActiveAudioNode = require("./helpers/is-active-audio-node");
var _isDcCurve = require("./helpers/is-dc-curve");
var _isPartOfACycle = require("./helpers/is-part-of-a-cycle");
var _isPassiveAudioNode = require("./helpers/is-passive-audio-node");
var _overwriteAccessors = require("./helpers/overwrite-accessors");
var _pickElementFromSet = require("./helpers/pick-element-from-set");
var _sanitizeAudioWorkletNodeOptions = require("./helpers/sanitize-audio-worklet-node-options");
var _sanitizeChannelSplitterOptions = require("./helpers/sanitize-channel-splitter-options");
var _sanitizePeriodicWaveOptions = require("./helpers/sanitize-periodic-wave-options");
var _setValueAtTimeUntilPossible = require("./helpers/set-value-at-time-until-possible");
var _testAudioBufferCopyChannelMethodsOutOfBoundsSupport = require("./helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support");
var _testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport = require("./helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support");
var _testAudioBufferSourceNodeStartMethodOffsetClampingSupport = require("./helpers/test-audio-buffer-source-node-start-method-offset-clamping-support");
var _testAudioBufferSourceNodeStopMethodNullifiedBufferSupport = require("./helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support");
var _testAudioScheduledSourceNodeStartMethodNegativeParametersSupport = require("./helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support");
var _testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport = require("./helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support");
var _testAudioScheduledSourceNodeStopMethodNegativeParametersSupport = require("./helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support");
var _testAudioWorkletNodeOptionsClonability = require("./helpers/test-audio-worklet-node-options-clonability");
var _testDomExceptionConstructorSupport = require("./helpers/test-dom-exception-constructor-support");
var _testPromiseSupport = require("./helpers/test-promise-support");
var _testTransferablesSupport = require("./helpers/test-transferables-support");
var _wrapAudioBufferSourceNodeStartMethodOffsetClamping = require("./helpers/wrap-audio-buffer-source-node-start-method-offset-clamping");
var _wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls = require("./helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls");
var _wrapEventListener = require("./helpers/wrap-event-listener");
/*
 * @todo Explicitly referencing the barrel file seems to be necessary when enabling the
 * isolatedModules compiler option.
 */ var _index = require("./interfaces/index");
parcelHelpers.exportAll(_index, exports);
var _index1 = require("./types/index");
parcelHelpers.exportAll(_index1, exports);
const addActiveInputConnectionToAudioNode = (0, _addActiveInputConnectionToAudioNode.createAddActiveInputConnectionToAudioNode)((0, _insertElementInSet.insertElementInSet));
const addPassiveInputConnectionToAudioNode = (0, _addPassiveInputConnectionToAudioNode.createAddPassiveInputConnectionToAudioNode)((0, _insertElementInSet.insertElementInSet));
const deleteActiveInputConnectionToAudioNode = (0, _deleteActiveInputConnectionToAudioNode.createDeleteActiveInputConnectionToAudioNode)((0, _pickElementFromSet.pickElementFromSet));
const audioNodeTailTimeStore = new WeakMap();
const getAudioNodeTailTime = (0, _getAudioNodeTailTime.createGetAudioNodeTailTime)(audioNodeTailTimeStore);
const cacheTestResult = (0, _cacheTestResult.createCacheTestResult)(new Map(), new WeakMap());
const window = (0, _window.createWindow)();
const createNativeAnalyserNode = (0, _nativeAnalyserNodeFactory.createNativeAnalyserNodeFactory)(cacheTestResult, (0, _indexSizeError.createIndexSizeError));
const getAudioNodeRenderer = (0, _getAudioNodeRenderer.createGetAudioNodeRenderer)((0, _getAudioNodeConnections.getAudioNodeConnections));
const renderInputsOfAudioNode = (0, _renderInputsOfAudioNode.createRenderInputsOfAudioNode)((0, _getAudioNodeConnections.getAudioNodeConnections), getAudioNodeRenderer, (0, _isPartOfACycle.isPartOfACycle));
const createAnalyserNodeRenderer = (0, _analyserNodeRendererFactory.createAnalyserNodeRendererFactory)(createNativeAnalyserNode, (0, _getNativeAudioNode.getNativeAudioNode), renderInputsOfAudioNode);
const getNativeContext = (0, _getNativeContext.createGetNativeContext)((0, _globals.CONTEXT_STORE));
const nativeOfflineAudioContextConstructor = (0, _nativeOfflineAudioContextConstructor.createNativeOfflineAudioContextConstructor)(window);
const isNativeOfflineAudioContext = (0, _isNativeOfflineAudioContext.createIsNativeOfflineAudioContext)(nativeOfflineAudioContextConstructor);
const audioParamAudioNodeStore = new WeakMap();
const eventTargetConstructor = (0, _eventTargetConstructor.createEventTargetConstructor)((0, _wrapEventListener.wrapEventListener));
const nativeAudioContextConstructor = (0, _nativeAudioContextConstructor.createNativeAudioContextConstructor)(window);
const isNativeAudioContext = (0, _isNativeAudioContext.createIsNativeAudioContext)(nativeAudioContextConstructor);
const isNativeAudioNode = (0, _isNativeAudioNode.createIsNativeAudioNode)(window);
const isNativeAudioParam = (0, _isNativeAudioParam.createIsNativeAudioParam)(window);
const nativeAudioWorkletNodeConstructor = (0, _nativeAudioWorkletNodeConstructor.createNativeAudioWorkletNodeConstructor)(window);
const audioNodeConstructor = (0, _audioNodeConstructor.createAudioNodeConstructor)((0, _addAudioNodeConnections.createAddAudioNodeConnections)((0, _globals.AUDIO_NODE_CONNECTIONS_STORE)), (0, _addConnectionToAudioNode.createAddConnectionToAudioNode)(addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, (0, _connectNativeAudioNodeToNativeAudioNode.connectNativeAudioNodeToNativeAudioNode), deleteActiveInputConnectionToAudioNode, (0, _disconnectNativeAudioNodeFromNativeAudioNode.disconnectNativeAudioNodeFromNativeAudioNode), (0, _getAudioNodeConnections.getAudioNodeConnections), getAudioNodeTailTime, (0, _getEventListenersOfAudioNode.getEventListenersOfAudioNode), (0, _getNativeAudioNode.getNativeAudioNode), (0, _insertElementInSet.insertElementInSet), (0, _isActiveAudioNode.isActiveAudioNode), (0, _isPartOfACycle.isPartOfACycle), (0, _isPassiveAudioNode.isPassiveAudioNode)), cacheTestResult, (0, _incrementCycleCounterFactory.createIncrementCycleCounterFactory)((0, _globals.CYCLE_COUNTERS), (0, _disconnectNativeAudioNodeFromNativeAudioNode.disconnectNativeAudioNodeFromNativeAudioNode), (0, _getAudioNodeConnections.getAudioNodeConnections), (0, _getNativeAudioNode.getNativeAudioNode), (0, _getNativeAudioParam.getNativeAudioParam), (0, _isActiveAudioNode.isActiveAudioNode)), (0, _indexSizeError.createIndexSizeError), (0, _invalidAccessError.createInvalidAccessError), (0, _notSupportedError.createNotSupportedError), (0, _decrementCycleCounter.createDecrementCycleCounter)((0, _connectNativeAudioNodeToNativeAudioNode.connectNativeAudioNodeToNativeAudioNode), (0, _globals.CYCLE_COUNTERS), (0, _getAudioNodeConnections.getAudioNodeConnections), (0, _getNativeAudioNode.getNativeAudioNode), (0, _getNativeAudioParam.getNativeAudioParam), getNativeContext, (0, _isActiveAudioNode.isActiveAudioNode), isNativeOfflineAudioContext), (0, _detectCycles.createDetectCycles)(audioParamAudioNodeStore, (0, _getAudioNodeConnections.getAudioNodeConnections), (0, _getValueForKey.getValueForKey)), eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor);
const analyserNodeConstructor = (0, _analyserNodeConstructor.createAnalyserNodeConstructor)(audioNodeConstructor, createAnalyserNodeRenderer, (0, _indexSizeError.createIndexSizeError), createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext);
const audioBufferStore = new WeakSet();
const nativeAudioBufferConstructor = (0, _nativeAudioBufferConstructor.createNativeAudioBufferConstructor)(window);
const convertNumberToUnsignedLong = (0, _convertNumberToUnsignedLong.createConvertNumberToUnsignedLong)(new Uint32Array(1));
const wrapAudioBufferCopyChannelMethods = (0, _wrapAudioBufferCopyChannelMethods.createWrapAudioBufferCopyChannelMethods)(convertNumberToUnsignedLong, (0, _indexSizeError.createIndexSizeError));
const wrapAudioBufferCopyChannelMethodsOutOfBounds = (0, _wrapAudioBufferCopyChannelMethodsOutOfBounds.createWrapAudioBufferCopyChannelMethodsOutOfBounds)(convertNumberToUnsignedLong);
const audioBufferConstructor = (0, _audioBufferConstructor.createAudioBufferConstructor)(audioBufferStore, cacheTestResult, (0, _notSupportedError.createNotSupportedError), nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, (0, _testAudioBufferConstructorSupport.createTestAudioBufferConstructorSupport)(nativeAudioBufferConstructor), wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);
const addSilentConnection = (0, _addSilentConnection.createAddSilentConnection)((0, _nativeGainNode.createNativeGainNode));
const renderInputsOfAudioParam = (0, _renderInputsOfAudioParam.createRenderInputsOfAudioParam)(getAudioNodeRenderer, (0, _getAudioParamConnections.getAudioParamConnections), (0, _isPartOfACycle.isPartOfACycle));
const connectAudioParam = (0, _connectAudioParam.createConnectAudioParam)(renderInputsOfAudioParam);
const createNativeAudioBufferSourceNode = (0, _nativeAudioBufferSourceNodeFactory.createNativeAudioBufferSourceNodeFactory)(addSilentConnection, cacheTestResult, (0, _testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport.testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport), (0, _testAudioBufferSourceNodeStartMethodOffsetClampingSupport.testAudioBufferSourceNodeStartMethodOffsetClampingSupport), (0, _testAudioBufferSourceNodeStopMethodNullifiedBufferSupport.testAudioBufferSourceNodeStopMethodNullifiedBufferSupport), (0, _testAudioScheduledSourceNodeStartMethodNegativeParametersSupport.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport), (0, _testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport.testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport), (0, _testAudioScheduledSourceNodeStopMethodNegativeParametersSupport.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport), (0, _wrapAudioBufferSourceNodeStartMethodOffsetClamping.wrapAudioBufferSourceNodeStartMethodOffsetClamping), (0, _wrapAudioBufferSourceNodeStopMethodNullifiedBuffer.createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer)((0, _overwriteAccessors.overwriteAccessors)), (0, _wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls.wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls));
const renderAutomation = (0, _renderAutomation.createRenderAutomation)((0, _getAudioParamRenderer.createGetAudioParamRenderer)((0, _getAudioParamConnections.getAudioParamConnections)), renderInputsOfAudioParam);
const createAudioBufferSourceNodeRenderer = (0, _audioBufferSourceNodeRendererFactory.createAudioBufferSourceNodeRendererFactory)(connectAudioParam, createNativeAudioBufferSourceNode, (0, _getNativeAudioNode.getNativeAudioNode), renderAutomation, renderInputsOfAudioNode);
const createAudioParam = (0, _audioParamFactory.createAudioParamFactory)((0, _addAudioParamConnections.createAddAudioParamConnections)((0, _globals.AUDIO_PARAM_CONNECTIONS_STORE)), audioParamAudioNodeStore, (0, _globals.AUDIO_PARAM_STORE), (0, _audioParamRenderer.createAudioParamRenderer), (0, _automationEvents.createCancelAndHoldAutomationEvent), (0, _automationEvents.createCancelScheduledValuesAutomationEvent), (0, _automationEvents.createExponentialRampToValueAutomationEvent), (0, _automationEvents.createLinearRampToValueAutomationEvent), (0, _automationEvents.createSetTargetAutomationEvent), (0, _automationEvents.createSetValueAutomationEvent), (0, _automationEvents.createSetValueCurveAutomationEvent), nativeAudioContextConstructor, (0, _setValueAtTimeUntilPossible.setValueAtTimeUntilPossible));
const audioBufferSourceNodeConstructor = (0, _audioBufferSourceNodeConstructor.createAudioBufferSourceNodeConstructor)(audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, (0, _invalidStateError.createInvalidStateError), createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, (0, _wrapEventListener.wrapEventListener));
const audioDestinationNodeConstructor = (0, _audioDestinationNodeConstructor.createAudioDestinationNodeConstructor)(audioNodeConstructor, (0, _audioDestinationNodeRendererFactory.createAudioDestinationNodeRenderer), (0, _indexSizeError.createIndexSizeError), (0, _invalidStateError.createInvalidStateError), (0, _nativeAudioDestinationNode.createNativeAudioDestinationNodeFactory)((0, _nativeGainNode.createNativeGainNode), (0, _overwriteAccessors.overwriteAccessors)), getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode);
const createBiquadFilterNodeRenderer = (0, _biquadFilterNodeRendererFactory.createBiquadFilterNodeRendererFactory)(connectAudioParam, (0, _nativeBiquadFilterNode.createNativeBiquadFilterNode), (0, _getNativeAudioNode.getNativeAudioNode), renderAutomation, renderInputsOfAudioNode);
const setAudioNodeTailTime = (0, _setAudioNodeTailTime.createSetAudioNodeTailTime)(audioNodeTailTimeStore);
const biquadFilterNodeConstructor = (0, _biquadFilterNodeConstructor.createBiquadFilterNodeConstructor)(audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, (0, _invalidAccessError.createInvalidAccessError), (0, _nativeBiquadFilterNode.createNativeBiquadFilterNode), getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const monitorConnections = (0, _monitorConnections.createMonitorConnections)((0, _insertElementInSet.insertElementInSet), isNativeAudioNode);
const wrapChannelMergerNode = (0, _wrapChannelMergerNode.createWrapChannelMergerNode)((0, _invalidStateError.createInvalidStateError), monitorConnections);
const createNativeChannelMergerNode = (0, _nativeChannelMergerNodeFactory.createNativeChannelMergerNodeFactory)(nativeAudioContextConstructor, wrapChannelMergerNode);
const createChannelMergerNodeRenderer = (0, _channelMergerNodeRendererFactory.createChannelMergerNodeRendererFactory)(createNativeChannelMergerNode, (0, _getNativeAudioNode.getNativeAudioNode), renderInputsOfAudioNode);
const channelMergerNodeConstructor = (0, _channelMergerNodeConstructor.createChannelMergerNodeConstructor)(audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext);
const createChannelSplitterNodeRenderer = (0, _channelSplitterNodeRendererFactory.createChannelSplitterNodeRendererFactory)((0, _nativeChannelSplitterNode.createNativeChannelSplitterNode), (0, _getNativeAudioNode.getNativeAudioNode), renderInputsOfAudioNode);
const channelSplitterNodeConstructor = (0, _channelSplitterNodeConstructor.createChannelSplitterNodeConstructor)(audioNodeConstructor, createChannelSplitterNodeRenderer, (0, _nativeChannelSplitterNode.createNativeChannelSplitterNode), getNativeContext, isNativeOfflineAudioContext, (0, _sanitizeChannelSplitterOptions.sanitizeChannelSplitterOptions));
const createNativeConstantSourceNodeFaker = (0, _nativeConstantSourceNodeFakerFactory.createNativeConstantSourceNodeFakerFactory)(addSilentConnection, createNativeAudioBufferSourceNode, (0, _nativeGainNode.createNativeGainNode), monitorConnections);
const createNativeConstantSourceNode = (0, _nativeConstantSourceNodeFactory.createNativeConstantSourceNodeFactory)(addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, (0, _testAudioScheduledSourceNodeStartMethodNegativeParametersSupport.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport), (0, _testAudioScheduledSourceNodeStopMethodNegativeParametersSupport.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport));
const createConstantSourceNodeRenderer = (0, _constantSourceNodeRendererFactory.createConstantSourceNodeRendererFactory)(connectAudioParam, createNativeConstantSourceNode, (0, _getNativeAudioNode.getNativeAudioNode), renderAutomation, renderInputsOfAudioNode);
const constantSourceNodeConstructor = (0, _constantSourceNodeConstructor.createConstantSourceNodeConstructor)(audioNodeConstructor, createAudioParam, createConstantSourceNodeRenderer, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, (0, _wrapEventListener.wrapEventListener));
const createNativeConvolverNode = (0, _nativeConvolverNodeFactory.createNativeConvolverNodeFactory)((0, _notSupportedError.createNotSupportedError), (0, _overwriteAccessors.overwriteAccessors));
const createConvolverNodeRenderer = (0, _convolverNodeRendererFactory.createConvolverNodeRendererFactory)(createNativeConvolverNode, (0, _getNativeAudioNode.getNativeAudioNode), renderInputsOfAudioNode);
const convolverNodeConstructor = (0, _convolverNodeConstructor.createConvolverNodeConstructor)(audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const createDelayNodeRenderer = (0, _delayNodeRendererFactory.createDelayNodeRendererFactory)(connectAudioParam, (0, _nativeDelayNode.createNativeDelayNode), (0, _getNativeAudioNode.getNativeAudioNode), renderAutomation, renderInputsOfAudioNode);
const delayNodeConstructor = (0, _delayNodeConstructor.createDelayNodeConstructor)(audioNodeConstructor, createAudioParam, createDelayNodeRenderer, (0, _nativeDelayNode.createNativeDelayNode), getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const createNativeDynamicsCompressorNode = (0, _nativeDynamicsCompressorNodeFactory.createNativeDynamicsCompressorNodeFactory)((0, _notSupportedError.createNotSupportedError));
const createDynamicsCompressorNodeRenderer = (0, _dynamicsCompressorNodeRendererFactory.createDynamicsCompressorNodeRendererFactory)(connectAudioParam, createNativeDynamicsCompressorNode, (0, _getNativeAudioNode.getNativeAudioNode), renderAutomation, renderInputsOfAudioNode);
const dynamicsCompressorNodeConstructor = (0, _dynamicsCompressorNodeConstructor.createDynamicsCompressorNodeConstructor)(audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, (0, _notSupportedError.createNotSupportedError), getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const createGainNodeRenderer = (0, _gainNodeRendererFactory.createGainNodeRendererFactory)(connectAudioParam, (0, _nativeGainNode.createNativeGainNode), (0, _getNativeAudioNode.getNativeAudioNode), renderAutomation, renderInputsOfAudioNode);
const gainNodeConstructor = (0, _gainNodeConstructor.createGainNodeConstructor)(audioNodeConstructor, createAudioParam, createGainNodeRenderer, (0, _nativeGainNode.createNativeGainNode), getNativeContext, isNativeOfflineAudioContext);
const createNativeIIRFilterNodeFaker = (0, _nativeIirFilterNodeFakerFactory.createNativeIIRFilterNodeFakerFactory)((0, _invalidAccessError.createInvalidAccessError), (0, _invalidStateError.createInvalidStateError), (0, _nativeScriptProcessorNode.createNativeScriptProcessorNode), (0, _notSupportedError.createNotSupportedError));
const renderNativeOfflineAudioContext = (0, _renderNativeOfflineAudioContext.createRenderNativeOfflineAudioContext)(cacheTestResult, (0, _nativeGainNode.createNativeGainNode), (0, _nativeScriptProcessorNode.createNativeScriptProcessorNode), (0, _testOfflineAudioContextCurrentTimeSupport.createTestOfflineAudioContextCurrentTimeSupport)((0, _nativeGainNode.createNativeGainNode), nativeOfflineAudioContextConstructor));
const createIIRFilterNodeRenderer = (0, _iirFilterNodeRendererFactory.createIIRFilterNodeRendererFactory)(createNativeAudioBufferSourceNode, (0, _getNativeAudioNode.getNativeAudioNode), nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext);
const createNativeIIRFilterNode = (0, _nativeIirFilterNodeFactory.createNativeIIRFilterNodeFactory)(createNativeIIRFilterNodeFaker);
const iIRFilterNodeConstructor = (0, _iirFilterNodeConstructor.createIIRFilterNodeConstructor)(audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const createAudioListener = (0, _audioListenerFactory.createAudioListenerFactory)(createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, (0, _nativeScriptProcessorNode.createNativeScriptProcessorNode), (0, _notSupportedError.createNotSupportedError), (0, _getFirstSample.getFirstSample), isNativeOfflineAudioContext, (0, _overwriteAccessors.overwriteAccessors));
const unrenderedAudioWorkletNodeStore = new WeakMap();
const minimalBaseAudioContextConstructor = (0, _minimalBaseAudioContextConstructor.createMinimalBaseAudioContextConstructor)(audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, (0, _wrapEventListener.wrapEventListener));
const createNativeOscillatorNode = (0, _nativeOscillatorNodeFactory.createNativeOscillatorNodeFactory)(addSilentConnection, cacheTestResult, (0, _testAudioScheduledSourceNodeStartMethodNegativeParametersSupport.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport), (0, _testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport.testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport), (0, _testAudioScheduledSourceNodeStopMethodNegativeParametersSupport.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport), (0, _wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls.wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls));
const createOscillatorNodeRenderer = (0, _oscillatorNodeRendererFactory.createOscillatorNodeRendererFactory)(connectAudioParam, createNativeOscillatorNode, (0, _getNativeAudioNode.getNativeAudioNode), renderAutomation, renderInputsOfAudioNode);
const oscillatorNodeConstructor = (0, _oscillatorNodeConstructor.createOscillatorNodeConstructor)(audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, (0, _wrapEventListener.wrapEventListener));
const createConnectedNativeAudioBufferSourceNode = (0, _connectedNativeAudioBufferSourceNodeFactory.createConnectedNativeAudioBufferSourceNodeFactory)(createNativeAudioBufferSourceNode);
const createNativeWaveShaperNodeFaker = (0, _nativeWaveShaperNodeFakerFactory.createNativeWaveShaperNodeFakerFactory)(createConnectedNativeAudioBufferSourceNode, (0, _invalidStateError.createInvalidStateError), (0, _nativeGainNode.createNativeGainNode), (0, _isDcCurve.isDCCurve), monitorConnections);
const createNativeWaveShaperNode = (0, _nativeWaveShaperNodeFactory.createNativeWaveShaperNodeFactory)(createConnectedNativeAudioBufferSourceNode, (0, _invalidStateError.createInvalidStateError), createNativeWaveShaperNodeFaker, (0, _isDcCurve.isDCCurve), monitorConnections, nativeAudioContextConstructor, (0, _overwriteAccessors.overwriteAccessors));
const createNativePannerNodeFaker = (0, _nativePannerNodeFakerFactory.createNativePannerNodeFakerFactory)((0, _connectNativeAudioNodeToNativeAudioNode.connectNativeAudioNodeToNativeAudioNode), (0, _invalidStateError.createInvalidStateError), createNativeChannelMergerNode, (0, _nativeGainNode.createNativeGainNode), (0, _nativeScriptProcessorNode.createNativeScriptProcessorNode), createNativeWaveShaperNode, (0, _notSupportedError.createNotSupportedError), (0, _disconnectNativeAudioNodeFromNativeAudioNode.disconnectNativeAudioNodeFromNativeAudioNode), (0, _getFirstSample.getFirstSample), monitorConnections);
const createNativePannerNode = (0, _nativePannerNodeFactory.createNativePannerNodeFactory)(createNativePannerNodeFaker);
const createPannerNodeRenderer = (0, _pannerNodeRendererFactory.createPannerNodeRendererFactory)(connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, (0, _nativeGainNode.createNativeGainNode), createNativePannerNode, (0, _getNativeAudioNode.getNativeAudioNode), nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);
const pannerNodeConstructor = (0, _pannerNodeConstructor.createPannerNodeConstructor)(audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const createNativePeriodicWave = (0, _nativePeriodicWaveFactory.createNativePeriodicWaveFactory)((0, _indexSizeError.createIndexSizeError));
const periodicWaveConstructor = (0, _periodicWaveConstructor.createPeriodicWaveConstructor)(createNativePeriodicWave, getNativeContext, new WeakSet(), (0, _sanitizePeriodicWaveOptions.sanitizePeriodicWaveOptions));
const nativeStereoPannerNodeFakerFactory = (0, _nativeStereoPannerNodeFakerFactory.createNativeStereoPannerNodeFakerFactory)(createNativeChannelMergerNode, (0, _nativeChannelSplitterNode.createNativeChannelSplitterNode), (0, _nativeGainNode.createNativeGainNode), createNativeWaveShaperNode, (0, _notSupportedError.createNotSupportedError), monitorConnections);
const createNativeStereoPannerNode = (0, _nativeStereoPannerNodeFactory.createNativeStereoPannerNodeFactory)(nativeStereoPannerNodeFakerFactory, (0, _notSupportedError.createNotSupportedError));
const createStereoPannerNodeRenderer = (0, _stereoPannerNodeRendererFactory.createStereoPannerNodeRendererFactory)(connectAudioParam, createNativeStereoPannerNode, (0, _getNativeAudioNode.getNativeAudioNode), renderAutomation, renderInputsOfAudioNode);
const stereoPannerNodeConstructor = (0, _stereoPannerNodeConstructor.createStereoPannerNodeConstructor)(audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext);
const createWaveShaperNodeRenderer = (0, _waveShaperNodeRendererFactory.createWaveShaperNodeRendererFactory)(createNativeWaveShaperNode, (0, _getNativeAudioNode.getNativeAudioNode), renderInputsOfAudioNode);
const waveShaperNodeConstructor = (0, _waveShaperNodeConstructor.createWaveShaperNodeConstructor)(audioNodeConstructor, (0, _invalidStateError.createInvalidStateError), createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const isSecureContext = (0, _isSecureContext.createIsSecureContext)(window);
const exposeCurrentFrameAndCurrentTime = (0, _exposeCurrentFrameAndCurrentTime.createExposeCurrentFrameAndCurrentTime)(window);
const backupOfflineAudioContextStore = new WeakMap();
const getOrCreateBackupOfflineAudioContext = (0, _getOrCreateBackupOfflineAudioContext.createGetOrCreateBackupOfflineAudioContext)(backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor);
const addAudioWorkletModule = isSecureContext ? (0, _addAudioWorkletModule.createAddAudioWorkletModule)(cacheTestResult, (0, _notSupportedError.createNotSupportedError), (0, _evaluateSource.createEvaluateSource)(window), exposeCurrentFrameAndCurrentTime, (0, _fetchSource.createFetchSource)((0, _abortError.createAbortError)), getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, new WeakMap(), new WeakMap(), (0, _testAudioWorkletProcessorPostMessageSupport.createTestAudioWorkletProcessorPostMessageSupport)(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), // @todo window is guaranteed to be defined because isSecureContext checks that as well.
window) : undefined;
const isNativeContext = (0, _isNativeContext.createIsNativeContext)(isNativeAudioContext, isNativeOfflineAudioContext);
const decodeAudioData = (0, _decodeAudioData.createDecodeAudioData)(audioBufferStore, cacheTestResult, (0, _dataCloneError.createDataCloneError), (0, _encodingError.createEncodingError), new WeakSet(), getNativeContext, isNativeContext, (0, _testAudioBufferCopyChannelMethodsOutOfBoundsSupport.testAudioBufferCopyChannelMethodsOutOfBoundsSupport), (0, _testPromiseSupport.testPromiseSupport), wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);
const baseAudioContextConstructor = (0, _baseAudioContextConstructor.createBaseAudioContextConstructor)(addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor);
const mediaElementAudioSourceNodeConstructor = (0, _mediaElementAudioSourceNodeConstructor.createMediaElementAudioSourceNodeConstructor)(audioNodeConstructor, (0, _nativeMediaElementAudioSourceNode.createNativeMediaElementAudioSourceNode), getNativeContext, isNativeOfflineAudioContext);
const mediaStreamAudioDestinationNodeConstructor = (0, _mediaStreamAudioDestinationNodeConstructor.createMediaStreamAudioDestinationNodeConstructor)(audioNodeConstructor, (0, _nativeMediaStreamAudioDestinationNode.createNativeMediaStreamAudioDestinationNode), getNativeContext, isNativeOfflineAudioContext);
const mediaStreamAudioSourceNodeConstructor = (0, _mediaStreamAudioSourceNodeConstructor.createMediaStreamAudioSourceNodeConstructor)(audioNodeConstructor, (0, _nativeMediaStreamAudioSourceNode.createNativeMediaStreamAudioSourceNode), getNativeContext, isNativeOfflineAudioContext);
const createNativeMediaStreamTrackAudioSourceNode = (0, _nativeMediaStreamTrackAudioSourceNodeFactory.createNativeMediaStreamTrackAudioSourceNodeFactory)((0, _invalidStateError.createInvalidStateError), isNativeOfflineAudioContext);
const mediaStreamTrackAudioSourceNodeConstructor = (0, _mediaStreamTrackAudioSourceNodeConstructor.createMediaStreamTrackAudioSourceNodeConstructor)(audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext);
const audioContextConstructor = (0, _audioContextConstructor.createAudioContextConstructor)(baseAudioContextConstructor, (0, _invalidStateError.createInvalidStateError), (0, _notSupportedError.createNotSupportedError), (0, _unknownError.createUnknownError), mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor);
const getUnrenderedAudioWorkletNodes = (0, _getUnrenderedAudioWorkletNodes.createGetUnrenderedAudioWorkletNodes)(unrenderedAudioWorkletNodeStore);
const addUnrenderedAudioWorkletNode = (0, _addUnrenderedAudioWorkletNode.createAddUnrenderedAudioWorkletNode)(getUnrenderedAudioWorkletNodes);
const connectMultipleOutputs = (0, _connectMultipleOutputs.createConnectMultipleOutputs)((0, _indexSizeError.createIndexSizeError));
const deleteUnrenderedAudioWorkletNode = (0, _deleteUnrenderedAudioWorkletNode.createDeleteUnrenderedAudioWorkletNode)(getUnrenderedAudioWorkletNodes);
const disconnectMultipleOutputs = (0, _disconnectMultipleOutputs.createDisconnectMultipleOutputs)((0, _indexSizeError.createIndexSizeError));
const activeAudioWorkletNodeInputsStore = new WeakMap();
const getActiveAudioWorkletNodeInputs = (0, _getActiveAudioWorkletNodeInputs.createGetActiveAudioWorkletNodeInputs)(activeAudioWorkletNodeInputsStore, (0, _getValueForKey.getValueForKey));
const createNativeAudioWorkletNodeFaker = (0, _nativeAudioWorkletNodeFakerFactory.createNativeAudioWorkletNodeFakerFactory)(connectMultipleOutputs, (0, _indexSizeError.createIndexSizeError), (0, _invalidStateError.createInvalidStateError), createNativeChannelMergerNode, (0, _nativeChannelSplitterNode.createNativeChannelSplitterNode), createNativeConstantSourceNode, (0, _nativeGainNode.createNativeGainNode), (0, _nativeScriptProcessorNode.createNativeScriptProcessorNode), (0, _notSupportedError.createNotSupportedError), disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections);
const createNativeAudioWorkletNode = (0, _nativeAudioWorkletNodeFactory.createNativeAudioWorkletNodeFactory)((0, _invalidStateError.createInvalidStateError), createNativeAudioWorkletNodeFaker, (0, _nativeGainNode.createNativeGainNode), (0, _notSupportedError.createNotSupportedError), monitorConnections);
const createAudioWorkletNodeRenderer = (0, _audioWorkletNodeRendererFactory.createAudioWorkletNodeRendererFactory)(connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, (0, _nativeChannelSplitterNode.createNativeChannelSplitterNode), createNativeConstantSourceNode, (0, _nativeGainNode.createNativeGainNode), deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, (0, _getNativeAudioNode.getNativeAudioNode), nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);
const getBackupOfflineAudioContext = (0, _getBackupOfflineAudioContext.createGetBackupOfflineAudioContext)(backupOfflineAudioContextStore);
const setActiveAudioWorkletNodeInputs = (0, _setActiveAudioWorkletNodeInputs.createSetActiveAudioWorkletNodeInputs)(activeAudioWorkletNodeInputsStore);
// The AudioWorkletNode constructor is only available in a SecureContext.
const audioWorkletNodeConstructor = isSecureContext ? (0, _audioWorkletNodeConstructor.createAudioWorkletNodeConstructor)(addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, (0, _getAudioNodeConnections.getAudioNodeConnections), getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, (0, _sanitizeAudioWorkletNodeOptions.sanitizeAudioWorkletNodeOptions), setActiveAudioWorkletNodeInputs, (0, _testAudioWorkletNodeOptionsClonability.testAudioWorkletNodeOptionsClonability), (0, _wrapEventListener.wrapEventListener)) : undefined;
const minimalAudioContextConstructor = (0, _minimalAudioContextConstructor.createMinimalAudioContextConstructor)((0, _invalidStateError.createInvalidStateError), (0, _notSupportedError.createNotSupportedError), (0, _unknownError.createUnknownError), minimalBaseAudioContextConstructor, nativeAudioContextConstructor);
const createNativeOfflineAudioContext = (0, _createNativeOfflineAudioContext.createCreateNativeOfflineAudioContext)((0, _notSupportedError.createNotSupportedError), nativeOfflineAudioContextConstructor);
const startRendering = (0, _startRendering.createStartRendering)(audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, (0, _testAudioBufferCopyChannelMethodsOutOfBoundsSupport.testAudioBufferCopyChannelMethodsOutOfBoundsSupport), wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);
const minimalOfflineAudioContextConstructor = (0, _minimalOfflineAudioContextConstructor.createMinimalOfflineAudioContextConstructor)(cacheTestResult, (0, _invalidStateError.createInvalidStateError), createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering);
const offlineAudioContextConstructor = (0, _offlineAudioContextConstructor.createOfflineAudioContextConstructor)(baseAudioContextConstructor, cacheTestResult, (0, _invalidStateError.createInvalidStateError), createNativeOfflineAudioContext, startRendering);
const isAnyAudioContext = (0, _isAnyAudioContext.createIsAnyAudioContext)((0, _globals.CONTEXT_STORE), isNativeAudioContext);
const isAnyAudioNode = (0, _isAnyAudioNode.createIsAnyAudioNode)((0, _globals.AUDIO_NODE_STORE), isNativeAudioNode);
const isAnyAudioParam = (0, _isAnyAudioParam.createIsAnyAudioParam)((0, _globals.AUDIO_PARAM_STORE), isNativeAudioParam);
const isAnyOfflineAudioContext = (0, _isAnyOfflineAudioContext.createIsAnyOfflineAudioContext)((0, _globals.CONTEXT_STORE), isNativeOfflineAudioContext);
const isSupported = ()=>(0, _isSupportedPromise.createIsSupportedPromise)(cacheTestResult, (0, _testAudioBufferCopyChannelMethodsSubarraySupport.createTestAudioBufferCopyChannelMethodsSubarraySupport)(nativeOfflineAudioContextConstructor), (0, _testAudioContextCloseMethodSupport.createTestAudioContextCloseMethodSupport)(nativeAudioContextConstructor), (0, _testAudioContextDecodeAudioDataMethodTypeErrorSupport.createTestAudioContextDecodeAudioDataMethodTypeErrorSupport)(nativeOfflineAudioContextConstructor), (0, _testAudioContextOptionsSupport.createTestAudioContextOptionsSupport)(nativeAudioContextConstructor), (0, _testAudioNodeConnectMethodSupport.createTestAudioNodeConnectMethodSupport)(nativeOfflineAudioContextConstructor), (0, _testAudioWorkletProcessorNoOutputsSupport.createTestAudioWorkletProcessorNoOutputsSupport)(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), (0, _testChannelMergerNodeChannelCountSupport.createTestChannelMergerNodeChannelCountSupport)(nativeOfflineAudioContextConstructor), (0, _testConstantSourceNodeAccurateSchedulingSupport.createTestConstantSourceNodeAccurateSchedulingSupport)(nativeOfflineAudioContextConstructor), (0, _testConvolverNodeBufferReassignabilitySupport.createTestConvolverNodeBufferReassignabilitySupport)(nativeOfflineAudioContextConstructor), (0, _testConvolverNodeChannelCountSupport.createTestConvolverNodeChannelCountSupport)(nativeOfflineAudioContextConstructor), (0, _testDomExceptionConstructorSupport.testDomExceptionConstructorSupport), (0, _testIsSecureContextSupport.createTestIsSecureContextSupport)(window), (0, _testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport.createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)(nativeAudioContextConstructor), (0, _testStereoPannerNodeDefaultValueSupport.createTestStereoPannerNodeDefaultValueSupport)(nativeOfflineAudioContextConstructor), (0, _testTransferablesSupport.testTransferablesSupport));

},{"automation-events":"kxaFt","./factories/abort-error":"68YNi","./factories/add-active-input-connection-to-audio-node":"hWkkO","./factories/add-audio-node-connections":"kbJuF","./factories/add-audio-param-connections":"yMuUk","./factories/add-audio-worklet-module":"78VC1","./factories/add-connection-to-audio-node":"euwNB","./factories/add-passive-input-connection-to-audio-node":"6IMYe","./factories/add-silent-connection":"67JSI","./factories/add-unrendered-audio-worklet-node":"8f4Y4","./factories/analyser-node-constructor":"3Jxni","./factories/analyser-node-renderer-factory":"6tQEB","./factories/audio-buffer-constructor":"dszIU","./factories/audio-buffer-source-node-constructor":"8EaZc","./factories/audio-buffer-source-node-renderer-factory":"610ix","./factories/audio-context-constructor":"atX0V","./factories/audio-destination-node-constructor":"4BIeJ","./factories/audio-destination-node-renderer-factory":"gunYG","./factories/audio-listener-factory":"1a6Qa","./factories/audio-node-constructor":"wwDLJ","./factories/audio-param-factory":"iMx7e","./factories/audio-param-renderer":"9IbWX","./factories/audio-worklet-node-constructor":"2Gmbn","./factories/audio-worklet-node-renderer-factory":"kfvDm","./factories/base-audio-context-constructor":"1Qln6","./factories/biquad-filter-node-constructor":"2ojuk","./factories/biquad-filter-node-renderer-factory":"hC3lP","./factories/cache-test-result":"jAn86","./factories/channel-merger-node-constructor":"5qPp9","./factories/channel-merger-node-renderer-factory":"4213f","./factories/channel-splitter-node-constructor":"kBxxA","./factories/channel-splitter-node-renderer-factory":"eO46O","./factories/connect-audio-param":"hqUP2","./factories/connect-multiple-outputs":"8jyft","./factories/connected-native-audio-buffer-source-node-factory":"hT5R1","./factories/constant-source-node-constructor":"6BBM1","./factories/constant-source-node-renderer-factory":"kDcHK","./factories/convert-number-to-unsigned-long":"1xC44","./factories/convolver-node-constructor":"kcFQc","./factories/convolver-node-renderer-factory":"kmgKW","./factories/create-native-offline-audio-context":"7737w","./factories/data-clone-error":"h0Bd5","./factories/decode-audio-data":"foJCq","./factories/decrement-cycle-counter":"jg4nh","./factories/delay-node-constructor":"byamz","./factories/delay-node-renderer-factory":"1NO5F","./factories/delete-active-input-connection-to-audio-node":"3FRri","./factories/delete-unrendered-audio-worklet-node":"fNWyx","./factories/detect-cycles":"8VyTi","./factories/disconnect-multiple-outputs":"jaNPz","./factories/dynamics-compressor-node-constructor":"1G29t","./factories/dynamics-compressor-node-renderer-factory":"pqFDv","./factories/encoding-error":"2alua","./factories/evaluate-source":"8CpjU","./factories/event-target-constructor":"gjDDq","./factories/expose-current-frame-and-current-time":"gNRs4","./factories/fetch-source":"h4onu","./factories/gain-node-constructor":"9a9Vk","./factories/gain-node-renderer-factory":"itz3A","./factories/get-active-audio-worklet-node-inputs":"dg8Gd","./factories/get-audio-node-renderer":"k8CrE","./factories/get-audio-node-tail-time":"cKCqS","./factories/get-audio-param-renderer":"k8fN6","./factories/get-backup-offline-audio-context":"1vR8R","./factories/get-native-context":"2Ytji","./factories/get-or-create-backup-offline-audio-context":"kLefC","./factories/get-unrendered-audio-worklet-nodes":"jI5Mi","./factories/iir-filter-node-constructor":"3jZOn","./factories/iir-filter-node-renderer-factory":"eyGMp","./factories/increment-cycle-counter-factory":"eIT5f","./factories/index-size-error":"iKVgV","./factories/invalid-access-error":"u7Sql","./factories/invalid-state-error":"diSZR","./factories/is-any-audio-context":"eHxqH","./factories/is-any-audio-node":"tjPuV","./factories/is-any-audio-param":"hncwE","./factories/is-any-offline-audio-context":"evgeG","./factories/is-native-audio-context":"ctipH","./factories/is-native-audio-node":"6XefY","./factories/is-native-audio-param":"8zo2U","./factories/is-native-context":"bqWH8","./factories/is-native-offline-audio-context":"absQf","./factories/is-secure-context":"c4RLa","./factories/is-supported-promise":"lB7Vh","./factories/media-element-audio-source-node-constructor":"gvVfX","./factories/media-stream-audio-destination-node-constructor":"76MLr","./factories/media-stream-audio-source-node-constructor":"7y92U","./factories/media-stream-track-audio-source-node-constructor":"eubAO","./factories/minimal-audio-context-constructor":"2Rukp","./factories/minimal-base-audio-context-constructor":"8u4st","./factories/minimal-offline-audio-context-constructor":"9yhkF","./factories/monitor-connections":"eUd0z","./factories/native-analyser-node-factory":"eAIIV","./factories/native-audio-buffer-constructor":"2XJiC","./factories/native-audio-buffer-source-node-factory":"fj4aF","./factories/native-audio-context-constructor":"awJaY","./factories/native-audio-destination-node":"l61vA","./factories/native-audio-worklet-node-constructor":"eKntr","./factories/native-audio-worklet-node-factory":"3bxEK","./factories/native-audio-worklet-node-faker-factory":"8dSFA","./factories/native-biquad-filter-node":"Apyjl","./factories/native-channel-merger-node-factory":"90fMG","./factories/native-channel-splitter-node":"8Z3X6","./factories/native-constant-source-node-factory":"aZ9aQ","./factories/native-constant-source-node-faker-factory":"Jx9uB","./factories/native-convolver-node-factory":"1os2P","./factories/native-delay-node":"76TcR","./factories/native-dynamics-compressor-node-factory":"63iaU","./factories/native-gain-node":"k23ba","./factories/native-iir-filter-node-factory":"kpXKu","./factories/native-iir-filter-node-faker-factory":"3kywH","./factories/native-media-element-audio-source-node":"g804o","./factories/native-media-stream-audio-destination-node":"5Nm8V","./factories/native-media-stream-audio-source-node":"cc1Vv","./factories/native-media-stream-track-audio-source-node-factory":"833HX","./factories/native-offline-audio-context-constructor":"clMxf","./factories/native-oscillator-node-factory":"gRc8o","./factories/native-panner-node-factory":"aE8DJ","./factories/native-panner-node-faker-factory":"doyFo","./factories/native-periodic-wave-factory":"hMgnX","./factories/native-script-processor-node":"63kc1","./factories/native-stereo-panner-node-factory":"46iGP","./factories/native-stereo-panner-node-faker-factory":"3tpsg","./factories/native-wave-shaper-node-factory":"fYxR5","./factories/native-wave-shaper-node-faker-factory":"48VV2","./factories/not-supported-error":"fLKAR","./factories/offline-audio-context-constructor":"9iLZs","./factories/oscillator-node-constructor":"cS1X5","./factories/oscillator-node-renderer-factory":"21Ubp","./factories/panner-node-constructor":"3pCGA","./factories/panner-node-renderer-factory":"dmoFH","./factories/periodic-wave-constructor":"lQWxF","./factories/render-automation":"beVBx","./factories/render-inputs-of-audio-node":"lHwkb","./factories/render-inputs-of-audio-param":"h2qZT","./factories/render-native-offline-audio-context":"iIK4Q","./factories/set-active-audio-worklet-node-inputs":"3VTsP","./factories/set-audio-node-tail-time":"hzHas","./factories/start-rendering":"ebqUV","./factories/stereo-panner-node-constructor":"gc2rO","./factories/stereo-panner-node-renderer-factory":"dAPan","./factories/test-audio-buffer-constructor-support":"60xJt","./factories/test-audio-buffer-copy-channel-methods-subarray-support":"fDZlv","./factories/test-audio-context-close-method-support":"k9nLI","./factories/test-audio-context-decode-audio-data-method-type-error-support":"8SGZm","./factories/test-audio-context-options-support":"5NBS1","./factories/test-audio-node-connect-method-support":"4ontN","./factories/test-audio-worklet-processor-no-outputs-support":"baMs2","./factories/test-audio-worklet-processor-post-message-support":"47G9e","./factories/test-channel-merger-node-channel-count-support":"X0MIV","./factories/test-constant-source-node-accurate-scheduling-support":"dl03N","./factories/test-convolver-node-buffer-reassignability-support":"5yl0D","./factories/test-convolver-node-channel-count-support":"gM3PR","./factories/test-is-secure-context-support":"amjh7","./factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support":"bfbzD","./factories/test-offline-audio-context-current-time-support":"5xrL5","./factories/test-stereo-panner-node-default-value-support":"eG97H","./factories/unknown-error":"Vr3Lh","./factories/wave-shaper-node-constructor":"1yyiX","./factories/wave-shaper-node-renderer-factory":"8vhCu","./factories/window":"dEK7L","./factories/wrap-audio-buffer-copy-channel-methods":"bNAxX","./factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds":"4XNvu","./factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer":"ckaEw","./factories/wrap-channel-merger-node":"8txzE","./globals":"j1ar4","./helpers/connect-native-audio-node-to-native-audio-node":"he3cM","./helpers/disconnect-native-audio-node-from-native-audio-node":"766cG","./helpers/get-audio-node-connections":"huPRp","./helpers/get-audio-param-connections":"hfbFD","./helpers/get-event-listeners-of-audio-node":"hrKEN","./helpers/get-first-sample":"lprXE","./helpers/get-native-audio-node":"f9hIK","./helpers/get-native-audio-param":"fLdpl","./helpers/get-value-for-key":"kJr16","./helpers/insert-element-in-set":"917M8","./helpers/is-active-audio-node":"j8Y4t","./helpers/is-dc-curve":"1AlFj","./helpers/is-part-of-a-cycle":"jcP4P","./helpers/is-passive-audio-node":"1eGb9","./helpers/overwrite-accessors":"hfSZZ","./helpers/pick-element-from-set":"9U2YJ","./helpers/sanitize-audio-worklet-node-options":"T7Ytc","./helpers/sanitize-channel-splitter-options":"eYcVh","./helpers/sanitize-periodic-wave-options":"2uUdY","./helpers/set-value-at-time-until-possible":"U9WdO","./helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support":"bwZhm","./helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support":"d1Bp3","./helpers/test-audio-buffer-source-node-start-method-offset-clamping-support":"ljLh5","./helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support":"1AlzI","./helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support":"iXOCC","./helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support":"6HMSy","./helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support":"3eDpC","./helpers/test-audio-worklet-node-options-clonability":"cKeDz","./helpers/test-dom-exception-constructor-support":"4CH46","./helpers/test-promise-support":"4hyPB","./helpers/test-transferables-support":"5nYF9","./helpers/wrap-audio-buffer-source-node-start-method-offset-clamping":"cWWvc","./helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls":"fZgIG","./helpers/wrap-event-listener":"gbqed","./interfaces/index":"bFhB6","./types/index":"6tI3M","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kxaFt":[function(require,module,exports) {
(function(global, factory) {
    factory(exports, require("6b9f2442ef6fdd24"), require("5f22b44ee4228890"), require("a5970f48809bf08a"));
})(this, function(exports1, _slicedToArray, _classCallCheck, _createClass) {
    "use strict";
    var createExtendedExponentialRampToValueAutomationEvent = function createExtendedExponentialRampToValueAutomationEvent(value, endTime, insertTime) {
        return {
            endTime: endTime,
            insertTime: insertTime,
            type: "exponentialRampToValue",
            value: value
        };
    };
    var createExtendedLinearRampToValueAutomationEvent = function createExtendedLinearRampToValueAutomationEvent(value, endTime, insertTime) {
        return {
            endTime: endTime,
            insertTime: insertTime,
            type: "linearRampToValue",
            value: value
        };
    };
    var createSetValueAutomationEvent = function createSetValueAutomationEvent(value, startTime) {
        return {
            startTime: startTime,
            type: "setValue",
            value: value
        };
    };
    var createSetValueCurveAutomationEvent = function createSetValueCurveAutomationEvent(values, startTime, duration) {
        return {
            duration: duration,
            startTime: startTime,
            type: "setValueCurve",
            values: values
        };
    };
    var getTargetValueAtTime = function getTargetValueAtTime(time, valueAtStartTime, _ref) {
        var startTime = _ref.startTime, target = _ref.target, timeConstant = _ref.timeConstant;
        return target + (valueAtStartTime - target) * Math.exp((startTime - time) / timeConstant);
    };
    var isExponentialRampToValueAutomationEvent = function isExponentialRampToValueAutomationEvent(automationEvent) {
        return automationEvent.type === "exponentialRampToValue";
    };
    var isLinearRampToValueAutomationEvent = function isLinearRampToValueAutomationEvent(automationEvent) {
        return automationEvent.type === "linearRampToValue";
    };
    var isAnyRampToValueAutomationEvent = function isAnyRampToValueAutomationEvent(automationEvent) {
        return isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent);
    };
    var isSetValueAutomationEvent = function isSetValueAutomationEvent(automationEvent) {
        return automationEvent.type === "setValue";
    };
    var isSetValueCurveAutomationEvent = function isSetValueCurveAutomationEvent(automationEvent) {
        return automationEvent.type === "setValueCurve";
    };
    var getValueOfAutomationEventAtIndexAtTime = function getValueOfAutomationEventAtIndexAtTime(automationEvents, index, time, defaultValue) {
        var automationEvent = automationEvents[index];
        return automationEvent === undefined ? defaultValue : isAnyRampToValueAutomationEvent(automationEvent) || isSetValueAutomationEvent(automationEvent) ? automationEvent.value : isSetValueCurveAutomationEvent(automationEvent) ? automationEvent.values[automationEvent.values.length - 1] : getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, automationEvent.startTime, defaultValue), automationEvent);
    };
    var getEndTimeAndValueOfPreviousAutomationEvent = function getEndTimeAndValueOfPreviousAutomationEvent(automationEvents, index, currentAutomationEvent, nextAutomationEvent, defaultValue) {
        return currentAutomationEvent === undefined ? [
            nextAutomationEvent.insertTime,
            defaultValue
        ] : isAnyRampToValueAutomationEvent(currentAutomationEvent) ? [
            currentAutomationEvent.endTime,
            currentAutomationEvent.value
        ] : isSetValueAutomationEvent(currentAutomationEvent) ? [
            currentAutomationEvent.startTime,
            currentAutomationEvent.value
        ] : isSetValueCurveAutomationEvent(currentAutomationEvent) ? [
            currentAutomationEvent.startTime + currentAutomationEvent.duration,
            currentAutomationEvent.values[currentAutomationEvent.values.length - 1]
        ] : [
            currentAutomationEvent.startTime,
            getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, currentAutomationEvent.startTime, defaultValue)
        ];
    };
    var isCancelAndHoldAutomationEvent = function isCancelAndHoldAutomationEvent(automationEvent) {
        return automationEvent.type === "cancelAndHold";
    };
    var isCancelScheduledValuesAutomationEvent = function isCancelScheduledValuesAutomationEvent(automationEvent) {
        return automationEvent.type === "cancelScheduledValues";
    };
    var getEventTime = function getEventTime(automationEvent) {
        if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) return automationEvent.cancelTime;
        if (isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent)) return automationEvent.endTime;
        return automationEvent.startTime;
    };
    var getExponentialRampValueAtTime = function getExponentialRampValueAtTime(time, startTime, valueAtStartTime, _ref) {
        var endTime = _ref.endTime, value = _ref.value;
        if (valueAtStartTime === value) return value;
        if (0 < valueAtStartTime && 0 < value || valueAtStartTime < 0 && value < 0) return valueAtStartTime * Math.pow(value / valueAtStartTime, (time - startTime) / (endTime - startTime));
        return 0;
    };
    var getLinearRampValueAtTime = function getLinearRampValueAtTime(time, startTime, valueAtStartTime, _ref) {
        var endTime = _ref.endTime, value = _ref.value;
        return valueAtStartTime + (time - startTime) / (endTime - startTime) * (value - valueAtStartTime);
    };
    var interpolateValue = function interpolateValue(values, theoreticIndex) {
        var lowerIndex = Math.floor(theoreticIndex);
        var upperIndex = Math.ceil(theoreticIndex);
        if (lowerIndex === upperIndex) return values[lowerIndex];
        return (1 - (theoreticIndex - lowerIndex)) * values[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * values[upperIndex];
    };
    var getValueCurveValueAtTime = function getValueCurveValueAtTime(time, _ref) {
        var duration = _ref.duration, startTime = _ref.startTime, values = _ref.values;
        var theoreticIndex = (time - startTime) / duration * (values.length - 1);
        return interpolateValue(values, theoreticIndex);
    };
    var isSetTargetAutomationEvent = function isSetTargetAutomationEvent(automationEvent) {
        return automationEvent.type === "setTarget";
    };
    var AutomationEventList = /*#__PURE__*/ function() {
        function AutomationEventList(defaultValue) {
            _classCallCheck(this, AutomationEventList);
            this._automationEvents = [];
            this._currenTime = 0;
            this._defaultValue = defaultValue;
        }
        return _createClass(AutomationEventList, [
            {
                key: Symbol.iterator,
                value: function value() {
                    return this._automationEvents[Symbol.iterator]();
                }
            },
            {
                key: "add",
                value: function add(automationEvent) {
                    var eventTime = getEventTime(automationEvent);
                    if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {
                        var index = this._automationEvents.findIndex(function(currentAutomationEvent) {
                            if (isCancelScheduledValuesAutomationEvent(automationEvent) && isSetValueCurveAutomationEvent(currentAutomationEvent)) return currentAutomationEvent.startTime + currentAutomationEvent.duration >= eventTime;
                            return getEventTime(currentAutomationEvent) >= eventTime;
                        });
                        var removedAutomationEvent = this._automationEvents[index];
                        if (index !== -1) this._automationEvents = this._automationEvents.slice(0, index);
                        if (isCancelAndHoldAutomationEvent(automationEvent)) {
                            var lastAutomationEvent = this._automationEvents[this._automationEvents.length - 1];
                            if (removedAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(removedAutomationEvent)) {
                                if (lastAutomationEvent !== undefined && isSetTargetAutomationEvent(lastAutomationEvent)) throw new Error("The internal list is malformed.");
                                var startTime = lastAutomationEvent === undefined ? removedAutomationEvent.insertTime : isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.startTime + lastAutomationEvent.duration : getEventTime(lastAutomationEvent);
                                var startValue = lastAutomationEvent === undefined ? this._defaultValue : isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.values[lastAutomationEvent.values.length - 1] : lastAutomationEvent.value;
                                var value = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? getExponentialRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent) : getLinearRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent);
                                var truncatedAutomationEvent = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? createExtendedExponentialRampToValueAutomationEvent(value, eventTime, this._currenTime) : createExtendedLinearRampToValueAutomationEvent(value, eventTime, this._currenTime);
                                this._automationEvents.push(truncatedAutomationEvent);
                            }
                            if (lastAutomationEvent !== undefined && isSetTargetAutomationEvent(lastAutomationEvent)) this._automationEvents.push(createSetValueAutomationEvent(this.getValue(eventTime), eventTime));
                            if (lastAutomationEvent !== undefined && isSetValueCurveAutomationEvent(lastAutomationEvent) && lastAutomationEvent.startTime + lastAutomationEvent.duration > eventTime) {
                                var duration = eventTime - lastAutomationEvent.startTime;
                                var ratio = (lastAutomationEvent.values.length - 1) / lastAutomationEvent.duration;
                                var length = Math.max(2, 1 + Math.ceil(duration * ratio));
                                var fraction = duration / (length - 1) * ratio;
                                var values = lastAutomationEvent.values.slice(0, length);
                                if (fraction < 1) for(var i = 1; i < length; i += 1){
                                    var factor = fraction * i % 1;
                                    values[i] = lastAutomationEvent.values[i - 1] * (1 - factor) + lastAutomationEvent.values[i] * factor;
                                }
                                this._automationEvents[this._automationEvents.length - 1] = createSetValueCurveAutomationEvent(values, lastAutomationEvent.startTime, duration);
                            }
                        }
                    } else {
                        var _index = this._automationEvents.findIndex(function(currentAutomationEvent) {
                            return getEventTime(currentAutomationEvent) > eventTime;
                        });
                        var previousAutomationEvent = _index === -1 ? this._automationEvents[this._automationEvents.length - 1] : this._automationEvents[_index - 1];
                        if (previousAutomationEvent !== undefined && isSetValueCurveAutomationEvent(previousAutomationEvent) && getEventTime(previousAutomationEvent) + previousAutomationEvent.duration > eventTime) return false;
                        var persistentAutomationEvent = isExponentialRampToValueAutomationEvent(automationEvent) ? createExtendedExponentialRampToValueAutomationEvent(automationEvent.value, automationEvent.endTime, this._currenTime) : isLinearRampToValueAutomationEvent(automationEvent) ? createExtendedLinearRampToValueAutomationEvent(automationEvent.value, eventTime, this._currenTime) : automationEvent;
                        if (_index === -1) this._automationEvents.push(persistentAutomationEvent);
                        else {
                            if (isSetValueCurveAutomationEvent(automationEvent) && eventTime + automationEvent.duration > getEventTime(this._automationEvents[_index])) return false;
                            this._automationEvents.splice(_index, 0, persistentAutomationEvent);
                        }
                    }
                    return true;
                }
            },
            {
                key: "flush",
                value: function flush(time) {
                    var index = this._automationEvents.findIndex(function(currentAutomationEvent) {
                        return getEventTime(currentAutomationEvent) > time;
                    });
                    if (index > 1) {
                        var remainingAutomationEvents = this._automationEvents.slice(index - 1);
                        var firstRemainingAutomationEvent = remainingAutomationEvents[0];
                        if (isSetTargetAutomationEvent(firstRemainingAutomationEvent)) remainingAutomationEvents.unshift(createSetValueAutomationEvent(getValueOfAutomationEventAtIndexAtTime(this._automationEvents, index - 2, firstRemainingAutomationEvent.startTime, this._defaultValue), firstRemainingAutomationEvent.startTime));
                        this._automationEvents = remainingAutomationEvents;
                    }
                }
            },
            {
                key: "getValue",
                value: function getValue(time) {
                    if (this._automationEvents.length === 0) return this._defaultValue;
                    var indexOfNextEvent = this._automationEvents.findIndex(function(automationEvent) {
                        return getEventTime(automationEvent) > time;
                    });
                    var nextAutomationEvent = this._automationEvents[indexOfNextEvent];
                    var indexOfCurrentEvent = (indexOfNextEvent === -1 ? this._automationEvents.length : indexOfNextEvent) - 1;
                    var currentAutomationEvent = this._automationEvents[indexOfCurrentEvent];
                    if (currentAutomationEvent !== undefined && isSetTargetAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || nextAutomationEvent.insertTime > time)) return getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(this._automationEvents, indexOfCurrentEvent - 1, currentAutomationEvent.startTime, this._defaultValue), currentAutomationEvent);
                    if (currentAutomationEvent !== undefined && isSetValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) return currentAutomationEvent.value;
                    if (currentAutomationEvent !== undefined && isSetValueCurveAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || currentAutomationEvent.startTime + currentAutomationEvent.duration > time)) {
                        if (time < currentAutomationEvent.startTime + currentAutomationEvent.duration) return getValueCurveValueAtTime(time, currentAutomationEvent);
                        return currentAutomationEvent.values[currentAutomationEvent.values.length - 1];
                    }
                    if (currentAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) return currentAutomationEvent.value;
                    if (nextAutomationEvent !== undefined && isExponentialRampToValueAutomationEvent(nextAutomationEvent)) {
                        var _getEndTimeAndValueOf = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, indexOfCurrentEvent, currentAutomationEvent, nextAutomationEvent, this._defaultValue), _getEndTimeAndValueOf2 = _slicedToArray(_getEndTimeAndValueOf, 2), startTime = _getEndTimeAndValueOf2[0], value = _getEndTimeAndValueOf2[1];
                        return getExponentialRampValueAtTime(time, startTime, value, nextAutomationEvent);
                    }
                    if (nextAutomationEvent !== undefined && isLinearRampToValueAutomationEvent(nextAutomationEvent)) {
                        var _getEndTimeAndValueOf3 = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, indexOfCurrentEvent, currentAutomationEvent, nextAutomationEvent, this._defaultValue), _getEndTimeAndValueOf4 = _slicedToArray(_getEndTimeAndValueOf3, 2), _startTime = _getEndTimeAndValueOf4[0], _value = _getEndTimeAndValueOf4[1];
                        return getLinearRampValueAtTime(time, _startTime, _value, nextAutomationEvent);
                    }
                    return this._defaultValue;
                }
            }
        ]);
    }();
    var createCancelAndHoldAutomationEvent = function createCancelAndHoldAutomationEvent(cancelTime) {
        return {
            cancelTime: cancelTime,
            type: "cancelAndHold"
        };
    };
    var createCancelScheduledValuesAutomationEvent = function createCancelScheduledValuesAutomationEvent(cancelTime) {
        return {
            cancelTime: cancelTime,
            type: "cancelScheduledValues"
        };
    };
    var createExponentialRampToValueAutomationEvent = function createExponentialRampToValueAutomationEvent(value, endTime) {
        return {
            endTime: endTime,
            type: "exponentialRampToValue",
            value: value
        };
    };
    var createLinearRampToValueAutomationEvent = function createLinearRampToValueAutomationEvent(value, endTime) {
        return {
            endTime: endTime,
            type: "linearRampToValue",
            value: value
        };
    };
    var createSetTargetAutomationEvent = function createSetTargetAutomationEvent(target, startTime, timeConstant) {
        return {
            startTime: startTime,
            target: target,
            timeConstant: timeConstant,
            type: "setTarget"
        };
    };
    exports1.AutomationEventList = AutomationEventList;
    exports1.createCancelAndHoldAutomationEvent = createCancelAndHoldAutomationEvent;
    exports1.createCancelScheduledValuesAutomationEvent = createCancelScheduledValuesAutomationEvent;
    exports1.createExponentialRampToValueAutomationEvent = createExponentialRampToValueAutomationEvent;
    exports1.createLinearRampToValueAutomationEvent = createLinearRampToValueAutomationEvent;
    exports1.createSetTargetAutomationEvent = createSetTargetAutomationEvent;
    exports1.createSetValueAutomationEvent = createSetValueAutomationEvent;
    exports1.createSetValueCurveAutomationEvent = createSetValueCurveAutomationEvent;
});

},{"6b9f2442ef6fdd24":"6AJmz","5f22b44ee4228890":"3nRml","a5970f48809bf08a":"2yzPp"}],"6AJmz":[function(require,module,exports) {
var arrayWithHoles = require("a3af206dbd14b1b5");
var iterableToArrayLimit = require("c109e0e3b1a7ef05");
var unsupportedIterableToArray = require("6782568c4383bd49");
var nonIterableRest = require("1e06d43f4bd6e532");
function _slicedToArray(r, e) {
    return arrayWithHoles(r) || iterableToArrayLimit(r, e) || unsupportedIterableToArray(r, e) || nonIterableRest();
}
module.exports = _slicedToArray, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{"a3af206dbd14b1b5":"5CPOx","c109e0e3b1a7ef05":"2B9nq","6782568c4383bd49":"cFxnT","1e06d43f4bd6e532":"9O5RF"}],"5CPOx":[function(require,module,exports) {
function _arrayWithHoles(r) {
    if (Array.isArray(r)) return r;
}
module.exports = _arrayWithHoles, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{}],"2B9nq":[function(require,module,exports) {
function _iterableToArrayLimit(r, l) {
    var t = null == r ? null : "undefined" != typeof Symbol && r[Symbol.iterator] || r["@@iterator"];
    if (null != t) {
        var e, n, i, u, a = [], f = !0, o = !1;
        try {
            if (i = (t = t.call(r)).next, 0 === l) {
                if (Object(t) !== t) return;
                f = !1;
            } else for(; !(f = (e = i.call(t)).done) && (a.push(e.value), a.length !== l); f = !0);
        } catch (r) {
            o = !0, n = r;
        } finally{
            try {
                if (!f && null != t["return"] && (u = t["return"](), Object(u) !== u)) return;
            } finally{
                if (o) throw n;
            }
        }
        return a;
    }
}
module.exports = _iterableToArrayLimit, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{}],"cFxnT":[function(require,module,exports) {
var arrayLikeToArray = require("f8ccc0353f5f3746");
function _unsupportedIterableToArray(r, a) {
    if (r) {
        if ("string" == typeof r) return arrayLikeToArray(r, a);
        var t = ({}).toString.call(r).slice(8, -1);
        return "Object" === t && r.constructor && (t = r.constructor.name), "Map" === t || "Set" === t ? Array.from(r) : "Arguments" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? arrayLikeToArray(r, a) : void 0;
    }
}
module.exports = _unsupportedIterableToArray, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{"f8ccc0353f5f3746":"2QyYi"}],"2QyYi":[function(require,module,exports) {
function _arrayLikeToArray(r, a) {
    (null == a || a > r.length) && (a = r.length);
    for(var e = 0, n = Array(a); e < a; e++)n[e] = r[e];
    return n;
}
module.exports = _arrayLikeToArray, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{}],"9O5RF":[function(require,module,exports) {
function _nonIterableRest() {
    throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.");
}
module.exports = _nonIterableRest, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{}],"3nRml":[function(require,module,exports) {
function _classCallCheck(a, n) {
    if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function");
}
module.exports = _classCallCheck, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{}],"2yzPp":[function(require,module,exports) {
var toPropertyKey = require("b03a9e1e96a7e901");
function _defineProperties(e, r) {
    for(var t = 0; t < r.length; t++){
        var o = r[t];
        o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, toPropertyKey(o.key), o);
    }
}
function _createClass(e, r, t) {
    return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", {
        writable: !1
    }), e;
}
module.exports = _createClass, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{"b03a9e1e96a7e901":"5P3X5"}],"5P3X5":[function(require,module,exports) {
var _typeof = require("a14bd529aa4ac1cd")["default"];
var toPrimitive = require("2713647ce51d8c75");
function toPropertyKey(t) {
    var i = toPrimitive(t, "string");
    return "symbol" == _typeof(i) ? i : i + "";
}
module.exports = toPropertyKey, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{"a14bd529aa4ac1cd":"jgQjt","2713647ce51d8c75":"eJCHQ"}],"jgQjt":[function(require,module,exports) {
function _typeof(o) {
    "@babel/helpers - typeof";
    return module.exports = _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function(o) {
        return typeof o;
    } : function(o) {
        return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o;
    }, module.exports.__esModule = true, module.exports["default"] = module.exports, _typeof(o);
}
module.exports = _typeof, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{}],"eJCHQ":[function(require,module,exports) {
var _typeof = require("e0211298897b2d31")["default"];
function toPrimitive(t, r) {
    if ("object" != _typeof(t) || !t) return t;
    var e = t[Symbol.toPrimitive];
    if (void 0 !== e) {
        var i = e.call(t, r || "default");
        if ("object" != _typeof(i)) return i;
        throw new TypeError("@@toPrimitive must return a primitive value.");
    }
    return ("string" === r ? String : Number)(t);
}
module.exports = toPrimitive, module.exports.__esModule = true, module.exports["default"] = module.exports;

},{"e0211298897b2d31":"jgQjt"}],"68YNi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAbortError", ()=>createAbortError);
const createAbortError = ()=>new DOMException("", "AbortError");

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hWkkO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddActiveInputConnectionToAudioNode", ()=>createAddActiveInputConnectionToAudioNode);
const createAddActiveInputConnectionToAudioNode = (insertElementInSet)=>{
    return (activeInputs, source, [output, input, eventListener], ignoreDuplicates)=>{
        insertElementInSet(activeInputs[input], [
            source,
            output,
            eventListener
        ], (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output, ignoreDuplicates);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kbJuF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddAudioNodeConnections", ()=>createAddAudioNodeConnections);
const createAddAudioNodeConnections = (audioNodeConnectionsStore)=>{
    return (audioNode, audioNodeRenderer, nativeAudioNode)=>{
        const activeInputs = [];
        for(let i = 0; i < nativeAudioNode.numberOfInputs; i += 1)activeInputs.push(new Set());
        audioNodeConnectionsStore.set(audioNode, {
            activeInputs,
            outputs: new Set(),
            passiveInputs: new WeakMap(),
            renderer: audioNodeRenderer
        });
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"yMuUk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddAudioParamConnections", ()=>createAddAudioParamConnections);
const createAddAudioParamConnections = (audioParamConnectionsStore)=>{
    return (audioParam, audioParamRenderer)=>{
        audioParamConnectionsStore.set(audioParam, {
            activeInputs: new Set(),
            passiveInputs: new WeakMap(),
            renderer: audioParamRenderer
        });
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"78VC1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddAudioWorkletModule", ()=>createAddAudioWorkletModule);
var _globals = require("../globals");
var _isConstructible = require("../helpers/is-constructible");
var _splitImportStatements = require("../helpers/split-import-statements");
const verifyParameterDescriptors = (parameterDescriptors)=>{
    if (parameterDescriptors !== undefined && !Array.isArray(parameterDescriptors)) throw new TypeError("The parameterDescriptors property of given value for processorCtor is not an array.");
};
const verifyProcessorCtor = (processorCtor)=>{
    if (!(0, _isConstructible.isConstructible)(processorCtor)) throw new TypeError("The given value for processorCtor should be a constructor.");
    if (processorCtor.prototype === null || typeof processorCtor.prototype !== "object") throw new TypeError("The given value for processorCtor should have a prototype.");
};
const createAddAudioWorkletModule = (cacheTestResult, createNotSupportedError, evaluateSource, exposeCurrentFrameAndCurrentTime, fetchSource, getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, ongoingRequests, resolvedRequests, testAudioWorkletProcessorPostMessageSupport, window)=>{
    let index = 0;
    return (context, moduleURL, options = {
        credentials: "omit"
    })=>{
        const resolvedRequestsOfContext = resolvedRequests.get(context);
        if (resolvedRequestsOfContext !== undefined && resolvedRequestsOfContext.has(moduleURL)) return Promise.resolve();
        const ongoingRequestsOfContext = ongoingRequests.get(context);
        if (ongoingRequestsOfContext !== undefined) {
            const promiseOfOngoingRequest = ongoingRequestsOfContext.get(moduleURL);
            if (promiseOfOngoingRequest !== undefined) return promiseOfOngoingRequest;
        }
        const nativeContext = getNativeContext(context);
        // Bug #59: Safari does not implement the audioWorklet property.
        const promise = nativeContext.audioWorklet === undefined ? fetchSource(moduleURL).then(([source, absoluteUrl])=>{
            const [importStatements, sourceWithoutImportStatements] = (0, _splitImportStatements.splitImportStatements)(source, absoluteUrl);
            /*
                 * This is the unminified version of the code used below:
                 *
                 * ```js
                 * ${ importStatements };
                 * ((a, b) => {
                 *     (a[b] = a[b] || [ ]).push(
                 *         (AudioWorkletProcessor, global, registerProcessor, sampleRate, self, window) => {
                 *             ${ sourceWithoutImportStatements }
                 *         }
                 *     );
                 * })(window, '_AWGS');
                 * ```
                 */ // tslint:disable-next-line:max-line-length
            const wrappedSource = `${importStatements};((a,b)=>{(a[b]=a[b]||[]).push((AudioWorkletProcessor,global,registerProcessor,sampleRate,self,window)=>{${sourceWithoutImportStatements}
})})(window,'_AWGS')`;
            // @todo Evaluating the given source code is a possible security problem.
            return evaluateSource(wrappedSource);
        }).then(()=>{
            const evaluateAudioWorkletGlobalScope = window._AWGS.pop();
            if (evaluateAudioWorkletGlobalScope === undefined) // Bug #182 Chrome and Edge do throw an instance of a SyntaxError instead of a DOMException.
            throw new SyntaxError();
            exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, ()=>evaluateAudioWorkletGlobalScope(class AudioWorkletProcessor {
                }, undefined, (name, processorCtor)=>{
                    if (name.trim() === "") throw createNotSupportedError();
                    const nodeNameToProcessorConstructorMap = (0, _globals.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS).get(nativeContext);
                    if (nodeNameToProcessorConstructorMap !== undefined) {
                        if (nodeNameToProcessorConstructorMap.has(name)) throw createNotSupportedError();
                        verifyProcessorCtor(processorCtor);
                        verifyParameterDescriptors(processorCtor.parameterDescriptors);
                        nodeNameToProcessorConstructorMap.set(name, processorCtor);
                    } else {
                        verifyProcessorCtor(processorCtor);
                        verifyParameterDescriptors(processorCtor.parameterDescriptors);
                        (0, _globals.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS).set(nativeContext, new Map([
                            [
                                name,
                                processorCtor
                            ]
                        ]));
                    }
                }, nativeContext.sampleRate, undefined, undefined));
        }) : Promise.all([
            fetchSource(moduleURL),
            Promise.resolve(cacheTestResult(testAudioWorkletProcessorPostMessageSupport, testAudioWorkletProcessorPostMessageSupport))
        ]).then(([[source, absoluteUrl], isSupportingPostMessage])=>{
            const currentIndex = index + 1;
            index = currentIndex;
            const [importStatements, sourceWithoutImportStatements] = (0, _splitImportStatements.splitImportStatements)(source, absoluteUrl);
            /*
                 * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.
                 *
                 * This is the unminified version of the code used below.
                 *
                 * ```js
                 * class extends AudioWorkletProcessor {
                 *
                 *     __buffers = new WeakSet();
                 *
                 *     constructor () {
                 *         super();
                 *
                 *         this.port.postMessage = ((postMessage) => {
                 *             return (message, transferables) => {
                 *                 const filteredTransferables = (transferables)
                 *                     ? transferables.filter((transferable) => !this.__buffers.has(transferable))
                 *                     : transferables;
                 *
                 *                 return postMessage.call(this.port, message, filteredTransferables);
                 *              };
                 *         })(this.port.postMessage);
                 *     }
                 * }
                 * ```
                 */ const patchedAudioWorkletProcessor = isSupportingPostMessage ? "AudioWorkletProcessor" : "class extends AudioWorkletProcessor {__b=new WeakSet();constructor(){super();(p=>p.postMessage=(q=>(m,t)=>q.call(p,m,t?t.filter(u=>!this.__b.has(u)):t))(p.postMessage))(this.port)}}";
            /*
                 * Bug #170: Chrome and Edge do call process() with an array with empty channelData for each input if no input is connected.
                 *
                 * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.
                 *
                 * Bug #190: Safari doesn't throw an error when loading an unparsable module.
                 *
                 * This is the unminified version of the code used below:
                 *
                 * ```js
                 * `${ importStatements };
                 * ((AudioWorkletProcessor, registerProcessor) => {${ sourceWithoutImportStatements }
                 * })(
                 *     ${patchedAudioWorkletProcessor },
                 *     (name, processorCtor) => registerProcessor(name, class extends processorCtor {
                 *
                 *         __collectBuffers = (array) => {
                 *             array.forEach((element) => this.__buffers.add(element.buffer));
                 *         };
                 *
                 *         process (inputs, outputs, parameters) {
                 *             inputs.forEach(this.__collectBuffers);
                 *             outputs.forEach(this.__collectBuffers);
                 *             this.__collectBuffers(Object.values(parameters));
                 *
                 *             return super.process(
                 *                 (inputs.map((input) => input.some((channelData) => channelData.length === 0)) ? [ ] : input),
                 *                 outputs,
                 *                 parameters
                 *             );
                 *         }
                 *
                 *     })
                 * );
                 *
                 * registerProcessor(`__sac${currentIndex}`, class extends AudioWorkletProcessor{
                 *
                 *     process () {
                 *         return false;
                 *     }
                 *
                 * })`
                 * ```
                 */ const memberDefinition = isSupportingPostMessage ? "" : "__c = (a) => a.forEach(e=>this.__b.add(e.buffer));";
            const bufferRegistration = isSupportingPostMessage ? "" : "i.forEach(this.__c);o.forEach(this.__c);this.__c(Object.values(p));";
            const wrappedSource = `${importStatements};((AudioWorkletProcessor,registerProcessor)=>{${sourceWithoutImportStatements}
})(${patchedAudioWorkletProcessor},(n,p)=>registerProcessor(n,class extends p{${memberDefinition}process(i,o,p){${bufferRegistration}return super.process(i.map(j=>j.some(k=>k.length===0)?[]:j),o,p)}}));registerProcessor('__sac${currentIndex}',class extends AudioWorkletProcessor{process(){return !1}})`;
            const blob = new Blob([
                wrappedSource
            ], {
                type: "application/javascript; charset=utf-8"
            });
            const url = URL.createObjectURL(blob);
            return nativeContext.audioWorklet.addModule(url, options).then(()=>{
                if (isNativeOfflineAudioContext(nativeContext)) return nativeContext;
                // Bug #186: Chrome and Edge do not allow to create an AudioWorkletNode on a closed AudioContext.
                const backupOfflineAudioContext = getOrCreateBackupOfflineAudioContext(nativeContext);
                return backupOfflineAudioContext.audioWorklet.addModule(url, options).then(()=>backupOfflineAudioContext);
            }).then((nativeContextOrBackupOfflineAudioContext)=>{
                if (nativeAudioWorkletNodeConstructor === null) throw new SyntaxError();
                try {
                    // Bug #190: Safari doesn't throw an error when loading an unparsable module.
                    new nativeAudioWorkletNodeConstructor(nativeContextOrBackupOfflineAudioContext, `__sac${currentIndex}`); // tslint:disable-line:no-unused-expression
                } catch  {
                    throw new SyntaxError();
                }
            }).finally(()=>URL.revokeObjectURL(url));
        });
        if (ongoingRequestsOfContext === undefined) ongoingRequests.set(context, new Map([
            [
                moduleURL,
                promise
            ]
        ]));
        else ongoingRequestsOfContext.set(moduleURL, promise);
        promise.then(()=>{
            const updatedResolvedRequestsOfContext = resolvedRequests.get(context);
            if (updatedResolvedRequestsOfContext === undefined) resolvedRequests.set(context, new Set([
                moduleURL
            ]));
            else updatedResolvedRequestsOfContext.add(moduleURL);
        }).finally(()=>{
            const updatedOngoingRequestsOfContext = ongoingRequests.get(context);
            if (updatedOngoingRequestsOfContext !== undefined) updatedOngoingRequestsOfContext.delete(moduleURL);
        });
        return promise;
    };
};

},{"../globals":"j1ar4","../helpers/is-constructible":"8iOwk","../helpers/split-import-statements":"6hOa5","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j1ar4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ACTIVE_AUDIO_NODE_STORE", ()=>ACTIVE_AUDIO_NODE_STORE);
parcelHelpers.export(exports, "AUDIO_NODE_CONNECTIONS_STORE", ()=>AUDIO_NODE_CONNECTIONS_STORE);
parcelHelpers.export(exports, "AUDIO_NODE_STORE", ()=>AUDIO_NODE_STORE);
parcelHelpers.export(exports, "AUDIO_PARAM_CONNECTIONS_STORE", ()=>AUDIO_PARAM_CONNECTIONS_STORE);
parcelHelpers.export(exports, "AUDIO_PARAM_STORE", ()=>AUDIO_PARAM_STORE);
parcelHelpers.export(exports, "CONTEXT_STORE", ()=>CONTEXT_STORE);
parcelHelpers.export(exports, "EVENT_LISTENERS", ()=>EVENT_LISTENERS);
parcelHelpers.export(exports, "CYCLE_COUNTERS", ()=>CYCLE_COUNTERS);
parcelHelpers.export(exports, "NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS", ()=>NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS);
parcelHelpers.export(exports, "NODE_TO_PROCESSOR_MAPS", ()=>NODE_TO_PROCESSOR_MAPS);
const ACTIVE_AUDIO_NODE_STORE = new WeakSet();
const AUDIO_NODE_CONNECTIONS_STORE = new WeakMap();
const AUDIO_NODE_STORE = new WeakMap();
const AUDIO_PARAM_CONNECTIONS_STORE = new WeakMap();
const AUDIO_PARAM_STORE = new WeakMap();
const CONTEXT_STORE = new WeakMap();
const EVENT_LISTENERS = new WeakMap();
const CYCLE_COUNTERS = new WeakMap();
const NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS = new WeakMap();
const NODE_TO_PROCESSOR_MAPS = new WeakMap();

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8iOwk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isConstructible", ()=>isConstructible);
const handler = {
    construct () {
        return handler;
    }
};
const isConstructible = (constructible)=>{
    try {
        const proxy = new Proxy(constructible, handler);
        new proxy(); // tslint:disable-line:no-unused-expression
    } catch  {
        return false;
    }
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6hOa5":[function(require,module,exports) {
/*
 * This massive regex tries to cover all the following cases.
 *
 * import './path';
 * import defaultImport from './path';
 * import { namedImport } from './path';
 * import { namedImport as renamendImport } from './path';
 * import * as namespaceImport from './path';
 * import defaultImport, { namedImport } from './path';
 * import defaultImport, { namedImport as renamendImport } from './path';
 * import defaultImport, * as namespaceImport from './path';
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "splitImportStatements", ()=>splitImportStatements);
const IMPORT_STATEMENT_REGEX = /^import(?:(?:[\s]+[\w]+|(?:[\s]+[\w]+[\s]*,)?[\s]*\{[\s]*[\w]+(?:[\s]+as[\s]+[\w]+)?(?:[\s]*,[\s]*[\w]+(?:[\s]+as[\s]+[\w]+)?)*[\s]*}|(?:[\s]+[\w]+[\s]*,)?[\s]*\*[\s]+as[\s]+[\w]+)[\s]+from)?(?:[\s]*)("([^"\\]|\\.)+"|'([^'\\]|\\.)+')(?:[\s]*);?/; // tslint:disable-line:max-line-length
const splitImportStatements = (source, url)=>{
    const importStatements = [];
    let sourceWithoutImportStatements = source.replace(/^[\s]+/, "");
    let result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);
    while(result !== null){
        const unresolvedUrl = result[1].slice(1, -1);
        const importStatementWithResolvedUrl = result[0].replace(/([\s]+)?;?$/, "").replace(unresolvedUrl, new URL(unresolvedUrl, url).toString());
        importStatements.push(importStatementWithResolvedUrl);
        sourceWithoutImportStatements = sourceWithoutImportStatements.slice(result[0].length).replace(/^[\s]+/, "");
        result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);
    }
    return [
        importStatements.join(";"),
        sourceWithoutImportStatements
    ];
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"euwNB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddConnectionToAudioNode", ()=>createAddConnectionToAudioNode);
var _deletePassiveInputConnectionToAudioNode = require("../helpers/delete-passive-input-connection-to-audio-node");
var _setInternalStateToActive = require("../helpers/set-internal-state-to-active");
var _setInternalStateToPassiveWhenNecessary = require("../helpers/set-internal-state-to-passive-when-necessary");
const createAddConnectionToAudioNode = (addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, connectNativeAudioNodeToNativeAudioNode, deleteActiveInputConnectionToAudioNode, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getAudioNodeTailTime, getEventListenersOfAudioNode, getNativeAudioNode, insertElementInSet, isActiveAudioNode, isPartOfACycle, isPassiveAudioNode)=>{
    const tailTimeTimeoutIds = new WeakMap();
    return (source, destination, output, input, isOffline)=>{
        const { activeInputs, passiveInputs } = getAudioNodeConnections(destination);
        const { outputs } = getAudioNodeConnections(source);
        const eventListeners = getEventListenersOfAudioNode(source);
        const eventListener = (isActive)=>{
            const nativeDestinationAudioNode = getNativeAudioNode(destination);
            const nativeSourceAudioNode = getNativeAudioNode(source);
            if (isActive) {
                const partialConnection = (0, _deletePassiveInputConnectionToAudioNode.deletePassiveInputConnectionToAudioNode)(passiveInputs, source, output, input);
                addActiveInputConnectionToAudioNode(activeInputs, source, partialConnection, false);
                if (!isOffline && !isPartOfACycle(source)) connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);
                if (isPassiveAudioNode(destination)) (0, _setInternalStateToActive.setInternalStateToActive)(destination);
            } else {
                const partialConnection = deleteActiveInputConnectionToAudioNode(activeInputs, source, output, input);
                addPassiveInputConnectionToAudioNode(passiveInputs, input, partialConnection, false);
                if (!isOffline && !isPartOfACycle(source)) disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);
                const tailTime = getAudioNodeTailTime(destination);
                if (tailTime === 0) {
                    if (isActiveAudioNode(destination)) (0, _setInternalStateToPassiveWhenNecessary.setInternalStateToPassiveWhenNecessary)(destination, activeInputs);
                } else {
                    const tailTimeTimeoutId = tailTimeTimeoutIds.get(destination);
                    if (tailTimeTimeoutId !== undefined) clearTimeout(tailTimeTimeoutId);
                    tailTimeTimeoutIds.set(destination, setTimeout(()=>{
                        if (isActiveAudioNode(destination)) (0, _setInternalStateToPassiveWhenNecessary.setInternalStateToPassiveWhenNecessary)(destination, activeInputs);
                    }, tailTime * 1000));
                }
            }
        };
        if (insertElementInSet(outputs, [
            destination,
            output,
            input
        ], (outputConnection)=>outputConnection[0] === destination && outputConnection[1] === output && outputConnection[2] === input, true)) {
            eventListeners.add(eventListener);
            if (isActiveAudioNode(source)) addActiveInputConnectionToAudioNode(activeInputs, source, [
                output,
                input,
                eventListener
            ], true);
            else addPassiveInputConnectionToAudioNode(passiveInputs, input, [
                source,
                output,
                eventListener
            ], true);
            return true;
        }
        return false;
    };
};

},{"../helpers/delete-passive-input-connection-to-audio-node":"6FBGr","../helpers/set-internal-state-to-active":"gc0b0","../helpers/set-internal-state-to-passive-when-necessary":"5zVeT","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6FBGr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deletePassiveInputConnectionToAudioNode", ()=>deletePassiveInputConnectionToAudioNode);
var _getValueForKey = require("./get-value-for-key");
var _pickElementFromSet = require("./pick-element-from-set");
const deletePassiveInputConnectionToAudioNode = (passiveInputs, source, output, input)=>{
    const passiveInputConnections = (0, _getValueForKey.getValueForKey)(passiveInputs, source);
    const matchingConnection = (0, _pickElementFromSet.pickElementFromSet)(passiveInputConnections, (passiveInputConnection)=>passiveInputConnection[0] === output && passiveInputConnection[1] === input);
    if (passiveInputConnections.size === 0) passiveInputs.delete(source);
    return matchingConnection;
};

},{"./get-value-for-key":"kJr16","./pick-element-from-set":"9U2YJ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kJr16":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getValueForKey", ()=>getValueForKey);
const getValueForKey = (map, key)=>{
    const value = map.get(key);
    if (value === undefined) throw new Error("A value with the given key could not be found.");
    return value;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9U2YJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "pickElementFromSet", ()=>pickElementFromSet);
const pickElementFromSet = (set, predicate)=>{
    const matchingElements = Array.from(set).filter(predicate);
    if (matchingElements.length > 1) throw Error("More than one element was found.");
    if (matchingElements.length === 0) throw Error("No element was found.");
    const [matchingElement] = matchingElements;
    set.delete(matchingElement);
    return matchingElement;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gc0b0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "setInternalStateToActive", ()=>setInternalStateToActive);
var _globals = require("../globals");
var _getEventListenersOfAudioNode = require("./get-event-listeners-of-audio-node");
const setInternalStateToActive = (audioNode)=>{
    if ((0, _globals.ACTIVE_AUDIO_NODE_STORE).has(audioNode)) throw new Error("The AudioNode is already stored.");
    (0, _globals.ACTIVE_AUDIO_NODE_STORE).add(audioNode);
    (0, _getEventListenersOfAudioNode.getEventListenersOfAudioNode)(audioNode).forEach((eventListener)=>eventListener(true));
};

},{"../globals":"j1ar4","./get-event-listeners-of-audio-node":"hrKEN","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hrKEN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getEventListenersOfAudioNode", ()=>getEventListenersOfAudioNode);
var _globals = require("../globals");
var _getValueForKey = require("./get-value-for-key");
const getEventListenersOfAudioNode = (audioNode)=>{
    return (0, _getValueForKey.getValueForKey)((0, _globals.EVENT_LISTENERS), audioNode);
};

},{"../globals":"j1ar4","./get-value-for-key":"kJr16","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5zVeT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "setInternalStateToPassiveWhenNecessary", ()=>setInternalStateToPassiveWhenNecessary);
var _audioWorkletNode = require("../guards/audio-worklet-node");
var _setInternalStateToPassive = require("./set-internal-state-to-passive");
const setInternalStateToPassiveWhenNecessary = (audioNode, activeInputs)=>{
    if (!(0, _audioWorkletNode.isAudioWorkletNode)(audioNode) && activeInputs.every((connections)=>connections.size === 0)) (0, _setInternalStateToPassive.setInternalStateToPassive)(audioNode);
};

},{"../guards/audio-worklet-node":"fwNup","./set-internal-state-to-passive":"1Xtwa","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fwNup":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isAudioWorkletNode", ()=>isAudioWorkletNode);
const isAudioWorkletNode = (audioNode)=>{
    return "port" in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1Xtwa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "setInternalStateToPassive", ()=>setInternalStateToPassive);
var _globals = require("../globals");
var _getEventListenersOfAudioNode = require("./get-event-listeners-of-audio-node");
const setInternalStateToPassive = (audioNode)=>{
    if (!(0, _globals.ACTIVE_AUDIO_NODE_STORE).has(audioNode)) throw new Error("The AudioNode is not stored.");
    (0, _globals.ACTIVE_AUDIO_NODE_STORE).delete(audioNode);
    (0, _getEventListenersOfAudioNode.getEventListenersOfAudioNode)(audioNode).forEach((eventListener)=>eventListener(false));
};

},{"../globals":"j1ar4","./get-event-listeners-of-audio-node":"hrKEN","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6IMYe":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddPassiveInputConnectionToAudioNode", ()=>createAddPassiveInputConnectionToAudioNode);
const createAddPassiveInputConnectionToAudioNode = (insertElementInSet)=>{
    return (passiveInputs, input, [source, output, eventListener], ignoreDuplicates)=>{
        const passiveInputConnections = passiveInputs.get(source);
        if (passiveInputConnections === undefined) passiveInputs.set(source, new Set([
            [
                output,
                input,
                eventListener
            ]
        ]));
        else insertElementInSet(passiveInputConnections, [
            output,
            input,
            eventListener
        ], (passiveInputConnection)=>passiveInputConnection[0] === output && passiveInputConnection[1] === input, ignoreDuplicates);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"67JSI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddSilentConnection", ()=>createAddSilentConnection);
const createAddSilentConnection = (createNativeGainNode)=>{
    return (nativeContext, nativeAudioScheduledSourceNode)=>{
        const nativeGainNode = createNativeGainNode(nativeContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            gain: 0
        });
        nativeAudioScheduledSourceNode.connect(nativeGainNode).connect(nativeContext.destination);
        const disconnect = ()=>{
            nativeAudioScheduledSourceNode.removeEventListener("ended", disconnect);
            nativeAudioScheduledSourceNode.disconnect(nativeGainNode);
            nativeGainNode.disconnect();
        };
        nativeAudioScheduledSourceNode.addEventListener("ended", disconnect);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8f4Y4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddUnrenderedAudioWorkletNode", ()=>createAddUnrenderedAudioWorkletNode);
const createAddUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes)=>{
    return (nativeContext, audioWorkletNode)=>{
        getUnrenderedAudioWorkletNodes(nativeContext).add(audioWorkletNode);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3Jxni":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAnalyserNodeConstructor", ()=>createAnalyserNodeConstructor);
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    fftSize: 2048,
    maxDecibels: -30,
    minDecibels: -100,
    smoothingTimeConstant: 0.8
};
const createAnalyserNodeConstructor = (audionNodeConstructor, createAnalyserNodeRenderer, createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class AnalyserNode extends audionNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeAnalyserNode = createNativeAnalyserNode(nativeContext, mergedOptions);
            const analyserNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createAnalyserNodeRenderer() : null;
            super(context, false, nativeAnalyserNode, analyserNodeRenderer);
            this._nativeAnalyserNode = nativeAnalyserNode;
        }
        get fftSize() {
            return this._nativeAnalyserNode.fftSize;
        }
        set fftSize(value) {
            this._nativeAnalyserNode.fftSize = value;
        }
        get frequencyBinCount() {
            return this._nativeAnalyserNode.frequencyBinCount;
        }
        get maxDecibels() {
            return this._nativeAnalyserNode.maxDecibels;
        }
        set maxDecibels(value) {
            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
            const maxDecibels = this._nativeAnalyserNode.maxDecibels;
            this._nativeAnalyserNode.maxDecibels = value;
            if (!(value > this._nativeAnalyserNode.minDecibels)) {
                this._nativeAnalyserNode.maxDecibels = maxDecibels;
                throw createIndexSizeError();
            }
        }
        get minDecibels() {
            return this._nativeAnalyserNode.minDecibels;
        }
        set minDecibels(value) {
            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
            const minDecibels = this._nativeAnalyserNode.minDecibels;
            this._nativeAnalyserNode.minDecibels = value;
            if (!(this._nativeAnalyserNode.maxDecibels > value)) {
                this._nativeAnalyserNode.minDecibels = minDecibels;
                throw createIndexSizeError();
            }
        }
        get smoothingTimeConstant() {
            return this._nativeAnalyserNode.smoothingTimeConstant;
        }
        set smoothingTimeConstant(value) {
            this._nativeAnalyserNode.smoothingTimeConstant = value;
        }
        getByteFrequencyData(array) {
            this._nativeAnalyserNode.getByteFrequencyData(array);
        }
        getByteTimeDomainData(array) {
            this._nativeAnalyserNode.getByteTimeDomainData(array);
        }
        getFloatFrequencyData(array) {
            this._nativeAnalyserNode.getFloatFrequencyData(array);
        }
        getFloatTimeDomainData(array) {
            this._nativeAnalyserNode.getFloatTimeDomainData(array);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6tQEB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAnalyserNodeRendererFactory", ()=>createAnalyserNodeRendererFactory);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createAnalyserNodeRendererFactory = (createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAnalyserNodes = new WeakMap();
        const createAnalyserNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAnalyserNode = getNativeAudioNode(proxy);
            // If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeAnalyserNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeAnalyserNode, nativeOfflineAudioContext);
            if (!nativeAnalyserNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeAnalyserNode.channelCount,
                    channelCountMode: nativeAnalyserNode.channelCountMode,
                    channelInterpretation: nativeAnalyserNode.channelInterpretation,
                    fftSize: nativeAnalyserNode.fftSize,
                    maxDecibels: nativeAnalyserNode.maxDecibels,
                    minDecibels: nativeAnalyserNode.minDecibels,
                    smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant
                };
                nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAnalyserNodes.set(nativeOfflineAudioContext, nativeAnalyserNode);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode);
            return nativeAnalyserNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeAnalyserNode = renderedNativeAnalyserNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAnalyserNode !== undefined) return Promise.resolve(renderedNativeAnalyserNode);
                return createAnalyserNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1Rud3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isOwnedByContext", ()=>isOwnedByContext);
const isOwnedByContext = (nativeAudioNode, nativeContext)=>{
    return nativeAudioNode.context === nativeContext;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dszIU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioBufferConstructor", ()=>createAudioBufferConstructor);
var _testAudioBufferCopyChannelMethodsOutOfBoundsSupport = require("../helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support");
var _wrapAudioBufferGetChannelDataMethod = require("../helpers/wrap-audio-buffer-get-channel-data-method");
const DEFAULT_OPTIONS = {
    numberOfChannels: 1
};
const createAudioBufferConstructor = (audioBufferStore, cacheTestResult, createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, testNativeAudioBufferConstructorSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds)=>{
    let nativeOfflineAudioContext = null;
    return class AudioBuffer {
        constructor(options){
            if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
            const { length, numberOfChannels, sampleRate } = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            if (nativeOfflineAudioContext === null) nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            /*
             * Bug #99: Firefox does not throw a NotSupportedError when the numberOfChannels is zero. But it only does it when using the
             * factory function. But since Firefox also supports the constructor everything should be fine.
             */ const audioBuffer = nativeAudioBufferConstructor !== null && cacheTestResult(testNativeAudioBufferConstructorSupport, testNativeAudioBufferConstructorSupport) ? new nativeAudioBufferConstructor({
                length,
                numberOfChannels,
                sampleRate
            }) : nativeOfflineAudioContext.createBuffer(numberOfChannels, length, sampleRate);
            // Bug #99: Safari does not throw an error when the numberOfChannels is zero.
            if (audioBuffer.numberOfChannels === 0) throw createNotSupportedError();
            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
            // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
            if (typeof audioBuffer.copyFromChannel !== "function") {
                wrapAudioBufferCopyChannelMethods(audioBuffer);
                (0, _wrapAudioBufferGetChannelDataMethod.wrapAudioBufferGetChannelDataMethod)(audioBuffer);
            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
            } else if (!cacheTestResult((0, _testAudioBufferCopyChannelMethodsOutOfBoundsSupport.testAudioBufferCopyChannelMethodsOutOfBoundsSupport), ()=>(0, _testAudioBufferCopyChannelMethodsOutOfBoundsSupport.testAudioBufferCopyChannelMethodsOutOfBoundsSupport)(audioBuffer))) wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
            audioBufferStore.add(audioBuffer);
            /*
             * This does violate all good pratices but it is necessary to allow this AudioBuffer to be used with native
             * (Offline)AudioContexts.
             */ return audioBuffer;
        }
        static [Symbol.hasInstance](instance) {
            return instance !== null && typeof instance === "object" && Object.getPrototypeOf(instance) === AudioBuffer.prototype || audioBufferStore.has(instance);
        }
    };
};

},{"../helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support":"bwZhm","../helpers/wrap-audio-buffer-get-channel-data-method":"bXfRI","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bwZhm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioBufferCopyChannelMethodsOutOfBoundsSupport", ()=>testAudioBufferCopyChannelMethodsOutOfBoundsSupport);
const testAudioBufferCopyChannelMethodsOutOfBoundsSupport = (nativeAudioBuffer)=>{
    try {
        nativeAudioBuffer.copyToChannel(new Float32Array(1), 0, -1);
    } catch  {
        return false;
    }
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bXfRI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioBufferGetChannelDataMethod", ()=>wrapAudioBufferGetChannelDataMethod);
var _indexSizeError = require("../factories/index-size-error");
const wrapAudioBufferGetChannelDataMethod = (audioBuffer)=>{
    audioBuffer.getChannelData = ((getChannelData)=>{
        return (channel)=>{
            try {
                return getChannelData.call(audioBuffer, channel);
            } catch (err) {
                if (err.code === 12) throw (0, _indexSizeError.createIndexSizeError)();
                throw err;
            }
        };
    })(audioBuffer.getChannelData);
};

},{"../factories/index-size-error":"iKVgV","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iKVgV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIndexSizeError", ()=>createIndexSizeError);
const createIndexSizeError = ()=>new DOMException("", "IndexSizeError");

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8EaZc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioBufferSourceNodeConstructor", ()=>createAudioBufferSourceNodeConstructor);
var _constants = require("../constants");
var _isActiveAudioNode = require("../helpers/is-active-audio-node");
var _setInternalStateToActive = require("../helpers/set-internal-state-to-active");
var _setInternalStateToPassive = require("../helpers/set-internal-state-to-passive");
const DEFAULT_OPTIONS = {
    buffer: null,
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    // Bug #149: Safari does not yet support the detune AudioParam.
    loop: false,
    loopEnd: 0,
    loopStart: 0,
    playbackRate: 1
};
const createAudioBufferSourceNodeConstructor = (audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener)=>{
    return class AudioBufferSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const audioBufferSourceNodeRenderer = isOffline ? createAudioBufferSourceNodeRenderer() : null;
            super(context, false, nativeAudioBufferSourceNode, audioBufferSourceNodeRenderer);
            this._audioBufferSourceNodeRenderer = audioBufferSourceNodeRenderer;
            this._isBufferNullified = false;
            this._isBufferSet = mergedOptions.buffer !== null;
            this._nativeAudioBufferSourceNode = nativeAudioBufferSourceNode;
            this._onended = null;
            // Bug #73: Safari does not export the correct values for maxValue and minValue.
            this._playbackRate = createAudioParam(this, isOffline, nativeAudioBufferSourceNode.playbackRate, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
        }
        get buffer() {
            if (this._isBufferNullified) return null;
            return this._nativeAudioBufferSourceNode.buffer;
        }
        set buffer(value) {
            this._nativeAudioBufferSourceNode.buffer = value;
            // Bug #72: Only Chrome & Edge do not allow to reassign the buffer yet.
            if (value !== null) {
                if (this._isBufferSet) throw createInvalidStateError();
                this._isBufferSet = true;
            }
        }
        get loop() {
            return this._nativeAudioBufferSourceNode.loop;
        }
        set loop(value) {
            this._nativeAudioBufferSourceNode.loop = value;
        }
        get loopEnd() {
            return this._nativeAudioBufferSourceNode.loopEnd;
        }
        set loopEnd(value) {
            this._nativeAudioBufferSourceNode.loopEnd = value;
        }
        get loopStart() {
            return this._nativeAudioBufferSourceNode.loopStart;
        }
        set loopStart(value) {
            this._nativeAudioBufferSourceNode.loopStart = value;
        }
        get onended() {
            return this._onended;
        }
        set onended(value) {
            const wrappedListener = typeof value === "function" ? wrapEventListener(this, value) : null;
            this._nativeAudioBufferSourceNode.onended = wrappedListener;
            const nativeOnEnded = this._nativeAudioBufferSourceNode.onended;
            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
        }
        get playbackRate() {
            return this._playbackRate;
        }
        start(when = 0, offset = 0, duration) {
            this._nativeAudioBufferSourceNode.start(when, offset, duration);
            if (this._audioBufferSourceNodeRenderer !== null) this._audioBufferSourceNodeRenderer.start = duration === undefined ? [
                when,
                offset
            ] : [
                when,
                offset,
                duration
            ];
            if (this.context.state !== "closed") {
                (0, _setInternalStateToActive.setInternalStateToActive)(this);
                const resetInternalStateToPassive = ()=>{
                    this._nativeAudioBufferSourceNode.removeEventListener("ended", resetInternalStateToPassive);
                    if ((0, _isActiveAudioNode.isActiveAudioNode)(this)) (0, _setInternalStateToPassive.setInternalStateToPassive)(this);
                };
                this._nativeAudioBufferSourceNode.addEventListener("ended", resetInternalStateToPassive);
            }
        }
        stop(when = 0) {
            this._nativeAudioBufferSourceNode.stop(when);
            if (this._audioBufferSourceNodeRenderer !== null) this._audioBufferSourceNodeRenderer.stop = when;
        }
    };
};

},{"../constants":"au584","../helpers/is-active-audio-node":"j8Y4t","../helpers/set-internal-state-to-active":"gc0b0","../helpers/set-internal-state-to-passive":"1Xtwa","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"au584":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "MOST_NEGATIVE_SINGLE_FLOAT", ()=>MOST_NEGATIVE_SINGLE_FLOAT);
parcelHelpers.export(exports, "MOST_POSITIVE_SINGLE_FLOAT", ()=>MOST_POSITIVE_SINGLE_FLOAT);
const MOST_NEGATIVE_SINGLE_FLOAT = -340282346638528860000000000000000000000;
const MOST_POSITIVE_SINGLE_FLOAT = -MOST_NEGATIVE_SINGLE_FLOAT;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j8Y4t":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isActiveAudioNode", ()=>isActiveAudioNode);
var _globals = require("../globals");
const isActiveAudioNode = (audioNode)=>(0, _globals.ACTIVE_AUDIO_NODE_STORE).has(audioNode);

},{"../globals":"j1ar4","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"610ix":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioBufferSourceNodeRendererFactory", ()=>createAudioBufferSourceNodeRendererFactory);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createAudioBufferSourceNodeRendererFactory = (connectAudioParam, createNativeAudioBufferSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAudioBufferSourceNodes = new WeakMap();
        let start = null;
        let stop = null;
        const createAudioBufferSourceNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAudioBufferSourceNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeAudioBufferSourceNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeAudioBufferSourceNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeAudioBufferSourceNode, nativeOfflineAudioContext);
            if (!nativeAudioBufferSourceNodeIsOwnedByContext) {
                const options = {
                    buffer: nativeAudioBufferSourceNode.buffer,
                    channelCount: nativeAudioBufferSourceNode.channelCount,
                    channelCountMode: nativeAudioBufferSourceNode.channelCountMode,
                    channelInterpretation: nativeAudioBufferSourceNode.channelInterpretation,
                    // Bug #149: Safari does not yet support the detune AudioParam.
                    loop: nativeAudioBufferSourceNode.loop,
                    loopEnd: nativeAudioBufferSourceNode.loopEnd,
                    loopStart: nativeAudioBufferSourceNode.loopStart,
                    playbackRate: nativeAudioBufferSourceNode.playbackRate.value
                };
                nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, options);
                if (start !== null) nativeAudioBufferSourceNode.start(...start);
                if (stop !== null) nativeAudioBufferSourceNode.stop(stop);
            }
            renderedNativeAudioBufferSourceNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode);
            if (!nativeAudioBufferSourceNodeIsOwnedByContext) // Bug #149: Safari does not yet support the detune AudioParam.
            await renderAutomation(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate);
            else // Bug #149: Safari does not yet support the detune AudioParam.
            await connectAudioParam(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioBufferSourceNode);
            return nativeAudioBufferSourceNode;
        };
        return {
            set start (value){
                start = value;
            },
            set stop (value){
                stop = value;
            },
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeAudioBufferSourceNode = renderedNativeAudioBufferSourceNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioBufferSourceNode !== undefined) return Promise.resolve(renderedNativeAudioBufferSourceNode);
                return createAudioBufferSourceNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"atX0V":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioContextConstructor", ()=>createAudioContextConstructor);
var _deactivateAudioGraph = require("../helpers/deactivate-audio-graph");
var _isValidLatencyHint = require("../helpers/is-valid-latency-hint");
const createAudioContextConstructor = (baseAudioContextConstructor, createInvalidStateError, createNotSupportedError, createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor)=>{
    return class AudioContext extends baseAudioContextConstructor {
        constructor(options = {}){
            if (nativeAudioContextConstructor === null) throw new Error("Missing the native AudioContext constructor.");
            let nativeAudioContext;
            try {
                nativeAudioContext = new nativeAudioContextConstructor(options);
            } catch (err) {
                // Bug #192 Safari does throw a SyntaxError if the sampleRate is not supported.
                if (err.code === 12 && err.message === "sampleRate is not in range") throw createNotSupportedError();
                throw err;
            }
            // Bug #131 Safari returns null when there are four other AudioContexts running already.
            if (nativeAudioContext === null) throw createUnknownError();
            // Bug #51 Only Chrome and Edge throw an error if the given latencyHint is invalid.
            if (!(0, _isValidLatencyHint.isValidLatencyHint)(options.latencyHint)) throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);
            // Bug #150 Safari does not support setting the sampleRate.
            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) throw createNotSupportedError();
            super(nativeAudioContext, 2);
            const { latencyHint } = options;
            const { sampleRate } = nativeAudioContext;
            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.
            this._baseLatency = typeof nativeAudioContext.baseLatency === "number" ? nativeAudioContext.baseLatency : latencyHint === "balanced" ? 512 / sampleRate : latencyHint === "interactive" || latencyHint === undefined ? 256 / sampleRate : latencyHint === "playback" ? 1024 / sampleRate : /*
                                   * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a
                                   * ScriptProcessorNode.
                                   */ Math.max(2, Math.min(128, Math.round(latencyHint * sampleRate / 128))) * 128 / sampleRate;
            this._nativeAudioContext = nativeAudioContext;
            // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.
            if (nativeAudioContextConstructor.name === "webkitAudioContext") {
                this._nativeGainNode = nativeAudioContext.createGain();
                this._nativeOscillatorNode = nativeAudioContext.createOscillator();
                this._nativeGainNode.gain.value = 1e-37;
                this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);
                this._nativeOscillatorNode.start();
            } else {
                this._nativeGainNode = null;
                this._nativeOscillatorNode = null;
            }
            this._state = null;
            /*
             * Bug #34: Chrome and Edge pretend to be running right away, but fire an onstatechange event when the state actually changes
             * to 'running'.
             */ if (nativeAudioContext.state === "running") {
                this._state = "suspended";
                const revokeState = ()=>{
                    if (this._state === "suspended") this._state = null;
                    nativeAudioContext.removeEventListener("statechange", revokeState);
                };
                nativeAudioContext.addEventListener("statechange", revokeState);
            }
        }
        get baseLatency() {
            return this._baseLatency;
        }
        get state() {
            return this._state !== null ? this._state : this._nativeAudioContext.state;
        }
        close() {
            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.
            if (this.state === "closed") return this._nativeAudioContext.close().then(()=>{
                throw createInvalidStateError();
            });
            // Bug #34: If the state was set to suspended before it should be revoked now.
            if (this._state === "suspended") this._state = null;
            return this._nativeAudioContext.close().then(()=>{
                if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {
                    this._nativeOscillatorNode.stop();
                    this._nativeGainNode.disconnect();
                    this._nativeOscillatorNode.disconnect();
                }
                (0, _deactivateAudioGraph.deactivateAudioGraph)(this);
            });
        }
        createMediaElementSource(mediaElement) {
            return new mediaElementAudioSourceNodeConstructor(this, {
                mediaElement
            });
        }
        createMediaStreamDestination() {
            return new mediaStreamAudioDestinationNodeConstructor(this);
        }
        createMediaStreamSource(mediaStream) {
            return new mediaStreamAudioSourceNodeConstructor(this, {
                mediaStream
            });
        }
        createMediaStreamTrackSource(mediaStreamTrack) {
            return new mediaStreamTrackAudioSourceNodeConstructor(this, {
                mediaStreamTrack
            });
        }
        resume() {
            if (this._state === "suspended") return new Promise((resolve, reject)=>{
                const resolvePromise = ()=>{
                    this._nativeAudioContext.removeEventListener("statechange", resolvePromise);
                    if (this._nativeAudioContext.state === "running") resolve();
                    else this.resume().then(resolve, reject);
                };
                this._nativeAudioContext.addEventListener("statechange", resolvePromise);
            });
            return this._nativeAudioContext.resume().catch((err)=>{
                // Bug #55: Chrome and Edge do throw an InvalidAccessError instead of an InvalidStateError.
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined || err.code === 15) throw createInvalidStateError();
                throw err;
            });
        }
        suspend() {
            return this._nativeAudioContext.suspend().catch((err)=>{
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined) throw createInvalidStateError();
                throw err;
            });
        }
    };
};

},{"../helpers/deactivate-audio-graph":"ap1I7","../helpers/is-valid-latency-hint":"7xWOy","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ap1I7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deactivateAudioGraph", ()=>deactivateAudioGraph);
var _deactivateActiveAudioNodeInputConnections = require("./deactivate-active-audio-node-input-connections");
const deactivateAudioGraph = (context)=>{
    (0, _deactivateActiveAudioNodeInputConnections.deactivateActiveAudioNodeInputConnections)(context.destination, []);
};

},{"./deactivate-active-audio-node-input-connections":"6Nufv","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6Nufv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deactivateActiveAudioNodeInputConnections", ()=>deactivateActiveAudioNodeInputConnections);
var _audioBufferSourceNode = require("../guards/audio-buffer-source-node");
var _audioWorkletNode = require("../guards/audio-worklet-node");
var _biquadFilterNode = require("../guards/biquad-filter-node");
var _constantSourceNode = require("../guards/constant-source-node");
var _gainNode = require("../guards/gain-node");
var _oscillatorNode = require("../guards/oscillator-node");
var _stereoPannerNode = require("../guards/stereo-panner-node");
var _getAudioNodeConnections = require("./get-audio-node-connections");
var _getAudioParamConnections = require("./get-audio-param-connections");
var _isActiveAudioNode = require("./is-active-audio-node");
var _setInternalStateToPassive = require("./set-internal-state-to-passive");
const deactivateActiveAudioNodeInputConnections = (audioNode, trace)=>{
    const { activeInputs } = (0, _getAudioNodeConnections.getAudioNodeConnections)(audioNode);
    activeInputs.forEach((connections)=>connections.forEach(([source])=>{
            if (!trace.includes(audioNode)) deactivateActiveAudioNodeInputConnections(source, [
                ...trace,
                audioNode
            ]);
        }));
    const audioParams = (0, _audioBufferSourceNode.isAudioBufferSourceNode)(audioNode) ? [
        // Bug #149: Safari does not yet support the detune AudioParam.
        audioNode.playbackRate
    ] : (0, _audioWorkletNode.isAudioWorkletNode)(audioNode) ? Array.from(audioNode.parameters.values()) : (0, _biquadFilterNode.isBiquadFilterNode)(audioNode) ? [
        audioNode.Q,
        audioNode.detune,
        audioNode.frequency,
        audioNode.gain
    ] : (0, _constantSourceNode.isConstantSourceNode)(audioNode) ? [
        audioNode.offset
    ] : (0, _gainNode.isGainNode)(audioNode) ? [
        audioNode.gain
    ] : (0, _oscillatorNode.isOscillatorNode)(audioNode) ? [
        audioNode.detune,
        audioNode.frequency
    ] : (0, _stereoPannerNode.isStereoPannerNode)(audioNode) ? [
        audioNode.pan
    ] : [];
    for (const audioParam of audioParams){
        const audioParamConnections = (0, _getAudioParamConnections.getAudioParamConnections)(audioParam);
        if (audioParamConnections !== undefined) audioParamConnections.activeInputs.forEach(([source])=>deactivateActiveAudioNodeInputConnections(source, trace));
    }
    if ((0, _isActiveAudioNode.isActiveAudioNode)(audioNode)) (0, _setInternalStateToPassive.setInternalStateToPassive)(audioNode);
};

},{"../guards/audio-buffer-source-node":"76moj","../guards/audio-worklet-node":"fwNup","../guards/biquad-filter-node":"22F3d","../guards/constant-source-node":"bPaC9","../guards/gain-node":"2gRUe","../guards/oscillator-node":"aJzLA","../guards/stereo-panner-node":"aKnOB","./get-audio-node-connections":"huPRp","./get-audio-param-connections":"hfbFD","./is-active-audio-node":"j8Y4t","./set-internal-state-to-passive":"1Xtwa","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"76moj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isAudioBufferSourceNode", ()=>isAudioBufferSourceNode);
const isAudioBufferSourceNode = (audioNode)=>{
    return "playbackRate" in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"22F3d":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isBiquadFilterNode", ()=>isBiquadFilterNode);
const isBiquadFilterNode = (audioNode)=>{
    return "frequency" in audioNode && "gain" in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bPaC9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isConstantSourceNode", ()=>isConstantSourceNode);
const isConstantSourceNode = (audioNode)=>{
    return "offset" in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2gRUe":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isGainNode", ()=>isGainNode);
const isGainNode = (audioNode)=>{
    return !("frequency" in audioNode) && "gain" in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aJzLA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isOscillatorNode", ()=>isOscillatorNode);
const isOscillatorNode = (audioNode)=>{
    return "detune" in audioNode && "frequency" in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aKnOB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isStereoPannerNode", ()=>isStereoPannerNode);
const isStereoPannerNode = (audioNode)=>{
    return "pan" in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"huPRp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getAudioNodeConnections", ()=>getAudioNodeConnections);
var _globals = require("../globals");
var _getValueForKey = require("./get-value-for-key");
const getAudioNodeConnections = (audioNode)=>{
    return (0, _getValueForKey.getValueForKey)((0, _globals.AUDIO_NODE_CONNECTIONS_STORE), audioNode);
};

},{"../globals":"j1ar4","./get-value-for-key":"kJr16","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hfbFD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getAudioParamConnections", ()=>getAudioParamConnections);
var _globals = require("../globals");
var _getValueForKey = require("./get-value-for-key");
const getAudioParamConnections = (audioParam)=>{
    return (0, _getValueForKey.getValueForKey)((0, _globals.AUDIO_PARAM_CONNECTIONS_STORE), audioParam);
};

},{"../globals":"j1ar4","./get-value-for-key":"kJr16","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7xWOy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isValidLatencyHint", ()=>isValidLatencyHint);
const isValidLatencyHint = (latencyHint)=>{
    return latencyHint === undefined || typeof latencyHint === "number" || typeof latencyHint === "string" && (latencyHint === "balanced" || latencyHint === "interactive" || latencyHint === "playback");
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4BIeJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioDestinationNodeConstructor", ()=>createAudioDestinationNodeConstructor);
const createAudioDestinationNodeConstructor = (audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode)=>{
    return class AudioDestinationNode extends audioNodeConstructor {
        constructor(context, channelCount){
            const nativeContext = getNativeContext(context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const nativeAudioDestinationNode = createNativeAudioDestinationNode(nativeContext, channelCount, isOffline);
            const audioDestinationNodeRenderer = isOffline ? createAudioDestinationNodeRenderer(renderInputsOfAudioNode) : null;
            super(context, false, nativeAudioDestinationNode, audioDestinationNodeRenderer);
            this._isNodeOfNativeOfflineAudioContext = isOffline;
            this._nativeAudioDestinationNode = nativeAudioDestinationNode;
        }
        get channelCount() {
            return this._nativeAudioDestinationNode.channelCount;
        }
        set channelCount(value) {
            // Bug #52: Chrome, Edge & Safari do not throw an exception at all.
            // Bug #54: Firefox does throw an IndexSizeError.
            if (this._isNodeOfNativeOfflineAudioContext) throw createInvalidStateError();
            // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.
            if (value > this._nativeAudioDestinationNode.maxChannelCount) throw createIndexSizeError();
            this._nativeAudioDestinationNode.channelCount = value;
        }
        get channelCountMode() {
            return this._nativeAudioDestinationNode.channelCountMode;
        }
        set channelCountMode(value) {
            // Bug #53: No browser does throw an exception yet.
            if (this._isNodeOfNativeOfflineAudioContext) throw createInvalidStateError();
            this._nativeAudioDestinationNode.channelCountMode = value;
        }
        get maxChannelCount() {
            return this._nativeAudioDestinationNode.maxChannelCount;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gunYG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioDestinationNodeRenderer", ()=>createAudioDestinationNodeRenderer);
const createAudioDestinationNodeRenderer = (renderInputsOfAudioNode)=>{
    const renderedNativeAudioDestinationNodes = new WeakMap();
    const createAudioDestinationNode = async (proxy, nativeOfflineAudioContext)=>{
        const nativeAudioDestinationNode = nativeOfflineAudioContext.destination;
        renderedNativeAudioDestinationNodes.set(nativeOfflineAudioContext, nativeAudioDestinationNode);
        await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioDestinationNode);
        return nativeAudioDestinationNode;
    };
    return {
        render (proxy, nativeOfflineAudioContext) {
            const renderedNativeAudioDestinationNode = renderedNativeAudioDestinationNodes.get(nativeOfflineAudioContext);
            if (renderedNativeAudioDestinationNode !== undefined) return Promise.resolve(renderedNativeAudioDestinationNode);
            return createAudioDestinationNode(proxy, nativeOfflineAudioContext);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1a6Qa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioListenerFactory", ()=>createAudioListenerFactory);
var _constants = require("../constants");
const createAudioListenerFactory = (createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeScriptProcessorNode, createNotSupportedError, getFirstSample, isNativeOfflineAudioContext, overwriteAccessors)=>{
    return (context, nativeContext)=>{
        const nativeListener = nativeContext.listener;
        // Bug #117: Only Chrome & Edge support the new interface already.
        const createFakeAudioParams = ()=>{
            const buffer = new Float32Array(1);
            const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
                channelCount: 1,
                channelCountMode: "explicit",
                channelInterpretation: "speakers",
                numberOfInputs: 9
            });
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            let isScriptProcessorNodeCreated = false;
            let lastOrientation = [
                0,
                0,
                -1,
                0,
                1,
                0
            ];
            let lastPosition = [
                0,
                0,
                0
            ];
            const createScriptProcessorNode = ()=>{
                if (isScriptProcessorNodeCreated) return;
                isScriptProcessorNodeCreated = true;
                const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 9, 0);
                // tslint:disable-next-line:deprecation
                scriptProcessorNode.onaudioprocess = ({ inputBuffer })=>{
                    const orientation = [
                        getFirstSample(inputBuffer, buffer, 0),
                        getFirstSample(inputBuffer, buffer, 1),
                        getFirstSample(inputBuffer, buffer, 2),
                        getFirstSample(inputBuffer, buffer, 3),
                        getFirstSample(inputBuffer, buffer, 4),
                        getFirstSample(inputBuffer, buffer, 5)
                    ];
                    if (orientation.some((value, index)=>value !== lastOrientation[index])) {
                        nativeListener.setOrientation(...orientation); // tslint:disable-line:deprecation
                        lastOrientation = orientation;
                    }
                    const positon = [
                        getFirstSample(inputBuffer, buffer, 6),
                        getFirstSample(inputBuffer, buffer, 7),
                        getFirstSample(inputBuffer, buffer, 8)
                    ];
                    if (positon.some((value, index)=>value !== lastPosition[index])) {
                        nativeListener.setPosition(...positon); // tslint:disable-line:deprecation
                        lastPosition = positon;
                    }
                };
                channelMergerNode.connect(scriptProcessorNode);
            };
            const createSetOrientation = (index)=>(value)=>{
                    if (value !== lastOrientation[index]) {
                        lastOrientation[index] = value;
                        nativeListener.setOrientation(...lastOrientation); // tslint:disable-line:deprecation
                    }
                };
            const createSetPosition = (index)=>(value)=>{
                    if (value !== lastPosition[index]) {
                        lastPosition[index] = value;
                        nativeListener.setPosition(...lastPosition); // tslint:disable-line:deprecation
                    }
                };
            const createFakeAudioParam = (input, initialValue, setValue)=>{
                const constantSourceNode = createNativeConstantSourceNode(nativeContext, {
                    channelCount: 1,
                    channelCountMode: "explicit",
                    channelInterpretation: "discrete",
                    offset: initialValue
                });
                constantSourceNode.connect(channelMergerNode, 0, input);
                // @todo This should be stopped when the context is closed.
                constantSourceNode.start();
                Object.defineProperty(constantSourceNode.offset, "defaultValue", {
                    get () {
                        return initialValue;
                    }
                });
                /*
                 * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and
                 * minValue for GainNodes.
                 */ const audioParam = createAudioParam({
                    context
                }, isOffline, constantSourceNode.offset, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
                overwriteAccessors(audioParam, "value", (get)=>()=>get.call(audioParam), (set)=>(value)=>{
                        try {
                            set.call(audioParam, value);
                        } catch (err) {
                            if (err.code !== 9) throw err;
                        }
                        createScriptProcessorNode();
                        if (isOffline) // Bug #117: Using setOrientation() and setPosition() doesn't work with an OfflineAudioContext.
                        setValue(value);
                    });
                audioParam.cancelAndHoldAtTime = ((cancelAndHoldAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = cancelAndHoldAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.cancelAndHoldAtTime);
                audioParam.cancelScheduledValues = ((cancelScheduledValues)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = cancelScheduledValues.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.cancelScheduledValues);
                audioParam.exponentialRampToValueAtTime = ((exponentialRampToValueAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = exponentialRampToValueAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.exponentialRampToValueAtTime);
                audioParam.linearRampToValueAtTime = ((linearRampToValueAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = linearRampToValueAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.linearRampToValueAtTime);
                audioParam.setTargetAtTime = ((setTargetAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = setTargetAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.setTargetAtTime);
                audioParam.setValueAtTime = ((setValueAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = setValueAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.setValueAtTime);
                audioParam.setValueCurveAtTime = ((setValueCurveAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = setValueCurveAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.setValueCurveAtTime);
                return audioParam;
            };
            return {
                forwardX: createFakeAudioParam(0, 0, createSetOrientation(0)),
                forwardY: createFakeAudioParam(1, 0, createSetOrientation(1)),
                forwardZ: createFakeAudioParam(2, -1, createSetOrientation(2)),
                positionX: createFakeAudioParam(6, 0, createSetPosition(0)),
                positionY: createFakeAudioParam(7, 0, createSetPosition(1)),
                positionZ: createFakeAudioParam(8, 0, createSetPosition(2)),
                upX: createFakeAudioParam(3, 0, createSetOrientation(3)),
                upY: createFakeAudioParam(4, 1, createSetOrientation(4)),
                upZ: createFakeAudioParam(5, 0, createSetOrientation(5))
            };
        };
        const { forwardX, forwardY, forwardZ, positionX, positionY, positionZ, upX, upY, upZ } = nativeListener.forwardX === undefined ? createFakeAudioParams() : nativeListener;
        return {
            get forwardX () {
                return forwardX;
            },
            get forwardY () {
                return forwardY;
            },
            get forwardZ () {
                return forwardZ;
            },
            get positionX () {
                return positionX;
            },
            get positionY () {
                return positionY;
            },
            get positionZ () {
                return positionZ;
            },
            get upX () {
                return upX;
            },
            get upY () {
                return upY;
            },
            get upZ () {
                return upZ;
            }
        };
    };
};

},{"../constants":"au584","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"wwDLJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioNodeConstructor", ()=>createAudioNodeConstructor);
var _globals = require("../globals");
var _audioNode = require("../guards/audio-node");
var _audioNodeOutputConnection = require("../guards/audio-node-output-connection");
var _addActiveInputConnectionToAudioParam = require("../helpers/add-active-input-connection-to-audio-param");
var _addPassiveInputConnectionToAudioParam = require("../helpers/add-passive-input-connection-to-audio-param");
var _connectNativeAudioNodeToNativeAudioNode = require("../helpers/connect-native-audio-node-to-native-audio-node");
var _deleteActiveInputConnection = require("../helpers/delete-active-input-connection");
var _deleteActiveInputConnectionToAudioParam = require("../helpers/delete-active-input-connection-to-audio-param");
var _deleteEventListenersOfAudioNode = require("../helpers/delete-event-listeners-of-audio-node");
var _deletePassiveInputConnectionToAudioNode = require("../helpers/delete-passive-input-connection-to-audio-node");
var _deletePassiveInputConnectionToAudioParam = require("../helpers/delete-passive-input-connection-to-audio-param");
var _disconnectNativeAudioNodeFromNativeAudioNode = require("../helpers/disconnect-native-audio-node-from-native-audio-node");
var _getAudioNodeConnections = require("../helpers/get-audio-node-connections");
var _getAudioParamConnections = require("../helpers/get-audio-param-connections");
var _getEventListenersOfAudioNode = require("../helpers/get-event-listeners-of-audio-node");
var _getNativeAudioNode = require("../helpers/get-native-audio-node");
var _getNativeAudioParam = require("../helpers/get-native-audio-param");
var _insertElementInSet = require("../helpers/insert-element-in-set");
var _isActiveAudioNode = require("../helpers/is-active-audio-node");
var _isPartOfACycle = require("../helpers/is-part-of-a-cycle");
var _isPassiveAudioNode = require("../helpers/is-passive-audio-node");
var _setInternalStateToActive = require("../helpers/set-internal-state-to-active");
var _setInternalStateToPassiveWhenNecessary = require("../helpers/set-internal-state-to-passive-when-necessary");
var _testAudioNodeDisconnectMethodSupport = require("../helpers/test-audio-node-disconnect-method-support");
var _visitEachAudioNodeOnce = require("../helpers/visit-each-audio-node-once");
var _wrapAudioNodeDisconnectMethod = require("../helpers/wrap-audio-node-disconnect-method");
const addConnectionToAudioParamOfAudioContext = (source, destination, output, isOffline)=>{
    const { activeInputs, passiveInputs } = (0, _getAudioParamConnections.getAudioParamConnections)(destination);
    const { outputs } = (0, _getAudioNodeConnections.getAudioNodeConnections)(source);
    const eventListeners = (0, _getEventListenersOfAudioNode.getEventListenersOfAudioNode)(source);
    const eventListener = (isActive)=>{
        const nativeAudioNode = (0, _getNativeAudioNode.getNativeAudioNode)(source);
        const nativeAudioParam = (0, _getNativeAudioParam.getNativeAudioParam)(destination);
        if (isActive) {
            const partialConnection = (0, _deletePassiveInputConnectionToAudioParam.deletePassiveInputConnectionToAudioParam)(passiveInputs, source, output);
            (0, _addActiveInputConnectionToAudioParam.addActiveInputConnectionToAudioParam)(activeInputs, source, partialConnection, false);
            if (!isOffline && !(0, _isPartOfACycle.isPartOfACycle)(source)) nativeAudioNode.connect(nativeAudioParam, output);
        } else {
            const partialConnection = (0, _deleteActiveInputConnectionToAudioParam.deleteActiveInputConnectionToAudioParam)(activeInputs, source, output);
            (0, _addPassiveInputConnectionToAudioParam.addPassiveInputConnectionToAudioParam)(passiveInputs, partialConnection, false);
            if (!isOffline && !(0, _isPartOfACycle.isPartOfACycle)(source)) nativeAudioNode.disconnect(nativeAudioParam, output);
        }
    };
    if ((0, _insertElementInSet.insertElementInSet)(outputs, [
        destination,
        output
    ], (outputConnection)=>outputConnection[0] === destination && outputConnection[1] === output, true)) {
        eventListeners.add(eventListener);
        if ((0, _isActiveAudioNode.isActiveAudioNode)(source)) (0, _addActiveInputConnectionToAudioParam.addActiveInputConnectionToAudioParam)(activeInputs, source, [
            output,
            eventListener
        ], true);
        else (0, _addPassiveInputConnectionToAudioParam.addPassiveInputConnectionToAudioParam)(passiveInputs, [
            source,
            output,
            eventListener
        ], true);
        return true;
    }
    return false;
};
const deleteInputConnectionOfAudioNode = (source, destination, output, input)=>{
    const { activeInputs, passiveInputs } = (0, _getAudioNodeConnections.getAudioNodeConnections)(destination);
    const activeInputConnection = (0, _deleteActiveInputConnection.deleteActiveInputConnection)(activeInputs[input], source, output);
    if (activeInputConnection === null) {
        const passiveInputConnection = (0, _deletePassiveInputConnectionToAudioNode.deletePassiveInputConnectionToAudioNode)(passiveInputs, source, output, input);
        return [
            passiveInputConnection[2],
            false
        ];
    }
    return [
        activeInputConnection[2],
        true
    ];
};
const deleteInputConnectionOfAudioParam = (source, destination, output)=>{
    const { activeInputs, passiveInputs } = (0, _getAudioParamConnections.getAudioParamConnections)(destination);
    const activeInputConnection = (0, _deleteActiveInputConnection.deleteActiveInputConnection)(activeInputs, source, output);
    if (activeInputConnection === null) {
        const passiveInputConnection = (0, _deletePassiveInputConnectionToAudioParam.deletePassiveInputConnectionToAudioParam)(passiveInputs, source, output);
        return [
            passiveInputConnection[1],
            false
        ];
    }
    return [
        activeInputConnection[2],
        true
    ];
};
const deleteInputsOfAudioNode = (source, isOffline, destination, output, input)=>{
    const [listener, isActive] = deleteInputConnectionOfAudioNode(source, destination, output, input);
    if (listener !== null) {
        (0, _deleteEventListenersOfAudioNode.deleteEventListenerOfAudioNode)(source, listener);
        if (isActive && !isOffline && !(0, _isPartOfACycle.isPartOfACycle)(source)) (0, _disconnectNativeAudioNodeFromNativeAudioNode.disconnectNativeAudioNodeFromNativeAudioNode)((0, _getNativeAudioNode.getNativeAudioNode)(source), (0, _getNativeAudioNode.getNativeAudioNode)(destination), output, input);
    }
    if ((0, _isActiveAudioNode.isActiveAudioNode)(destination)) {
        const { activeInputs } = (0, _getAudioNodeConnections.getAudioNodeConnections)(destination);
        (0, _setInternalStateToPassiveWhenNecessary.setInternalStateToPassiveWhenNecessary)(destination, activeInputs);
    }
};
const deleteInputsOfAudioParam = (source, isOffline, destination, output)=>{
    const [listener, isActive] = deleteInputConnectionOfAudioParam(source, destination, output);
    if (listener !== null) {
        (0, _deleteEventListenersOfAudioNode.deleteEventListenerOfAudioNode)(source, listener);
        if (isActive && !isOffline && !(0, _isPartOfACycle.isPartOfACycle)(source)) (0, _getNativeAudioNode.getNativeAudioNode)(source).disconnect((0, _getNativeAudioParam.getNativeAudioParam)(destination), output);
    }
};
const deleteAnyConnection = (source, isOffline)=>{
    const audioNodeConnectionsOfSource = (0, _getAudioNodeConnections.getAudioNodeConnections)(source);
    const destinations = [];
    for (const outputConnection of audioNodeConnectionsOfSource.outputs){
        if ((0, _audioNodeOutputConnection.isAudioNodeOutputConnection)(outputConnection)) deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
        else deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
        destinations.push(outputConnection[0]);
    }
    audioNodeConnectionsOfSource.outputs.clear();
    return destinations;
};
const deleteConnectionAtOutput = (source, isOffline, output)=>{
    const audioNodeConnectionsOfSource = (0, _getAudioNodeConnections.getAudioNodeConnections)(source);
    const destinations = [];
    for (const outputConnection of audioNodeConnectionsOfSource.outputs)if (outputConnection[1] === output) {
        if ((0, _audioNodeOutputConnection.isAudioNodeOutputConnection)(outputConnection)) deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
        else deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
        destinations.push(outputConnection[0]);
        audioNodeConnectionsOfSource.outputs.delete(outputConnection);
    }
    return destinations;
};
const deleteConnectionToDestination = (source, isOffline, destination, output, input)=>{
    const audioNodeConnectionsOfSource = (0, _getAudioNodeConnections.getAudioNodeConnections)(source);
    return Array.from(audioNodeConnectionsOfSource.outputs).filter((outputConnection)=>outputConnection[0] === destination && (output === undefined || outputConnection[1] === output) && (input === undefined || outputConnection[2] === input)).map((outputConnection)=>{
        if ((0, _audioNodeOutputConnection.isAudioNodeOutputConnection)(outputConnection)) deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
        else deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
        audioNodeConnectionsOfSource.outputs.delete(outputConnection);
        return outputConnection[0];
    });
};
const createAudioNodeConstructor = (addAudioNodeConnections, addConnectionToAudioNode, cacheTestResult, createIncrementCycleCounter, createIndexSizeError, createInvalidAccessError, createNotSupportedError, decrementCycleCounter, detectCycles, eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor)=>{
    return class AudioNode extends eventTargetConstructor {
        constructor(context, isActive, nativeAudioNode, audioNodeRenderer){
            super(nativeAudioNode);
            this._context = context;
            this._nativeAudioNode = nativeAudioNode;
            const nativeContext = getNativeContext(context);
            // Bug #12: Safari does not support to disconnect a specific destination.
            if (isNativeAudioContext(nativeContext) && true !== cacheTestResult((0, _testAudioNodeDisconnectMethodSupport.testAudioNodeDisconnectMethodSupport), ()=>{
                return (0, _testAudioNodeDisconnectMethodSupport.testAudioNodeDisconnectMethodSupport)(nativeContext, nativeAudioWorkletNodeConstructor);
            })) (0, _wrapAudioNodeDisconnectMethod.wrapAudioNodeDisconnectMethod)(nativeAudioNode);
            (0, _globals.AUDIO_NODE_STORE).set(this, nativeAudioNode);
            (0, _globals.EVENT_LISTENERS).set(this, new Set());
            if (context.state !== "closed" && isActive) (0, _setInternalStateToActive.setInternalStateToActive)(this);
            addAudioNodeConnections(this, audioNodeRenderer, nativeAudioNode);
        }
        get channelCount() {
            return this._nativeAudioNode.channelCount;
        }
        set channelCount(value) {
            this._nativeAudioNode.channelCount = value;
        }
        get channelCountMode() {
            return this._nativeAudioNode.channelCountMode;
        }
        set channelCountMode(value) {
            this._nativeAudioNode.channelCountMode = value;
        }
        get channelInterpretation() {
            return this._nativeAudioNode.channelInterpretation;
        }
        set channelInterpretation(value) {
            this._nativeAudioNode.channelInterpretation = value;
        }
        get context() {
            return this._context;
        }
        get numberOfInputs() {
            return this._nativeAudioNode.numberOfInputs;
        }
        get numberOfOutputs() {
            return this._nativeAudioNode.numberOfOutputs;
        }
        // tslint:disable-next-line:invalid-void
        connect(destination, output = 0, input = 0) {
            // Bug #174: Safari does expose a wrong numberOfOutputs for MediaStreamAudioDestinationNodes.
            if (output < 0 || output >= this._nativeAudioNode.numberOfOutputs) throw createIndexSizeError();
            const nativeContext = getNativeContext(this._context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            if (isNativeAudioNode(destination) || isNativeAudioParam(destination)) throw createInvalidAccessError();
            if ((0, _audioNode.isAudioNode)(destination)) {
                const nativeDestinationAudioNode = (0, _getNativeAudioNode.getNativeAudioNode)(destination);
                try {
                    const connection = (0, _connectNativeAudioNodeToNativeAudioNode.connectNativeAudioNodeToNativeAudioNode)(this._nativeAudioNode, nativeDestinationAudioNode, output, input);
                    const isPassive = (0, _isPassiveAudioNode.isPassiveAudioNode)(this);
                    if (isOffline || isPassive) this._nativeAudioNode.disconnect(...connection);
                    if (this.context.state !== "closed" && !isPassive && (0, _isPassiveAudioNode.isPassiveAudioNode)(destination)) (0, _setInternalStateToActive.setInternalStateToActive)(destination);
                } catch (err) {
                    // Bug #41: Safari does not throw the correct exception so far.
                    if (err.code === 12) throw createInvalidAccessError();
                    throw err;
                }
                const isNewConnectionToAudioNode = addConnectionToAudioNode(this, destination, output, input, isOffline);
                // Bug #164: Only Firefox detects cycles so far.
                if (isNewConnectionToAudioNode) {
                    const cycles = detectCycles([
                        this
                    ], destination);
                    (0, _visitEachAudioNodeOnce.visitEachAudioNodeOnce)(cycles, createIncrementCycleCounter(isOffline));
                }
                return destination;
            }
            const nativeAudioParam = (0, _getNativeAudioParam.getNativeAudioParam)(destination);
            /*
             * Bug #73, #147 & #153: Safari does not support to connect an input signal to the playbackRate AudioParam of an
             * AudioBufferSourceNode. This can't be easily detected and that's why the outdated name property is used here to identify
             * Safari. In addition to that the maxValue property is used to only detect the affected versions below v14.0.2.
             */ if (nativeAudioParam.name === "playbackRate" && nativeAudioParam.maxValue === 1024) throw createNotSupportedError();
            try {
                this._nativeAudioNode.connect(nativeAudioParam, output);
                if (isOffline || (0, _isPassiveAudioNode.isPassiveAudioNode)(this)) this._nativeAudioNode.disconnect(nativeAudioParam, output);
            } catch (err) {
                // Bug #58: Safari doesn't throw an InvalidAccessError yet.
                if (err.code === 12) throw createInvalidAccessError();
                throw err;
            }
            const isNewConnectionToAudioParam = addConnectionToAudioParamOfAudioContext(this, destination, output, isOffline);
            // Bug #164: Only Firefox detects cycles so far.
            if (isNewConnectionToAudioParam) {
                const cycles = detectCycles([
                    this
                ], destination);
                (0, _visitEachAudioNodeOnce.visitEachAudioNodeOnce)(cycles, createIncrementCycleCounter(isOffline));
            }
        }
        disconnect(destinationOrOutput, output, input) {
            let destinations;
            const nativeContext = getNativeContext(this._context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            if (destinationOrOutput === undefined) destinations = deleteAnyConnection(this, isOffline);
            else if (typeof destinationOrOutput === "number") {
                if (destinationOrOutput < 0 || destinationOrOutput >= this.numberOfOutputs) throw createIndexSizeError();
                destinations = deleteConnectionAtOutput(this, isOffline, destinationOrOutput);
            } else {
                if (output !== undefined && (output < 0 || output >= this.numberOfOutputs)) throw createIndexSizeError();
                if ((0, _audioNode.isAudioNode)(destinationOrOutput) && input !== undefined && (input < 0 || input >= destinationOrOutput.numberOfInputs)) throw createIndexSizeError();
                destinations = deleteConnectionToDestination(this, isOffline, destinationOrOutput, output, input);
                if (destinations.length === 0) throw createInvalidAccessError();
            }
            // Bug #164: Only Firefox detects cycles so far.
            for (const destination of destinations){
                const cycles = detectCycles([
                    this
                ], destination);
                (0, _visitEachAudioNodeOnce.visitEachAudioNodeOnce)(cycles, decrementCycleCounter);
            }
        }
    };
};

},{"../globals":"j1ar4","../guards/audio-node":"daTkx","../guards/audio-node-output-connection":"5S2ZA","../helpers/add-active-input-connection-to-audio-param":"hBnfW","../helpers/add-passive-input-connection-to-audio-param":"fRCym","../helpers/connect-native-audio-node-to-native-audio-node":"he3cM","../helpers/delete-active-input-connection":"iog9s","../helpers/delete-active-input-connection-to-audio-param":"6FKI8","../helpers/delete-event-listeners-of-audio-node":"kjxRm","../helpers/delete-passive-input-connection-to-audio-node":"6FBGr","../helpers/delete-passive-input-connection-to-audio-param":"g8OnC","../helpers/disconnect-native-audio-node-from-native-audio-node":"766cG","../helpers/get-audio-node-connections":"huPRp","../helpers/get-audio-param-connections":"hfbFD","../helpers/get-event-listeners-of-audio-node":"hrKEN","../helpers/get-native-audio-node":"f9hIK","../helpers/get-native-audio-param":"fLdpl","../helpers/insert-element-in-set":"917M8","../helpers/is-active-audio-node":"j8Y4t","../helpers/is-part-of-a-cycle":"jcP4P","../helpers/is-passive-audio-node":"1eGb9","../helpers/set-internal-state-to-active":"gc0b0","../helpers/set-internal-state-to-passive-when-necessary":"5zVeT","../helpers/test-audio-node-disconnect-method-support":"d1FDF","../helpers/visit-each-audio-node-once":"9N5TU","../helpers/wrap-audio-node-disconnect-method":"3z2pK","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"daTkx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isAudioNode", ()=>isAudioNode);
const isAudioNode = (audioNodeOrAudioParam)=>{
    return "context" in audioNodeOrAudioParam;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5S2ZA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isAudioNodeOutputConnection", ()=>isAudioNodeOutputConnection);
var _audioNode = require("./audio-node");
const isAudioNodeOutputConnection = (outputConnection)=>{
    return (0, _audioNode.isAudioNode)(outputConnection[0]);
};

},{"./audio-node":"daTkx","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hBnfW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "addActiveInputConnectionToAudioParam", ()=>addActiveInputConnectionToAudioParam);
var _insertElementInSet = require("./insert-element-in-set");
const addActiveInputConnectionToAudioParam = (activeInputs, source, [output, eventListener], ignoreDuplicates)=>{
    (0, _insertElementInSet.insertElementInSet)(activeInputs, [
        source,
        output,
        eventListener
    ], (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output, ignoreDuplicates);
};

},{"./insert-element-in-set":"917M8","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"917M8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "insertElementInSet", ()=>insertElementInSet);
const insertElementInSet = (set, element, predicate, ignoreDuplicates)=>{
    for (const lmnt of set)if (predicate(lmnt)) {
        if (ignoreDuplicates) return false;
        throw Error("The set contains at least one similar element.");
    }
    set.add(element);
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fRCym":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "addPassiveInputConnectionToAudioParam", ()=>addPassiveInputConnectionToAudioParam);
var _insertElementInSet = require("./insert-element-in-set");
const addPassiveInputConnectionToAudioParam = (passiveInputs, [source, output, eventListener], ignoreDuplicates)=>{
    const passiveInputConnections = passiveInputs.get(source);
    if (passiveInputConnections === undefined) passiveInputs.set(source, new Set([
        [
            output,
            eventListener
        ]
    ]));
    else (0, _insertElementInSet.insertElementInSet)(passiveInputConnections, [
        output,
        eventListener
    ], (passiveInputConnection)=>passiveInputConnection[0] === output, ignoreDuplicates);
};

},{"./insert-element-in-set":"917M8","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"he3cM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "connectNativeAudioNodeToNativeAudioNode", ()=>connectNativeAudioNodeToNativeAudioNode);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
const connectNativeAudioNodeToNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input)=>{
    if ((0, _nativeAudioNodeFaker.isNativeAudioNodeFaker)(nativeDestinationAudioNode)) {
        const fakeNativeDestinationAudioNode = nativeDestinationAudioNode.inputs[input];
        nativeSourceAudioNode.connect(fakeNativeDestinationAudioNode, output, 0);
        return [
            fakeNativeDestinationAudioNode,
            output,
            0
        ];
    }
    nativeSourceAudioNode.connect(nativeDestinationAudioNode, output, input);
    return [
        nativeDestinationAudioNode,
        output,
        input
    ];
};

},{"../guards/native-audio-node-faker":"fNQvH","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fNQvH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isNativeAudioNodeFaker", ()=>isNativeAudioNodeFaker);
const isNativeAudioNodeFaker = (nativeAudioNodeOrNativeAudioNodeFaker)=>{
    return "inputs" in nativeAudioNodeOrNativeAudioNodeFaker;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iog9s":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deleteActiveInputConnection", ()=>deleteActiveInputConnection);
const deleteActiveInputConnection = (activeInputConnections, source, output)=>{
    for (const activeInputConnection of activeInputConnections)if (activeInputConnection[0] === source && activeInputConnection[1] === output) {
        activeInputConnections.delete(activeInputConnection);
        return activeInputConnection;
    }
    return null;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6FKI8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deleteActiveInputConnectionToAudioParam", ()=>deleteActiveInputConnectionToAudioParam);
var _pickElementFromSet = require("./pick-element-from-set");
const deleteActiveInputConnectionToAudioParam = (activeInputs, source, output)=>{
    return (0, _pickElementFromSet.pickElementFromSet)(activeInputs, (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output);
};

},{"./pick-element-from-set":"9U2YJ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kjxRm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deleteEventListenerOfAudioNode", ()=>deleteEventListenerOfAudioNode);
var _getEventListenersOfAudioNode = require("./get-event-listeners-of-audio-node");
const deleteEventListenerOfAudioNode = (audioNode, eventListener)=>{
    const eventListeners = (0, _getEventListenersOfAudioNode.getEventListenersOfAudioNode)(audioNode);
    if (!eventListeners.delete(eventListener)) throw new Error("Missing the expected event listener.");
};

},{"./get-event-listeners-of-audio-node":"hrKEN","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g8OnC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deletePassiveInputConnectionToAudioParam", ()=>deletePassiveInputConnectionToAudioParam);
var _getValueForKey = require("./get-value-for-key");
var _pickElementFromSet = require("./pick-element-from-set");
const deletePassiveInputConnectionToAudioParam = (passiveInputs, source, output)=>{
    const passiveInputConnections = (0, _getValueForKey.getValueForKey)(passiveInputs, source);
    const matchingConnection = (0, _pickElementFromSet.pickElementFromSet)(passiveInputConnections, (passiveInputConnection)=>passiveInputConnection[0] === output);
    if (passiveInputConnections.size === 0) passiveInputs.delete(source);
    return matchingConnection;
};

},{"./get-value-for-key":"kJr16","./pick-element-from-set":"9U2YJ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"766cG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "disconnectNativeAudioNodeFromNativeAudioNode", ()=>disconnectNativeAudioNodeFromNativeAudioNode);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
const disconnectNativeAudioNodeFromNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input)=>{
    if ((0, _nativeAudioNodeFaker.isNativeAudioNodeFaker)(nativeDestinationAudioNode)) nativeSourceAudioNode.disconnect(nativeDestinationAudioNode.inputs[input], output, 0);
    else nativeSourceAudioNode.disconnect(nativeDestinationAudioNode, output, input);
};

},{"../guards/native-audio-node-faker":"fNQvH","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"f9hIK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getNativeAudioNode", ()=>getNativeAudioNode);
var _globals = require("../globals");
var _getValueForKey = require("./get-value-for-key");
const getNativeAudioNode = (audioNode)=>{
    return (0, _getValueForKey.getValueForKey)((0, _globals.AUDIO_NODE_STORE), audioNode);
};

},{"../globals":"j1ar4","./get-value-for-key":"kJr16","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fLdpl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getNativeAudioParam", ()=>getNativeAudioParam);
var _globals = require("../globals");
var _getValueForKey = require("./get-value-for-key");
const getNativeAudioParam = (audioParam)=>{
    return (0, _getValueForKey.getValueForKey)((0, _globals.AUDIO_PARAM_STORE), audioParam);
};

},{"../globals":"j1ar4","./get-value-for-key":"kJr16","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jcP4P":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isPartOfACycle", ()=>isPartOfACycle);
var _globals = require("../globals");
const isPartOfACycle = (audioNode)=>{
    return (0, _globals.CYCLE_COUNTERS).has(audioNode);
};

},{"../globals":"j1ar4","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1eGb9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isPassiveAudioNode", ()=>isPassiveAudioNode);
var _globals = require("../globals");
const isPassiveAudioNode = (audioNode)=>{
    return !(0, _globals.ACTIVE_AUDIO_NODE_STORE).has(audioNode);
};

},{"../globals":"j1ar4","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"d1FDF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioNodeDisconnectMethodSupport", ()=>testAudioNodeDisconnectMethodSupport);
const testAudioNodeDisconnectMethodSupport = (nativeAudioContext, nativeAudioWorkletNodeConstructor)=>{
    return new Promise((resolve)=>{
        /*
         * This bug existed in Safari up until v14.0.2. Since AudioWorklets were not supported in Safari until v14.1 the presence of the
         * constructor for an AudioWorkletNode can be used here to skip the test.
         */ if (nativeAudioWorkletNodeConstructor !== null) resolve(true);
        else {
            const analyzer = nativeAudioContext.createScriptProcessor(256, 1, 1); // tslint:disable-line deprecation
            const dummy = nativeAudioContext.createGain();
            // Bug #95: Safari does not play one sample buffers.
            const ones = nativeAudioContext.createBuffer(1, 2, 44100);
            const channelData = ones.getChannelData(0);
            channelData[0] = 1;
            channelData[1] = 1;
            const source = nativeAudioContext.createBufferSource();
            source.buffer = ones;
            source.loop = true;
            source.connect(analyzer).connect(nativeAudioContext.destination);
            source.connect(dummy);
            source.disconnect(dummy);
            // tslint:disable-next-line:deprecation
            analyzer.onaudioprocess = (event)=>{
                const chnnlDt = event.inputBuffer.getChannelData(0); // tslint:disable-line deprecation
                if (Array.prototype.some.call(chnnlDt, (sample)=>sample === 1)) resolve(true);
                else resolve(false);
                source.stop();
                analyzer.onaudioprocess = null; // tslint:disable-line:deprecation
                source.disconnect(analyzer);
                analyzer.disconnect(nativeAudioContext.destination);
            };
            source.start();
        }
    });
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9N5TU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "visitEachAudioNodeOnce", ()=>visitEachAudioNodeOnce);
const visitEachAudioNodeOnce = (cycles, visitor)=>{
    const counts = new Map();
    for (const cycle of cycles)for (const audioNode of cycle){
        const count = counts.get(audioNode);
        counts.set(audioNode, count === undefined ? 1 : count + 1);
    }
    counts.forEach((count, audioNode)=>visitor(audioNode, count));
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3z2pK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioNodeDisconnectMethod", ()=>wrapAudioNodeDisconnectMethod);
var _nativeAudioNode = require("../guards/native-audio-node");
const wrapAudioNodeDisconnectMethod = (nativeAudioNode)=>{
    const connections = new Map();
    nativeAudioNode.connect = ((connect)=>{
        // tslint:disable-next-line:invalid-void no-inferrable-types
        return (destination, output = 0, input = 0)=>{
            const returnValue = (0, _nativeAudioNode.isNativeAudioNode)(destination) ? connect(destination, output, input) : connect(destination, output);
            // Save the new connection only if the calls to connect above didn't throw an error.
            const connectionsToDestination = connections.get(destination);
            if (connectionsToDestination === undefined) connections.set(destination, [
                {
                    input,
                    output
                }
            ]);
            else if (connectionsToDestination.every((connection)=>connection.input !== input || connection.output !== output)) connectionsToDestination.push({
                input,
                output
            });
            return returnValue;
        };
    })(nativeAudioNode.connect.bind(nativeAudioNode));
    nativeAudioNode.disconnect = ((disconnect)=>{
        return (destinationOrOutput, output, input)=>{
            disconnect.apply(nativeAudioNode);
            if (destinationOrOutput === undefined) connections.clear();
            else if (typeof destinationOrOutput === "number") for (const [destination, connectionsToDestination] of connections){
                const filteredConnections = connectionsToDestination.filter((connection)=>connection.output !== destinationOrOutput);
                if (filteredConnections.length === 0) connections.delete(destination);
                else connections.set(destination, filteredConnections);
            }
            else if (connections.has(destinationOrOutput)) {
                if (output === undefined) connections.delete(destinationOrOutput);
                else {
                    const connectionsToDestination = connections.get(destinationOrOutput);
                    if (connectionsToDestination !== undefined) {
                        const filteredConnections = connectionsToDestination.filter((connection)=>connection.output !== output && (connection.input !== input || input === undefined));
                        if (filteredConnections.length === 0) connections.delete(destinationOrOutput);
                        else connections.set(destinationOrOutput, filteredConnections);
                    }
                }
            }
            for (const [destination, connectionsToDestination] of connections)connectionsToDestination.forEach((connection)=>{
                if ((0, _nativeAudioNode.isNativeAudioNode)(destination)) nativeAudioNode.connect(destination, connection.output, connection.input);
                else nativeAudioNode.connect(destination, connection.output);
            });
        };
    })(nativeAudioNode.disconnect);
};

},{"../guards/native-audio-node":"hUupW","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hUupW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isNativeAudioNode", ()=>isNativeAudioNode);
const isNativeAudioNode = (nativeAudioNodeOrAudioParam)=>{
    return "context" in nativeAudioNodeOrAudioParam;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iMx7e":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioParamFactory", ()=>createAudioParamFactory);
var _automationEvents = require("automation-events");
const createAudioParamFactory = (addAudioParamConnections, audioParamAudioNodeStore, audioParamStore, createAudioParamRenderer, createCancelAndHoldAutomationEvent, createCancelScheduledValuesAutomationEvent, createExponentialRampToValueAutomationEvent, createLinearRampToValueAutomationEvent, createSetTargetAutomationEvent, createSetValueAutomationEvent, createSetValueCurveAutomationEvent, nativeAudioContextConstructor, setValueAtTimeUntilPossible)=>{
    return (audioNode, isAudioParamOfOfflineAudioContext, nativeAudioParam, maxValue = null, minValue = null)=>{
        // Bug #196 Only Safari sets the defaultValue to the initial value.
        const defaultValue = nativeAudioParam.value;
        const automationEventList = new (0, _automationEvents.AutomationEventList)(defaultValue);
        const audioParamRenderer = isAudioParamOfOfflineAudioContext ? createAudioParamRenderer(automationEventList) : null;
        const audioParam = {
            get defaultValue () {
                return defaultValue;
            },
            get maxValue () {
                return maxValue === null ? nativeAudioParam.maxValue : maxValue;
            },
            get minValue () {
                return minValue === null ? nativeAudioParam.minValue : minValue;
            },
            get value () {
                return nativeAudioParam.value;
            },
            set value (value){
                nativeAudioParam.value = value;
                // Bug #98: Firefox & Safari do not yet treat the value setter like a call to setValueAtTime().
                audioParam.setValueAtTime(value, audioNode.context.currentTime);
            },
            cancelAndHoldAtTime (cancelTime) {
                // Bug #28: Firefox & Safari do not yet implement cancelAndHoldAtTime().
                if (typeof nativeAudioParam.cancelAndHoldAtTime === "function") {
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));
                    nativeAudioParam.cancelAndHoldAtTime(cancelTime);
                } else {
                    const previousLastEvent = Array.from(automationEventList).pop();
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));
                    const currentLastEvent = Array.from(automationEventList).pop();
                    nativeAudioParam.cancelScheduledValues(cancelTime);
                    if (previousLastEvent !== currentLastEvent && currentLastEvent !== undefined) {
                        if (currentLastEvent.type === "exponentialRampToValue") nativeAudioParam.exponentialRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);
                        else if (currentLastEvent.type === "linearRampToValue") nativeAudioParam.linearRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);
                        else if (currentLastEvent.type === "setValue") nativeAudioParam.setValueAtTime(currentLastEvent.value, currentLastEvent.startTime);
                        else if (currentLastEvent.type === "setValueCurve") nativeAudioParam.setValueCurveAtTime(currentLastEvent.values, currentLastEvent.startTime, currentLastEvent.duration);
                    }
                }
                return audioParam;
            },
            cancelScheduledValues (cancelTime) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createCancelScheduledValuesAutomationEvent(cancelTime));
                nativeAudioParam.cancelScheduledValues(cancelTime);
                return audioParam;
            },
            exponentialRampToValueAtTime (value1, endTime) {
                // Bug #45: Safari does not throw an error yet.
                if (value1 === 0) throw new RangeError();
                // Bug #187: Safari does not throw an error yet.
                if (!Number.isFinite(endTime) || endTime < 0) throw new RangeError();
                const currentTime = audioNode.context.currentTime;
                if (audioParamRenderer === null) automationEventList.flush(currentTime);
                // Bug #194: Firefox does not implicitly call setValueAtTime() if there is no previous event.
                if (Array.from(automationEventList).length === 0) {
                    automationEventList.add(createSetValueAutomationEvent(defaultValue, currentTime));
                    nativeAudioParam.setValueAtTime(defaultValue, currentTime);
                }
                automationEventList.add(createExponentialRampToValueAutomationEvent(value1, endTime));
                nativeAudioParam.exponentialRampToValueAtTime(value1, endTime);
                return audioParam;
            },
            linearRampToValueAtTime (value1, endTime) {
                const currentTime = audioNode.context.currentTime;
                if (audioParamRenderer === null) automationEventList.flush(currentTime);
                // Bug #195: Firefox does not implicitly call setValueAtTime() if there is no previous event.
                if (Array.from(automationEventList).length === 0) {
                    automationEventList.add(createSetValueAutomationEvent(defaultValue, currentTime));
                    nativeAudioParam.setValueAtTime(defaultValue, currentTime);
                }
                automationEventList.add(createLinearRampToValueAutomationEvent(value1, endTime));
                nativeAudioParam.linearRampToValueAtTime(value1, endTime);
                return audioParam;
            },
            setTargetAtTime (target, startTime, timeConstant) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createSetTargetAutomationEvent(target, startTime, timeConstant));
                nativeAudioParam.setTargetAtTime(target, startTime, timeConstant);
                return audioParam;
            },
            setValueAtTime (value1, startTime) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createSetValueAutomationEvent(value1, startTime));
                nativeAudioParam.setValueAtTime(value1, startTime);
                return audioParam;
            },
            setValueCurveAtTime (values, startTime, duration) {
                // Bug 183: Safari only accepts a Float32Array.
                const convertedValues = values instanceof Float32Array ? values : new Float32Array(values);
                /*
                 * Bug #152: Safari does not correctly interpolate the values of the curve.
                 * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the
                 * existence of the webkitAudioContext is used as a workaround here.
                 */ if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === "webkitAudioContext") {
                    const endTime = startTime + duration;
                    const sampleRate = audioNode.context.sampleRate;
                    const firstSample = Math.ceil(startTime * sampleRate);
                    const lastSample = Math.floor(endTime * sampleRate);
                    const numberOfInterpolatedValues = lastSample - firstSample;
                    const interpolatedValues = new Float32Array(numberOfInterpolatedValues);
                    for(let i = 0; i < numberOfInterpolatedValues; i += 1){
                        const theoreticIndex = (convertedValues.length - 1) / duration * ((firstSample + i) / sampleRate - startTime);
                        const lowerIndex = Math.floor(theoreticIndex);
                        const upperIndex = Math.ceil(theoreticIndex);
                        interpolatedValues[i] = lowerIndex === upperIndex ? convertedValues[lowerIndex] : (1 - (theoreticIndex - lowerIndex)) * convertedValues[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * convertedValues[upperIndex];
                    }
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createSetValueCurveAutomationEvent(interpolatedValues, startTime, duration));
                    nativeAudioParam.setValueCurveAtTime(interpolatedValues, startTime, duration);
                    const timeOfLastSample = lastSample / sampleRate;
                    if (timeOfLastSample < endTime) setValueAtTimeUntilPossible(audioParam, interpolatedValues[interpolatedValues.length - 1], timeOfLastSample);
                    setValueAtTimeUntilPossible(audioParam, convertedValues[convertedValues.length - 1], endTime);
                } else {
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createSetValueCurveAutomationEvent(convertedValues, startTime, duration));
                    nativeAudioParam.setValueCurveAtTime(convertedValues, startTime, duration);
                }
                return audioParam;
            }
        };
        audioParamStore.set(audioParam, nativeAudioParam);
        audioParamAudioNodeStore.set(audioParam, audioNode);
        addAudioParamConnections(audioParam, audioParamRenderer);
        return audioParam;
    };
};

},{"automation-events":"kxaFt","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9IbWX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioParamRenderer", ()=>createAudioParamRenderer);
const createAudioParamRenderer = (automationEventList)=>{
    return {
        replay (audioParam) {
            for (const automationEvent of automationEventList){
                if (automationEvent.type === "exponentialRampToValue") {
                    const { endTime, value } = automationEvent;
                    audioParam.exponentialRampToValueAtTime(value, endTime);
                } else if (automationEvent.type === "linearRampToValue") {
                    const { endTime, value } = automationEvent;
                    audioParam.linearRampToValueAtTime(value, endTime);
                } else if (automationEvent.type === "setTarget") {
                    const { startTime, target, timeConstant } = automationEvent;
                    audioParam.setTargetAtTime(target, startTime, timeConstant);
                } else if (automationEvent.type === "setValue") {
                    const { startTime, value } = automationEvent;
                    audioParam.setValueAtTime(value, startTime);
                } else if (automationEvent.type === "setValueCurve") {
                    const { duration, startTime, values } = automationEvent;
                    audioParam.setValueCurveAtTime(values, startTime, duration);
                } else throw new Error("Can't apply an unknown automation.");
            }
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2Gmbn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioWorkletNodeConstructor", ()=>createAudioWorkletNodeConstructor);
var _globals = require("../globals");
var _readOnlyMap = require("../read-only-map");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    // Bug #61: The channelCountMode should be 'max' according to the spec but is set to 'explicit' to achieve consistent behavior.
    channelCountMode: "explicit",
    channelInterpretation: "speakers",
    numberOfInputs: 1,
    numberOfOutputs: 1,
    parameterData: {},
    processorOptions: {}
};
const createAudioWorkletNodeConstructor = (addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, getAudioNodeConnections, getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, sanitizeAudioWorkletNodeOptions, setActiveAudioWorkletNodeInputs, testAudioWorkletNodeOptionsClonability, wrapEventListener)=>{
    return class AudioWorkletNode extends audioNodeConstructor {
        constructor(context, name, options){
            var _a;
            const nativeContext = getNativeContext(context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const mergedOptions = sanitizeAudioWorkletNodeOptions({
                ...DEFAULT_OPTIONS,
                ...options
            });
            // Bug #191: Safari doesn't throw an error if the options aren't clonable.
            testAudioWorkletNodeOptionsClonability(mergedOptions);
            const nodeNameToProcessorConstructorMap = (0, _globals.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS).get(nativeContext);
            const processorConstructor = nodeNameToProcessorConstructorMap === null || nodeNameToProcessorConstructorMap === void 0 ? void 0 : nodeNameToProcessorConstructorMap.get(name);
            // Bug #186: Chrome and Edge do not allow to create an AudioWorkletNode on a closed AudioContext.
            const nativeContextOrBackupOfflineAudioContext = isOffline || nativeContext.state !== "closed" ? nativeContext : (_a = getBackupOfflineAudioContext(nativeContext)) !== null && _a !== void 0 ? _a : nativeContext;
            const nativeAudioWorkletNode = createNativeAudioWorkletNode(nativeContextOrBackupOfflineAudioContext, isOffline ? null : context.baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, mergedOptions);
            const audioWorkletNodeRenderer = isOffline ? createAudioWorkletNodeRenderer(name, mergedOptions, processorConstructor) : null;
            /*
             * @todo Add a mechanism to switch an AudioWorkletNode to passive once the process() function of the AudioWorkletProcessor
             * returns false.
             */ super(context, true, nativeAudioWorkletNode, audioWorkletNodeRenderer);
            const parameters = [];
            nativeAudioWorkletNode.parameters.forEach((nativeAudioParam, nm)=>{
                const audioParam = createAudioParam(this, isOffline, nativeAudioParam);
                parameters.push([
                    nm,
                    audioParam
                ]);
            });
            this._nativeAudioWorkletNode = nativeAudioWorkletNode;
            this._onprocessorerror = null;
            this._parameters = new (0, _readOnlyMap.ReadOnlyMap)(parameters);
            /*
             * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to
             * the destination.
             */ if (isOffline) addUnrenderedAudioWorkletNode(nativeContext, this);
            const { activeInputs } = getAudioNodeConnections(this);
            setActiveAudioWorkletNodeInputs(nativeAudioWorkletNode, activeInputs);
        }
        get onprocessorerror() {
            return this._onprocessorerror;
        }
        set onprocessorerror(value) {
            const wrappedListener = typeof value === "function" ? wrapEventListener(this, value) : null;
            this._nativeAudioWorkletNode.onprocessorerror = wrappedListener;
            const nativeOnProcessorError = this._nativeAudioWorkletNode.onprocessorerror;
            this._onprocessorerror = nativeOnProcessorError !== null && nativeOnProcessorError === wrappedListener ? value : nativeOnProcessorError;
        }
        get parameters() {
            if (this._parameters === null) // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
            return this._nativeAudioWorkletNode.parameters;
            return this._parameters;
        }
        get port() {
            return this._nativeAudioWorkletNode.port;
        }
    };
};

},{"../globals":"j1ar4","../read-only-map":"3UYbJ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3UYbJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ReadOnlyMap", ()=>ReadOnlyMap);
class ReadOnlyMap {
    constructor(parameters){
        this._map = new Map(parameters);
    }
    get size() {
        return this._map.size;
    }
    entries() {
        return this._map.entries();
    }
    forEach(callback, thisArg = null) {
        return this._map.forEach((value, key)=>callback.call(thisArg, value, key, this));
    }
    get(name) {
        return this._map.get(name);
    }
    has(name) {
        return this._map.has(name);
    }
    keys() {
        return this._map.keys();
    }
    values() {
        return this._map.values();
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kfvDm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioWorkletNodeRendererFactory", ()=>createAudioWorkletNodeRendererFactory);
var _copyFromChannel = require("../helpers/copy-from-channel");
var _copyToChannel = require("../helpers/copy-to-channel");
var _createNestedArrays = require("../helpers/create-nested-arrays");
var _getAudioNodeConnections = require("../helpers/get-audio-node-connections");
var _getAudioWorkletProcessor = require("../helpers/get-audio-worklet-processor");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const processBuffer = async (proxy, renderedBuffer, nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime)=>{
    // Ceil the length to the next full render quantum.
    // Bug #17: Safari does not yet expose the length.
    const length = renderedBuffer === null ? Math.ceil(proxy.context.length / 128) * 128 : renderedBuffer.length;
    const numberOfInputChannels = options.channelCount * options.numberOfInputs;
    const numberOfOutputChannels = outputChannelCount.reduce((sum, value)=>sum + value, 0);
    const processedBuffer = numberOfOutputChannels === 0 ? null : nativeOfflineAudioContext.createBuffer(numberOfOutputChannels, length, nativeOfflineAudioContext.sampleRate);
    if (processorConstructor === undefined) throw new Error("Missing the processor constructor.");
    const audioNodeConnections = (0, _getAudioNodeConnections.getAudioNodeConnections)(proxy);
    const audioWorkletProcessor = await (0, _getAudioWorkletProcessor.getAudioWorkletProcessor)(nativeOfflineAudioContext, proxy);
    const inputs = (0, _createNestedArrays.createNestedArrays)(options.numberOfInputs, options.channelCount);
    const outputs = (0, _createNestedArrays.createNestedArrays)(options.numberOfOutputs, outputChannelCount);
    const parameters = Array.from(proxy.parameters.keys()).reduce((prmtrs, name)=>({
            ...prmtrs,
            [name]: new Float32Array(128)
        }), {});
    for(let i = 0; i < length; i += 128){
        if (options.numberOfInputs > 0 && renderedBuffer !== null) {
            for(let j = 0; j < options.numberOfInputs; j += 1)for(let k = 0; k < options.channelCount; k += 1)(0, _copyFromChannel.copyFromChannel)(renderedBuffer, inputs[j], k, k, i);
        }
        if (processorConstructor.parameterDescriptors !== undefined && renderedBuffer !== null) processorConstructor.parameterDescriptors.forEach(({ name }, index)=>{
            (0, _copyFromChannel.copyFromChannel)(renderedBuffer, parameters, name, numberOfInputChannels + index, i);
        });
        for(let j = 0; j < options.numberOfInputs; j += 1){
            for(let k = 0; k < outputChannelCount[j]; k += 1)// The byteLength will be 0 when the ArrayBuffer was transferred.
            if (outputs[j][k].byteLength === 0) outputs[j][k] = new Float32Array(128);
        }
        try {
            const potentiallyEmptyInputs = inputs.map((input, index)=>{
                if (audioNodeConnections.activeInputs[index].size === 0) return [];
                return input;
            });
            const activeSourceFlag = exposeCurrentFrameAndCurrentTime(i / nativeOfflineAudioContext.sampleRate, nativeOfflineAudioContext.sampleRate, ()=>audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));
            if (processedBuffer !== null) for(let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1){
                for(let k = 0; k < outputChannelCount[j]; k += 1)(0, _copyToChannel.copyToChannel)(processedBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);
                outputChannelSplitterNodeOutput += outputChannelCount[j];
            }
            if (!activeSourceFlag) break;
        } catch (error) {
            proxy.dispatchEvent(new ErrorEvent("processorerror", {
                colno: error.colno,
                filename: error.filename,
                lineno: error.lineno,
                message: error.message
            }));
            break;
        }
    }
    return processedBuffer;
};
const createAudioWorkletNodeRendererFactory = (connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext)=>{
    return (name, options, processorConstructor)=>{
        const renderedNativeAudioNodes = new WeakMap();
        let processedBufferPromise = null;
        const createAudioNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAudioWorkletNode = getNativeAudioNode(proxy);
            let nativeOutputNodes = null;
            const nativeAudioWorkletNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeAudioWorkletNode, nativeOfflineAudioContext);
            const outputChannelCount = Array.isArray(options.outputChannelCount) ? options.outputChannelCount : Array.from(options.outputChannelCount);
            // Bug #61: Only Chrome, Edge & Firefox have an implementation of the AudioWorkletNode yet.
            if (nativeAudioWorkletNodeConstructor === null) {
                const numberOfOutputChannels = outputChannelCount.reduce((sum, value)=>sum + value, 0);
                const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, {
                    channelCount: Math.max(1, numberOfOutputChannels),
                    channelCountMode: "explicit",
                    channelInterpretation: "discrete",
                    numberOfOutputs: Math.max(1, numberOfOutputChannels)
                });
                const outputChannelMergerNodes = [];
                for(let i = 0; i < proxy.numberOfOutputs; i += 1)outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeOfflineAudioContext, {
                    channelCount: 1,
                    channelCountMode: "explicit",
                    channelInterpretation: "speakers",
                    numberOfInputs: outputChannelCount[i]
                }));
                const outputGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    channelCount: options.channelCount,
                    channelCountMode: options.channelCountMode,
                    channelInterpretation: options.channelInterpretation,
                    gain: 1
                });
                outputGainNode.connect = connectMultipleOutputs.bind(null, outputChannelMergerNodes);
                outputGainNode.disconnect = disconnectMultipleOutputs.bind(null, outputChannelMergerNodes);
                nativeOutputNodes = [
                    outputChannelSplitterNode,
                    outputChannelMergerNodes,
                    outputGainNode
                ];
            } else if (!nativeAudioWorkletNodeIsOwnedByContext) nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeOfflineAudioContext, name);
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeOutputNodes === null ? nativeAudioWorkletNode : nativeOutputNodes[2]);
            if (nativeOutputNodes !== null) {
                if (processedBufferPromise === null) {
                    if (processorConstructor === undefined) throw new Error("Missing the processor constructor.");
                    if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
                    // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.
                    const numberOfInputChannels = proxy.channelCount * proxy.numberOfInputs;
                    const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;
                    const numberOfChannels = numberOfInputChannels + numberOfParameters;
                    const renderBuffer = async ()=>{
                        const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, // Ceil the length to the next full render quantum.
                        // Bug #17: Safari does not yet expose the length.
                        Math.ceil(proxy.context.length / 128) * 128, nativeOfflineAudioContext.sampleRate);
                        const gainNodes = [];
                        const inputChannelSplitterNodes = [];
                        for(let i = 0; i < options.numberOfInputs; i += 1){
                            gainNodes.push(createNativeGainNode(partialOfflineAudioContext, {
                                channelCount: options.channelCount,
                                channelCountMode: options.channelCountMode,
                                channelInterpretation: options.channelInterpretation,
                                gain: 1
                            }));
                            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(partialOfflineAudioContext, {
                                channelCount: options.channelCount,
                                channelCountMode: "explicit",
                                channelInterpretation: "discrete",
                                numberOfOutputs: options.channelCount
                            }));
                        }
                        const constantSourceNodes = await Promise.all(Array.from(proxy.parameters.values()).map(async (audioParam)=>{
                            const constantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {
                                channelCount: 1,
                                channelCountMode: "explicit",
                                channelInterpretation: "discrete",
                                offset: audioParam.value
                            });
                            await renderAutomation(partialOfflineAudioContext, audioParam, constantSourceNode.offset);
                            return constantSourceNode;
                        }));
                        const inputChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {
                            channelCount: 1,
                            channelCountMode: "explicit",
                            channelInterpretation: "speakers",
                            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)
                        });
                        for(let i = 0; i < options.numberOfInputs; i += 1){
                            gainNodes[i].connect(inputChannelSplitterNodes[i]);
                            for(let j = 0; j < options.channelCount; j += 1)inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, i * options.channelCount + j);
                        }
                        for (const [index, constantSourceNode] of constantSourceNodes.entries()){
                            constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);
                            constantSourceNode.start(0);
                        }
                        inputChannelMergerNode.connect(partialOfflineAudioContext.destination);
                        await Promise.all(gainNodes.map((gainNode)=>renderInputsOfAudioNode(proxy, partialOfflineAudioContext, gainNode)));
                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);
                    };
                    processedBufferPromise = processBuffer(proxy, numberOfChannels === 0 ? null : await renderBuffer(), nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime);
                }
                const processedBuffer = await processedBufferPromise;
                const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {
                    buffer: null,
                    channelCount: 2,
                    channelCountMode: "max",
                    channelInterpretation: "speakers",
                    loop: false,
                    loopEnd: 0,
                    loopStart: 0,
                    playbackRate: 1
                });
                const [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode] = nativeOutputNodes;
                if (processedBuffer !== null) {
                    audioBufferSourceNode.buffer = processedBuffer;
                    audioBufferSourceNode.start(0);
                }
                audioBufferSourceNode.connect(outputChannelSplitterNode);
                for(let i = 0, outputChannelSplitterNodeOutput = 0; i < proxy.numberOfOutputs; i += 1){
                    const outputChannelMergerNode = outputChannelMergerNodes[i];
                    for(let j = 0; j < outputChannelCount[i]; j += 1)outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                    outputChannelSplitterNodeOutput += outputChannelCount[i];
                }
                return outputGainNode;
            }
            if (!nativeAudioWorkletNodeIsOwnedByContext) for (const [nm, audioParam] of proxy.parameters.entries())await renderAutomation(nativeOfflineAudioContext, audioParam, // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
            nativeAudioWorkletNode.parameters.get(nm));
            else for (const [nm, audioParam] of proxy.parameters.entries())await connectAudioParam(nativeOfflineAudioContext, audioParam, // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
            nativeAudioWorkletNode.parameters.get(nm));
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioWorkletNode);
            return nativeAudioWorkletNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                deleteUnrenderedAudioWorkletNode(nativeOfflineAudioContext, proxy);
                const renderedNativeAudioWorkletNodeOrGainNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioWorkletNodeOrGainNode !== undefined) return Promise.resolve(renderedNativeAudioWorkletNodeOrGainNode);
                return createAudioNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/copy-from-channel":"7bLp3","../helpers/copy-to-channel":"eA0D4","../helpers/create-nested-arrays":"jcLoC","../helpers/get-audio-node-connections":"huPRp","../helpers/get-audio-worklet-processor":"k4Q26","../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7bLp3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "copyFromChannel", ()=>copyFromChannel);
function copyFromChannel(audioBuffer, // @todo There is currently no way to define something like { [ key: number | string ]: Float32Array }
parent, key, channelNumber, bufferOffset) {
    if (typeof audioBuffer.copyFromChannel === "function") {
        // The byteLength will be 0 when the ArrayBuffer was transferred.
        if (parent[key].byteLength === 0) parent[key] = new Float32Array(128);
        audioBuffer.copyFromChannel(parent[key], channelNumber, bufferOffset);
    // Bug #5: Safari does not support copyFromChannel().
    } else {
        const channelData = audioBuffer.getChannelData(channelNumber);
        // The byteLength will be 0 when the ArrayBuffer was transferred.
        if (parent[key].byteLength === 0) parent[key] = channelData.slice(bufferOffset, bufferOffset + 128);
        else {
            const slicedInput = new Float32Array(channelData.buffer, bufferOffset * Float32Array.BYTES_PER_ELEMENT, 128);
            parent[key].set(slicedInput);
        }
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eA0D4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "copyToChannel", ()=>copyToChannel);
const copyToChannel = (audioBuffer, parent, key, channelNumber, bufferOffset)=>{
    if (typeof audioBuffer.copyToChannel === "function") // The byteLength will be 0 when the ArrayBuffer was transferred.
    {
        if (parent[key].byteLength !== 0) audioBuffer.copyToChannel(parent[key], channelNumber, bufferOffset);
    } else // The byteLength will be 0 when the ArrayBuffer was transferred.
    if (parent[key].byteLength !== 0) audioBuffer.getChannelData(channelNumber).set(parent[key], bufferOffset);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jcLoC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNestedArrays", ()=>createNestedArrays);
const createNestedArrays = (x, y)=>{
    const arrays = [];
    for(let i = 0; i < x; i += 1){
        const array = [];
        const length = typeof y === "number" ? y : y[i];
        for(let j = 0; j < length; j += 1)array.push(new Float32Array(128));
        arrays.push(array);
    }
    return arrays;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k4Q26":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getAudioWorkletProcessor", ()=>getAudioWorkletProcessor);
var _globals = require("../globals");
var _getNativeAudioNode = require("./get-native-audio-node");
var _getValueForKey = require("./get-value-for-key");
const getAudioWorkletProcessor = (nativeOfflineAudioContext, proxy)=>{
    const nodeToProcessorMap = (0, _getValueForKey.getValueForKey)((0, _globals.NODE_TO_PROCESSOR_MAPS), nativeOfflineAudioContext);
    const nativeAudioWorkletNode = (0, _getNativeAudioNode.getNativeAudioNode)(proxy);
    return (0, _getValueForKey.getValueForKey)(nodeToProcessorMap, nativeAudioWorkletNode);
};

},{"../globals":"j1ar4","./get-native-audio-node":"f9hIK","./get-value-for-key":"kJr16","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1Qln6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createBaseAudioContextConstructor", ()=>createBaseAudioContextConstructor);
const createBaseAudioContextConstructor = (addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor)=>{
    return class BaseAudioContext extends minimalBaseAudioContextConstructor {
        constructor(_nativeContext, numberOfChannels){
            super(_nativeContext, numberOfChannels);
            this._nativeContext = _nativeContext;
            this._audioWorklet = addAudioWorkletModule === undefined ? undefined : {
                addModule: (moduleURL, options)=>{
                    return addAudioWorkletModule(this, moduleURL, options);
                }
            };
        }
        get audioWorklet() {
            return this._audioWorklet;
        }
        createAnalyser() {
            return new analyserNodeConstructor(this);
        }
        createBiquadFilter() {
            return new biquadFilterNodeConstructor(this);
        }
        createBuffer(numberOfChannels, length, sampleRate) {
            return new audioBufferConstructor({
                length,
                numberOfChannels,
                sampleRate
            });
        }
        createBufferSource() {
            return new audioBufferSourceNodeConstructor(this);
        }
        createChannelMerger(numberOfInputs = 6) {
            return new channelMergerNodeConstructor(this, {
                numberOfInputs
            });
        }
        createChannelSplitter(numberOfOutputs = 6) {
            return new channelSplitterNodeConstructor(this, {
                numberOfOutputs
            });
        }
        createConstantSource() {
            return new constantSourceNodeConstructor(this);
        }
        createConvolver() {
            return new convolverNodeConstructor(this);
        }
        createDelay(maxDelayTime = 1) {
            return new delayNodeConstructor(this, {
                maxDelayTime
            });
        }
        createDynamicsCompressor() {
            return new dynamicsCompressorNodeConstructor(this);
        }
        createGain() {
            return new gainNodeConstructor(this);
        }
        createIIRFilter(feedforward, feedback) {
            return new iIRFilterNodeConstructor(this, {
                feedback,
                feedforward
            });
        }
        createOscillator() {
            return new oscillatorNodeConstructor(this);
        }
        createPanner() {
            return new pannerNodeConstructor(this);
        }
        createPeriodicWave(real, imag, constraints = {
            disableNormalization: false
        }) {
            return new periodicWaveConstructor(this, {
                ...constraints,
                imag,
                real
            });
        }
        createStereoPanner() {
            return new stereoPannerNodeConstructor(this);
        }
        createWaveShaper() {
            return new waveShaperNodeConstructor(this);
        }
        decodeAudioData(audioData, successCallback, errorCallback) {
            return decodeAudioData(this._nativeContext, audioData).then((audioBuffer)=>{
                if (typeof successCallback === "function") successCallback(audioBuffer);
                return audioBuffer;
            }, (err)=>{
                if (typeof errorCallback === "function") errorCallback(err);
                throw err;
            });
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2ojuk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createBiquadFilterNodeConstructor", ()=>createBiquadFilterNodeConstructor);
var _constants = require("../constants");
const DEFAULT_OPTIONS = {
    Q: 1,
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    detune: 0,
    frequency: 350,
    gain: 0,
    type: "lowpass"
};
const createBiquadFilterNodeConstructor = (audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class BiquadFilterNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const biquadFilterNodeRenderer = isOffline ? createBiquadFilterNodeRenderer() : null;
            super(context, false, nativeBiquadFilterNode, biquadFilterNodeRenderer);
            // Bug #80: Safari does not export the correct values for maxValue and minValue.
            this._Q = createAudioParam(this, isOffline, nativeBiquadFilterNode.Q, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
            // Bug #78: Firefox & Safari do not export the correct values for maxValue and minValue.
            this._detune = createAudioParam(this, isOffline, nativeBiquadFilterNode.detune, 1200 * Math.log2((0, _constants.MOST_POSITIVE_SINGLE_FLOAT)), -1200 * Math.log2((0, _constants.MOST_POSITIVE_SINGLE_FLOAT)));
            // Bug #77: Firefox & Safari do not export the correct value for minValue.
            this._frequency = createAudioParam(this, isOffline, nativeBiquadFilterNode.frequency, context.sampleRate / 2, 0);
            // Bug #79: Firefox & Safari do not export the correct values for maxValue and minValue.
            this._gain = createAudioParam(this, isOffline, nativeBiquadFilterNode.gain, 40 * Math.log10((0, _constants.MOST_POSITIVE_SINGLE_FLOAT)), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
            this._nativeBiquadFilterNode = nativeBiquadFilterNode;
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        get detune() {
            return this._detune;
        }
        get frequency() {
            return this._frequency;
        }
        get gain() {
            return this._gain;
        }
        get Q() {
            return this._Q;
        }
        get type() {
            return this._nativeBiquadFilterNode.type;
        }
        set type(value) {
            this._nativeBiquadFilterNode.type = value;
        }
        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
            // Bug #189: Safari does throw an InvalidStateError.
            try {
                this._nativeBiquadFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);
            } catch (err) {
                if (err.code === 11) throw createInvalidAccessError();
                throw err;
            }
            // Bug #68: Safari does not throw an error if the parameters differ in their length.
            if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) throw createInvalidAccessError();
        }
    };
};

},{"../constants":"au584","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hC3lP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createBiquadFilterNodeRendererFactory", ()=>createBiquadFilterNodeRendererFactory);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createBiquadFilterNodeRendererFactory = (connectAudioParam, createNativeBiquadFilterNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeBiquadFilterNodes = new WeakMap();
        const createBiquadFilterNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeBiquadFilterNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeBiquadFilterNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeBiquadFilterNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeBiquadFilterNode, nativeOfflineAudioContext);
            if (!nativeBiquadFilterNodeIsOwnedByContext) {
                const options = {
                    Q: nativeBiquadFilterNode.Q.value,
                    channelCount: nativeBiquadFilterNode.channelCount,
                    channelCountMode: nativeBiquadFilterNode.channelCountMode,
                    channelInterpretation: nativeBiquadFilterNode.channelInterpretation,
                    detune: nativeBiquadFilterNode.detune.value,
                    frequency: nativeBiquadFilterNode.frequency.value,
                    gain: nativeBiquadFilterNode.gain.value,
                    type: nativeBiquadFilterNode.type
                };
                nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeOfflineAudioContext, options);
            }
            renderedNativeBiquadFilterNodes.set(nativeOfflineAudioContext, nativeBiquadFilterNode);
            if (!nativeBiquadFilterNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q);
                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune);
                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency);
                await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q);
                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune);
                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency);
                await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain);
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeBiquadFilterNode);
            return nativeBiquadFilterNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeBiquadFilterNode = renderedNativeBiquadFilterNodes.get(nativeOfflineAudioContext);
                if (renderedNativeBiquadFilterNode !== undefined) return Promise.resolve(renderedNativeBiquadFilterNode);
                return createBiquadFilterNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jAn86":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createCacheTestResult", ()=>createCacheTestResult);
const createCacheTestResult = (ongoingTests, testResults)=>{
    return (tester, test)=>{
        const cachedTestResult = testResults.get(tester);
        if (cachedTestResult !== undefined) return cachedTestResult;
        const ongoingTest = ongoingTests.get(tester);
        if (ongoingTest !== undefined) return ongoingTest;
        try {
            const synchronousTestResult = test();
            if (synchronousTestResult instanceof Promise) {
                ongoingTests.set(tester, synchronousTestResult);
                return synchronousTestResult.catch(()=>false).then((finalTestResult)=>{
                    ongoingTests.delete(tester);
                    testResults.set(tester, finalTestResult);
                    return finalTestResult;
                });
            }
            testResults.set(tester, synchronousTestResult);
            return synchronousTestResult;
        } catch  {
            testResults.set(tester, false);
            return false;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5qPp9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createChannelMergerNodeConstructor", ()=>createChannelMergerNodeConstructor);
const DEFAULT_OPTIONS = {
    channelCount: 1,
    channelCountMode: "explicit",
    channelInterpretation: "speakers",
    numberOfInputs: 6
};
const createChannelMergerNodeConstructor = (audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class ChannelMergerNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeChannelMergerNode = createNativeChannelMergerNode(nativeContext, mergedOptions);
            const channelMergerNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createChannelMergerNodeRenderer() : null;
            super(context, false, nativeChannelMergerNode, channelMergerNodeRenderer);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4213f":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createChannelMergerNodeRendererFactory", ()=>createChannelMergerNodeRendererFactory);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createChannelMergerNodeRendererFactory = (createNativeChannelMergerNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAudioNodes = new WeakMap();
        const createAudioNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAudioNode = getNativeAudioNode(proxy);
            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeAudioNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeAudioNode, nativeOfflineAudioContext);
            if (!nativeAudioNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeAudioNode.channelCount,
                    channelCountMode: nativeAudioNode.channelCountMode,
                    channelInterpretation: nativeAudioNode.channelInterpretation,
                    numberOfInputs: nativeAudioNode.numberOfInputs
                };
                nativeAudioNode = createNativeChannelMergerNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);
            return nativeAudioNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioNode !== undefined) return Promise.resolve(renderedNativeAudioNode);
                return createAudioNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kBxxA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createChannelSplitterNodeConstructor", ()=>createChannelSplitterNodeConstructor);
const DEFAULT_OPTIONS = {
    channelCount: 6,
    channelCountMode: "explicit",
    channelInterpretation: "discrete",
    numberOfOutputs: 6
};
const createChannelSplitterNodeConstructor = (audioNodeConstructor, createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext, sanitizeChannelSplitterOptions)=>{
    return class ChannelSplitterNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = sanitizeChannelSplitterOptions({
                ...DEFAULT_OPTIONS,
                ...options
            });
            const nativeChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, mergedOptions);
            const channelSplitterNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createChannelSplitterNodeRenderer() : null;
            super(context, false, nativeChannelSplitterNode, channelSplitterNodeRenderer);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eO46O":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createChannelSplitterNodeRendererFactory", ()=>createChannelSplitterNodeRendererFactory);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createChannelSplitterNodeRendererFactory = (createNativeChannelSplitterNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAudioNodes = new WeakMap();
        const createAudioNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAudioNode = getNativeAudioNode(proxy);
            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeAudioNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeAudioNode, nativeOfflineAudioContext);
            if (!nativeAudioNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeAudioNode.channelCount,
                    channelCountMode: nativeAudioNode.channelCountMode,
                    channelInterpretation: nativeAudioNode.channelInterpretation,
                    numberOfOutputs: nativeAudioNode.numberOfOutputs
                };
                nativeAudioNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);
            return nativeAudioNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioNode !== undefined) return Promise.resolve(renderedNativeAudioNode);
                return createAudioNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hqUP2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConnectAudioParam", ()=>createConnectAudioParam);
const createConnectAudioParam = (renderInputsOfAudioParam)=>{
    return (nativeOfflineAudioContext, audioParam, nativeAudioParam)=>{
        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8jyft":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConnectMultipleOutputs", ()=>createConnectMultipleOutputs);
var _nativeAudioNode = require("../guards/native-audio-node");
const createConnectMultipleOutputs = (createIndexSizeError)=>{
    return (outputAudioNodes, destination, output = 0, input = 0)=>{
        const outputAudioNode = outputAudioNodes[output];
        if (outputAudioNode === undefined) throw createIndexSizeError();
        if ((0, _nativeAudioNode.isNativeAudioNode)(destination)) return outputAudioNode.connect(destination, 0, input);
        return outputAudioNode.connect(destination, 0);
    };
};

},{"../guards/native-audio-node":"hUupW","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hT5R1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConnectedNativeAudioBufferSourceNodeFactory", ()=>createConnectedNativeAudioBufferSourceNodeFactory);
const createConnectedNativeAudioBufferSourceNodeFactory = (createNativeAudioBufferSourceNode)=>{
    return (nativeContext, nativeAudioNode)=>{
        const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {
            buffer: null,
            channelCount: 2,
            channelCountMode: "max",
            channelInterpretation: "speakers",
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            playbackRate: 1
        });
        const nativeAudioBuffer = nativeContext.createBuffer(1, 2, 44100);
        nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
        nativeAudioBufferSourceNode.loop = true;
        nativeAudioBufferSourceNode.connect(nativeAudioNode);
        nativeAudioBufferSourceNode.start();
        return ()=>{
            nativeAudioBufferSourceNode.stop();
            nativeAudioBufferSourceNode.disconnect(nativeAudioNode);
        };
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6BBM1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConstantSourceNodeConstructor", ()=>createConstantSourceNodeConstructor);
var _constants = require("../constants");
var _isActiveAudioNode = require("../helpers/is-active-audio-node");
var _setInternalStateToActive = require("../helpers/set-internal-state-to-active");
var _setInternalStateToPassive = require("../helpers/set-internal-state-to-passive");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    offset: 1
};
const createConstantSourceNodeConstructor = (audioNodeConstructor, createAudioParam, createConstantSourceNodeRendererFactory, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener)=>{
    return class ConstantSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeConstantSourceNode = createNativeConstantSourceNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const constantSourceNodeRenderer = isOffline ? createConstantSourceNodeRendererFactory() : null;
            super(context, false, nativeConstantSourceNode, constantSourceNodeRenderer);
            this._constantSourceNodeRenderer = constantSourceNodeRenderer;
            this._nativeConstantSourceNode = nativeConstantSourceNode;
            /*
             * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and minValue
             * for GainNodes.
             */ this._offset = createAudioParam(this, isOffline, nativeConstantSourceNode.offset, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
            this._onended = null;
        }
        get offset() {
            return this._offset;
        }
        get onended() {
            return this._onended;
        }
        set onended(value) {
            const wrappedListener = typeof value === "function" ? wrapEventListener(this, value) : null;
            this._nativeConstantSourceNode.onended = wrappedListener;
            const nativeOnEnded = this._nativeConstantSourceNode.onended;
            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
        }
        start(when = 0) {
            this._nativeConstantSourceNode.start(when);
            if (this._constantSourceNodeRenderer !== null) this._constantSourceNodeRenderer.start = when;
            if (this.context.state !== "closed") {
                (0, _setInternalStateToActive.setInternalStateToActive)(this);
                const resetInternalStateToPassive = ()=>{
                    this._nativeConstantSourceNode.removeEventListener("ended", resetInternalStateToPassive);
                    if ((0, _isActiveAudioNode.isActiveAudioNode)(this)) (0, _setInternalStateToPassive.setInternalStateToPassive)(this);
                };
                this._nativeConstantSourceNode.addEventListener("ended", resetInternalStateToPassive);
            }
        }
        stop(when = 0) {
            this._nativeConstantSourceNode.stop(when);
            if (this._constantSourceNodeRenderer !== null) this._constantSourceNodeRenderer.stop = when;
        }
    };
};

},{"../constants":"au584","../helpers/is-active-audio-node":"j8Y4t","../helpers/set-internal-state-to-active":"gc0b0","../helpers/set-internal-state-to-passive":"1Xtwa","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kDcHK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConstantSourceNodeRendererFactory", ()=>createConstantSourceNodeRendererFactory);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createConstantSourceNodeRendererFactory = (connectAudioParam, createNativeConstantSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeConstantSourceNodes = new WeakMap();
        let start = null;
        let stop = null;
        const createConstantSourceNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeConstantSourceNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeConstantSourceNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeConstantSourceNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeConstantSourceNode, nativeOfflineAudioContext);
            if (!nativeConstantSourceNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeConstantSourceNode.channelCount,
                    channelCountMode: nativeConstantSourceNode.channelCountMode,
                    channelInterpretation: nativeConstantSourceNode.channelInterpretation,
                    offset: nativeConstantSourceNode.offset.value
                };
                nativeConstantSourceNode = createNativeConstantSourceNode(nativeOfflineAudioContext, options);
                if (start !== null) nativeConstantSourceNode.start(start);
                if (stop !== null) nativeConstantSourceNode.stop(stop);
            }
            renderedNativeConstantSourceNodes.set(nativeOfflineAudioContext, nativeConstantSourceNode);
            if (!nativeConstantSourceNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConstantSourceNode);
            return nativeConstantSourceNode;
        };
        return {
            set start (value){
                start = value;
            },
            set stop (value){
                stop = value;
            },
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeConstantSourceNode = renderedNativeConstantSourceNodes.get(nativeOfflineAudioContext);
                if (renderedNativeConstantSourceNode !== undefined) return Promise.resolve(renderedNativeConstantSourceNode);
                return createConstantSourceNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1xC44":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConvertNumberToUnsignedLong", ()=>createConvertNumberToUnsignedLong);
const createConvertNumberToUnsignedLong = (unit32Array)=>{
    return (value)=>{
        unit32Array[0] = value;
        return unit32Array[0];
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kcFQc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConvolverNodeConstructor", ()=>createConvolverNodeConstructor);
const DEFAULT_OPTIONS = {
    buffer: null,
    channelCount: 2,
    channelCountMode: "clamped-max",
    channelInterpretation: "speakers",
    disableNormalization: false
};
const createConvolverNodeConstructor = (audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class ConvolverNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeConvolverNode = createNativeConvolverNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const convolverNodeRenderer = isOffline ? createConvolverNodeRenderer() : null;
            super(context, false, nativeConvolverNode, convolverNodeRenderer);
            this._isBufferNullified = false;
            this._nativeConvolverNode = nativeConvolverNode;
            if (mergedOptions.buffer !== null) setAudioNodeTailTime(this, mergedOptions.buffer.duration);
        }
        get buffer() {
            if (this._isBufferNullified) return null;
            return this._nativeConvolverNode.buffer;
        }
        set buffer(value) {
            this._nativeConvolverNode.buffer = value;
            // Bug #115: Safari does not allow to set the buffer to null.
            if (value === null && this._nativeConvolverNode.buffer !== null) {
                const nativeContext = this._nativeConvolverNode.context;
                this._nativeConvolverNode.buffer = nativeContext.createBuffer(1, 1, nativeContext.sampleRate);
                this._isBufferNullified = true;
                setAudioNodeTailTime(this, 0);
            } else {
                this._isBufferNullified = false;
                setAudioNodeTailTime(this, this._nativeConvolverNode.buffer === null ? 0 : this._nativeConvolverNode.buffer.duration);
            }
        }
        get normalize() {
            return this._nativeConvolverNode.normalize;
        }
        set normalize(value) {
            this._nativeConvolverNode.normalize = value;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kmgKW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConvolverNodeRendererFactory", ()=>createConvolverNodeRendererFactory);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createConvolverNodeRendererFactory = (createNativeConvolverNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeConvolverNodes = new WeakMap();
        const createConvolverNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeConvolverNode = getNativeAudioNode(proxy);
            // If the initially used nativeConvolverNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeConvolverNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeConvolverNode, nativeOfflineAudioContext);
            if (!nativeConvolverNodeIsOwnedByContext) {
                const options = {
                    buffer: nativeConvolverNode.buffer,
                    channelCount: nativeConvolverNode.channelCount,
                    channelCountMode: nativeConvolverNode.channelCountMode,
                    channelInterpretation: nativeConvolverNode.channelInterpretation,
                    disableNormalization: !nativeConvolverNode.normalize
                };
                nativeConvolverNode = createNativeConvolverNode(nativeOfflineAudioContext, options);
            }
            renderedNativeConvolverNodes.set(nativeOfflineAudioContext, nativeConvolverNode);
            if ((0, _nativeAudioNodeFaker.isNativeAudioNodeFaker)(nativeConvolverNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode.inputs[0]);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode);
            return nativeConvolverNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeConvolverNode = renderedNativeConvolverNodes.get(nativeOfflineAudioContext);
                if (renderedNativeConvolverNode !== undefined) return Promise.resolve(renderedNativeConvolverNode);
                return createConvolverNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../guards/native-audio-node-faker":"fNQvH","../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7737w":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createCreateNativeOfflineAudioContext", ()=>createCreateNativeOfflineAudioContext);
const createCreateNativeOfflineAudioContext = (createNotSupportedError, nativeOfflineAudioContextConstructor)=>{
    return (numberOfChannels, length, sampleRate)=>{
        if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
        try {
            return new nativeOfflineAudioContextConstructor(numberOfChannels, length, sampleRate);
        } catch (err) {
            // Bug #143, #144 & #146: Safari throws a SyntaxError when numberOfChannels, length or sampleRate are invalid.
            if (err.name === "SyntaxError") throw createNotSupportedError();
            throw err;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h0Bd5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDataCloneError", ()=>createDataCloneError);
const createDataCloneError = ()=>new DOMException("", "DataCloneError");

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"foJCq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDecodeAudioData", ()=>createDecodeAudioData);
var _detachArrayBuffer = require("../helpers/detach-array-buffer");
var _wrapAudioBufferGetChannelDataMethod = require("../helpers/wrap-audio-buffer-get-channel-data-method");
const createDecodeAudioData = (audioBufferStore, cacheTestResult, createDataCloneError, createEncodingError, detachedArrayBuffers, getNativeContext, isNativeContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds)=>{
    return (anyContext, audioData)=>{
        const nativeContext = isNativeContext(anyContext) ? anyContext : getNativeContext(anyContext);
        // Bug #43: Only Chrome and Edge do throw a DataCloneError.
        if (detachedArrayBuffers.has(audioData)) {
            const err = createDataCloneError();
            return Promise.reject(err);
        }
        // The audioData parameter maybe of a type which can't be added to a WeakSet.
        try {
            detachedArrayBuffers.add(audioData);
        } catch  {
        // Ignore errors.
        }
        // Bug #21: Safari does not support promises yet.
        if (cacheTestResult(testPromiseSupport, ()=>testPromiseSupport(nativeContext))) return nativeContext.decodeAudioData(audioData).then((audioBuffer)=>{
            // Bug #133: Safari does neuter the ArrayBuffer.
            (0, _detachArrayBuffer.detachArrayBuffer)(audioData).catch(()=>{
            // Ignore errors.
            });
            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
            if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, ()=>testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
            audioBufferStore.add(audioBuffer);
            return audioBuffer;
        });
        // Bug #21: Safari does not return a Promise yet.
        return new Promise((resolve, reject)=>{
            const complete = async ()=>{
                // Bug #133: Safari does neuter the ArrayBuffer.
                try {
                    await (0, _detachArrayBuffer.detachArrayBuffer)(audioData);
                } catch  {
                // Ignore errors.
                }
            };
            const fail = (err)=>{
                reject(err);
                complete();
            };
            // Bug #26: Safari throws a synchronous error.
            try {
                // Bug #1: Safari requires a successCallback.
                nativeContext.decodeAudioData(audioData, (audioBuffer)=>{
                    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
                    // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
                    if (typeof audioBuffer.copyFromChannel !== "function") {
                        wrapAudioBufferCopyChannelMethods(audioBuffer);
                        (0, _wrapAudioBufferGetChannelDataMethod.wrapAudioBufferGetChannelDataMethod)(audioBuffer);
                    }
                    audioBufferStore.add(audioBuffer);
                    complete().then(()=>resolve(audioBuffer));
                }, (err)=>{
                    // Bug #4: Safari returns null instead of an error.
                    if (err === null) fail(createEncodingError());
                    else fail(err);
                });
            } catch (err) {
                fail(err);
            }
        });
    };
};

},{"../helpers/detach-array-buffer":"eX3OU","../helpers/wrap-audio-buffer-get-channel-data-method":"bXfRI","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eX3OU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "detachArrayBuffer", ()=>detachArrayBuffer);
const detachArrayBuffer = (arrayBuffer)=>{
    const { port1, port2 } = new MessageChannel();
    return new Promise((resolve)=>{
        const closeAndResolve = ()=>{
            port2.onmessage = null;
            port1.close();
            port2.close();
            resolve();
        };
        port2.onmessage = ()=>closeAndResolve();
        try {
            port1.postMessage(arrayBuffer, [
                arrayBuffer
            ]);
        } catch  {
        // Ignore errors.
        } finally{
            closeAndResolve();
        }
    });
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jg4nh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDecrementCycleCounter", ()=>createDecrementCycleCounter);
var _audioNodeOutputConnection = require("../guards/audio-node-output-connection");
const createDecrementCycleCounter = (connectNativeAudioNodeToNativeAudioNode, cycleCounters, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, getNativeContext, isActiveAudioNode, isNativeOfflineAudioContext)=>{
    return (audioNode, count)=>{
        const cycleCounter = cycleCounters.get(audioNode);
        if (cycleCounter === undefined) throw new Error("Missing the expected cycle count.");
        const nativeContext = getNativeContext(audioNode.context);
        const isOffline = isNativeOfflineAudioContext(nativeContext);
        if (cycleCounter === count) {
            cycleCounters.delete(audioNode);
            if (!isOffline && isActiveAudioNode(audioNode)) {
                const nativeSourceAudioNode = getNativeAudioNode(audioNode);
                const { outputs } = getAudioNodeConnections(audioNode);
                for (const output of outputs)if ((0, _audioNodeOutputConnection.isAudioNodeOutputConnection)(output)) {
                    const nativeDestinationAudioNode = getNativeAudioNode(output[0]);
                    connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);
                } else {
                    const nativeDestinationAudioParam = getNativeAudioParam(output[0]);
                    nativeSourceAudioNode.connect(nativeDestinationAudioParam, output[1]);
                }
            }
        } else cycleCounters.set(audioNode, cycleCounter - count);
    };
};

},{"../guards/audio-node-output-connection":"5S2ZA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"byamz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDelayNodeConstructor", ()=>createDelayNodeConstructor);
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    delayTime: 0,
    maxDelayTime: 1
};
const createDelayNodeConstructor = (audioNodeConstructor, createAudioParam, createDelayNodeRenderer, createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class DelayNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeDelayNode = createNativeDelayNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const delayNodeRenderer = isOffline ? createDelayNodeRenderer(mergedOptions.maxDelayTime) : null;
            super(context, false, nativeDelayNode, delayNodeRenderer);
            this._delayTime = createAudioParam(this, isOffline, nativeDelayNode.delayTime);
            setAudioNodeTailTime(this, mergedOptions.maxDelayTime);
        }
        get delayTime() {
            return this._delayTime;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1NO5F":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDelayNodeRendererFactory", ()=>createDelayNodeRendererFactory);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createDelayNodeRendererFactory = (connectAudioParam, createNativeDelayNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return (maxDelayTime)=>{
        const renderedNativeDelayNodes = new WeakMap();
        const createDelayNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeDelayNode = getNativeAudioNode(proxy);
            // If the initially used nativeDelayNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeDelayNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeDelayNode, nativeOfflineAudioContext);
            if (!nativeDelayNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeDelayNode.channelCount,
                    channelCountMode: nativeDelayNode.channelCountMode,
                    channelInterpretation: nativeDelayNode.channelInterpretation,
                    delayTime: nativeDelayNode.delayTime.value,
                    maxDelayTime
                };
                nativeDelayNode = createNativeDelayNode(nativeOfflineAudioContext, options);
            }
            renderedNativeDelayNodes.set(nativeOfflineAudioContext, nativeDelayNode);
            if (!nativeDelayNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDelayNode);
            return nativeDelayNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeDelayNode = renderedNativeDelayNodes.get(nativeOfflineAudioContext);
                if (renderedNativeDelayNode !== undefined) return Promise.resolve(renderedNativeDelayNode);
                return createDelayNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3FRri":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDeleteActiveInputConnectionToAudioNode", ()=>createDeleteActiveInputConnectionToAudioNode);
const createDeleteActiveInputConnectionToAudioNode = (pickElementFromSet)=>{
    return (activeInputs, source, output, input)=>{
        return pickElementFromSet(activeInputs[input], (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fNWyx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDeleteUnrenderedAudioWorkletNode", ()=>createDeleteUnrenderedAudioWorkletNode);
const createDeleteUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes)=>{
    return (nativeContext, audioWorkletNode)=>{
        getUnrenderedAudioWorkletNodes(nativeContext).delete(audioWorkletNode);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8VyTi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDetectCycles", ()=>createDetectCycles);
var _audioNode = require("../guards/audio-node");
var _delayNode = require("../guards/delay-node");
const createDetectCycles = (audioParamAudioNodeStore, getAudioNodeConnections, getValueForKey)=>{
    return function detectCycles(chain, nextLink) {
        const audioNode = (0, _audioNode.isAudioNode)(nextLink) ? nextLink : getValueForKey(audioParamAudioNodeStore, nextLink);
        if ((0, _delayNode.isDelayNode)(audioNode)) return [];
        if (chain[0] === audioNode) return [
            chain
        ];
        if (chain.includes(audioNode)) return [];
        const { outputs } = getAudioNodeConnections(audioNode);
        return Array.from(outputs).map((outputConnection)=>detectCycles([
                ...chain,
                audioNode
            ], outputConnection[0])).reduce((mergedCycles, nestedCycles)=>mergedCycles.concat(nestedCycles), []);
    };
};

},{"../guards/audio-node":"daTkx","../guards/delay-node":"1HW08","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1HW08":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isDelayNode", ()=>isDelayNode);
const isDelayNode = (audioNode)=>{
    return "delayTime" in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jaNPz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDisconnectMultipleOutputs", ()=>createDisconnectMultipleOutputs);
var _nativeAudioNode = require("../guards/native-audio-node");
const getOutputAudioNodeAtIndex = (createIndexSizeError, outputAudioNodes, output)=>{
    const outputAudioNode = outputAudioNodes[output];
    if (outputAudioNode === undefined) throw createIndexSizeError();
    return outputAudioNode;
};
const createDisconnectMultipleOutputs = (createIndexSizeError)=>{
    return (outputAudioNodes, destinationOrOutput, output, input = 0)=>{
        if (destinationOrOutput === undefined) return outputAudioNodes.forEach((outputAudioNode)=>outputAudioNode.disconnect());
        if (typeof destinationOrOutput === "number") return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, destinationOrOutput).disconnect();
        if ((0, _nativeAudioNode.isNativeAudioNode)(destinationOrOutput)) {
            if (output === undefined) return outputAudioNodes.forEach((outputAudioNode)=>outputAudioNode.disconnect(destinationOrOutput));
            if (input === undefined) return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);
            return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0, input);
        }
        if (output === undefined) return outputAudioNodes.forEach((outputAudioNode)=>outputAudioNode.disconnect(destinationOrOutput));
        return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);
    };
};

},{"../guards/native-audio-node":"hUupW","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1G29t":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDynamicsCompressorNodeConstructor", ()=>createDynamicsCompressorNodeConstructor);
const DEFAULT_OPTIONS = {
    attack: 0.003,
    channelCount: 2,
    channelCountMode: "clamped-max",
    channelInterpretation: "speakers",
    knee: 30,
    ratio: 12,
    release: 0.25,
    threshold: -24
};
const createDynamicsCompressorNodeConstructor = (audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, createNotSupportedError, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class DynamicsCompressorNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const dynamicsCompressorNodeRenderer = isOffline ? createDynamicsCompressorNodeRenderer() : null;
            super(context, false, nativeDynamicsCompressorNode, dynamicsCompressorNodeRenderer);
            this._attack = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.attack);
            this._knee = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.knee);
            this._nativeDynamicsCompressorNode = nativeDynamicsCompressorNode;
            this._ratio = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.ratio);
            this._release = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.release);
            this._threshold = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.threshold);
            setAudioNodeTailTime(this, 0.006);
        }
        get attack() {
            return this._attack;
        }
        // Bug #108: Safari allows a channelCount of three and above which is why the getter and setter needs to be overwritten here.
        get channelCount() {
            return this._nativeDynamicsCompressorNode.channelCount;
        }
        set channelCount(value) {
            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCount;
            this._nativeDynamicsCompressorNode.channelCount = value;
            if (value > 2) {
                this._nativeDynamicsCompressorNode.channelCount = previousChannelCount;
                throw createNotSupportedError();
            }
        }
        /*
         * Bug #109: Only Chrome and Firefox disallow a channelCountMode of 'max' yet which is why the getter and setter needs to be
         * overwritten here.
         */ get channelCountMode() {
            return this._nativeDynamicsCompressorNode.channelCountMode;
        }
        set channelCountMode(value) {
            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCountMode;
            this._nativeDynamicsCompressorNode.channelCountMode = value;
            if (value === "max") {
                this._nativeDynamicsCompressorNode.channelCountMode = previousChannelCount;
                throw createNotSupportedError();
            }
        }
        get knee() {
            return this._knee;
        }
        get ratio() {
            return this._ratio;
        }
        get reduction() {
            // Bug #111: Safari returns an AudioParam instead of a number.
            if (typeof this._nativeDynamicsCompressorNode.reduction.value === "number") return this._nativeDynamicsCompressorNode.reduction.value;
            return this._nativeDynamicsCompressorNode.reduction;
        }
        get release() {
            return this._release;
        }
        get threshold() {
            return this._threshold;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"pqFDv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDynamicsCompressorNodeRendererFactory", ()=>createDynamicsCompressorNodeRendererFactory);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createDynamicsCompressorNodeRendererFactory = (connectAudioParam, createNativeDynamicsCompressorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeDynamicsCompressorNodes = new WeakMap();
        const createDynamicsCompressorNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeDynamicsCompressorNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeDynamicsCompressorNode was not constructed on the same OfflineAudioContext it needs to be
             * created again.
             */ const nativeDynamicsCompressorNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeDynamicsCompressorNode, nativeOfflineAudioContext);
            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {
                const options = {
                    attack: nativeDynamicsCompressorNode.attack.value,
                    channelCount: nativeDynamicsCompressorNode.channelCount,
                    channelCountMode: nativeDynamicsCompressorNode.channelCountMode,
                    channelInterpretation: nativeDynamicsCompressorNode.channelInterpretation,
                    knee: nativeDynamicsCompressorNode.knee.value,
                    ratio: nativeDynamicsCompressorNode.ratio.value,
                    release: nativeDynamicsCompressorNode.release.value,
                    threshold: nativeDynamicsCompressorNode.threshold.value
                };
                nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeOfflineAudioContext, options);
            }
            renderedNativeDynamicsCompressorNodes.set(nativeOfflineAudioContext, nativeDynamicsCompressorNode);
            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack);
                await renderAutomation(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee);
                await renderAutomation(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio);
                await renderAutomation(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release);
                await renderAutomation(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack);
                await connectAudioParam(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee);
                await connectAudioParam(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio);
                await connectAudioParam(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release);
                await connectAudioParam(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold);
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDynamicsCompressorNode);
            return nativeDynamicsCompressorNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeDynamicsCompressorNode = renderedNativeDynamicsCompressorNodes.get(nativeOfflineAudioContext);
                if (renderedNativeDynamicsCompressorNode !== undefined) return Promise.resolve(renderedNativeDynamicsCompressorNode);
                return createDynamicsCompressorNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2alua":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createEncodingError", ()=>createEncodingError);
const createEncodingError = ()=>new DOMException("", "EncodingError");

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8CpjU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createEvaluateSource", ()=>createEvaluateSource);
const createEvaluateSource = (window)=>{
    return (source)=>new Promise((resolve, reject)=>{
            if (window === null) {
                // Bug #182 Chrome and Edge do throw an instance of a SyntaxError instead of a DOMException.
                reject(new SyntaxError());
                return;
            }
            const head = window.document.head;
            if (head === null) // Bug #182 Chrome and Edge do throw an instance of a SyntaxError instead of a DOMException.
            reject(new SyntaxError());
            else {
                const script = window.document.createElement("script");
                // @todo Safari doesn't like URLs with a type of 'application/javascript; charset=utf-8'.
                const blob = new Blob([
                    source
                ], {
                    type: "application/javascript"
                });
                const url = URL.createObjectURL(blob);
                const originalOnErrorHandler = window.onerror;
                const removeErrorEventListenerAndRevokeUrl = ()=>{
                    window.onerror = originalOnErrorHandler;
                    URL.revokeObjectURL(url);
                };
                window.onerror = (message, src, lineno, colno, error)=>{
                    // @todo Edge thinks the source is the one of the html document.
                    if (src === url || src === window.location.href && lineno === 1 && colno === 1) {
                        removeErrorEventListenerAndRevokeUrl();
                        reject(error);
                        return false;
                    }
                    if (originalOnErrorHandler !== null) return originalOnErrorHandler(message, src, lineno, colno, error);
                };
                script.onerror = ()=>{
                    removeErrorEventListenerAndRevokeUrl();
                    // Bug #182 Chrome and Edge do throw an instance of a SyntaxError instead of a DOMException.
                    reject(new SyntaxError());
                };
                script.onload = ()=>{
                    removeErrorEventListenerAndRevokeUrl();
                    resolve();
                };
                script.src = url;
                script.type = "module";
                head.appendChild(script);
            }
        });
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gjDDq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createEventTargetConstructor", ()=>createEventTargetConstructor);
const createEventTargetConstructor = (wrapEventListener)=>{
    return class EventTarget {
        constructor(_nativeEventTarget){
            this._nativeEventTarget = _nativeEventTarget;
            this._listeners = new WeakMap();
        }
        addEventListener(type, listener, options) {
            if (listener !== null) {
                let wrappedEventListener = this._listeners.get(listener);
                if (wrappedEventListener === undefined) {
                    wrappedEventListener = wrapEventListener(this, listener);
                    if (typeof listener === "function") this._listeners.set(listener, wrappedEventListener);
                }
                this._nativeEventTarget.addEventListener(type, wrappedEventListener, options);
            }
        }
        dispatchEvent(event) {
            return this._nativeEventTarget.dispatchEvent(event);
        }
        removeEventListener(type, listener, options) {
            const wrappedEventListener = listener === null ? undefined : this._listeners.get(listener);
            this._nativeEventTarget.removeEventListener(type, wrappedEventListener === undefined ? null : wrappedEventListener, options);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gNRs4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createExposeCurrentFrameAndCurrentTime", ()=>createExposeCurrentFrameAndCurrentTime);
const createExposeCurrentFrameAndCurrentTime = (window)=>{
    return (currentTime, sampleRate, fn)=>{
        Object.defineProperties(window, {
            currentFrame: {
                configurable: true,
                get () {
                    return Math.round(currentTime * sampleRate);
                }
            },
            currentTime: {
                configurable: true,
                get () {
                    return currentTime;
                }
            }
        });
        try {
            return fn();
        } finally{
            if (window !== null) {
                delete window.currentFrame;
                delete window.currentTime;
            }
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h4onu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createFetchSource", ()=>createFetchSource);
const createFetchSource = (createAbortError)=>{
    return async (url)=>{
        try {
            const response = await fetch(url);
            if (response.ok) return [
                await response.text(),
                response.url
            ];
        } catch  {
        // Ignore errors.
        } // tslint:disable-line:no-empty
        throw createAbortError();
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9a9Vk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGainNodeConstructor", ()=>createGainNodeConstructor);
var _constants = require("../constants");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    gain: 1
};
const createGainNodeConstructor = (audioNodeConstructor, createAudioParam, createGainNodeRenderer, createNativeGainNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class GainNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeGainNode = createNativeGainNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const gainNodeRenderer = isOffline ? createGainNodeRenderer() : null;
            super(context, false, nativeGainNode, gainNodeRenderer);
            // Bug #74: Safari does not export the correct values for maxValue and minValue.
            this._gain = createAudioParam(this, isOffline, nativeGainNode.gain, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
        }
        get gain() {
            return this._gain;
        }
    };
};

},{"../constants":"au584","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"itz3A":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGainNodeRendererFactory", ()=>createGainNodeRendererFactory);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createGainNodeRendererFactory = (connectAudioParam, createNativeGainNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeGainNodes = new WeakMap();
        const createGainNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeGainNode = getNativeAudioNode(proxy);
            // If the initially used nativeGainNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeGainNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeGainNode, nativeOfflineAudioContext);
            if (!nativeGainNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeGainNode.channelCount,
                    channelCountMode: nativeGainNode.channelCountMode,
                    channelInterpretation: nativeGainNode.channelInterpretation,
                    gain: nativeGainNode.gain.value
                };
                nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, options);
            }
            renderedNativeGainNodes.set(nativeOfflineAudioContext, nativeGainNode);
            if (!nativeGainNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeGainNode);
            return nativeGainNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeGainNode = renderedNativeGainNodes.get(nativeOfflineAudioContext);
                if (renderedNativeGainNode !== undefined) return Promise.resolve(renderedNativeGainNode);
                return createGainNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dg8Gd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetActiveAudioWorkletNodeInputs", ()=>createGetActiveAudioWorkletNodeInputs);
const createGetActiveAudioWorkletNodeInputs = (activeAudioWorkletNodeInputsStore, getValueForKey)=>{
    return (nativeAudioWorkletNode)=>getValueForKey(activeAudioWorkletNodeInputsStore, nativeAudioWorkletNode);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k8CrE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetAudioNodeRenderer", ()=>createGetAudioNodeRenderer);
const createGetAudioNodeRenderer = (getAudioNodeConnections)=>{
    return (audioNode)=>{
        const audioNodeConnections = getAudioNodeConnections(audioNode);
        if (audioNodeConnections.renderer === null) throw new Error("Missing the renderer of the given AudioNode in the audio graph.");
        return audioNodeConnections.renderer;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cKCqS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetAudioNodeTailTime", ()=>createGetAudioNodeTailTime);
const createGetAudioNodeTailTime = (audioNodeTailTimeStore)=>{
    return (audioNode)=>{
        var _a;
        return (_a = audioNodeTailTimeStore.get(audioNode)) !== null && _a !== void 0 ? _a : 0;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k8fN6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetAudioParamRenderer", ()=>createGetAudioParamRenderer);
const createGetAudioParamRenderer = (getAudioParamConnections)=>{
    return (audioParam)=>{
        const audioParamConnections = getAudioParamConnections(audioParam);
        if (audioParamConnections.renderer === null) throw new Error("Missing the renderer of the given AudioParam in the audio graph.");
        return audioParamConnections.renderer;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1vR8R":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetBackupOfflineAudioContext", ()=>createGetBackupOfflineAudioContext);
const createGetBackupOfflineAudioContext = (backupOfflineAudioContextStore)=>{
    return (nativeContext)=>{
        return backupOfflineAudioContextStore.get(nativeContext);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2Ytji":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetNativeContext", ()=>createGetNativeContext);
var _invalidStateError = require("./invalid-state-error");
const createGetNativeContext = (contextStore)=>{
    return (context)=>{
        const nativeContext = contextStore.get(context);
        if (nativeContext === undefined) throw (0, _invalidStateError.createInvalidStateError)();
        return nativeContext;
    };
};

},{"./invalid-state-error":"diSZR","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"diSZR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createInvalidStateError", ()=>createInvalidStateError);
const createInvalidStateError = ()=>new DOMException("", "InvalidStateError");

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kLefC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetOrCreateBackupOfflineAudioContext", ()=>createGetOrCreateBackupOfflineAudioContext);
const createGetOrCreateBackupOfflineAudioContext = (backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor)=>{
    return (nativeContext)=>{
        let backupOfflineAudioContext = backupOfflineAudioContextStore.get(nativeContext);
        if (backupOfflineAudioContext !== undefined) return backupOfflineAudioContext;
        if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.
        backupOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        backupOfflineAudioContextStore.set(nativeContext, backupOfflineAudioContext);
        return backupOfflineAudioContext;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jI5Mi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetUnrenderedAudioWorkletNodes", ()=>createGetUnrenderedAudioWorkletNodes);
const createGetUnrenderedAudioWorkletNodes = (unrenderedAudioWorkletNodeStore)=>{
    return (nativeContext)=>{
        const unrenderedAudioWorkletNodes = unrenderedAudioWorkletNodeStore.get(nativeContext);
        if (unrenderedAudioWorkletNodes === undefined) throw new Error("The context has no set of AudioWorkletNodes.");
        return unrenderedAudioWorkletNodes;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3jZOn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIIRFilterNodeConstructor", ()=>createIIRFilterNodeConstructor);
var _wrapIirFilterNodeGetFrequencyResponseMethod = require("../helpers/wrap-iir-filter-node-get-frequency-response-method");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers"
};
const createIIRFilterNodeConstructor = (audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class IIRFilterNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeIIRFilterNode = createNativeIIRFilterNode(nativeContext, isOffline ? null : context.baseLatency, mergedOptions);
            const iirFilterNodeRenderer = isOffline ? createIIRFilterNodeRenderer(mergedOptions.feedback, mergedOptions.feedforward) : null;
            super(context, false, nativeIIRFilterNode, iirFilterNodeRenderer);
            // Bug #23 & #24: FirefoxDeveloper does not throw an InvalidAccessError.
            // @todo Write a test which allows other browsers to remain unpatched.
            (0, _wrapIirFilterNodeGetFrequencyResponseMethod.wrapIIRFilterNodeGetFrequencyResponseMethod)(nativeIIRFilterNode);
            this._nativeIIRFilterNode = nativeIIRFilterNode;
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
            return this._nativeIIRFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);
        }
    };
};

},{"../helpers/wrap-iir-filter-node-get-frequency-response-method":"chGIz","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"chGIz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapIIRFilterNodeGetFrequencyResponseMethod", ()=>wrapIIRFilterNodeGetFrequencyResponseMethod);
var _invalidAccessError = require("../factories/invalid-access-error");
const wrapIIRFilterNodeGetFrequencyResponseMethod = (nativeIIRFilterNode)=>{
    nativeIIRFilterNode.getFrequencyResponse = ((getFrequencyResponse)=>{
        return (frequencyHz, magResponse, phaseResponse)=>{
            if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) throw (0, _invalidAccessError.createInvalidAccessError)();
            return getFrequencyResponse.call(nativeIIRFilterNode, frequencyHz, magResponse, phaseResponse);
        };
    })(nativeIIRFilterNode.getFrequencyResponse);
};

},{"../factories/invalid-access-error":"u7Sql","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"u7Sql":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createInvalidAccessError", ()=>createInvalidAccessError);
const createInvalidAccessError = ()=>new DOMException("", "InvalidAccessError");

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eyGMp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIIRFilterNodeRendererFactory", ()=>createIIRFilterNodeRendererFactory);
var _filterBuffer = require("../helpers/filter-buffer");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const filterFullBuffer = (renderedBuffer, nativeOfflineAudioContext, feedback, feedforward)=>{
    const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);
    const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);
    const feedbackLength = convertedFeedback.length;
    const feedforwardLength = convertedFeedforward.length;
    const minLength = Math.min(feedbackLength, feedforwardLength);
    if (convertedFeedback[0] !== 1) {
        for(let i = 0; i < feedbackLength; i += 1)convertedFeedforward[i] /= convertedFeedback[0];
        for(let i = 1; i < feedforwardLength; i += 1)convertedFeedback[i] /= convertedFeedback[0];
    }
    const bufferLength = 32;
    const xBuffer = new Float32Array(bufferLength);
    const yBuffer = new Float32Array(bufferLength);
    const filteredBuffer = nativeOfflineAudioContext.createBuffer(renderedBuffer.numberOfChannels, renderedBuffer.length, renderedBuffer.sampleRate);
    const numberOfChannels = renderedBuffer.numberOfChannels;
    for(let i = 0; i < numberOfChannels; i += 1){
        const input = renderedBuffer.getChannelData(i);
        const output = filteredBuffer.getChannelData(i);
        xBuffer.fill(0);
        yBuffer.fill(0);
        (0, _filterBuffer.filterBuffer)(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffer, yBuffer, 0, bufferLength, input, output);
    }
    return filteredBuffer;
};
const createIIRFilterNodeRendererFactory = (createNativeAudioBufferSourceNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext)=>{
    return (feedback, feedforward)=>{
        const renderedNativeAudioNodes = new WeakMap();
        let filteredBufferPromise = null;
        const createAudioNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAudioBufferSourceNode = null;
            let nativeIIRFilterNode = getNativeAudioNode(proxy);
            // If the initially used nativeIIRFilterNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeIIRFilterNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeIIRFilterNode, nativeOfflineAudioContext);
            // Bug #9: Safari does not support IIRFilterNodes.
            if (nativeOfflineAudioContext.createIIRFilter === undefined) nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {
                buffer: null,
                channelCount: 2,
                channelCountMode: "max",
                channelInterpretation: "speakers",
                loop: false,
                loopEnd: 0,
                loopStart: 0,
                playbackRate: 1
            });
            else if (!nativeIIRFilterNodeIsOwnedByContext) // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.
            nativeIIRFilterNode = nativeOfflineAudioContext.createIIRFilter(feedforward, feedback);
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode === null ? nativeIIRFilterNode : nativeAudioBufferSourceNode);
            if (nativeAudioBufferSourceNode !== null) {
                if (filteredBufferPromise === null) {
                    if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(// Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.
                    proxy.context.destination.channelCount, // Bug #17: Safari does not yet expose the length.
                    proxy.context.length, nativeOfflineAudioContext.sampleRate);
                    filteredBufferPromise = (async ()=>{
                        await renderInputsOfAudioNode(proxy, partialOfflineAudioContext, partialOfflineAudioContext.destination);
                        const renderedBuffer = await renderNativeOfflineAudioContext(partialOfflineAudioContext);
                        return filterFullBuffer(renderedBuffer, nativeOfflineAudioContext, feedback, feedforward);
                    })();
                }
                const filteredBuffer = await filteredBufferPromise;
                nativeAudioBufferSourceNode.buffer = filteredBuffer;
                nativeAudioBufferSourceNode.start(0);
                return nativeAudioBufferSourceNode;
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeIIRFilterNode);
            return nativeIIRFilterNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioNode !== undefined) return Promise.resolve(renderedNativeAudioNode);
                return createAudioNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/filter-buffer":"bnsBL","../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bnsBL":[function(require,module,exports) {
// This implementation as shamelessly inspired by source code of
// tslint:disable-next-line:max-line-length
// {@link https://chromium.googlesource.com/chromium/src.git/+/master/third_party/WebKit/Source/platform/audio/IIRFilter.cpp|Chromium's IIRFilter}.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "filterBuffer", ()=>filterBuffer);
const filterBuffer = (feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffer, yBuffer, bufferIndex, bufferLength, input, output)=>{
    const inputLength = input.length;
    let i = bufferIndex;
    for(let j = 0; j < inputLength; j += 1){
        let y = feedforward[0] * input[j];
        for(let k = 1; k < minLength; k += 1){
            const x = i - k & bufferLength - 1; // tslint:disable-line:no-bitwise
            y += feedforward[k] * xBuffer[x];
            y -= feedback[k] * yBuffer[x];
        }
        for(let k = minLength; k < feedforwardLength; k += 1)y += feedforward[k] * xBuffer[i - k & bufferLength - 1]; // tslint:disable-line:no-bitwise
        for(let k = minLength; k < feedbackLength; k += 1)y -= feedback[k] * yBuffer[i - k & bufferLength - 1]; // tslint:disable-line:no-bitwise
        xBuffer[i] = input[j];
        yBuffer[i] = y;
        i = i + 1 & bufferLength - 1; // tslint:disable-line:no-bitwise
        output[j] = y;
    }
    return i;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eIT5f":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIncrementCycleCounterFactory", ()=>createIncrementCycleCounterFactory);
var _audioNodeOutputConnection = require("../guards/audio-node-output-connection");
const createIncrementCycleCounterFactory = (cycleCounters, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, isActiveAudioNode)=>{
    return (isOffline)=>{
        return (audioNode, count)=>{
            const cycleCounter = cycleCounters.get(audioNode);
            if (cycleCounter === undefined) {
                if (!isOffline && isActiveAudioNode(audioNode)) {
                    const nativeSourceAudioNode = getNativeAudioNode(audioNode);
                    const { outputs } = getAudioNodeConnections(audioNode);
                    for (const output of outputs)if ((0, _audioNodeOutputConnection.isAudioNodeOutputConnection)(output)) {
                        const nativeDestinationAudioNode = getNativeAudioNode(output[0]);
                        disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);
                    } else {
                        const nativeDestinationAudioParam = getNativeAudioParam(output[0]);
                        nativeSourceAudioNode.disconnect(nativeDestinationAudioParam, output[1]);
                    }
                }
                cycleCounters.set(audioNode, count);
            } else cycleCounters.set(audioNode, cycleCounter + count);
        };
    };
};

},{"../guards/audio-node-output-connection":"5S2ZA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eHxqH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsAnyAudioContext", ()=>createIsAnyAudioContext);
const createIsAnyAudioContext = (contextStore, isNativeAudioContext)=>{
    return (anything)=>{
        const nativeContext = contextStore.get(anything);
        return isNativeAudioContext(nativeContext) || isNativeAudioContext(anything);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"tjPuV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsAnyAudioNode", ()=>createIsAnyAudioNode);
const createIsAnyAudioNode = (audioNodeStore, isNativeAudioNode)=>{
    return (anything)=>audioNodeStore.has(anything) || isNativeAudioNode(anything);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hncwE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsAnyAudioParam", ()=>createIsAnyAudioParam);
const createIsAnyAudioParam = (audioParamStore, isNativeAudioParam)=>{
    return (anything)=>audioParamStore.has(anything) || isNativeAudioParam(anything);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"evgeG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsAnyOfflineAudioContext", ()=>createIsAnyOfflineAudioContext);
const createIsAnyOfflineAudioContext = (contextStore, isNativeOfflineAudioContext)=>{
    return (anything)=>{
        const nativeContext = contextStore.get(anything);
        return isNativeOfflineAudioContext(nativeContext) || isNativeOfflineAudioContext(anything);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ctipH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsNativeAudioContext", ()=>createIsNativeAudioContext);
const createIsNativeAudioContext = (nativeAudioContextConstructor)=>{
    return (anything)=>{
        return nativeAudioContextConstructor !== null && anything instanceof nativeAudioContextConstructor;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6XefY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsNativeAudioNode", ()=>createIsNativeAudioNode);
const createIsNativeAudioNode = (window)=>{
    return (anything)=>{
        return window !== null && typeof window.AudioNode === "function" && anything instanceof window.AudioNode;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8zo2U":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsNativeAudioParam", ()=>createIsNativeAudioParam);
const createIsNativeAudioParam = (window)=>{
    return (anything)=>{
        return window !== null && typeof window.AudioParam === "function" && anything instanceof window.AudioParam;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bqWH8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsNativeContext", ()=>createIsNativeContext);
const createIsNativeContext = (isNativeAudioContext, isNativeOfflineAudioContext)=>{
    return (anything)=>{
        return isNativeAudioContext(anything) || isNativeOfflineAudioContext(anything);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"absQf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsNativeOfflineAudioContext", ()=>createIsNativeOfflineAudioContext);
const createIsNativeOfflineAudioContext = (nativeOfflineAudioContextConstructor)=>{
    return (anything)=>{
        return nativeOfflineAudioContextConstructor !== null && anything instanceof nativeOfflineAudioContextConstructor;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"c4RLa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsSecureContext", ()=>createIsSecureContext);
const createIsSecureContext = (window)=>window !== null && window.isSecureContext;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lB7Vh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsSupportedPromise", ()=>createIsSupportedPromise);
const createIsSupportedPromise = async (cacheTestResult, testAudioBufferCopyChannelMethodsSubarraySupport, testAudioContextCloseMethodSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextOptionsSupport, testAudioNodeConnectMethodSupport, testAudioWorkletProcessorNoOutputsSupport, testChannelMergerNodeChannelCountSupport, testConstantSourceNodeAccurateSchedulingSupport, testConvolverNodeBufferReassignabilitySupport, testConvolverNodeChannelCountSupport, testDomExceptionContrucorSupport, testIsSecureContextSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testStereoPannerNodeDefaultValueSupport, testTransferablesSupport)=>{
    if (cacheTestResult(testAudioBufferCopyChannelMethodsSubarraySupport, testAudioBufferCopyChannelMethodsSubarraySupport) && cacheTestResult(testAudioContextCloseMethodSupport, testAudioContextCloseMethodSupport) && cacheTestResult(testAudioContextOptionsSupport, testAudioContextOptionsSupport) && cacheTestResult(testAudioNodeConnectMethodSupport, testAudioNodeConnectMethodSupport) && cacheTestResult(testChannelMergerNodeChannelCountSupport, testChannelMergerNodeChannelCountSupport) && cacheTestResult(testConstantSourceNodeAccurateSchedulingSupport, testConstantSourceNodeAccurateSchedulingSupport) && cacheTestResult(testConvolverNodeBufferReassignabilitySupport, testConvolverNodeBufferReassignabilitySupport) && cacheTestResult(testConvolverNodeChannelCountSupport, testConvolverNodeChannelCountSupport) && cacheTestResult(testDomExceptionContrucorSupport, testDomExceptionContrucorSupport) && cacheTestResult(testIsSecureContextSupport, testIsSecureContextSupport) && cacheTestResult(testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)) {
        const results = await Promise.all([
            cacheTestResult(testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport),
            cacheTestResult(testAudioWorkletProcessorNoOutputsSupport, testAudioWorkletProcessorNoOutputsSupport),
            cacheTestResult(testStereoPannerNodeDefaultValueSupport, testStereoPannerNodeDefaultValueSupport),
            cacheTestResult(testTransferablesSupport, testTransferablesSupport)
        ]);
        return results.every((result)=>result);
    }
    return false;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gvVfX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMediaElementAudioSourceNodeConstructor", ()=>createMediaElementAudioSourceNodeConstructor);
const createMediaElementAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class MediaElementAudioSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const nativeMediaElementAudioSourceNode = createNativeMediaElementAudioSourceNode(nativeContext, options);
            // Bug #171: Safari allows to create a MediaElementAudioSourceNode with an OfflineAudioContext.
            if (isNativeOfflineAudioContext(nativeContext)) throw TypeError();
            super(context, true, nativeMediaElementAudioSourceNode, null);
            this._nativeMediaElementAudioSourceNode = nativeMediaElementAudioSourceNode;
        }
        get mediaElement() {
            return this._nativeMediaElementAudioSourceNode.mediaElement;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"76MLr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMediaStreamAudioDestinationNodeConstructor", ()=>createMediaStreamAudioDestinationNodeConstructor);
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "explicit",
    channelInterpretation: "speakers"
};
const createMediaStreamAudioDestinationNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class MediaStreamAudioDestinationNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            // Bug #173: Safari allows to create a MediaStreamAudioDestinationNode with an OfflineAudioContext.
            if (isNativeOfflineAudioContext(nativeContext)) throw new TypeError();
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeMediaStreamAudioDestinationNode = createNativeMediaStreamAudioDestinationNode(nativeContext, mergedOptions);
            super(context, false, nativeMediaStreamAudioDestinationNode, null);
            this._nativeMediaStreamAudioDestinationNode = nativeMediaStreamAudioDestinationNode;
        }
        get stream() {
            return this._nativeMediaStreamAudioDestinationNode.stream;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7y92U":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMediaStreamAudioSourceNodeConstructor", ()=>createMediaStreamAudioSourceNodeConstructor);
const createMediaStreamAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class MediaStreamAudioSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const nativeMediaStreamAudioSourceNode = createNativeMediaStreamAudioSourceNode(nativeContext, options);
            // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.
            if (isNativeOfflineAudioContext(nativeContext)) throw new TypeError();
            super(context, true, nativeMediaStreamAudioSourceNode, null);
            this._nativeMediaStreamAudioSourceNode = nativeMediaStreamAudioSourceNode;
        }
        get mediaStream() {
            return this._nativeMediaStreamAudioSourceNode.mediaStream;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eubAO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMediaStreamTrackAudioSourceNodeConstructor", ()=>createMediaStreamTrackAudioSourceNodeConstructor);
const createMediaStreamTrackAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext)=>{
    return class MediaStreamTrackAudioSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const nativeMediaStreamTrackAudioSourceNode = createNativeMediaStreamTrackAudioSourceNode(nativeContext, options);
            super(context, true, nativeMediaStreamTrackAudioSourceNode, null);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2Rukp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMinimalAudioContextConstructor", ()=>createMinimalAudioContextConstructor);
var _deactivateAudioGraph = require("../helpers/deactivate-audio-graph");
var _isValidLatencyHint = require("../helpers/is-valid-latency-hint");
const createMinimalAudioContextConstructor = (createInvalidStateError, createNotSupportedError, createUnknownError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor)=>{
    return class MinimalAudioContext extends minimalBaseAudioContextConstructor {
        constructor(options = {}){
            if (nativeAudioContextConstructor === null) throw new Error("Missing the native AudioContext constructor.");
            let nativeAudioContext;
            try {
                nativeAudioContext = new nativeAudioContextConstructor(options);
            } catch (err) {
                // Bug #192 Safari does throw a SyntaxError if the sampleRate is not supported.
                if (err.code === 12 && err.message === "sampleRate is not in range") throw createNotSupportedError();
                throw err;
            }
            // Bug #131 Safari returns null when there are four other AudioContexts running already.
            if (nativeAudioContext === null) throw createUnknownError();
            // Bug #51 Only Chrome and Edge throw an error if the given latencyHint is invalid.
            if (!(0, _isValidLatencyHint.isValidLatencyHint)(options.latencyHint)) throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);
            // Bug #150 Safari does not support setting the sampleRate.
            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) throw createNotSupportedError();
            super(nativeAudioContext, 2);
            const { latencyHint } = options;
            const { sampleRate } = nativeAudioContext;
            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.
            this._baseLatency = typeof nativeAudioContext.baseLatency === "number" ? nativeAudioContext.baseLatency : latencyHint === "balanced" ? 512 / sampleRate : latencyHint === "interactive" || latencyHint === undefined ? 256 / sampleRate : latencyHint === "playback" ? 1024 / sampleRate : /*
                                   * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a
                                   * ScriptProcessorNode.
                                   */ Math.max(2, Math.min(128, Math.round(latencyHint * sampleRate / 128))) * 128 / sampleRate;
            this._nativeAudioContext = nativeAudioContext;
            // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.
            if (nativeAudioContextConstructor.name === "webkitAudioContext") {
                this._nativeGainNode = nativeAudioContext.createGain();
                this._nativeOscillatorNode = nativeAudioContext.createOscillator();
                this._nativeGainNode.gain.value = 1e-37;
                this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);
                this._nativeOscillatorNode.start();
            } else {
                this._nativeGainNode = null;
                this._nativeOscillatorNode = null;
            }
            this._state = null;
            /*
             * Bug #34: Chrome and Edge pretend to be running right away, but fire an onstatechange event when the state actually changes
             * to 'running'.
             */ if (nativeAudioContext.state === "running") {
                this._state = "suspended";
                const revokeState = ()=>{
                    if (this._state === "suspended") this._state = null;
                    nativeAudioContext.removeEventListener("statechange", revokeState);
                };
                nativeAudioContext.addEventListener("statechange", revokeState);
            }
        }
        get baseLatency() {
            return this._baseLatency;
        }
        get state() {
            return this._state !== null ? this._state : this._nativeAudioContext.state;
        }
        close() {
            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.
            if (this.state === "closed") return this._nativeAudioContext.close().then(()=>{
                throw createInvalidStateError();
            });
            // Bug #34: If the state was set to suspended before it should be revoked now.
            if (this._state === "suspended") this._state = null;
            return this._nativeAudioContext.close().then(()=>{
                if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {
                    this._nativeOscillatorNode.stop();
                    this._nativeGainNode.disconnect();
                    this._nativeOscillatorNode.disconnect();
                }
                (0, _deactivateAudioGraph.deactivateAudioGraph)(this);
            });
        }
        resume() {
            if (this._state === "suspended") return new Promise((resolve, reject)=>{
                const resolvePromise = ()=>{
                    this._nativeAudioContext.removeEventListener("statechange", resolvePromise);
                    if (this._nativeAudioContext.state === "running") resolve();
                    else this.resume().then(resolve, reject);
                };
                this._nativeAudioContext.addEventListener("statechange", resolvePromise);
            });
            return this._nativeAudioContext.resume().catch((err)=>{
                // Bug #55: Chrome and Edge do throw an InvalidAccessError instead of an InvalidStateError.
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined || err.code === 15) throw createInvalidStateError();
                throw err;
            });
        }
        suspend() {
            return this._nativeAudioContext.suspend().catch((err)=>{
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined) throw createInvalidStateError();
                throw err;
            });
        }
    };
};

},{"../helpers/deactivate-audio-graph":"ap1I7","../helpers/is-valid-latency-hint":"7xWOy","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8u4st":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMinimalBaseAudioContextConstructor", ()=>createMinimalBaseAudioContextConstructor);
var _globals = require("../globals");
const createMinimalBaseAudioContextConstructor = (audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, wrapEventListener)=>{
    return class MinimalBaseAudioContext extends eventTargetConstructor {
        constructor(_nativeContext, numberOfChannels){
            super(_nativeContext);
            this._nativeContext = _nativeContext;
            (0, _globals.CONTEXT_STORE).set(this, _nativeContext);
            if (isNativeOfflineAudioContext(_nativeContext)) unrenderedAudioWorkletNodeStore.set(_nativeContext, new Set());
            this._destination = new audioDestinationNodeConstructor(this, numberOfChannels);
            this._listener = createAudioListener(this, _nativeContext);
            this._onstatechange = null;
        }
        get currentTime() {
            return this._nativeContext.currentTime;
        }
        get destination() {
            return this._destination;
        }
        get listener() {
            return this._listener;
        }
        get onstatechange() {
            return this._onstatechange;
        }
        set onstatechange(value) {
            const wrappedListener = typeof value === "function" ? wrapEventListener(this, value) : null;
            this._nativeContext.onstatechange = wrappedListener;
            const nativeOnStateChange = this._nativeContext.onstatechange;
            this._onstatechange = nativeOnStateChange !== null && nativeOnStateChange === wrappedListener ? value : nativeOnStateChange;
        }
        get sampleRate() {
            return this._nativeContext.sampleRate;
        }
        get state() {
            return this._nativeContext.state;
        }
    };
};

},{"../globals":"j1ar4","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9yhkF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMinimalOfflineAudioContextConstructor", ()=>createMinimalOfflineAudioContextConstructor);
var _deactivateAudioGraph = require("../helpers/deactivate-audio-graph");
var _testPromiseSupport = require("../helpers/test-promise-support");
const DEFAULT_OPTIONS = {
    numberOfChannels: 1
};
const createMinimalOfflineAudioContextConstructor = (cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering)=>{
    return class MinimalOfflineAudioContext extends minimalBaseAudioContextConstructor {
        constructor(options){
            const { length, numberOfChannels, sampleRate } = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);
            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.
            if (!cacheTestResult((0, _testPromiseSupport.testPromiseSupport), ()=>(0, _testPromiseSupport.testPromiseSupport)(nativeOfflineAudioContext))) nativeOfflineAudioContext.addEventListener("statechange", (()=>{
                let i = 0;
                const delayStateChangeEvent = (event)=>{
                    if (this._state === "running") {
                        if (i > 0) {
                            nativeOfflineAudioContext.removeEventListener("statechange", delayStateChangeEvent);
                            event.stopImmediatePropagation();
                            this._waitForThePromiseToSettle(event);
                        } else i += 1;
                    }
                };
                return delayStateChangeEvent;
            })());
            super(nativeOfflineAudioContext, numberOfChannels);
            this._length = length;
            this._nativeOfflineAudioContext = nativeOfflineAudioContext;
            this._state = null;
        }
        get length() {
            // Bug #17: Safari does not yet expose the length.
            if (this._nativeOfflineAudioContext.length === undefined) return this._length;
            return this._nativeOfflineAudioContext.length;
        }
        get state() {
            return this._state === null ? this._nativeOfflineAudioContext.state : this._state;
        }
        startRendering() {
            /*
             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore
             * the state of the nativeOfflineAudioContext might no transition to running immediately.
             */ if (this._state === "running") return Promise.reject(createInvalidStateError());
            this._state = "running";
            return startRendering(this.destination, this._nativeOfflineAudioContext).finally(()=>{
                this._state = null;
                (0, _deactivateAudioGraph.deactivateAudioGraph)(this);
            });
        }
        _waitForThePromiseToSettle(event) {
            if (this._state === null) this._nativeOfflineAudioContext.dispatchEvent(event);
            else setTimeout(()=>this._waitForThePromiseToSettle(event));
        }
    };
};

},{"../helpers/deactivate-audio-graph":"ap1I7","../helpers/test-promise-support":"4hyPB","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4hyPB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testPromiseSupport", ()=>testPromiseSupport);
const testPromiseSupport = (nativeContext)=>{
    // This 12 numbers represent the 48 bytes of an empty WAVE file with a single sample.
    const uint32Array = new Uint32Array([
        1179011410,
        40,
        1163280727,
        544501094,
        16,
        131073,
        44100,
        176400,
        1048580,
        1635017060,
        4,
        0
    ]);
    try {
        // Bug #1: Safari requires a successCallback.
        const promise = nativeContext.decodeAudioData(uint32Array.buffer, ()=>{
        // Ignore the success callback.
        });
        if (promise === undefined) return false;
        promise.catch(()=>{
        // Ignore rejected errors.
        });
        return true;
    } catch  {
    // Ignore errors.
    }
    return false;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eUd0z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMonitorConnections", ()=>createMonitorConnections);
const createMonitorConnections = (insertElementInSet, isNativeAudioNode)=>{
    return (nativeAudioNode, whenConnected, whenDisconnected)=>{
        const connections = new Set();
        nativeAudioNode.connect = ((connect)=>{
            // tslint:disable-next-line:invalid-void no-inferrable-types
            return (destination, output = 0, input = 0)=>{
                const wasDisconnected = connections.size === 0;
                if (isNativeAudioNode(destination)) {
                    // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
                    connect.call(nativeAudioNode, destination, output, input);
                    insertElementInSet(connections, [
                        destination,
                        output,
                        input
                    ], (connection)=>connection[0] === destination && connection[1] === output && connection[2] === input, true);
                    if (wasDisconnected) whenConnected();
                    return destination;
                }
                connect.call(nativeAudioNode, destination, output);
                insertElementInSet(connections, [
                    destination,
                    output
                ], (connection)=>connection[0] === destination && connection[1] === output, true);
                if (wasDisconnected) whenConnected();
                return;
            };
        })(nativeAudioNode.connect);
        nativeAudioNode.disconnect = ((disconnect)=>{
            return (destinationOrOutput, output, input)=>{
                const wasConnected = connections.size > 0;
                if (destinationOrOutput === undefined) {
                    disconnect.apply(nativeAudioNode);
                    connections.clear();
                } else if (typeof destinationOrOutput === "number") {
                    // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.
                    disconnect.call(nativeAudioNode, destinationOrOutput);
                    for (const connection of connections)if (connection[1] === destinationOrOutput) connections.delete(connection);
                } else {
                    if (isNativeAudioNode(destinationOrOutput)) // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
                    disconnect.call(nativeAudioNode, destinationOrOutput, output, input);
                    else // @todo TypeScript cannot infer the overloaded signature with 2 arguments yet.
                    disconnect.call(nativeAudioNode, destinationOrOutput, output);
                    for (const connection of connections)if (connection[0] === destinationOrOutput && (output === undefined || connection[1] === output) && (input === undefined || connection[2] === input)) connections.delete(connection);
                }
                const isDisconnected = connections.size === 0;
                if (wasConnected && isDisconnected) whenDisconnected();
            };
        })(nativeAudioNode.disconnect);
        return nativeAudioNode;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eAIIV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAnalyserNodeFactory", ()=>createNativeAnalyserNodeFactory);
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _testAnalyserNodeGetFloatTimeDomainDataMethodSupport = require("../helpers/test-analyser-node-get-float-time-domain-data-method-support");
var _wrapAnalyserNodeGetFloatTimeDomainDataMethod = require("../helpers/wrap-analyser-node-get-float-time-domain-data-method");
const createNativeAnalyserNodeFactory = (cacheTestResult, createIndexSizeError)=>{
    return (nativeContext, options)=>{
        const nativeAnalyserNode = nativeContext.createAnalyser();
        // Bug #37: Firefox does not create an AnalyserNode with the default properties.
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeAnalyserNode, options);
        // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
        if (!(options.maxDecibels > options.minDecibels)) throw createIndexSizeError();
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAnalyserNode, options, "fftSize");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAnalyserNode, options, "maxDecibels");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAnalyserNode, options, "minDecibels");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAnalyserNode, options, "smoothingTimeConstant");
        // Bug #36: Safari does not support getFloatTimeDomainData() yet.
        if (!cacheTestResult((0, _testAnalyserNodeGetFloatTimeDomainDataMethodSupport.testAnalyserNodeGetFloatTimeDomainDataMethodSupport), ()=>(0, _testAnalyserNodeGetFloatTimeDomainDataMethodSupport.testAnalyserNodeGetFloatTimeDomainDataMethodSupport)(nativeAnalyserNode))) (0, _wrapAnalyserNodeGetFloatTimeDomainDataMethod.wrapAnalyserNodeGetFloatTimeDomainDataMethod)(nativeAnalyserNode);
        return nativeAnalyserNode;
    };
};

},{"../helpers/assign-native-audio-node-option":"gLjOv","../helpers/assign-native-audio-node-options":"hQ1ig","../helpers/test-analyser-node-get-float-time-domain-data-method-support":"7GxbJ","../helpers/wrap-analyser-node-get-float-time-domain-data-method":"glG5y","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gLjOv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "assignNativeAudioNodeOption", ()=>assignNativeAudioNodeOption);
const assignNativeAudioNodeOption = (nativeAudioNode, options, option)=>{
    const value = options[option];
    if (value !== undefined && value !== nativeAudioNode[option]) nativeAudioNode[option] = value;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hQ1ig":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "assignNativeAudioNodeOptions", ()=>assignNativeAudioNodeOptions);
var _assignNativeAudioNodeOption = require("./assign-native-audio-node-option");
const assignNativeAudioNodeOptions = (nativeAudioNode, options)=>{
    (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAudioNode, options, "channelCount");
    (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAudioNode, options, "channelCountMode");
    (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAudioNode, options, "channelInterpretation");
};

},{"./assign-native-audio-node-option":"gLjOv","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7GxbJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAnalyserNodeGetFloatTimeDomainDataMethodSupport", ()=>testAnalyserNodeGetFloatTimeDomainDataMethodSupport);
const testAnalyserNodeGetFloatTimeDomainDataMethodSupport = (nativeAnalyserNode)=>{
    return typeof nativeAnalyserNode.getFloatTimeDomainData === "function";
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"glG5y":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAnalyserNodeGetFloatTimeDomainDataMethod", ()=>wrapAnalyserNodeGetFloatTimeDomainDataMethod);
const wrapAnalyserNodeGetFloatTimeDomainDataMethod = (nativeAnalyserNode)=>{
    nativeAnalyserNode.getFloatTimeDomainData = (array)=>{
        const byteTimeDomainData = new Uint8Array(array.length);
        nativeAnalyserNode.getByteTimeDomainData(byteTimeDomainData);
        const length = Math.max(byteTimeDomainData.length, nativeAnalyserNode.fftSize);
        for(let i = 0; i < length; i += 1)array[i] = (byteTimeDomainData[i] - 128) * 0.0078125;
        return array;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2XJiC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioBufferConstructor", ()=>createNativeAudioBufferConstructor);
const createNativeAudioBufferConstructor = (window)=>{
    if (window === null) return null;
    if (window.hasOwnProperty("AudioBuffer")) return window.AudioBuffer;
    return null;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fj4aF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioBufferSourceNodeFactory", ()=>createNativeAudioBufferSourceNodeFactory);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _wrapAudioBufferSourceNodeStartMethodConsecutiveCalls = require("../helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls");
var _wrapAudioScheduledSourceNodeStartMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters");
var _wrapAudioScheduledSourceNodeStopMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters");
const createNativeAudioBufferSourceNodeFactory = (addSilentConnection, cacheTestResult, testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, testAudioBufferSourceNodeStartMethodOffsetClampingSupport, testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioBufferSourceNodeStartMethodOffsetClampling, wrapAudioBufferSourceNodeStopMethodNullifiedBuffer, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls)=>{
    return (nativeContext, options)=>{
        const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeAudioBufferSourceNode, options);
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeAudioBufferSourceNode, options, "playbackRate");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, "buffer");
        // Bug #149: Safari does not yet support the detune AudioParam.
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, "loop");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, "loopEnd");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, "loopStart");
        // Bug #69: Safari does allow calls to start() of an already scheduled AudioBufferSourceNode.
        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, ()=>testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport(nativeContext))) (0, _wrapAudioBufferSourceNodeStartMethodConsecutiveCalls.wrapAudioBufferSourceNodeStartMethodConsecutiveCalls)(nativeAudioBufferSourceNode);
        // Bug #154 & #155: Safari does not handle offsets which are equal to or greater than the duration of the buffer.
        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodOffsetClampingSupport, ()=>testAudioBufferSourceNodeStartMethodOffsetClampingSupport(nativeContext))) wrapAudioBufferSourceNodeStartMethodOffsetClampling(nativeAudioBufferSourceNode);
        // Bug #162: Safari does throw an error when stop() is called on an AudioBufferSourceNode which has no buffer assigned to it.
        if (!cacheTestResult(testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, ()=>testAudioBufferSourceNodeStopMethodNullifiedBufferSupport(nativeContext))) wrapAudioBufferSourceNodeStopMethodNullifiedBuffer(nativeAudioBufferSourceNode, nativeContext);
        // Bug #44: Safari does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) (0, _wrapAudioScheduledSourceNodeStartMethodNegativeParameters.wrapAudioScheduledSourceNodeStartMethodNegativeParameters)(nativeAudioBufferSourceNode);
        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, ()=>testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeAudioBufferSourceNode, nativeContext);
        // Bug #44: Only Firefox does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) (0, _wrapAudioScheduledSourceNodeStopMethodNegativeParameters.wrapAudioScheduledSourceNodeStopMethodNegativeParameters)(nativeAudioBufferSourceNode);
        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.
        addSilentConnection(nativeContext, nativeAudioBufferSourceNode);
        return nativeAudioBufferSourceNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"2k6Ld","../helpers/assign-native-audio-node-option":"gLjOv","../helpers/assign-native-audio-node-options":"hQ1ig","../helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls":"80LCj","../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters":"eTpqG","../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters":"iy3CQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2k6Ld":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "assignNativeAudioNodeAudioParamValue", ()=>assignNativeAudioNodeAudioParamValue);
const assignNativeAudioNodeAudioParamValue = (nativeAudioNode, options, audioParam)=>{
    const value = options[audioParam];
    if (value !== undefined && value !== nativeAudioNode[audioParam].value) nativeAudioNode[audioParam].value = value;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"80LCj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioBufferSourceNodeStartMethodConsecutiveCalls", ()=>wrapAudioBufferSourceNodeStartMethodConsecutiveCalls);
var _invalidStateError = require("../factories/invalid-state-error");
const wrapAudioBufferSourceNodeStartMethodConsecutiveCalls = (nativeAudioBufferSourceNode)=>{
    nativeAudioBufferSourceNode.start = ((start)=>{
        let isScheduled = false;
        return (when = 0, offset = 0, duration)=>{
            if (isScheduled) throw (0, _invalidStateError.createInvalidStateError)();
            start.call(nativeAudioBufferSourceNode, when, offset, duration);
            isScheduled = true;
        };
    })(nativeAudioBufferSourceNode.start);
};

},{"../factories/invalid-state-error":"diSZR","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eTpqG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioScheduledSourceNodeStartMethodNegativeParameters", ()=>wrapAudioScheduledSourceNodeStartMethodNegativeParameters);
const wrapAudioScheduledSourceNodeStartMethodNegativeParameters = (nativeAudioScheduledSourceNode)=>{
    nativeAudioScheduledSourceNode.start = ((start)=>{
        return (when = 0, offset = 0, duration)=>{
            if (typeof duration === "number" && duration < 0 || offset < 0 || when < 0) throw new RangeError("The parameters can't be negative.");
            // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
            start.call(nativeAudioScheduledSourceNode, when, offset, duration);
        };
    })(nativeAudioScheduledSourceNode.start);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iy3CQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioScheduledSourceNodeStopMethodNegativeParameters", ()=>wrapAudioScheduledSourceNodeStopMethodNegativeParameters);
const wrapAudioScheduledSourceNodeStopMethodNegativeParameters = (nativeAudioScheduledSourceNode)=>{
    nativeAudioScheduledSourceNode.stop = ((stop)=>{
        return (when = 0)=>{
            if (when < 0) throw new RangeError("The parameter can't be negative.");
            stop.call(nativeAudioScheduledSourceNode, when);
        };
    })(nativeAudioScheduledSourceNode.stop);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"awJaY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioContextConstructor", ()=>createNativeAudioContextConstructor);
const createNativeAudioContextConstructor = (window)=>{
    if (window === null) return null;
    if (window.hasOwnProperty("AudioContext")) return window.AudioContext;
    return window.hasOwnProperty("webkitAudioContext") ? window.webkitAudioContext : null;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"l61vA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioDestinationNodeFactory", ()=>createNativeAudioDestinationNodeFactory);
const createNativeAudioDestinationNodeFactory = (createNativeGainNode, overwriteAccessors)=>{
    return (nativeContext, channelCount, isNodeOfNativeOfflineAudioContext)=>{
        const nativeAudioDestinationNode = nativeContext.destination;
        // Bug #132: Safari does not have the correct channelCount.
        if (nativeAudioDestinationNode.channelCount !== channelCount) try {
            nativeAudioDestinationNode.channelCount = channelCount;
        } catch  {
        // Bug #169: Safari throws an error on each attempt to change the channelCount.
        }
        // Bug #83: Safari does not have the correct channelCountMode.
        if (isNodeOfNativeOfflineAudioContext && nativeAudioDestinationNode.channelCountMode !== "explicit") nativeAudioDestinationNode.channelCountMode = "explicit";
        // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.
        if (nativeAudioDestinationNode.maxChannelCount === 0) Object.defineProperty(nativeAudioDestinationNode, "maxChannelCount", {
            value: channelCount
        });
        // Bug #168: No browser does yet have an AudioDestinationNode with an output.
        const gainNode = createNativeGainNode(nativeContext, {
            channelCount,
            channelCountMode: nativeAudioDestinationNode.channelCountMode,
            channelInterpretation: nativeAudioDestinationNode.channelInterpretation,
            gain: 1
        });
        overwriteAccessors(gainNode, "channelCount", (get)=>()=>get.call(gainNode), (set)=>(value)=>{
                set.call(gainNode, value);
                try {
                    nativeAudioDestinationNode.channelCount = value;
                } catch (err) {
                    // Bug #169: Safari throws an error on each attempt to change the channelCount.
                    if (value > nativeAudioDestinationNode.maxChannelCount) throw err;
                }
            });
        overwriteAccessors(gainNode, "channelCountMode", (get)=>()=>get.call(gainNode), (set)=>(value)=>{
                set.call(gainNode, value);
                nativeAudioDestinationNode.channelCountMode = value;
            });
        overwriteAccessors(gainNode, "channelInterpretation", (get)=>()=>get.call(gainNode), (set)=>(value)=>{
                set.call(gainNode, value);
                nativeAudioDestinationNode.channelInterpretation = value;
            });
        Object.defineProperty(gainNode, "maxChannelCount", {
            get: ()=>nativeAudioDestinationNode.maxChannelCount
        });
        // @todo This should be disconnected when the context is closed.
        gainNode.connect(nativeAudioDestinationNode);
        return gainNode;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eKntr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioWorkletNodeConstructor", ()=>createNativeAudioWorkletNodeConstructor);
const createNativeAudioWorkletNodeConstructor = (window)=>{
    if (window === null) return null;
    return window.hasOwnProperty("AudioWorkletNode") ? window.AudioWorkletNode : null;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3bxEK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioWorkletNodeFactory", ()=>createNativeAudioWorkletNodeFactory);
var _testClonabilityOfAudioWorkletNodeOptions = require("../helpers/test-clonability-of-audio-worklet-node-options");
const createNativeAudioWorkletNodeFactory = (createInvalidStateError, createNativeAudioWorkletNodeFaker, createNativeGainNode, createNotSupportedError, monitorConnections)=>{
    return (nativeContext, baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, options)=>{
        if (nativeAudioWorkletNodeConstructor !== null) try {
            const nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeContext, name, options);
            const patchedEventListeners = new Map();
            let onprocessorerror = null;
            Object.defineProperties(nativeAudioWorkletNode, {
                /*
                     * Bug #61: Overwriting the property accessors for channelCount and channelCountMode is necessary as long as some
                     * browsers have no native implementation to achieve a consistent behavior.
                     */ channelCount: {
                    get: ()=>options.channelCount,
                    set: ()=>{
                        throw createInvalidStateError();
                    }
                },
                channelCountMode: {
                    get: ()=>"explicit",
                    set: ()=>{
                        throw createInvalidStateError();
                    }
                },
                // Bug #156: Chrome and Edge do not yet fire an ErrorEvent.
                onprocessorerror: {
                    get: ()=>onprocessorerror,
                    set: (value)=>{
                        if (typeof onprocessorerror === "function") nativeAudioWorkletNode.removeEventListener("processorerror", onprocessorerror);
                        onprocessorerror = typeof value === "function" ? value : null;
                        if (typeof onprocessorerror === "function") nativeAudioWorkletNode.addEventListener("processorerror", onprocessorerror);
                    }
                }
            });
            nativeAudioWorkletNode.addEventListener = ((addEventListener)=>{
                return (...args)=>{
                    if (args[0] === "processorerror") {
                        const unpatchedEventListener = typeof args[1] === "function" ? args[1] : typeof args[1] === "object" && args[1] !== null && typeof args[1].handleEvent === "function" ? args[1].handleEvent : null;
                        if (unpatchedEventListener !== null) {
                            const patchedEventListener = patchedEventListeners.get(args[1]);
                            if (patchedEventListener !== undefined) args[1] = patchedEventListener;
                            else {
                                args[1] = (event)=>{
                                    // Bug #178: Chrome and Edge do fire an event of type error.
                                    if (event.type === "error") {
                                        Object.defineProperties(event, {
                                            type: {
                                                value: "processorerror"
                                            }
                                        });
                                        unpatchedEventListener(event);
                                    } else unpatchedEventListener(new ErrorEvent(args[0], {
                                        ...event
                                    }));
                                };
                                patchedEventListeners.set(unpatchedEventListener, args[1]);
                            }
                        }
                    }
                    // Bug #178: Chrome and Edge do fire an event of type error.
                    addEventListener.call(nativeAudioWorkletNode, "error", args[1], args[2]);
                    return addEventListener.call(nativeAudioWorkletNode, ...args);
                };
            })(nativeAudioWorkletNode.addEventListener);
            nativeAudioWorkletNode.removeEventListener = ((removeEventListener)=>{
                return (...args)=>{
                    if (args[0] === "processorerror") {
                        const patchedEventListener = patchedEventListeners.get(args[1]);
                        if (patchedEventListener !== undefined) {
                            patchedEventListeners.delete(args[1]);
                            args[1] = patchedEventListener;
                        }
                    }
                    // Bug #178: Chrome and Edge do fire an event of type error.
                    removeEventListener.call(nativeAudioWorkletNode, "error", args[1], args[2]);
                    return removeEventListener.call(nativeAudioWorkletNode, args[0], args[1], args[2]);
                };
            })(nativeAudioWorkletNode.removeEventListener);
            /*
                 * Bug #86: Chrome and Edge do not invoke the process() function if the corresponding AudioWorkletNode is unconnected but
                 * has an output.
                 */ if (options.numberOfOutputs !== 0) {
                const nativeGainNode = createNativeGainNode(nativeContext, {
                    channelCount: 1,
                    channelCountMode: "explicit",
                    channelInterpretation: "discrete",
                    gain: 0
                });
                nativeAudioWorkletNode.connect(nativeGainNode).connect(nativeContext.destination);
                const whenConnected = ()=>nativeGainNode.disconnect();
                const whenDisconnected = ()=>nativeGainNode.connect(nativeContext.destination);
                // @todo Disconnect the connection when the process() function of the AudioWorkletNode returns false.
                return monitorConnections(nativeAudioWorkletNode, whenConnected, whenDisconnected);
            }
            return nativeAudioWorkletNode;
        } catch (err) {
            // Bug #60: Chrome & Edge throw an InvalidStateError instead of a NotSupportedError.
            if (err.code === 11) throw createNotSupportedError();
            throw err;
        }
        // Bug #61: Only Chrome & Edge have an implementation of the AudioWorkletNode yet.
        if (processorConstructor === undefined) throw createNotSupportedError();
        (0, _testClonabilityOfAudioWorkletNodeOptions.testClonabilityOfAudioWorkletNodeOptions)(options);
        return createNativeAudioWorkletNodeFaker(nativeContext, baseLatency, processorConstructor, options);
    };
};

},{"../helpers/test-clonability-of-audio-worklet-node-options":"6QBSP","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6QBSP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testClonabilityOfAudioWorkletNodeOptions", ()=>testClonabilityOfAudioWorkletNodeOptions);
const testClonabilityOfAudioWorkletNodeOptions = (audioWorkletNodeOptions)=>{
    const { port1 } = new MessageChannel();
    try {
        // This will throw an error if the audioWorkletNodeOptions are not clonable.
        port1.postMessage(audioWorkletNodeOptions);
    } finally{
        port1.close();
    }
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8dSFA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioWorkletNodeFakerFactory", ()=>createNativeAudioWorkletNodeFakerFactory);
var _constants = require("../constants");
var _computeBufferSize = require("../helpers/compute-buffer-size");
var _copyFromChannel = require("../helpers/copy-from-channel");
var _copyToChannel = require("../helpers/copy-to-channel");
var _createAudioWorkletProcessor = require("../helpers/create-audio-worklet-processor");
var _createNestedArrays = require("../helpers/create-nested-arrays");
var _readOnlyMap = require("../read-only-map");
const createNativeAudioWorkletNodeFakerFactory = (connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNativeScriptProcessorNode, createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections)=>{
    return (nativeContext, baseLatency, processorConstructor, options)=>{
        if (options.numberOfInputs === 0 && options.numberOfOutputs === 0) throw createNotSupportedError();
        const outputChannelCount = Array.isArray(options.outputChannelCount) ? options.outputChannelCount : Array.from(options.outputChannelCount);
        // @todo Check if any of the channelCount values is greater than the implementation's maximum number of channels.
        if (outputChannelCount.some((channelCount)=>channelCount < 1)) throw createNotSupportedError();
        if (outputChannelCount.length !== options.numberOfOutputs) throw createIndexSizeError();
        // Bug #61: This is not part of the standard but required for the faker to work.
        if (options.channelCountMode !== "explicit") throw createNotSupportedError();
        const numberOfInputChannels = options.channelCount * options.numberOfInputs;
        const numberOfOutputChannels = outputChannelCount.reduce((sum, value1)=>sum + value1, 0);
        const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;
        // Bug #61: This is not part of the standard but required for the faker to work.
        if (numberOfInputChannels + numberOfParameters > 6 || numberOfOutputChannels > 6) throw createNotSupportedError();
        const messageChannel = new MessageChannel();
        const gainNodes = [];
        const inputChannelSplitterNodes = [];
        for(let i = 0; i < options.numberOfInputs; i += 1){
            gainNodes.push(createNativeGainNode(nativeContext, {
                channelCount: options.channelCount,
                channelCountMode: options.channelCountMode,
                channelInterpretation: options.channelInterpretation,
                gain: 1
            }));
            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(nativeContext, {
                channelCount: options.channelCount,
                channelCountMode: "explicit",
                channelInterpretation: "discrete",
                numberOfOutputs: options.channelCount
            }));
        }
        const constantSourceNodes = [];
        if (processorConstructor.parameterDescriptors !== undefined) for (const { defaultValue, maxValue, minValue, name } of processorConstructor.parameterDescriptors){
            const constantSourceNode = createNativeConstantSourceNode(nativeContext, {
                channelCount: 1,
                channelCountMode: "explicit",
                channelInterpretation: "discrete",
                offset: options.parameterData[name] !== undefined ? options.parameterData[name] : defaultValue === undefined ? 0 : defaultValue
            });
            Object.defineProperties(constantSourceNode.offset, {
                defaultValue: {
                    get: ()=>defaultValue === undefined ? 0 : defaultValue
                },
                maxValue: {
                    get: ()=>maxValue === undefined ? (0, _constants.MOST_POSITIVE_SINGLE_FLOAT) : maxValue
                },
                minValue: {
                    get: ()=>minValue === undefined ? (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT) : minValue
                }
            });
            constantSourceNodes.push(constantSourceNode);
        }
        const inputChannelMergerNode = createNativeChannelMergerNode(nativeContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "speakers",
            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)
        });
        const bufferSize = (0, _computeBufferSize.computeBufferSize)(baseLatency, nativeContext.sampleRate);
        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, numberOfInputChannels + numberOfParameters, // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.
        Math.max(1, numberOfOutputChannels));
        const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, {
            channelCount: Math.max(1, numberOfOutputChannels),
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            numberOfOutputs: Math.max(1, numberOfOutputChannels)
        });
        const outputChannelMergerNodes = [];
        for(let i = 0; i < options.numberOfOutputs; i += 1)outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "speakers",
            numberOfInputs: outputChannelCount[i]
        }));
        for(let i = 0; i < options.numberOfInputs; i += 1){
            gainNodes[i].connect(inputChannelSplitterNodes[i]);
            for(let j = 0; j < options.channelCount; j += 1)inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, i * options.channelCount + j);
        }
        const parameterMap = new (0, _readOnlyMap.ReadOnlyMap)(processorConstructor.parameterDescriptors === undefined ? [] : processorConstructor.parameterDescriptors.map(({ name }, index)=>{
            const constantSourceNode = constantSourceNodes[index];
            constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);
            constantSourceNode.start(0);
            return [
                name,
                constantSourceNode.offset
            ];
        }));
        inputChannelMergerNode.connect(scriptProcessorNode);
        let channelInterpretation = options.channelInterpretation;
        let onprocessorerror = null;
        // Bug #87: Expose at least one output to make this node connectable.
        const outputAudioNodes = options.numberOfOutputs === 0 ? [
            scriptProcessorNode
        ] : outputChannelMergerNodes;
        const nativeAudioWorkletNodeFaker = {
            get bufferSize () {
                return bufferSize;
            },
            get channelCount () {
                return options.channelCount;
            },
            set channelCount (_){
                // Bug #61: This is not part of the standard but required for the faker to work.
                throw createInvalidStateError();
            },
            get channelCountMode () {
                return options.channelCountMode;
            },
            set channelCountMode (_){
                // Bug #61: This is not part of the standard but required for the faker to work.
                throw createInvalidStateError();
            },
            get channelInterpretation () {
                return channelInterpretation;
            },
            set channelInterpretation (value){
                for (const gainNode of gainNodes)gainNode.channelInterpretation = value;
                channelInterpretation = value;
            },
            get context () {
                return scriptProcessorNode.context;
            },
            get inputs () {
                return gainNodes;
            },
            get numberOfInputs () {
                return options.numberOfInputs;
            },
            get numberOfOutputs () {
                return options.numberOfOutputs;
            },
            get onprocessorerror () {
                return onprocessorerror;
            },
            set onprocessorerror (value){
                if (typeof onprocessorerror === "function") nativeAudioWorkletNodeFaker.removeEventListener("processorerror", onprocessorerror);
                onprocessorerror = typeof value === "function" ? value : null;
                if (typeof onprocessorerror === "function") nativeAudioWorkletNodeFaker.addEventListener("processorerror", onprocessorerror);
            },
            get parameters () {
                return parameterMap;
            },
            get port () {
                return messageChannel.port2;
            },
            addEventListener (...args) {
                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);
            },
            connect: connectMultipleOutputs.bind(null, outputAudioNodes),
            disconnect: disconnectMultipleOutputs.bind(null, outputAudioNodes),
            dispatchEvent (...args) {
                return scriptProcessorNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        const patchedEventListeners = new Map();
        messageChannel.port1.addEventListener = ((addEventListener)=>{
            return (...args)=>{
                if (args[0] === "message") {
                    const unpatchedEventListener = typeof args[1] === "function" ? args[1] : typeof args[1] === "object" && args[1] !== null && typeof args[1].handleEvent === "function" ? args[1].handleEvent : null;
                    if (unpatchedEventListener !== null) {
                        const patchedEventListener = patchedEventListeners.get(args[1]);
                        if (patchedEventListener !== undefined) args[1] = patchedEventListener;
                        else {
                            args[1] = (event)=>{
                                exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, ()=>unpatchedEventListener(event));
                            };
                            patchedEventListeners.set(unpatchedEventListener, args[1]);
                        }
                    }
                }
                return addEventListener.call(messageChannel.port1, args[0], args[1], args[2]);
            };
        })(messageChannel.port1.addEventListener);
        messageChannel.port1.removeEventListener = ((removeEventListener)=>{
            return (...args)=>{
                if (args[0] === "message") {
                    const patchedEventListener = patchedEventListeners.get(args[1]);
                    if (patchedEventListener !== undefined) {
                        patchedEventListeners.delete(args[1]);
                        args[1] = patchedEventListener;
                    }
                }
                return removeEventListener.call(messageChannel.port1, args[0], args[1], args[2]);
            };
        })(messageChannel.port1.removeEventListener);
        let onmessage = null;
        Object.defineProperty(messageChannel.port1, "onmessage", {
            get: ()=>onmessage,
            set: (value1)=>{
                if (typeof onmessage === "function") messageChannel.port1.removeEventListener("message", onmessage);
                onmessage = typeof value1 === "function" ? value1 : null;
                if (typeof onmessage === "function") {
                    messageChannel.port1.addEventListener("message", onmessage);
                    messageChannel.port1.start();
                }
            }
        });
        processorConstructor.prototype.port = messageChannel.port1;
        let audioWorkletProcessor = null;
        const audioWorkletProcessorPromise = (0, _createAudioWorkletProcessor.createAudioWorkletProcessor)(nativeContext, nativeAudioWorkletNodeFaker, processorConstructor, options);
        audioWorkletProcessorPromise.then((dWrkltPrcssr)=>audioWorkletProcessor = dWrkltPrcssr);
        const inputs = (0, _createNestedArrays.createNestedArrays)(options.numberOfInputs, options.channelCount);
        const outputs = (0, _createNestedArrays.createNestedArrays)(options.numberOfOutputs, outputChannelCount);
        const parameters = processorConstructor.parameterDescriptors === undefined ? [] : processorConstructor.parameterDescriptors.reduce((prmtrs, { name })=>({
                ...prmtrs,
                [name]: new Float32Array(128)
            }), {});
        let isActive = true;
        const disconnectOutputsGraph = ()=>{
            if (options.numberOfOutputs > 0) scriptProcessorNode.disconnect(outputChannelSplitterNode);
            for(let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1){
                const outputChannelMergerNode = outputChannelMergerNodes[i];
                for(let j = 0; j < outputChannelCount[i]; j += 1)outputChannelSplitterNode.disconnect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                outputChannelSplitterNodeOutput += outputChannelCount[i];
            }
        };
        const activeInputIndexes = new Map();
        // tslint:disable-next-line:deprecation
        scriptProcessorNode.onaudioprocess = ({ inputBuffer, outputBuffer })=>{
            if (audioWorkletProcessor !== null) {
                const activeInputs = getActiveAudioWorkletNodeInputs(nativeAudioWorkletNodeFaker);
                for(let i = 0; i < bufferSize; i += 128){
                    for(let j = 0; j < options.numberOfInputs; j += 1)for(let k = 0; k < options.channelCount; k += 1)(0, _copyFromChannel.copyFromChannel)(inputBuffer, inputs[j], k, k, i);
                    if (processorConstructor.parameterDescriptors !== undefined) processorConstructor.parameterDescriptors.forEach(({ name }, index)=>{
                        (0, _copyFromChannel.copyFromChannel)(inputBuffer, parameters, name, numberOfInputChannels + index, i);
                    });
                    for(let j = 0; j < options.numberOfInputs; j += 1){
                        for(let k = 0; k < outputChannelCount[j]; k += 1)// The byteLength will be 0 when the ArrayBuffer was transferred.
                        if (outputs[j][k].byteLength === 0) outputs[j][k] = new Float32Array(128);
                    }
                    try {
                        const potentiallyEmptyInputs = inputs.map((input, index)=>{
                            const activeInput = activeInputs[index];
                            if (activeInput.size > 0) {
                                activeInputIndexes.set(index, bufferSize / 128);
                                return input;
                            }
                            const count = activeInputIndexes.get(index);
                            if (count === undefined) return [];
                            if (input.every((channelData)=>channelData.every((sample)=>sample === 0))) {
                                if (count === 1) activeInputIndexes.delete(index);
                                else activeInputIndexes.set(index, count - 1);
                            }
                            return input;
                        });
                        const activeSourceFlag = exposeCurrentFrameAndCurrentTime(nativeContext.currentTime + i / nativeContext.sampleRate, nativeContext.sampleRate, ()=>audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));
                        isActive = activeSourceFlag;
                        for(let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1){
                            for(let k = 0; k < outputChannelCount[j]; k += 1)(0, _copyToChannel.copyToChannel)(outputBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);
                            outputChannelSplitterNodeOutput += outputChannelCount[j];
                        }
                    } catch (error) {
                        isActive = false;
                        nativeAudioWorkletNodeFaker.dispatchEvent(new ErrorEvent("processorerror", {
                            colno: error.colno,
                            filename: error.filename,
                            lineno: error.lineno,
                            message: error.message
                        }));
                    }
                    if (!isActive) {
                        for(let j = 0; j < options.numberOfInputs; j += 1){
                            gainNodes[j].disconnect(inputChannelSplitterNodes[j]);
                            for(let k = 0; k < options.channelCount; k += 1)inputChannelSplitterNodes[i].disconnect(inputChannelMergerNode, k, j * options.channelCount + k);
                        }
                        if (processorConstructor.parameterDescriptors !== undefined) {
                            const length = processorConstructor.parameterDescriptors.length;
                            for(let j = 0; j < length; j += 1){
                                const constantSourceNode = constantSourceNodes[j];
                                constantSourceNode.disconnect(inputChannelMergerNode, 0, numberOfInputChannels + j);
                                constantSourceNode.stop();
                            }
                        }
                        inputChannelMergerNode.disconnect(scriptProcessorNode);
                        scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation
                        if (isConnected) disconnectOutputsGraph();
                        else disconnectFakeGraph();
                        break;
                    }
                }
            }
        };
        let isConnected = false;
        // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.
        const nativeGainNode = createNativeGainNode(nativeContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            gain: 0
        });
        const connectFakeGraph = ()=>scriptProcessorNode.connect(nativeGainNode).connect(nativeContext.destination);
        const disconnectFakeGraph = ()=>{
            scriptProcessorNode.disconnect(nativeGainNode);
            nativeGainNode.disconnect();
        };
        const whenConnected = ()=>{
            if (isActive) {
                disconnectFakeGraph();
                if (options.numberOfOutputs > 0) scriptProcessorNode.connect(outputChannelSplitterNode);
                for(let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1){
                    const outputChannelMergerNode = outputChannelMergerNodes[i];
                    for(let j = 0; j < outputChannelCount[i]; j += 1)outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                    outputChannelSplitterNodeOutput += outputChannelCount[i];
                }
            }
            isConnected = true;
        };
        const whenDisconnected = ()=>{
            if (isActive) {
                connectFakeGraph();
                disconnectOutputsGraph();
            }
            isConnected = false;
        };
        connectFakeGraph();
        return monitorConnections(nativeAudioWorkletNodeFaker, whenConnected, whenDisconnected);
    };
};

},{"../constants":"au584","../helpers/compute-buffer-size":"bimg2","../helpers/copy-from-channel":"7bLp3","../helpers/copy-to-channel":"eA0D4","../helpers/create-audio-worklet-processor":"2k17r","../helpers/create-nested-arrays":"jcLoC","../read-only-map":"3UYbJ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bimg2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "computeBufferSize", ()=>computeBufferSize);
const computeBufferSize = (baseLatency, sampleRate)=>{
    if (baseLatency === null) return 512;
    return Math.max(512, Math.min(16384, Math.pow(2, Math.round(Math.log2(baseLatency * sampleRate)))));
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2k17r":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioWorkletProcessor", ()=>createAudioWorkletProcessor);
var _globals = require("../globals");
var _createAudioWorkletProcessorPromise = require("./create-audio-worklet-processor-promise");
const createAudioWorkletProcessor = (nativeContext, nativeAudioWorkletNode, processorConstructor, audioWorkletNodeOptions)=>{
    let nodeToProcessorMap = (0, _globals.NODE_TO_PROCESSOR_MAPS).get(nativeContext);
    if (nodeToProcessorMap === undefined) {
        nodeToProcessorMap = new WeakMap();
        (0, _globals.NODE_TO_PROCESSOR_MAPS).set(nativeContext, nodeToProcessorMap);
    }
    const audioWorkletProcessorPromise = (0, _createAudioWorkletProcessorPromise.createAudioWorkletProcessorPromise)(processorConstructor, audioWorkletNodeOptions);
    nodeToProcessorMap.set(nativeAudioWorkletNode, audioWorkletProcessorPromise);
    return audioWorkletProcessorPromise;
};

},{"../globals":"j1ar4","./create-audio-worklet-processor-promise":"1r4lx","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1r4lx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioWorkletProcessorPromise", ()=>createAudioWorkletProcessorPromise);
var _cloneAudioWorkletNodeOptions = require("./clone-audio-worklet-node-options");
const createAudioWorkletProcessorPromise = async (processorConstructor, audioWorkletNodeOptions)=>{
    const clonedAudioWorkletNodeOptions = await (0, _cloneAudioWorkletNodeOptions.cloneAudioWorkletNodeOptions)(audioWorkletNodeOptions);
    return new processorConstructor(clonedAudioWorkletNodeOptions);
};

},{"./clone-audio-worklet-node-options":"k1u1R","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k1u1R":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "cloneAudioWorkletNodeOptions", ()=>cloneAudioWorkletNodeOptions);
const cloneAudioWorkletNodeOptions = (audioWorkletNodeOptions)=>{
    return new Promise((resolve, reject)=>{
        const { port1, port2 } = new MessageChannel();
        port1.onmessage = ({ data })=>{
            port1.close();
            port2.close();
            resolve(data);
        };
        port1.onmessageerror = ({ data })=>{
            port1.close();
            port2.close();
            reject(data);
        };
        // This will throw an error if the audioWorkletNodeOptions are not clonable.
        port2.postMessage(audioWorkletNodeOptions);
    });
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"Apyjl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeBiquadFilterNode", ()=>createNativeBiquadFilterNode);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeBiquadFilterNode = (nativeContext, options)=>{
    const nativeBiquadFilterNode = nativeContext.createBiquadFilter();
    (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeBiquadFilterNode, options);
    (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, "Q");
    (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, "detune");
    (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, "frequency");
    (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, "gain");
    (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeBiquadFilterNode, options, "type");
    return nativeBiquadFilterNode;
};

},{"../helpers/assign-native-audio-node-audio-param-value":"2k6Ld","../helpers/assign-native-audio-node-option":"gLjOv","../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"90fMG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeChannelMergerNodeFactory", ()=>createNativeChannelMergerNodeFactory);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeChannelMergerNodeFactory = (nativeAudioContextConstructor, wrapChannelMergerNode)=>{
    return (nativeContext, options)=>{
        const nativeChannelMergerNode = nativeContext.createChannelMerger(options.numberOfInputs);
        /*
         * Bug #20: Safari requires a connection of any kind to treat the input signal correctly.
         * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of
         * the webkitAudioContext is used as a workaround here.
         */ if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === "webkitAudioContext") wrapChannelMergerNode(nativeContext, nativeChannelMergerNode);
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeChannelMergerNode, options);
        return nativeChannelMergerNode;
    };
};

},{"../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8Z3X6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeChannelSplitterNode", ()=>createNativeChannelSplitterNode);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _wrapChannelSplitterNode = require("../helpers/wrap-channel-splitter-node");
const createNativeChannelSplitterNode = (nativeContext, options)=>{
    const nativeChannelSplitterNode = nativeContext.createChannelSplitter(options.numberOfOutputs);
    // Bug #96: Safari does not have the correct channelCount.
    // Bug #29: Safari does not have the correct channelCountMode.
    // Bug #31: Safari does not have the correct channelInterpretation.
    (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeChannelSplitterNode, options);
    // Bug #29, #30, #31, #32, #96 & #97: Only Chrome, Edge & Firefox partially support the spec yet.
    (0, _wrapChannelSplitterNode.wrapChannelSplitterNode)(nativeChannelSplitterNode);
    return nativeChannelSplitterNode;
};

},{"../helpers/assign-native-audio-node-options":"hQ1ig","../helpers/wrap-channel-splitter-node":"nuf83","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"nuf83":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapChannelSplitterNode", ()=>wrapChannelSplitterNode);
var _invalidStateError = require("../factories/invalid-state-error");
const wrapChannelSplitterNode = (channelSplitterNode)=>{
    const channelCount = channelSplitterNode.numberOfOutputs;
    // Bug #97: Safari does not throw an error when attempting to change the channelCount to something other than its initial value.
    Object.defineProperty(channelSplitterNode, "channelCount", {
        get: ()=>channelCount,
        set: (value)=>{
            if (value !== channelCount) throw (0, _invalidStateError.createInvalidStateError)();
        }
    });
    // Bug #30: Safari does not throw an error when attempting to change the channelCountMode to something other than explicit.
    Object.defineProperty(channelSplitterNode, "channelCountMode", {
        get: ()=>"explicit",
        set: (value)=>{
            if (value !== "explicit") throw (0, _invalidStateError.createInvalidStateError)();
        }
    });
    // Bug #32: Safari does not throw an error when attempting to change the channelInterpretation to something other than discrete.
    Object.defineProperty(channelSplitterNode, "channelInterpretation", {
        get: ()=>"discrete",
        set: (value)=>{
            if (value !== "discrete") throw (0, _invalidStateError.createInvalidStateError)();
        }
    });
};

},{"../factories/invalid-state-error":"diSZR","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aZ9aQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeConstantSourceNodeFactory", ()=>createNativeConstantSourceNodeFactory);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _wrapAudioScheduledSourceNodeStartMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters");
var _wrapAudioScheduledSourceNodeStopMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters");
const createNativeConstantSourceNodeFactory = (addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport)=>{
    return (nativeContext, options)=>{
        // Bug #62: Safari does not support ConstantSourceNodes.
        if (nativeContext.createConstantSource === undefined) return createNativeConstantSourceNodeFaker(nativeContext, options);
        const nativeConstantSourceNode = nativeContext.createConstantSource();
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeConstantSourceNode, options);
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeConstantSourceNode, options, "offset");
        // Bug #44: Safari does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) (0, _wrapAudioScheduledSourceNodeStartMethodNegativeParameters.wrapAudioScheduledSourceNodeStartMethodNegativeParameters)(nativeConstantSourceNode);
        // Bug #44: Only Firefox does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) (0, _wrapAudioScheduledSourceNodeStopMethodNegativeParameters.wrapAudioScheduledSourceNodeStopMethodNegativeParameters)(nativeConstantSourceNode);
        // Bug #175: Safari will not fire an ended event if the ConstantSourceNode is unconnected.
        addSilentConnection(nativeContext, nativeConstantSourceNode);
        return nativeConstantSourceNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"2k6Ld","../helpers/assign-native-audio-node-options":"hQ1ig","../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters":"eTpqG","../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters":"iy3CQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"Jx9uB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeConstantSourceNodeFakerFactory", ()=>createNativeConstantSourceNodeFakerFactory);
var _interceptConnections = require("../helpers/intercept-connections");
const createNativeConstantSourceNodeFakerFactory = (addSilentConnection, createNativeAudioBufferSourceNode, createNativeGainNode, monitorConnections)=>{
    return (nativeContext, { offset, ...audioNodeOptions })=>{
        const audioBuffer = nativeContext.createBuffer(1, 2, 44100);
        const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {
            buffer: null,
            channelCount: 2,
            channelCountMode: "max",
            channelInterpretation: "speakers",
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            playbackRate: 1
        });
        const gainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: offset
        });
        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
        const channelData = audioBuffer.getChannelData(0);
        // Bug #95: Safari does not play or loop one sample buffers.
        channelData[0] = 1;
        channelData[1] = 1;
        audioBufferSourceNode.buffer = audioBuffer;
        audioBufferSourceNode.loop = true;
        const nativeConstantSourceNodeFaker = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return gainNode.channelCount;
            },
            set channelCount (value){
                gainNode.channelCount = value;
            },
            get channelCountMode () {
                return gainNode.channelCountMode;
            },
            set channelCountMode (value){
                gainNode.channelCountMode = value;
            },
            get channelInterpretation () {
                return gainNode.channelInterpretation;
            },
            set channelInterpretation (value){
                gainNode.channelInterpretation = value;
            },
            get context () {
                return gainNode.context;
            },
            get inputs () {
                return [];
            },
            get numberOfInputs () {
                return audioBufferSourceNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return gainNode.numberOfOutputs;
            },
            get offset () {
                return gainNode.gain;
            },
            get onended () {
                return audioBufferSourceNode.onended;
            },
            set onended (value){
                audioBufferSourceNode.onended = value;
            },
            addEventListener (...args) {
                return audioBufferSourceNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return audioBufferSourceNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return audioBufferSourceNode.removeEventListener(args[0], args[1], args[2]);
            },
            start (when = 0) {
                audioBufferSourceNode.start.call(audioBufferSourceNode, when);
            },
            stop (when = 0) {
                audioBufferSourceNode.stop.call(audioBufferSourceNode, when);
            }
        };
        const whenConnected = ()=>audioBufferSourceNode.connect(gainNode);
        const whenDisconnected = ()=>audioBufferSourceNode.disconnect(gainNode);
        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.
        addSilentConnection(nativeContext, audioBufferSourceNode);
        return monitorConnections((0, _interceptConnections.interceptConnections)(nativeConstantSourceNodeFaker, gainNode), whenConnected, whenDisconnected);
    };
};

},{"../helpers/intercept-connections":"jvEjr","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jvEjr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "interceptConnections", ()=>interceptConnections);
const interceptConnections = (original, interceptor)=>{
    original.connect = interceptor.connect.bind(interceptor);
    original.disconnect = interceptor.disconnect.bind(interceptor);
    return original;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1os2P":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeConvolverNodeFactory", ()=>createNativeConvolverNodeFactory);
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeConvolverNodeFactory = (createNotSupportedError, overwriteAccessors)=>{
    return (nativeContext, options)=>{
        const nativeConvolverNode = nativeContext.createConvolver();
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeConvolverNode, options);
        // The normalize property needs to be set before setting the buffer.
        if (options.disableNormalization === nativeConvolverNode.normalize) nativeConvolverNode.normalize = !options.disableNormalization;
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeConvolverNode, options, "buffer");
        // Bug #113: Safari does allow to set the channelCount to a value larger than 2.
        if (options.channelCount > 2) throw createNotSupportedError();
        overwriteAccessors(nativeConvolverNode, "channelCount", (get)=>()=>get.call(nativeConvolverNode), (set)=>(value)=>{
                if (value > 2) throw createNotSupportedError();
                return set.call(nativeConvolverNode, value);
            });
        // Bug #114: Safari allows to set the channelCountMode to 'max'.
        if (options.channelCountMode === "max") throw createNotSupportedError();
        overwriteAccessors(nativeConvolverNode, "channelCountMode", (get)=>()=>get.call(nativeConvolverNode), (set)=>(value)=>{
                if (value === "max") throw createNotSupportedError();
                return set.call(nativeConvolverNode, value);
            });
        return nativeConvolverNode;
    };
};

},{"../helpers/assign-native-audio-node-option":"gLjOv","../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"76TcR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeDelayNode", ()=>createNativeDelayNode);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeDelayNode = (nativeContext, options)=>{
    const nativeDelayNode = nativeContext.createDelay(options.maxDelayTime);
    (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeDelayNode, options);
    (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeDelayNode, options, "delayTime");
    return nativeDelayNode;
};

},{"../helpers/assign-native-audio-node-audio-param-value":"2k6Ld","../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"63iaU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeDynamicsCompressorNodeFactory", ()=>createNativeDynamicsCompressorNodeFactory);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeDynamicsCompressorNodeFactory = (createNotSupportedError)=>{
    return (nativeContext, options)=>{
        const nativeDynamicsCompressorNode = nativeContext.createDynamicsCompressor();
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeDynamicsCompressorNode, options);
        // Bug #108: Safari allows a channelCount of three and above.
        if (options.channelCount > 2) throw createNotSupportedError();
        // Bug #109: Only Chrome and Firefox disallow a channelCountMode of 'max'.
        if (options.channelCountMode === "max") throw createNotSupportedError();
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, "attack");
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, "knee");
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, "ratio");
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, "release");
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, "threshold");
        return nativeDynamicsCompressorNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"2k6Ld","../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k23ba":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeGainNode", ()=>createNativeGainNode);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeGainNode = (nativeContext, options)=>{
    const nativeGainNode = nativeContext.createGain();
    (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeGainNode, options);
    (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeGainNode, options, "gain");
    return nativeGainNode;
};

},{"../helpers/assign-native-audio-node-audio-param-value":"2k6Ld","../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kpXKu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeIIRFilterNodeFactory", ()=>createNativeIIRFilterNodeFactory);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeIIRFilterNodeFactory = (createNativeIIRFilterNodeFaker)=>{
    return (nativeContext, baseLatency, options)=>{
        // Bug #9: Safari does not support IIRFilterNodes.
        if (nativeContext.createIIRFilter === undefined) return createNativeIIRFilterNodeFaker(nativeContext, baseLatency, options);
        // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.
        const nativeIIRFilterNode = nativeContext.createIIRFilter(options.feedforward, options.feedback);
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeIIRFilterNode, options);
        return nativeIIRFilterNode;
    };
};

},{"../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3kywH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeIIRFilterNodeFakerFactory", ()=>createNativeIIRFilterNodeFakerFactory);
var _computeBufferSize = require("../helpers/compute-buffer-size");
var _filterBuffer = require("../helpers/filter-buffer");
var _interceptConnections = require("../helpers/intercept-connections");
function divide(a, b) {
    const denominator = b[0] * b[0] + b[1] * b[1];
    return [
        (a[0] * b[0] + a[1] * b[1]) / denominator,
        (a[1] * b[0] - a[0] * b[1]) / denominator
    ];
}
function multiply(a, b) {
    return [
        a[0] * b[0] - a[1] * b[1],
        a[0] * b[1] + a[1] * b[0]
    ];
}
function evaluatePolynomial(coefficient, z) {
    let result = [
        0,
        0
    ];
    for(let i = coefficient.length - 1; i >= 0; i -= 1){
        result = multiply(result, z);
        result[0] += coefficient[i];
    }
    return result;
}
const createNativeIIRFilterNodeFakerFactory = (createInvalidAccessError, createInvalidStateError, createNativeScriptProcessorNode, createNotSupportedError)=>{
    return (nativeContext, baseLatency, { channelCount, channelCountMode, channelInterpretation, feedback, feedforward })=>{
        const bufferSize = (0, _computeBufferSize.computeBufferSize)(baseLatency, nativeContext.sampleRate);
        const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);
        const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);
        const feedbackLength = convertedFeedback.length;
        const feedforwardLength = convertedFeedforward.length;
        const minLength = Math.min(feedbackLength, feedforwardLength);
        if (feedbackLength === 0 || feedbackLength > 20) throw createNotSupportedError();
        if (convertedFeedback[0] === 0) throw createInvalidStateError();
        if (feedforwardLength === 0 || feedforwardLength > 20) throw createNotSupportedError();
        if (convertedFeedforward[0] === 0) throw createInvalidStateError();
        if (convertedFeedback[0] !== 1) {
            for(let i = 0; i < feedforwardLength; i += 1)convertedFeedforward[i] /= convertedFeedback[0];
            for(let i = 1; i < feedbackLength; i += 1)convertedFeedback[i] /= convertedFeedback[0];
        }
        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, channelCount, channelCount);
        scriptProcessorNode.channelCount = channelCount;
        scriptProcessorNode.channelCountMode = channelCountMode;
        scriptProcessorNode.channelInterpretation = channelInterpretation;
        const bufferLength = 32;
        const bufferIndexes = [];
        const xBuffers = [];
        const yBuffers = [];
        for(let i = 0; i < channelCount; i += 1){
            bufferIndexes.push(0);
            const xBuffer = new Float32Array(bufferLength);
            const yBuffer = new Float32Array(bufferLength);
            xBuffer.fill(0);
            yBuffer.fill(0);
            xBuffers.push(xBuffer);
            yBuffers.push(yBuffer);
        }
        // tslint:disable-next-line:deprecation
        scriptProcessorNode.onaudioprocess = (event)=>{
            const inputBuffer = event.inputBuffer;
            const outputBuffer = event.outputBuffer;
            const numberOfChannels = inputBuffer.numberOfChannels;
            for(let i = 0; i < numberOfChannels; i += 1){
                const input = inputBuffer.getChannelData(i);
                const output = outputBuffer.getChannelData(i);
                bufferIndexes[i] = (0, _filterBuffer.filterBuffer)(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffers[i], yBuffers[i], bufferIndexes[i], bufferLength, input, output);
            }
        };
        const nyquist = nativeContext.sampleRate / 2;
        const nativeIIRFilterNodeFaker = {
            get bufferSize () {
                return bufferSize;
            },
            get channelCount () {
                return scriptProcessorNode.channelCount;
            },
            set channelCount (value){
                scriptProcessorNode.channelCount = value;
            },
            get channelCountMode () {
                return scriptProcessorNode.channelCountMode;
            },
            set channelCountMode (value){
                scriptProcessorNode.channelCountMode = value;
            },
            get channelInterpretation () {
                return scriptProcessorNode.channelInterpretation;
            },
            set channelInterpretation (value){
                scriptProcessorNode.channelInterpretation = value;
            },
            get context () {
                return scriptProcessorNode.context;
            },
            get inputs () {
                return [
                    scriptProcessorNode
                ];
            },
            get numberOfInputs () {
                return scriptProcessorNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return scriptProcessorNode.numberOfOutputs;
            },
            addEventListener (...args) {
                // @todo Dissallow adding an audioprocess listener.
                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return scriptProcessorNode.dispatchEvent(args[0]);
            },
            getFrequencyResponse (frequencyHz, magResponse, phaseResponse) {
                if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) throw createInvalidAccessError();
                const length = frequencyHz.length;
                for(let i = 0; i < length; i += 1){
                    const omega = -Math.PI * (frequencyHz[i] / nyquist);
                    const z = [
                        Math.cos(omega),
                        Math.sin(omega)
                    ];
                    const numerator = evaluatePolynomial(convertedFeedforward, z);
                    const denominator = evaluatePolynomial(convertedFeedback, z);
                    const response = divide(numerator, denominator);
                    magResponse[i] = Math.sqrt(response[0] * response[0] + response[1] * response[1]);
                    phaseResponse[i] = Math.atan2(response[1], response[0]);
                }
            },
            removeEventListener (...args) {
                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        return (0, _interceptConnections.interceptConnections)(nativeIIRFilterNodeFaker, scriptProcessorNode);
    };
};

},{"../helpers/compute-buffer-size":"bimg2","../helpers/filter-buffer":"bnsBL","../helpers/intercept-connections":"jvEjr","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g804o":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeMediaElementAudioSourceNode", ()=>createNativeMediaElementAudioSourceNode);
const createNativeMediaElementAudioSourceNode = (nativeAudioContext, options)=>{
    return nativeAudioContext.createMediaElementSource(options.mediaElement);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5Nm8V":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeMediaStreamAudioDestinationNode", ()=>createNativeMediaStreamAudioDestinationNode);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeMediaStreamAudioDestinationNode = (nativeAudioContext, options)=>{
    const nativeMediaStreamAudioDestinationNode = nativeAudioContext.createMediaStreamDestination();
    (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeMediaStreamAudioDestinationNode, options);
    // Bug #174: Safari does expose a wrong numberOfOutputs.
    if (nativeMediaStreamAudioDestinationNode.numberOfOutputs === 1) Object.defineProperty(nativeMediaStreamAudioDestinationNode, "numberOfOutputs", {
        get: ()=>0
    });
    return nativeMediaStreamAudioDestinationNode;
};

},{"../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cc1Vv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeMediaStreamAudioSourceNode", ()=>createNativeMediaStreamAudioSourceNode);
const createNativeMediaStreamAudioSourceNode = (nativeAudioContext, { mediaStream })=>{
    const audioStreamTracks = mediaStream.getAudioTracks();
    /*
     * Bug #151: Safari does not use the audio track as input anymore if it gets removed from the mediaStream after construction.
     * Bug #159: Safari picks the first audio track if the MediaStream has more than one audio track.
     */ audioStreamTracks.sort((a, b)=>a.id < b.id ? -1 : a.id > b.id ? 1 : 0);
    const filteredAudioStreamTracks = audioStreamTracks.slice(0, 1);
    const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(new MediaStream(filteredAudioStreamTracks));
    /*
     * Bug #151 & #159: The given mediaStream gets reconstructed before it gets passed to the native node which is why the accessor needs
     * to be overwritten as it would otherwise expose the reconstructed version.
     */ Object.defineProperty(nativeMediaStreamAudioSourceNode, "mediaStream", {
        value: mediaStream
    });
    return nativeMediaStreamAudioSourceNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"833HX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeMediaStreamTrackAudioSourceNodeFactory", ()=>createNativeMediaStreamTrackAudioSourceNodeFactory);
const createNativeMediaStreamTrackAudioSourceNodeFactory = (createInvalidStateError, isNativeOfflineAudioContext)=>{
    return (nativeAudioContext, { mediaStreamTrack })=>{
        // Bug #121: Only Firefox does yet support the MediaStreamTrackAudioSourceNode.
        if (typeof nativeAudioContext.createMediaStreamTrackSource === "function") return nativeAudioContext.createMediaStreamTrackSource(mediaStreamTrack);
        const mediaStream = new MediaStream([
            mediaStreamTrack
        ]);
        const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(mediaStream);
        // Bug #120: Firefox does not throw an error if the mediaStream has no audio track.
        if (mediaStreamTrack.kind !== "audio") throw createInvalidStateError();
        // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.
        if (isNativeOfflineAudioContext(nativeAudioContext)) throw new TypeError();
        return nativeMediaStreamAudioSourceNode;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"clMxf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeOfflineAudioContextConstructor", ()=>createNativeOfflineAudioContextConstructor);
const createNativeOfflineAudioContextConstructor = (window)=>{
    if (window === null) return null;
    if (window.hasOwnProperty("OfflineAudioContext")) return window.OfflineAudioContext;
    return window.hasOwnProperty("webkitOfflineAudioContext") ? window.webkitOfflineAudioContext : null;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gRc8o":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeOscillatorNodeFactory", ()=>createNativeOscillatorNodeFactory);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _wrapAudioScheduledSourceNodeStartMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters");
var _wrapAudioScheduledSourceNodeStopMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters");
const createNativeOscillatorNodeFactory = (addSilentConnection, cacheTestResult, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls)=>{
    return (nativeContext, options)=>{
        const nativeOscillatorNode = nativeContext.createOscillator();
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeOscillatorNode, options);
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeOscillatorNode, options, "detune");
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeOscillatorNode, options, "frequency");
        if (options.periodicWave !== undefined) nativeOscillatorNode.setPeriodicWave(options.periodicWave);
        else (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeOscillatorNode, options, "type");
        // Bug #44: Only Chrome & Edge throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) (0, _wrapAudioScheduledSourceNodeStartMethodNegativeParameters.wrapAudioScheduledSourceNodeStartMethodNegativeParameters)(nativeOscillatorNode);
        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, ()=>testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeOscillatorNode, nativeContext);
        // Bug #44: Only Firefox does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) (0, _wrapAudioScheduledSourceNodeStopMethodNegativeParameters.wrapAudioScheduledSourceNodeStopMethodNegativeParameters)(nativeOscillatorNode);
        // Bug #175: Safari will not fire an ended event if the OscillatorNode is unconnected.
        addSilentConnection(nativeContext, nativeOscillatorNode);
        return nativeOscillatorNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"2k6Ld","../helpers/assign-native-audio-node-option":"gLjOv","../helpers/assign-native-audio-node-options":"hQ1ig","../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters":"eTpqG","../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters":"iy3CQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aE8DJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativePannerNodeFactory", ()=>createNativePannerNodeFactory);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativePannerNodeFactory = (createNativePannerNodeFaker)=>{
    return (nativeContext, options)=>{
        const nativePannerNode = nativeContext.createPanner();
        // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.
        if (nativePannerNode.orientationX === undefined) return createNativePannerNodeFaker(nativeContext, options);
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativePannerNode, options);
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, "orientationX");
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, "orientationY");
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, "orientationZ");
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, "positionX");
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, "positionY");
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, "positionZ");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativePannerNode, options, "coneInnerAngle");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativePannerNode, options, "coneOuterAngle");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativePannerNode, options, "coneOuterGain");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativePannerNode, options, "distanceModel");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativePannerNode, options, "maxDistance");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativePannerNode, options, "panningModel");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativePannerNode, options, "refDistance");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativePannerNode, options, "rolloffFactor");
        return nativePannerNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"2k6Ld","../helpers/assign-native-audio-node-option":"gLjOv","../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"doyFo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativePannerNodeFakerFactory", ()=>createNativePannerNodeFakerFactory);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _interceptConnections = require("../helpers/intercept-connections");
const createNativePannerNodeFakerFactory = (connectNativeAudioNodeToNativeAudioNode, createInvalidStateError, createNativeChannelMergerNode, createNativeGainNode, createNativeScriptProcessorNode, createNativeWaveShaperNode, createNotSupportedError, disconnectNativeAudioNodeFromNativeAudioNode, getFirstSample, monitorConnections)=>{
    return (nativeContext, { coneInnerAngle, coneOuterAngle, coneOuterGain, distanceModel, maxDistance, orientationX, orientationY, orientationZ, panningModel, positionX, positionY, positionZ, refDistance, rolloffFactor, ...audioNodeOptions })=>{
        const pannerNode = nativeContext.createPanner();
        // Bug #125: Safari does not throw an error yet.
        if (audioNodeOptions.channelCount > 2) throw createNotSupportedError();
        // Bug #126: Safari does not throw an error yet.
        if (audioNodeOptions.channelCountMode === "max") throw createNotSupportedError();
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(pannerNode, audioNodeOptions);
        const SINGLE_CHANNEL_OPTIONS = {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "discrete"
        };
        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            channelInterpretation: "speakers",
            numberOfInputs: 6
        });
        const inputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: 1
        });
        const orientationXGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 1
        });
        const orientationYGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const orientationZGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const positionXGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const positionYGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const positionZGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 6, 1);
        const waveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            curve: new Float32Array([
                1,
                1
            ]),
            oversample: "none"
        });
        let lastOrientation = [
            orientationX,
            orientationY,
            orientationZ
        ];
        let lastPosition = [
            positionX,
            positionY,
            positionZ
        ];
        const buffer = new Float32Array(1);
        // tslint:disable-next-line:deprecation
        scriptProcessorNode.onaudioprocess = ({ inputBuffer })=>{
            const orientation = [
                getFirstSample(inputBuffer, buffer, 0),
                getFirstSample(inputBuffer, buffer, 1),
                getFirstSample(inputBuffer, buffer, 2)
            ];
            if (orientation.some((value1, index)=>value1 !== lastOrientation[index])) {
                pannerNode.setOrientation(...orientation); // tslint:disable-line:deprecation
                lastOrientation = orientation;
            }
            const positon = [
                getFirstSample(inputBuffer, buffer, 3),
                getFirstSample(inputBuffer, buffer, 4),
                getFirstSample(inputBuffer, buffer, 5)
            ];
            if (positon.some((value1, index)=>value1 !== lastPosition[index])) {
                pannerNode.setPosition(...positon); // tslint:disable-line:deprecation
                lastPosition = positon;
            }
        };
        Object.defineProperty(orientationYGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        Object.defineProperty(orientationZGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        Object.defineProperty(positionXGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        Object.defineProperty(positionYGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        Object.defineProperty(positionZGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        const nativePannerNodeFaker = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return pannerNode.channelCount;
            },
            set channelCount (value){
                // Bug #125: Safari does not throw an error yet.
                if (value > 2) throw createNotSupportedError();
                inputGainNode.channelCount = value;
                pannerNode.channelCount = value;
            },
            get channelCountMode () {
                return pannerNode.channelCountMode;
            },
            set channelCountMode (value){
                // Bug #126: Safari does not throw an error yet.
                if (value === "max") throw createNotSupportedError();
                inputGainNode.channelCountMode = value;
                pannerNode.channelCountMode = value;
            },
            get channelInterpretation () {
                return pannerNode.channelInterpretation;
            },
            set channelInterpretation (value){
                inputGainNode.channelInterpretation = value;
                pannerNode.channelInterpretation = value;
            },
            get coneInnerAngle () {
                return pannerNode.coneInnerAngle;
            },
            set coneInnerAngle (value){
                pannerNode.coneInnerAngle = value;
            },
            get coneOuterAngle () {
                return pannerNode.coneOuterAngle;
            },
            set coneOuterAngle (value){
                pannerNode.coneOuterAngle = value;
            },
            get coneOuterGain () {
                return pannerNode.coneOuterGain;
            },
            set coneOuterGain (value){
                // Bug #127: Safari does not throw an InvalidStateError yet.
                if (value < 0 || value > 1) throw createInvalidStateError();
                pannerNode.coneOuterGain = value;
            },
            get context () {
                return pannerNode.context;
            },
            get distanceModel () {
                return pannerNode.distanceModel;
            },
            set distanceModel (value){
                pannerNode.distanceModel = value;
            },
            get inputs () {
                return [
                    inputGainNode
                ];
            },
            get maxDistance () {
                return pannerNode.maxDistance;
            },
            set maxDistance (value){
                // Bug #128: Safari does not throw an error yet.
                if (value < 0) throw new RangeError();
                pannerNode.maxDistance = value;
            },
            get numberOfInputs () {
                return pannerNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return pannerNode.numberOfOutputs;
            },
            get orientationX () {
                return orientationXGainNode.gain;
            },
            get orientationY () {
                return orientationYGainNode.gain;
            },
            get orientationZ () {
                return orientationZGainNode.gain;
            },
            get panningModel () {
                return pannerNode.panningModel;
            },
            set panningModel (value){
                pannerNode.panningModel = value;
            },
            get positionX () {
                return positionXGainNode.gain;
            },
            get positionY () {
                return positionYGainNode.gain;
            },
            get positionZ () {
                return positionZGainNode.gain;
            },
            get refDistance () {
                return pannerNode.refDistance;
            },
            set refDistance (value){
                // Bug #129: Safari does not throw an error yet.
                if (value < 0) throw new RangeError();
                pannerNode.refDistance = value;
            },
            get rolloffFactor () {
                return pannerNode.rolloffFactor;
            },
            set rolloffFactor (value){
                // Bug #130: Safari does not throw an error yet.
                if (value < 0) throw new RangeError();
                pannerNode.rolloffFactor = value;
            },
            addEventListener (...args) {
                return inputGainNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return inputGainNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return inputGainNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        if (coneInnerAngle !== nativePannerNodeFaker.coneInnerAngle) nativePannerNodeFaker.coneInnerAngle = coneInnerAngle;
        if (coneOuterAngle !== nativePannerNodeFaker.coneOuterAngle) nativePannerNodeFaker.coneOuterAngle = coneOuterAngle;
        if (coneOuterGain !== nativePannerNodeFaker.coneOuterGain) nativePannerNodeFaker.coneOuterGain = coneOuterGain;
        if (distanceModel !== nativePannerNodeFaker.distanceModel) nativePannerNodeFaker.distanceModel = distanceModel;
        if (maxDistance !== nativePannerNodeFaker.maxDistance) nativePannerNodeFaker.maxDistance = maxDistance;
        if (orientationX !== nativePannerNodeFaker.orientationX.value) nativePannerNodeFaker.orientationX.value = orientationX;
        if (orientationY !== nativePannerNodeFaker.orientationY.value) nativePannerNodeFaker.orientationY.value = orientationY;
        if (orientationZ !== nativePannerNodeFaker.orientationZ.value) nativePannerNodeFaker.orientationZ.value = orientationZ;
        if (panningModel !== nativePannerNodeFaker.panningModel) nativePannerNodeFaker.panningModel = panningModel;
        if (positionX !== nativePannerNodeFaker.positionX.value) nativePannerNodeFaker.positionX.value = positionX;
        if (positionY !== nativePannerNodeFaker.positionY.value) nativePannerNodeFaker.positionY.value = positionY;
        if (positionZ !== nativePannerNodeFaker.positionZ.value) nativePannerNodeFaker.positionZ.value = positionZ;
        if (refDistance !== nativePannerNodeFaker.refDistance) nativePannerNodeFaker.refDistance = refDistance;
        if (rolloffFactor !== nativePannerNodeFaker.rolloffFactor) nativePannerNodeFaker.rolloffFactor = rolloffFactor;
        if (lastOrientation[0] !== 1 || lastOrientation[1] !== 0 || lastOrientation[2] !== 0) pannerNode.setOrientation(...lastOrientation); // tslint:disable-line:deprecation
        if (lastPosition[0] !== 0 || lastPosition[1] !== 0 || lastPosition[2] !== 0) pannerNode.setPosition(...lastPosition); // tslint:disable-line:deprecation
        const whenConnected = ()=>{
            inputGainNode.connect(pannerNode);
            // Bug #119: Safari does not fully support the WaveShaperNode.
            connectNativeAudioNodeToNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);
            waveShaperNode.connect(orientationXGainNode).connect(channelMergerNode, 0, 0);
            waveShaperNode.connect(orientationYGainNode).connect(channelMergerNode, 0, 1);
            waveShaperNode.connect(orientationZGainNode).connect(channelMergerNode, 0, 2);
            waveShaperNode.connect(positionXGainNode).connect(channelMergerNode, 0, 3);
            waveShaperNode.connect(positionYGainNode).connect(channelMergerNode, 0, 4);
            waveShaperNode.connect(positionZGainNode).connect(channelMergerNode, 0, 5);
            channelMergerNode.connect(scriptProcessorNode).connect(nativeContext.destination);
        };
        const whenDisconnected = ()=>{
            inputGainNode.disconnect(pannerNode);
            // Bug #119: Safari does not fully support the WaveShaperNode.
            disconnectNativeAudioNodeFromNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);
            waveShaperNode.disconnect(orientationXGainNode);
            orientationXGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(orientationYGainNode);
            orientationYGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(orientationZGainNode);
            orientationZGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(positionXGainNode);
            positionXGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(positionYGainNode);
            positionYGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(positionZGainNode);
            positionZGainNode.disconnect(channelMergerNode);
            channelMergerNode.disconnect(scriptProcessorNode);
            scriptProcessorNode.disconnect(nativeContext.destination);
        };
        return monitorConnections((0, _interceptConnections.interceptConnections)(nativePannerNodeFaker, pannerNode), whenConnected, whenDisconnected);
    };
};

},{"../helpers/assign-native-audio-node-options":"hQ1ig","../helpers/intercept-connections":"jvEjr","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hMgnX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativePeriodicWaveFactory", ()=>createNativePeriodicWaveFactory);
const createNativePeriodicWaveFactory = (createIndexSizeError)=>{
    return (nativeContext, { disableNormalization, imag, real })=>{
        // Bug #180: Safari does not allow to use ordinary arrays.
        const convertedImag = imag instanceof Float32Array ? imag : new Float32Array(imag);
        const convertedReal = real instanceof Float32Array ? real : new Float32Array(real);
        const nativePeriodicWave = nativeContext.createPeriodicWave(convertedReal, convertedImag, {
            disableNormalization
        });
        // Bug #181: Safari does not throw an IndexSizeError so far if the given arrays have less than two values.
        if (Array.from(imag).length < 2) throw createIndexSizeError();
        return nativePeriodicWave;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"63kc1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeScriptProcessorNode", ()=>createNativeScriptProcessorNode);
const createNativeScriptProcessorNode = (nativeContext, bufferSize, numberOfInputChannels, numberOfOutputChannels)=>{
    return nativeContext.createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels); // tslint:disable-line deprecation
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"46iGP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeStereoPannerNodeFactory", ()=>createNativeStereoPannerNodeFactory);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeStereoPannerNodeFactory = (createNativeStereoPannerNodeFaker, createNotSupportedError)=>{
    return (nativeContext, options)=>{
        const channelCountMode = options.channelCountMode;
        /*
         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari
         * which supports it and therefore it can't be supported at all.
         */ if (channelCountMode === "clamped-max") throw createNotSupportedError();
        // Bug #105: Safari does not support the StereoPannerNode.
        if (nativeContext.createStereoPanner === undefined) return createNativeStereoPannerNodeFaker(nativeContext, options);
        const nativeStereoPannerNode = nativeContext.createStereoPanner();
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeStereoPannerNode, options);
        (0, _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue)(nativeStereoPannerNode, options, "pan");
        /*
         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari
         * which supports it and therefore it can't be supported at all.
         */ Object.defineProperty(nativeStereoPannerNode, "channelCountMode", {
            get: ()=>channelCountMode,
            set: (value)=>{
                if (value !== channelCountMode) throw createNotSupportedError();
            }
        });
        return nativeStereoPannerNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"2k6Ld","../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3tpsg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeStereoPannerNodeFakerFactory", ()=>createNativeStereoPannerNodeFakerFactory);
var _interceptConnections = require("../helpers/intercept-connections");
const createNativeStereoPannerNodeFakerFactory = (createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeGainNode, createNativeWaveShaperNode, createNotSupportedError, monitorConnections)=>{
    // The curve has a size of 14bit plus 1 value to have an exact representation for zero. This value has been determined experimentally.
    const CURVE_SIZE = 16385;
    const DC_CURVE = new Float32Array([
        1,
        1
    ]);
    const HALF_PI = Math.PI / 2;
    const SINGLE_CHANNEL_OPTIONS = {
        channelCount: 1,
        channelCountMode: "explicit",
        channelInterpretation: "discrete"
    };
    const SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS = {
        ...SINGLE_CHANNEL_OPTIONS,
        oversample: "none"
    };
    const buildInternalGraphForMono = (nativeContext, inputGainNode, panGainNode, channelMergerNode)=>{
        const leftWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const rightWaveShaperCurve = new Float32Array(CURVE_SIZE);
        for(let i = 0; i < CURVE_SIZE; i += 1){
            const x = i / (CURVE_SIZE - 1) * HALF_PI;
            leftWaveShaperCurve[i] = Math.cos(x);
            rightWaveShaperCurve[i] = Math.sin(x);
        }
        const leftGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const leftWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: leftWaveShaperCurve
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const panWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: DC_CURVE
        });
        const rightGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const rightWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: rightWaveShaperCurve
        });
        return {
            connectGraph () {
                inputGainNode.connect(leftGainNode);
                inputGainNode.connect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                inputGainNode.connect(rightGainNode);
                panWaveShaperNode.connect(panGainNode);
                panGainNode.connect(leftWaveShaperNode.inputs === undefined ? leftWaveShaperNode : leftWaveShaperNode.inputs[0]);
                panGainNode.connect(rightWaveShaperNode.inputs === undefined ? rightWaveShaperNode : rightWaveShaperNode.inputs[0]);
                leftWaveShaperNode.connect(leftGainNode.gain);
                rightWaveShaperNode.connect(rightGainNode.gain);
                leftGainNode.connect(channelMergerNode, 0, 0);
                rightGainNode.connect(channelMergerNode, 0, 1);
            },
            disconnectGraph () {
                inputGainNode.disconnect(leftGainNode);
                inputGainNode.disconnect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                inputGainNode.disconnect(rightGainNode);
                panWaveShaperNode.disconnect(panGainNode);
                panGainNode.disconnect(leftWaveShaperNode.inputs === undefined ? leftWaveShaperNode : leftWaveShaperNode.inputs[0]);
                panGainNode.disconnect(rightWaveShaperNode.inputs === undefined ? rightWaveShaperNode : rightWaveShaperNode.inputs[0]);
                leftWaveShaperNode.disconnect(leftGainNode.gain);
                rightWaveShaperNode.disconnect(rightGainNode.gain);
                leftGainNode.disconnect(channelMergerNode, 0, 0);
                rightGainNode.disconnect(channelMergerNode, 0, 1);
            }
        };
    };
    const buildInternalGraphForStereo = (nativeContext, inputGainNode, panGainNode, channelMergerNode)=>{
        const leftInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const leftInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const rightInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const rightInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const centerIndex = Math.floor(CURVE_SIZE / 2);
        for(let i = 0; i < CURVE_SIZE; i += 1)if (i > centerIndex) {
            const x = (i - centerIndex) / (CURVE_SIZE - 1 - centerIndex) * HALF_PI;
            leftInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);
            leftInputForRightOutputWaveShaperCurve[i] = Math.sin(x);
            rightInputForLeftOutputWaveShaperCurve[i] = 0;
            rightInputForRightOutputWaveShaperCurve[i] = 1;
        } else {
            const x = i / (CURVE_SIZE - 1 - centerIndex) * HALF_PI;
            leftInputForLeftOutputWaveShaperCurve[i] = 1;
            leftInputForRightOutputWaveShaperCurve[i] = 0;
            rightInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);
            rightInputForRightOutputWaveShaperCurve[i] = Math.sin(x);
        }
        const channelSplitterNode = createNativeChannelSplitterNode(nativeContext, {
            channelCount: 2,
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            numberOfOutputs: 2
        });
        const leftInputForLeftOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const leftInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: leftInputForLeftOutputWaveShaperCurve
        });
        const leftInputForRightOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const leftInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: leftInputForRightOutputWaveShaperCurve
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const panWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: DC_CURVE
        });
        const rightInputForLeftOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const rightInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: rightInputForLeftOutputWaveShaperCurve
        });
        const rightInputForRightOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const rightInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: rightInputForRightOutputWaveShaperCurve
        });
        return {
            connectGraph () {
                inputGainNode.connect(channelSplitterNode);
                inputGainNode.connect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                channelSplitterNode.connect(leftInputForLeftOutputGainNode, 0);
                channelSplitterNode.connect(leftInputForRightOutputGainNode, 0);
                channelSplitterNode.connect(rightInputForLeftOutputGainNode, 1);
                channelSplitterNode.connect(rightInputForRightOutputGainNode, 1);
                panWaveShaperNode.connect(panGainNode);
                panGainNode.connect(leftInputForLeftOutputWaveShaperNode.inputs === undefined ? leftInputForLeftOutputWaveShaperNode : leftInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.connect(leftInputForRightOutputWaveShaperNode.inputs === undefined ? leftInputForRightOutputWaveShaperNode : leftInputForRightOutputWaveShaperNode.inputs[0]);
                panGainNode.connect(rightInputForLeftOutputWaveShaperNode.inputs === undefined ? rightInputForLeftOutputWaveShaperNode : rightInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.connect(rightInputForRightOutputWaveShaperNode.inputs === undefined ? rightInputForRightOutputWaveShaperNode : rightInputForRightOutputWaveShaperNode.inputs[0]);
                leftInputForLeftOutputWaveShaperNode.connect(leftInputForLeftOutputGainNode.gain);
                leftInputForRightOutputWaveShaperNode.connect(leftInputForRightOutputGainNode.gain);
                rightInputForLeftOutputWaveShaperNode.connect(rightInputForLeftOutputGainNode.gain);
                rightInputForRightOutputWaveShaperNode.connect(rightInputForRightOutputGainNode.gain);
                leftInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);
                rightInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);
                leftInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);
                rightInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);
            },
            disconnectGraph () {
                inputGainNode.disconnect(channelSplitterNode);
                inputGainNode.disconnect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                channelSplitterNode.disconnect(leftInputForLeftOutputGainNode, 0);
                channelSplitterNode.disconnect(leftInputForRightOutputGainNode, 0);
                channelSplitterNode.disconnect(rightInputForLeftOutputGainNode, 1);
                channelSplitterNode.disconnect(rightInputForRightOutputGainNode, 1);
                panWaveShaperNode.disconnect(panGainNode);
                panGainNode.disconnect(leftInputForLeftOutputWaveShaperNode.inputs === undefined ? leftInputForLeftOutputWaveShaperNode : leftInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.disconnect(leftInputForRightOutputWaveShaperNode.inputs === undefined ? leftInputForRightOutputWaveShaperNode : leftInputForRightOutputWaveShaperNode.inputs[0]);
                panGainNode.disconnect(rightInputForLeftOutputWaveShaperNode.inputs === undefined ? rightInputForLeftOutputWaveShaperNode : rightInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.disconnect(rightInputForRightOutputWaveShaperNode.inputs === undefined ? rightInputForRightOutputWaveShaperNode : rightInputForRightOutputWaveShaperNode.inputs[0]);
                leftInputForLeftOutputWaveShaperNode.disconnect(leftInputForLeftOutputGainNode.gain);
                leftInputForRightOutputWaveShaperNode.disconnect(leftInputForRightOutputGainNode.gain);
                rightInputForLeftOutputWaveShaperNode.disconnect(rightInputForLeftOutputGainNode.gain);
                rightInputForRightOutputWaveShaperNode.disconnect(rightInputForRightOutputGainNode.gain);
                leftInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);
                rightInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);
                leftInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);
                rightInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);
            }
        };
    };
    const buildInternalGraph = (nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode)=>{
        if (channelCount === 1) return buildInternalGraphForMono(nativeContext, inputGainNode, panGainNode, channelMergerNode);
        if (channelCount === 2) return buildInternalGraphForStereo(nativeContext, inputGainNode, panGainNode, channelMergerNode);
        throw createNotSupportedError();
    };
    return (nativeContext, { channelCount, channelCountMode, pan, ...audioNodeOptions })=>{
        if (channelCountMode === "max") throw createNotSupportedError();
        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
            ...audioNodeOptions,
            channelCount: 1,
            channelCountMode,
            numberOfInputs: 2
        });
        const inputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            channelCount,
            channelCountMode,
            gain: 1
        });
        const panGainNode = createNativeGainNode(nativeContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            gain: pan
        });
        let { connectGraph, disconnectGraph } = buildInternalGraph(nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode);
        Object.defineProperty(panGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        Object.defineProperty(panGainNode.gain, "maxValue", {
            get: ()=>1
        });
        Object.defineProperty(panGainNode.gain, "minValue", {
            get: ()=>-1
        });
        const nativeStereoPannerNodeFakerFactory = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return inputGainNode.channelCount;
            },
            set channelCount (value){
                if (inputGainNode.channelCount !== value) {
                    if (isConnected) disconnectGraph();
                    ({ connectGraph, disconnectGraph } = buildInternalGraph(nativeContext, value, inputGainNode, panGainNode, channelMergerNode));
                    if (isConnected) connectGraph();
                }
                inputGainNode.channelCount = value;
            },
            get channelCountMode () {
                return inputGainNode.channelCountMode;
            },
            set channelCountMode (value){
                if (value === "clamped-max" || value === "max") throw createNotSupportedError();
                inputGainNode.channelCountMode = value;
            },
            get channelInterpretation () {
                return inputGainNode.channelInterpretation;
            },
            set channelInterpretation (value){
                inputGainNode.channelInterpretation = value;
            },
            get context () {
                return inputGainNode.context;
            },
            get inputs () {
                return [
                    inputGainNode
                ];
            },
            get numberOfInputs () {
                return inputGainNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return inputGainNode.numberOfOutputs;
            },
            get pan () {
                return panGainNode.gain;
            },
            addEventListener (...args) {
                return inputGainNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return inputGainNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return inputGainNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        let isConnected = false;
        const whenConnected = ()=>{
            connectGraph();
            isConnected = true;
        };
        const whenDisconnected = ()=>{
            disconnectGraph();
            isConnected = false;
        };
        return monitorConnections((0, _interceptConnections.interceptConnections)(nativeStereoPannerNodeFakerFactory, channelMergerNode), whenConnected, whenDisconnected);
    };
};

},{"../helpers/intercept-connections":"jvEjr","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fYxR5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeWaveShaperNodeFactory", ()=>createNativeWaveShaperNodeFactory);
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeWaveShaperNodeFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeWaveShaperNodeFaker, isDCCurve, monitorConnections, nativeAudioContextConstructor, overwriteAccessors)=>{
    return (nativeContext, options)=>{
        const nativeWaveShaperNode = nativeContext.createWaveShaper();
        /*
         * Bug #119: Safari does not correctly map the values.
         * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of
         * the webkitAudioContext is used as a workaround here. Testing for the automationRate property is necessary because this workaround
         * isn't necessary anymore since v14.0.2 of Safari.
         */ if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === "webkitAudioContext" && nativeContext.createGain().gain.automationRate === undefined) return createNativeWaveShaperNodeFaker(nativeContext, options);
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(nativeWaveShaperNode, options);
        const curve = options.curve === null || options.curve instanceof Float32Array ? options.curve : new Float32Array(options.curve);
        // Bug #104: Chrome and Edge will throw an InvalidAccessError when the curve has less than two samples.
        if (curve !== null && curve.length < 2) throw createInvalidStateError();
        // Only values of type Float32Array can be assigned to the curve property.
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeWaveShaperNode, {
            curve
        }, "curve");
        (0, _assignNativeAudioNodeOption.assignNativeAudioNodeOption)(nativeWaveShaperNode, options, "oversample");
        let disconnectNativeAudioBufferSourceNode = null;
        let isConnected = false;
        overwriteAccessors(nativeWaveShaperNode, "curve", (get)=>()=>get.call(nativeWaveShaperNode), (set)=>(value)=>{
                set.call(nativeWaveShaperNode, value);
                if (isConnected) {
                    if (isDCCurve(value) && disconnectNativeAudioBufferSourceNode === null) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);
                    else if (!isDCCurve(value) && disconnectNativeAudioBufferSourceNode !== null) {
                        disconnectNativeAudioBufferSourceNode();
                        disconnectNativeAudioBufferSourceNode = null;
                    }
                }
                return value;
            });
        const whenConnected = ()=>{
            isConnected = true;
            if (isDCCurve(nativeWaveShaperNode.curve)) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);
        };
        const whenDisconnected = ()=>{
            isConnected = false;
            if (disconnectNativeAudioBufferSourceNode !== null) {
                disconnectNativeAudioBufferSourceNode();
                disconnectNativeAudioBufferSourceNode = null;
            }
        };
        return monitorConnections(nativeWaveShaperNode, whenConnected, whenDisconnected);
    };
};

},{"../helpers/assign-native-audio-node-option":"gLjOv","../helpers/assign-native-audio-node-options":"hQ1ig","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"48VV2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeWaveShaperNodeFakerFactory", ()=>createNativeWaveShaperNodeFakerFactory);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _interceptConnections = require("../helpers/intercept-connections");
const createNativeWaveShaperNodeFakerFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeGainNode, isDCCurve, monitorConnections)=>{
    return (nativeContext, { curve, oversample, ...audioNodeOptions })=>{
        const negativeWaveShaperNode = nativeContext.createWaveShaper();
        const positiveWaveShaperNode = nativeContext.createWaveShaper();
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(negativeWaveShaperNode, audioNodeOptions);
        (0, _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions)(positiveWaveShaperNode, audioNodeOptions);
        const inputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: 1
        });
        const invertGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: -1
        });
        const outputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: 1
        });
        const revertGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: -1
        });
        let disconnectNativeAudioBufferSourceNode = null;
        let isConnected = false;
        let unmodifiedCurve = null;
        const nativeWaveShaperNodeFaker = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return negativeWaveShaperNode.channelCount;
            },
            set channelCount (value){
                inputGainNode.channelCount = value;
                invertGainNode.channelCount = value;
                negativeWaveShaperNode.channelCount = value;
                outputGainNode.channelCount = value;
                positiveWaveShaperNode.channelCount = value;
                revertGainNode.channelCount = value;
            },
            get channelCountMode () {
                return negativeWaveShaperNode.channelCountMode;
            },
            set channelCountMode (value){
                inputGainNode.channelCountMode = value;
                invertGainNode.channelCountMode = value;
                negativeWaveShaperNode.channelCountMode = value;
                outputGainNode.channelCountMode = value;
                positiveWaveShaperNode.channelCountMode = value;
                revertGainNode.channelCountMode = value;
            },
            get channelInterpretation () {
                return negativeWaveShaperNode.channelInterpretation;
            },
            set channelInterpretation (value){
                inputGainNode.channelInterpretation = value;
                invertGainNode.channelInterpretation = value;
                negativeWaveShaperNode.channelInterpretation = value;
                outputGainNode.channelInterpretation = value;
                positiveWaveShaperNode.channelInterpretation = value;
                revertGainNode.channelInterpretation = value;
            },
            get context () {
                return negativeWaveShaperNode.context;
            },
            get curve () {
                return unmodifiedCurve;
            },
            set curve (value){
                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.
                if (value !== null && value.length < 2) throw createInvalidStateError();
                if (value === null) {
                    negativeWaveShaperNode.curve = value;
                    positiveWaveShaperNode.curve = value;
                } else {
                    const curveLength = value.length;
                    const negativeCurve = new Float32Array(curveLength + 2 - curveLength % 2);
                    const positiveCurve = new Float32Array(curveLength + 2 - curveLength % 2);
                    negativeCurve[0] = value[0];
                    positiveCurve[0] = -value[curveLength - 1];
                    const length = Math.ceil((curveLength + 1) / 2);
                    const centerIndex = (curveLength + 1) / 2 - 1;
                    for(let i = 1; i < length; i += 1){
                        const theoreticIndex = i / length * centerIndex;
                        const lowerIndex = Math.floor(theoreticIndex);
                        const upperIndex = Math.ceil(theoreticIndex);
                        negativeCurve[i] = lowerIndex === upperIndex ? value[lowerIndex] : (1 - (theoreticIndex - lowerIndex)) * value[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * value[upperIndex];
                        positiveCurve[i] = lowerIndex === upperIndex ? -value[curveLength - 1 - lowerIndex] : -((1 - (theoreticIndex - lowerIndex)) * value[curveLength - 1 - lowerIndex]) - (1 - (upperIndex - theoreticIndex)) * value[curveLength - 1 - upperIndex];
                    }
                    negativeCurve[length] = curveLength % 2 === 1 ? value[length - 1] : (value[length - 2] + value[length - 1]) / 2;
                    negativeWaveShaperNode.curve = negativeCurve;
                    positiveWaveShaperNode.curve = positiveCurve;
                }
                unmodifiedCurve = value;
                if (isConnected) {
                    if (isDCCurve(unmodifiedCurve) && disconnectNativeAudioBufferSourceNode === null) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);
                    else if (disconnectNativeAudioBufferSourceNode !== null) {
                        disconnectNativeAudioBufferSourceNode();
                        disconnectNativeAudioBufferSourceNode = null;
                    }
                }
            },
            get inputs () {
                return [
                    inputGainNode
                ];
            },
            get numberOfInputs () {
                return negativeWaveShaperNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return negativeWaveShaperNode.numberOfOutputs;
            },
            get oversample () {
                return negativeWaveShaperNode.oversample;
            },
            set oversample (value){
                negativeWaveShaperNode.oversample = value;
                positiveWaveShaperNode.oversample = value;
            },
            addEventListener (...args) {
                return inputGainNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return inputGainNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return inputGainNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        if (curve !== null) // Only values of type Float32Array can be assigned to the curve property.
        nativeWaveShaperNodeFaker.curve = curve instanceof Float32Array ? curve : new Float32Array(curve);
        if (oversample !== nativeWaveShaperNodeFaker.oversample) nativeWaveShaperNodeFaker.oversample = oversample;
        const whenConnected = ()=>{
            inputGainNode.connect(negativeWaveShaperNode).connect(outputGainNode);
            inputGainNode.connect(invertGainNode).connect(positiveWaveShaperNode).connect(revertGainNode).connect(outputGainNode);
            isConnected = true;
            if (isDCCurve(unmodifiedCurve)) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);
        };
        const whenDisconnected = ()=>{
            inputGainNode.disconnect(negativeWaveShaperNode);
            negativeWaveShaperNode.disconnect(outputGainNode);
            inputGainNode.disconnect(invertGainNode);
            invertGainNode.disconnect(positiveWaveShaperNode);
            positiveWaveShaperNode.disconnect(revertGainNode);
            revertGainNode.disconnect(outputGainNode);
            isConnected = false;
            if (disconnectNativeAudioBufferSourceNode !== null) {
                disconnectNativeAudioBufferSourceNode();
                disconnectNativeAudioBufferSourceNode = null;
            }
        };
        return monitorConnections((0, _interceptConnections.interceptConnections)(nativeWaveShaperNodeFaker, outputGainNode), whenConnected, whenDisconnected);
    };
};

},{"../helpers/assign-native-audio-node-options":"hQ1ig","../helpers/intercept-connections":"jvEjr","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fLKAR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNotSupportedError", ()=>createNotSupportedError);
const createNotSupportedError = ()=>new DOMException("", "NotSupportedError");

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9iLZs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createOfflineAudioContextConstructor", ()=>createOfflineAudioContextConstructor);
var _deactivateAudioGraph = require("../helpers/deactivate-audio-graph");
var _testPromiseSupport = require("../helpers/test-promise-support");
const DEFAULT_OPTIONS = {
    numberOfChannels: 1
};
const createOfflineAudioContextConstructor = (baseAudioContextConstructor, cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, startRendering)=>{
    return class OfflineAudioContext extends baseAudioContextConstructor {
        constructor(a, b, c){
            let options;
            if (typeof a === "number" && b !== undefined && c !== undefined) options = {
                length: b,
                numberOfChannels: a,
                sampleRate: c
            };
            else if (typeof a === "object") options = a;
            else throw new Error("The given parameters are not valid.");
            const { length, numberOfChannels, sampleRate } = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);
            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.
            if (!cacheTestResult((0, _testPromiseSupport.testPromiseSupport), ()=>(0, _testPromiseSupport.testPromiseSupport)(nativeOfflineAudioContext))) nativeOfflineAudioContext.addEventListener("statechange", (()=>{
                let i = 0;
                const delayStateChangeEvent = (event)=>{
                    if (this._state === "running") {
                        if (i > 0) {
                            nativeOfflineAudioContext.removeEventListener("statechange", delayStateChangeEvent);
                            event.stopImmediatePropagation();
                            this._waitForThePromiseToSettle(event);
                        } else i += 1;
                    }
                };
                return delayStateChangeEvent;
            })());
            super(nativeOfflineAudioContext, numberOfChannels);
            this._length = length;
            this._nativeOfflineAudioContext = nativeOfflineAudioContext;
            this._state = null;
        }
        get length() {
            // Bug #17: Safari does not yet expose the length.
            if (this._nativeOfflineAudioContext.length === undefined) return this._length;
            return this._nativeOfflineAudioContext.length;
        }
        get state() {
            return this._state === null ? this._nativeOfflineAudioContext.state : this._state;
        }
        startRendering() {
            /*
             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore
             * the state of the nativeOfflineAudioContext might no transition to running immediately.
             */ if (this._state === "running") return Promise.reject(createInvalidStateError());
            this._state = "running";
            return startRendering(this.destination, this._nativeOfflineAudioContext).finally(()=>{
                this._state = null;
                (0, _deactivateAudioGraph.deactivateAudioGraph)(this);
            });
        }
        _waitForThePromiseToSettle(event) {
            if (this._state === null) this._nativeOfflineAudioContext.dispatchEvent(event);
            else setTimeout(()=>this._waitForThePromiseToSettle(event));
        }
    };
};

},{"../helpers/deactivate-audio-graph":"ap1I7","../helpers/test-promise-support":"4hyPB","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cS1X5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createOscillatorNodeConstructor", ()=>createOscillatorNodeConstructor);
var _isActiveAudioNode = require("../helpers/is-active-audio-node");
var _setInternalStateToActive = require("../helpers/set-internal-state-to-active");
var _setInternalStateToPassive = require("../helpers/set-internal-state-to-passive");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    detune: 0,
    frequency: 440,
    periodicWave: undefined,
    type: "sine"
};
const createOscillatorNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, wrapEventListener)=>{
    return class OscillatorNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeOscillatorNode = createNativeOscillatorNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const oscillatorNodeRenderer = isOffline ? createOscillatorNodeRenderer() : null;
            const nyquist = context.sampleRate / 2;
            super(context, false, nativeOscillatorNode, oscillatorNodeRenderer);
            // Bug #81: Firefox & Safari do not export the correct values for maxValue and minValue.
            this._detune = createAudioParam(this, isOffline, nativeOscillatorNode.detune, 153600, -153600);
            // Bug #76: Safari does not export the correct values for maxValue and minValue.
            this._frequency = createAudioParam(this, isOffline, nativeOscillatorNode.frequency, nyquist, -nyquist);
            this._nativeOscillatorNode = nativeOscillatorNode;
            this._onended = null;
            this._oscillatorNodeRenderer = oscillatorNodeRenderer;
            if (this._oscillatorNodeRenderer !== null && mergedOptions.periodicWave !== undefined) this._oscillatorNodeRenderer.periodicWave = mergedOptions.periodicWave;
        }
        get detune() {
            return this._detune;
        }
        get frequency() {
            return this._frequency;
        }
        get onended() {
            return this._onended;
        }
        set onended(value) {
            const wrappedListener = typeof value === "function" ? wrapEventListener(this, value) : null;
            this._nativeOscillatorNode.onended = wrappedListener;
            const nativeOnEnded = this._nativeOscillatorNode.onended;
            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
        }
        get type() {
            return this._nativeOscillatorNode.type;
        }
        set type(value) {
            this._nativeOscillatorNode.type = value;
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.periodicWave = null;
        }
        setPeriodicWave(periodicWave) {
            this._nativeOscillatorNode.setPeriodicWave(periodicWave);
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.periodicWave = periodicWave;
        }
        start(when = 0) {
            this._nativeOscillatorNode.start(when);
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.start = when;
            if (this.context.state !== "closed") {
                (0, _setInternalStateToActive.setInternalStateToActive)(this);
                const resetInternalStateToPassive = ()=>{
                    this._nativeOscillatorNode.removeEventListener("ended", resetInternalStateToPassive);
                    if ((0, _isActiveAudioNode.isActiveAudioNode)(this)) (0, _setInternalStateToPassive.setInternalStateToPassive)(this);
                };
                this._nativeOscillatorNode.addEventListener("ended", resetInternalStateToPassive);
            }
        }
        stop(when = 0) {
            this._nativeOscillatorNode.stop(when);
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.stop = when;
        }
    };
};

},{"../helpers/is-active-audio-node":"j8Y4t","../helpers/set-internal-state-to-active":"gc0b0","../helpers/set-internal-state-to-passive":"1Xtwa","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"21Ubp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createOscillatorNodeRendererFactory", ()=>createOscillatorNodeRendererFactory);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createOscillatorNodeRendererFactory = (connectAudioParam, createNativeOscillatorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeOscillatorNodes = new WeakMap();
        let periodicWave = null;
        let start = null;
        let stop = null;
        const createOscillatorNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeOscillatorNode = getNativeAudioNode(proxy);
            // If the initially used nativeOscillatorNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeOscillatorNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeOscillatorNode, nativeOfflineAudioContext);
            if (!nativeOscillatorNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeOscillatorNode.channelCount,
                    channelCountMode: nativeOscillatorNode.channelCountMode,
                    channelInterpretation: nativeOscillatorNode.channelInterpretation,
                    detune: nativeOscillatorNode.detune.value,
                    frequency: nativeOscillatorNode.frequency.value,
                    periodicWave: periodicWave === null ? undefined : periodicWave,
                    type: nativeOscillatorNode.type
                };
                nativeOscillatorNode = createNativeOscillatorNode(nativeOfflineAudioContext, options);
                if (start !== null) nativeOscillatorNode.start(start);
                if (stop !== null) nativeOscillatorNode.stop(stop);
            }
            renderedNativeOscillatorNodes.set(nativeOfflineAudioContext, nativeOscillatorNode);
            if (!nativeOscillatorNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune);
                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune);
                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency);
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeOscillatorNode);
            return nativeOscillatorNode;
        };
        return {
            set periodicWave (value){
                periodicWave = value;
            },
            set start (value){
                start = value;
            },
            set stop (value){
                stop = value;
            },
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeOscillatorNode = renderedNativeOscillatorNodes.get(nativeOfflineAudioContext);
                if (renderedNativeOscillatorNode !== undefined) return Promise.resolve(renderedNativeOscillatorNode);
                return createOscillatorNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3pCGA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createPannerNodeConstructor", ()=>createPannerNodeConstructor);
var _constants = require("../constants");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "clamped-max",
    channelInterpretation: "speakers",
    coneInnerAngle: 360,
    coneOuterAngle: 360,
    coneOuterGain: 0,
    distanceModel: "inverse",
    maxDistance: 10000,
    orientationX: 1,
    orientationY: 0,
    orientationZ: 0,
    panningModel: "equalpower",
    positionX: 0,
    positionY: 0,
    positionZ: 0,
    refDistance: 1,
    rolloffFactor: 1
};
const createPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class PannerNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativePannerNode = createNativePannerNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const pannerNodeRenderer = isOffline ? createPannerNodeRenderer() : null;
            super(context, false, nativePannerNode, pannerNodeRenderer);
            this._nativePannerNode = nativePannerNode;
            // Bug #74: Safari does not export the correct values for maxValue and minValue.
            this._orientationX = createAudioParam(this, isOffline, nativePannerNode.orientationX, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
            this._orientationY = createAudioParam(this, isOffline, nativePannerNode.orientationY, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
            this._orientationZ = createAudioParam(this, isOffline, nativePannerNode.orientationZ, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
            this._positionX = createAudioParam(this, isOffline, nativePannerNode.positionX, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
            this._positionY = createAudioParam(this, isOffline, nativePannerNode.positionY, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
            this._positionZ = createAudioParam(this, isOffline, nativePannerNode.positionZ, (0, _constants.MOST_POSITIVE_SINGLE_FLOAT), (0, _constants.MOST_NEGATIVE_SINGLE_FLOAT));
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        get coneInnerAngle() {
            return this._nativePannerNode.coneInnerAngle;
        }
        set coneInnerAngle(value) {
            this._nativePannerNode.coneInnerAngle = value;
        }
        get coneOuterAngle() {
            return this._nativePannerNode.coneOuterAngle;
        }
        set coneOuterAngle(value) {
            this._nativePannerNode.coneOuterAngle = value;
        }
        get coneOuterGain() {
            return this._nativePannerNode.coneOuterGain;
        }
        set coneOuterGain(value) {
            this._nativePannerNode.coneOuterGain = value;
        }
        get distanceModel() {
            return this._nativePannerNode.distanceModel;
        }
        set distanceModel(value) {
            this._nativePannerNode.distanceModel = value;
        }
        get maxDistance() {
            return this._nativePannerNode.maxDistance;
        }
        set maxDistance(value) {
            this._nativePannerNode.maxDistance = value;
        }
        get orientationX() {
            return this._orientationX;
        }
        get orientationY() {
            return this._orientationY;
        }
        get orientationZ() {
            return this._orientationZ;
        }
        get panningModel() {
            return this._nativePannerNode.panningModel;
        }
        set panningModel(value) {
            this._nativePannerNode.panningModel = value;
        }
        get positionX() {
            return this._positionX;
        }
        get positionY() {
            return this._positionY;
        }
        get positionZ() {
            return this._positionZ;
        }
        get refDistance() {
            return this._nativePannerNode.refDistance;
        }
        set refDistance(value) {
            this._nativePannerNode.refDistance = value;
        }
        get rolloffFactor() {
            return this._nativePannerNode.rolloffFactor;
        }
        set rolloffFactor(value) {
            this._nativePannerNode.rolloffFactor = value;
        }
    };
};

},{"../constants":"au584","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dmoFH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createPannerNodeRendererFactory", ()=>createPannerNodeRendererFactory);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createPannerNodeRendererFactory = (connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeGainNode, createNativePannerNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext)=>{
    return ()=>{
        const renderedNativeAudioNodes = new WeakMap();
        let renderedBufferPromise = null;
        const createAudioNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeGainNode = null;
            let nativePannerNode = getNativeAudioNode(proxy);
            const commonAudioNodeOptions = {
                channelCount: nativePannerNode.channelCount,
                channelCountMode: nativePannerNode.channelCountMode,
                channelInterpretation: nativePannerNode.channelInterpretation
            };
            const commonNativePannerNodeOptions = {
                ...commonAudioNodeOptions,
                coneInnerAngle: nativePannerNode.coneInnerAngle,
                coneOuterAngle: nativePannerNode.coneOuterAngle,
                coneOuterGain: nativePannerNode.coneOuterGain,
                distanceModel: nativePannerNode.distanceModel,
                maxDistance: nativePannerNode.maxDistance,
                panningModel: nativePannerNode.panningModel,
                refDistance: nativePannerNode.refDistance,
                rolloffFactor: nativePannerNode.rolloffFactor
            };
            // If the initially used nativePannerNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativePannerNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativePannerNode, nativeOfflineAudioContext);
            // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.
            if ("bufferSize" in nativePannerNode) nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                ...commonAudioNodeOptions,
                gain: 1
            });
            else if (!nativePannerNodeIsOwnedByContext) {
                const options = {
                    ...commonNativePannerNodeOptions,
                    orientationX: nativePannerNode.orientationX.value,
                    orientationY: nativePannerNode.orientationY.value,
                    orientationZ: nativePannerNode.orientationZ.value,
                    positionX: nativePannerNode.positionX.value,
                    positionY: nativePannerNode.positionY.value,
                    positionZ: nativePannerNode.positionZ.value
                };
                nativePannerNode = createNativePannerNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeGainNode === null ? nativePannerNode : nativeGainNode);
            if (nativeGainNode !== null) {
                if (renderedBufferPromise === null) {
                    if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(6, // Bug #17: Safari does not yet expose the length.
                    proxy.context.length, nativeOfflineAudioContext.sampleRate);
                    const nativeChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {
                        channelCount: 1,
                        channelCountMode: "explicit",
                        channelInterpretation: "speakers",
                        numberOfInputs: 6
                    });
                    nativeChannelMergerNode.connect(partialOfflineAudioContext.destination);
                    renderedBufferPromise = (async ()=>{
                        const nativeConstantSourceNodes = await Promise.all([
                            proxy.orientationX,
                            proxy.orientationY,
                            proxy.orientationZ,
                            proxy.positionX,
                            proxy.positionY,
                            proxy.positionZ
                        ].map(async (audioParam, index)=>{
                            const nativeConstantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {
                                channelCount: 1,
                                channelCountMode: "explicit",
                                channelInterpretation: "discrete",
                                offset: index === 0 ? 1 : 0
                            });
                            await renderAutomation(partialOfflineAudioContext, audioParam, nativeConstantSourceNode.offset);
                            return nativeConstantSourceNode;
                        }));
                        for(let i = 0; i < 6; i += 1){
                            nativeConstantSourceNodes[i].connect(nativeChannelMergerNode, 0, i);
                            nativeConstantSourceNodes[i].start(0);
                        }
                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);
                    })();
                }
                const renderedBuffer = await renderedBufferPromise;
                const inputGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    ...commonAudioNodeOptions,
                    gain: 1
                });
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, inputGainNode);
                const channelDatas = [];
                for(let i = 0; i < renderedBuffer.numberOfChannels; i += 1)channelDatas.push(renderedBuffer.getChannelData(i));
                let lastOrientation = [
                    channelDatas[0][0],
                    channelDatas[1][0],
                    channelDatas[2][0]
                ];
                let lastPosition = [
                    channelDatas[3][0],
                    channelDatas[4][0],
                    channelDatas[5][0]
                ];
                let gateGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    ...commonAudioNodeOptions,
                    gain: 1
                });
                let partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {
                    ...commonNativePannerNodeOptions,
                    orientationX: lastOrientation[0],
                    orientationY: lastOrientation[1],
                    orientationZ: lastOrientation[2],
                    positionX: lastPosition[0],
                    positionY: lastPosition[1],
                    positionZ: lastPosition[2]
                });
                inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);
                partialPannerNode.connect(nativeGainNode);
                for(let i = 128; i < renderedBuffer.length; i += 128){
                    const orientation = [
                        channelDatas[0][i],
                        channelDatas[1][i],
                        channelDatas[2][i]
                    ];
                    const positon = [
                        channelDatas[3][i],
                        channelDatas[4][i],
                        channelDatas[5][i]
                    ];
                    if (orientation.some((value, index)=>value !== lastOrientation[index]) || positon.some((value, index)=>value !== lastPosition[index])) {
                        lastOrientation = orientation;
                        lastPosition = positon;
                        const currentTime = i / nativeOfflineAudioContext.sampleRate;
                        gateGainNode.gain.setValueAtTime(0, currentTime);
                        gateGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                            ...commonAudioNodeOptions,
                            gain: 0
                        });
                        partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {
                            ...commonNativePannerNodeOptions,
                            orientationX: lastOrientation[0],
                            orientationY: lastOrientation[1],
                            orientationZ: lastOrientation[2],
                            positionX: lastPosition[0],
                            positionY: lastPosition[1],
                            positionZ: lastPosition[2]
                        });
                        gateGainNode.gain.setValueAtTime(1, currentTime);
                        inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);
                        partialPannerNode.connect(nativeGainNode);
                    }
                }
                return nativeGainNode;
            }
            if (!nativePannerNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX);
                await renderAutomation(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY);
                await renderAutomation(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ);
                await renderAutomation(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX);
                await renderAutomation(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY);
                await renderAutomation(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX);
                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY);
                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ);
                await connectAudioParam(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX);
                await connectAudioParam(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY);
                await connectAudioParam(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ);
            }
            if ((0, _nativeAudioNodeFaker.isNativeAudioNodeFaker)(nativePannerNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode.inputs[0]);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode);
            return nativePannerNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeGainNodeOrNativePannerNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeGainNodeOrNativePannerNode !== undefined) return Promise.resolve(renderedNativeGainNodeOrNativePannerNode);
                return createAudioNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../guards/native-audio-node-faker":"fNQvH","../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lQWxF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createPeriodicWaveConstructor", ()=>createPeriodicWaveConstructor);
const DEFAULT_OPTIONS = {
    disableNormalization: false
};
const createPeriodicWaveConstructor = (createNativePeriodicWave, getNativeContext, periodicWaveStore, sanitizePeriodicWaveOptions)=>{
    return class PeriodicWave {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = sanitizePeriodicWaveOptions({
                ...DEFAULT_OPTIONS,
                ...options
            });
            const periodicWave = createNativePeriodicWave(nativeContext, mergedOptions);
            periodicWaveStore.add(periodicWave);
            // This does violate all good pratices but it is used here to simplify the handling of periodic waves.
            return periodicWave;
        }
        static [Symbol.hasInstance](instance) {
            return instance !== null && typeof instance === "object" && Object.getPrototypeOf(instance) === PeriodicWave.prototype || periodicWaveStore.has(instance);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"beVBx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createRenderAutomation", ()=>createRenderAutomation);
const createRenderAutomation = (getAudioParamRenderer, renderInputsOfAudioParam)=>{
    return (nativeOfflineAudioContext, audioParam, nativeAudioParam)=>{
        const audioParamRenderer = getAudioParamRenderer(audioParam);
        audioParamRenderer.replay(nativeAudioParam);
        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lHwkb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createRenderInputsOfAudioNode", ()=>createRenderInputsOfAudioNode);
const createRenderInputsOfAudioNode = (getAudioNodeConnections, getAudioNodeRenderer, isPartOfACycle)=>{
    return async (audioNode, nativeOfflineAudioContext, nativeAudioNode)=>{
        const audioNodeConnections = getAudioNodeConnections(audioNode);
        await Promise.all(audioNodeConnections.activeInputs.map((connections, input)=>Array.from(connections).map(async ([source, output])=>{
                const audioNodeRenderer = getAudioNodeRenderer(source);
                const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext);
                const destination = audioNode.context.destination;
                if (!isPartOfACycle(source) && (audioNode !== destination || !isPartOfACycle(audioNode))) renderedNativeAudioNode.connect(nativeAudioNode, output, input);
            })).reduce((allRenderingPromises, renderingPromises)=>[
                ...allRenderingPromises,
                ...renderingPromises
            ], []));
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h2qZT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createRenderInputsOfAudioParam", ()=>createRenderInputsOfAudioParam);
const createRenderInputsOfAudioParam = (getAudioNodeRenderer, getAudioParamConnections, isPartOfACycle)=>{
    return async (audioParam, nativeOfflineAudioContext, nativeAudioParam)=>{
        const audioParamConnections = getAudioParamConnections(audioParam);
        await Promise.all(Array.from(audioParamConnections.activeInputs).map(async ([source, output])=>{
            const audioNodeRenderer = getAudioNodeRenderer(source);
            const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext);
            if (!isPartOfACycle(source)) renderedNativeAudioNode.connect(nativeAudioParam, output);
        }));
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iIK4Q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createRenderNativeOfflineAudioContext", ()=>createRenderNativeOfflineAudioContext);
var _testPromiseSupport = require("../helpers/test-promise-support");
const createRenderNativeOfflineAudioContext = (cacheTestResult, createNativeGainNode, createNativeScriptProcessorNode, testOfflineAudioContextCurrentTimeSupport)=>{
    return (nativeOfflineAudioContext)=>{
        // Bug #21: Safari does not support promises yet.
        if (cacheTestResult((0, _testPromiseSupport.testPromiseSupport), ()=>(0, _testPromiseSupport.testPromiseSupport)(nativeOfflineAudioContext))) // Bug #158: Chrome and Edge do not advance currentTime if it is not accessed while rendering the audio.
        return Promise.resolve(cacheTestResult(testOfflineAudioContextCurrentTimeSupport, testOfflineAudioContextCurrentTimeSupport)).then((isOfflineAudioContextCurrentTimeSupported)=>{
            if (!isOfflineAudioContextCurrentTimeSupported) {
                const scriptProcessorNode = createNativeScriptProcessorNode(nativeOfflineAudioContext, 512, 0, 1);
                nativeOfflineAudioContext.oncomplete = ()=>{
                    scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation
                    scriptProcessorNode.disconnect();
                };
                scriptProcessorNode.onaudioprocess = ()=>nativeOfflineAudioContext.currentTime; // tslint:disable-line:deprecation
                scriptProcessorNode.connect(nativeOfflineAudioContext.destination);
            }
            return nativeOfflineAudioContext.startRendering();
        });
        return new Promise((resolve)=>{
            // Bug #48: Safari does not render an OfflineAudioContext without any connected node.
            const gainNode = createNativeGainNode(nativeOfflineAudioContext, {
                channelCount: 1,
                channelCountMode: "explicit",
                channelInterpretation: "discrete",
                gain: 0
            });
            nativeOfflineAudioContext.oncomplete = (event)=>{
                gainNode.disconnect();
                resolve(event.renderedBuffer);
            };
            gainNode.connect(nativeOfflineAudioContext.destination);
            nativeOfflineAudioContext.startRendering();
        });
    };
};

},{"../helpers/test-promise-support":"4hyPB","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3VTsP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createSetActiveAudioWorkletNodeInputs", ()=>createSetActiveAudioWorkletNodeInputs);
const createSetActiveAudioWorkletNodeInputs = (activeAudioWorkletNodeInputsStore)=>{
    return (nativeAudioWorkletNode, activeInputs)=>{
        activeAudioWorkletNodeInputsStore.set(nativeAudioWorkletNode, activeInputs);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hzHas":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createSetAudioNodeTailTime", ()=>createSetAudioNodeTailTime);
const createSetAudioNodeTailTime = (audioNodeTailTimeStore)=>{
    return (audioNode, tailTime)=>audioNodeTailTimeStore.set(audioNode, tailTime);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ebqUV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createStartRendering", ()=>createStartRendering);
var _wrapAudioBufferGetChannelDataMethod = require("../helpers/wrap-audio-buffer-get-channel-data-method");
const createStartRendering = (audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds)=>{
    return (destination, nativeOfflineAudioContext)=>getAudioNodeRenderer(destination).render(destination, nativeOfflineAudioContext)/*
         * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to the
         * destination.
         */ .then(()=>Promise.all(Array.from(getUnrenderedAudioWorkletNodes(nativeOfflineAudioContext)).map((audioWorkletNode)=>getAudioNodeRenderer(audioWorkletNode).render(audioWorkletNode, nativeOfflineAudioContext)))).then(()=>renderNativeOfflineAudioContext(nativeOfflineAudioContext)).then((audioBuffer)=>{
            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
            // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
            if (typeof audioBuffer.copyFromChannel !== "function") {
                wrapAudioBufferCopyChannelMethods(audioBuffer);
                (0, _wrapAudioBufferGetChannelDataMethod.wrapAudioBufferGetChannelDataMethod)(audioBuffer);
            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
            } else if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, ()=>testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
            audioBufferStore.add(audioBuffer);
            return audioBuffer;
        });
};

},{"../helpers/wrap-audio-buffer-get-channel-data-method":"bXfRI","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gc2rO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createStereoPannerNodeConstructor", ()=>createStereoPannerNodeConstructor);
const DEFAULT_OPTIONS = {
    channelCount: 2,
    /*
     * Bug #105: The channelCountMode should be 'clamped-max' according to the spec but is set to 'explicit' to achieve consistent
     * behavior.
     */ channelCountMode: "explicit",
    channelInterpretation: "speakers",
    pan: 0
};
const createStereoPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext)=>{
    return class StereoPannerNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeStereoPannerNode = createNativeStereoPannerNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const stereoPannerNodeRenderer = isOffline ? createStereoPannerNodeRenderer() : null;
            super(context, false, nativeStereoPannerNode, stereoPannerNodeRenderer);
            this._pan = createAudioParam(this, isOffline, nativeStereoPannerNode.pan);
        }
        get pan() {
            return this._pan;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dAPan":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createStereoPannerNodeRendererFactory", ()=>createStereoPannerNodeRendererFactory);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createStereoPannerNodeRendererFactory = (connectAudioParam, createNativeStereoPannerNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeStereoPannerNodes = new WeakMap();
        const createStereoPannerNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeStereoPannerNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeStereoPannerNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeStereoPannerNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeStereoPannerNode, nativeOfflineAudioContext);
            if (!nativeStereoPannerNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeStereoPannerNode.channelCount,
                    channelCountMode: nativeStereoPannerNode.channelCountMode,
                    channelInterpretation: nativeStereoPannerNode.channelInterpretation,
                    pan: nativeStereoPannerNode.pan.value
                };
                nativeStereoPannerNode = createNativeStereoPannerNode(nativeOfflineAudioContext, options);
            }
            renderedNativeStereoPannerNodes.set(nativeOfflineAudioContext, nativeStereoPannerNode);
            if (!nativeStereoPannerNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan);
            if ((0, _nativeAudioNodeFaker.isNativeAudioNodeFaker)(nativeStereoPannerNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode.inputs[0]);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode);
            return nativeStereoPannerNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeStereoPannerNode = renderedNativeStereoPannerNodes.get(nativeOfflineAudioContext);
                if (renderedNativeStereoPannerNode !== undefined) return Promise.resolve(renderedNativeStereoPannerNode);
                return createStereoPannerNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../guards/native-audio-node-faker":"fNQvH","../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"60xJt":[function(require,module,exports) {
// Bug #33: Safari exposes an AudioBuffer but it can't be used as a constructor.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioBufferConstructorSupport", ()=>createTestAudioBufferConstructorSupport);
const createTestAudioBufferConstructorSupport = (nativeAudioBufferConstructor)=>{
    return ()=>{
        if (nativeAudioBufferConstructor === null) return false;
        try {
            new nativeAudioBufferConstructor({
                length: 1,
                sampleRate: 44100
            }); // tslint:disable-line:no-unused-expression
        } catch  {
            return false;
        }
        return true;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fDZlv":[function(require,module,exports) {
/*
 * Firefox up to version 67 didn't fully support the copyFromChannel() and copyToChannel() methods. Therefore testing one of those methods
 * is enough to know if the other one is supported as well.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioBufferCopyChannelMethodsSubarraySupport", ()=>createTestAudioBufferCopyChannelMethodsSubarraySupport);
const createTestAudioBufferCopyChannelMethodsSubarraySupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeAudioBuffer = nativeOfflineAudioContext.createBuffer(1, 1, 44100);
        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
        if (nativeAudioBuffer.copyToChannel === undefined) return true;
        const source = new Float32Array(2);
        try {
            nativeAudioBuffer.copyFromChannel(source, 0, 0);
        } catch  {
            return false;
        }
        return true;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k9nLI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioContextCloseMethodSupport", ()=>createTestAudioContextCloseMethodSupport);
const createTestAudioContextCloseMethodSupport = (nativeAudioContextConstructor)=>{
    return ()=>{
        if (nativeAudioContextConstructor === null) return false;
        // Try to check the prototype before constructing the AudioContext.
        if (nativeAudioContextConstructor.prototype !== undefined && nativeAudioContextConstructor.prototype.close !== undefined) return true;
        const audioContext = new nativeAudioContextConstructor();
        const isAudioContextClosable = audioContext.close !== undefined;
        try {
            audioContext.close();
        } catch  {
        // Ignore errors.
        }
        return isAudioContextClosable;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8SGZm":[function(require,module,exports) {
/**
 * Edge up to version 14, Firefox up to version 52, Safari up to version 9 and maybe other browsers
 * did not refuse to decode invalid parameters with a TypeError.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioContextDecodeAudioDataMethodTypeErrorSupport", ()=>createTestAudioContextDecodeAudioDataMethodTypeErrorSupport);
const createTestAudioContextDecodeAudioDataMethodTypeErrorSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return Promise.resolve(false);
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        // Bug #21: Safari does not support promises yet.
        return new Promise((resolve)=>{
            let isPending = true;
            const resolvePromise = (err)=>{
                if (isPending) {
                    isPending = false;
                    offlineAudioContext.startRendering();
                    resolve(err instanceof TypeError);
                }
            };
            let promise;
            // Bug #26: Safari throws a synchronous error.
            try {
                promise = offlineAudioContext// Bug #1: Safari requires a successCallback.
                .decodeAudioData(null, ()=>{
                // Ignore the success callback.
                }, resolvePromise);
            } catch (err) {
                resolvePromise(err);
            }
            // Bug #21: Safari does not support promises yet.
            if (promise !== undefined) // Bug #6: Chrome, Edge and Firefox do not call the errorCallback.
            promise.catch(resolvePromise);
        });
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5NBS1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioContextOptionsSupport", ()=>createTestAudioContextOptionsSupport);
const createTestAudioContextOptionsSupport = (nativeAudioContextConstructor)=>{
    return ()=>{
        if (nativeAudioContextConstructor === null) return false;
        let audioContext;
        try {
            audioContext = new nativeAudioContextConstructor({
                latencyHint: "balanced"
            });
        } catch  {
            return false;
        }
        audioContext.close();
        return true;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4ontN":[function(require,module,exports) {
// Safari up to version 12.0 (but not v12.1) didn't return the destination in case it was an AudioNode.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioNodeConnectMethodSupport", ()=>createTestAudioNodeConnectMethodSupport);
const createTestAudioNodeConnectMethodSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeGainNode = nativeOfflineAudioContext.createGain();
        const isSupported = nativeGainNode.connect(nativeGainNode) === nativeGainNode;
        nativeGainNode.disconnect(nativeGainNode);
        return isSupported;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"baMs2":[function(require,module,exports) {
/**
 * Chrome version 66 and 67 did not call the process() function of an AudioWorkletProcessor if it had no outputs. AudioWorklet support was
 * enabled by default in version 66.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioWorkletProcessorNoOutputsSupport", ()=>createTestAudioWorkletProcessorNoOutputsSupport);
const createTestAudioWorkletProcessorNoOutputsSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor)=>{
    return async ()=>{
        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.
        if (nativeAudioWorkletNodeConstructor === null) return true;
        if (nativeOfflineAudioContextConstructor === null) return false;
        const blob = new Blob([
            'let c,p;class A extends AudioWorkletProcessor{constructor(){super();this.port.onmessage=(e)=>{p=e.data;p.onmessage=()=>{p.postMessage(c);p.close()};this.port.postMessage(0)}}process(){c=1}}registerProcessor("a",A)'
        ], {
            type: "application/javascript; charset=utf-8"
        });
        const messageChannel = new MessageChannel();
        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 44100);
        const url = URL.createObjectURL(blob);
        let isCallingProcess = false;
        try {
            await offlineAudioContext.audioWorklet.addModule(url);
            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, "a", {
                numberOfOutputs: 0
            });
            const oscillator = offlineAudioContext.createOscillator();
            await new Promise((resolve)=>{
                audioWorkletNode.port.onmessage = ()=>resolve();
                audioWorkletNode.port.postMessage(messageChannel.port2, [
                    messageChannel.port2
                ]);
            });
            audioWorkletNode.port.onmessage = ()=>isCallingProcess = true;
            oscillator.connect(audioWorkletNode);
            oscillator.start(0);
            await offlineAudioContext.startRendering();
            isCallingProcess = await new Promise((resolve)=>{
                messageChannel.port1.onmessage = ({ data })=>resolve(data === 1);
                messageChannel.port1.postMessage(0);
            });
        } catch  {
        // Ignore errors.
        } finally{
            messageChannel.port1.close();
            URL.revokeObjectURL(url);
        }
        return isCallingProcess;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"47G9e":[function(require,module,exports) {
// Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioWorkletProcessorPostMessageSupport", ()=>createTestAudioWorkletProcessorPostMessageSupport);
const createTestAudioWorkletProcessorPostMessageSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor)=>{
    return async ()=>{
        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.
        if (nativeAudioWorkletNodeConstructor === null) return true;
        if (nativeOfflineAudioContextConstructor === null) return false;
        const blob = new Blob([
            'class A extends AudioWorkletProcessor{process(i){this.port.postMessage(i,[i[0][0].buffer])}}registerProcessor("a",A)'
        ], {
            type: "application/javascript; charset=utf-8"
        });
        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 44100);
        const url = URL.createObjectURL(blob);
        let isEmittingMessageEvents = false;
        let isEmittingProcessorErrorEvents = false;
        try {
            await offlineAudioContext.audioWorklet.addModule(url);
            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, "a", {
                numberOfOutputs: 0
            });
            const oscillator = offlineAudioContext.createOscillator();
            audioWorkletNode.port.onmessage = ()=>isEmittingMessageEvents = true;
            audioWorkletNode.onprocessorerror = ()=>isEmittingProcessorErrorEvents = true;
            oscillator.connect(audioWorkletNode);
            oscillator.start(0);
            await offlineAudioContext.startRendering();
            // Bug #197: Safari does not deliver the messages before the promise returned by startRendering() resolves.
            await new Promise((resolve)=>setTimeout(resolve));
        } catch  {
        // Ignore errors.
        } finally{
            URL.revokeObjectURL(url);
        }
        return isEmittingMessageEvents && !isEmittingProcessorErrorEvents;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"X0MIV":[function(require,module,exports) {
/**
 * Firefox up to version 69 did not throw an error when setting a different channelCount or channelCountMode.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestChannelMergerNodeChannelCountSupport", ()=>createTestChannelMergerNodeChannelCountSupport);
const createTestChannelMergerNodeChannelCountSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeChannelMergerNode = offlineAudioContext.createChannelMerger();
        /**
         * Bug #15: Safari does not return the default properties. It still needs to be patched. This test is supposed to test the support
         * in other browsers.
         */ if (nativeChannelMergerNode.channelCountMode === "max") return true;
        try {
            nativeChannelMergerNode.channelCount = 2;
        } catch  {
            return true;
        }
        return false;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dl03N":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestConstantSourceNodeAccurateSchedulingSupport", ()=>createTestConstantSourceNodeAccurateSchedulingSupport);
const createTestConstantSourceNodeAccurateSchedulingSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        // Bug #62: Safari does not support ConstantSourceNodes.
        if (nativeOfflineAudioContext.createConstantSource === undefined) return true;
        const nativeConstantSourceNode = nativeOfflineAudioContext.createConstantSource();
        /*
         * @todo This is using bug #75 to detect bug #70. That works because both bugs were unique to
         * the implementation of Firefox right now, but it could probably be done in a better way.
         */ return nativeConstantSourceNode.offset.maxValue !== Number.POSITIVE_INFINITY;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5yl0D":[function(require,module,exports) {
// Opera up to version 57 did not allow to reassign the buffer of a ConvolverNode.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestConvolverNodeBufferReassignabilitySupport", ()=>createTestConvolverNodeBufferReassignabilitySupport);
const createTestConvolverNodeBufferReassignabilitySupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeConvolverNode = offlineAudioContext.createConvolver();
        nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);
        try {
            nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);
        } catch  {
            return false;
        }
        return true;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gM3PR":[function(require,module,exports) {
// Chrome up to version v80, Edge up to version v80 and Opera up to version v67 did not allow to set the channelCount property of a ConvolverNode to 1. They also did not allow to set the channelCountMode to 'explicit'.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestConvolverNodeChannelCountSupport", ()=>createTestConvolverNodeChannelCountSupport);
const createTestConvolverNodeChannelCountSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeConvolverNode = offlineAudioContext.createConvolver();
        try {
            nativeConvolverNode.channelCount = 1;
        } catch  {
            return false;
        }
        return true;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"amjh7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestIsSecureContextSupport", ()=>createTestIsSecureContextSupport);
const createTestIsSecureContextSupport = (window)=>{
    return ()=>window !== null && window.hasOwnProperty("isSecureContext");
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bfbzD":[function(require,module,exports) {
// Firefox up to version 68 did not throw an error when creating a MediaStreamAudioSourceNode with a mediaStream that had no audio track.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport", ()=>createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport);
const createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport = (nativeAudioContextConstructor)=>{
    return ()=>{
        if (nativeAudioContextConstructor === null) return false;
        const audioContext = new nativeAudioContextConstructor();
        try {
            audioContext.createMediaStreamSource(new MediaStream());
            return false;
        } catch (err) {
            return true;
        } finally{
            audioContext.close();
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5xrL5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestOfflineAudioContextCurrentTimeSupport", ()=>createTestOfflineAudioContextCurrentTimeSupport);
const createTestOfflineAudioContextCurrentTimeSupport = (createNativeGainNode, nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return Promise.resolve(false);
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        // Bug #48: Safari does not render an OfflineAudioContext without any connected node.
        const gainNode = createNativeGainNode(nativeOfflineAudioContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            gain: 0
        });
        // Bug #21: Safari does not support promises yet.
        return new Promise((resolve)=>{
            nativeOfflineAudioContext.oncomplete = ()=>{
                gainNode.disconnect();
                resolve(nativeOfflineAudioContext.currentTime !== 0);
            };
            nativeOfflineAudioContext.startRendering();
        });
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eG97H":[function(require,module,exports) {
/**
 * Firefox up to version 62 did not kick off the processing of the StereoPannerNode if the value of pan was zero.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestStereoPannerNodeDefaultValueSupport", ()=>createTestStereoPannerNodeDefaultValueSupport);
const createTestStereoPannerNodeDefaultValueSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return Promise.resolve(false);
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        /*
         * Bug #105: Safari does not support the StereoPannerNode. Therefore the returned value should normally be false but the faker does
         * support the tested behaviour.
         */ if (nativeOfflineAudioContext.createStereoPanner === undefined) return Promise.resolve(true);
        // Bug #62: Safari does not support ConstantSourceNodes.
        if (nativeOfflineAudioContext.createConstantSource === undefined) return Promise.resolve(true);
        const constantSourceNode = nativeOfflineAudioContext.createConstantSource();
        const stereoPanner = nativeOfflineAudioContext.createStereoPanner();
        constantSourceNode.channelCount = 1;
        constantSourceNode.offset.value = 1;
        stereoPanner.channelCount = 1;
        constantSourceNode.start();
        constantSourceNode.connect(stereoPanner).connect(nativeOfflineAudioContext.destination);
        return nativeOfflineAudioContext.startRendering().then((buffer)=>buffer.getChannelData(0)[0] !== 1);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"Vr3Lh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createUnknownError", ()=>createUnknownError);
const createUnknownError = ()=>new DOMException("", "UnknownError");

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1yyiX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWaveShaperNodeConstructor", ()=>createWaveShaperNodeConstructor);
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    curve: null,
    oversample: "none"
};
const createWaveShaperNodeConstructor = (audioNodeConstructor, createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class WaveShaperNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeWaveShaperNode = createNativeWaveShaperNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const waveShaperNodeRenderer = isOffline ? createWaveShaperNodeRenderer() : null;
            // @todo Add a mechanism to only switch a WaveShaperNode to active while it is connected.
            super(context, true, nativeWaveShaperNode, waveShaperNodeRenderer);
            this._isCurveNullified = false;
            this._nativeWaveShaperNode = nativeWaveShaperNode;
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        get curve() {
            if (this._isCurveNullified) return null;
            return this._nativeWaveShaperNode.curve;
        }
        set curve(value) {
            // Bug #103: Safari does not allow to set the curve to null.
            if (value === null) {
                this._isCurveNullified = true;
                this._nativeWaveShaperNode.curve = new Float32Array([
                    0,
                    0
                ]);
            } else {
                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.
                // Bug #104: Chrome and Edge will throw an InvalidAccessError when the curve has less than two samples.
                if (value.length < 2) throw createInvalidStateError();
                this._isCurveNullified = false;
                this._nativeWaveShaperNode.curve = value;
            }
        }
        get oversample() {
            return this._nativeWaveShaperNode.oversample;
        }
        set oversample(value) {
            this._nativeWaveShaperNode.oversample = value;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8vhCu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWaveShaperNodeRendererFactory", ()=>createWaveShaperNodeRendererFactory);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createWaveShaperNodeRendererFactory = (createNativeWaveShaperNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeWaveShaperNodes = new WeakMap();
        const createWaveShaperNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeWaveShaperNode = getNativeAudioNode(proxy);
            // If the initially used nativeWaveShaperNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeWaveShaperNodeIsOwnedByContext = (0, _isOwnedByContext.isOwnedByContext)(nativeWaveShaperNode, nativeOfflineAudioContext);
            if (!nativeWaveShaperNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeWaveShaperNode.channelCount,
                    channelCountMode: nativeWaveShaperNode.channelCountMode,
                    channelInterpretation: nativeWaveShaperNode.channelInterpretation,
                    curve: nativeWaveShaperNode.curve,
                    oversample: nativeWaveShaperNode.oversample
                };
                nativeWaveShaperNode = createNativeWaveShaperNode(nativeOfflineAudioContext, options);
            }
            renderedNativeWaveShaperNodes.set(nativeOfflineAudioContext, nativeWaveShaperNode);
            if ((0, _nativeAudioNodeFaker.isNativeAudioNodeFaker)(nativeWaveShaperNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode.inputs[0]);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode);
            return nativeWaveShaperNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeWaveShaperNode = renderedNativeWaveShaperNodes.get(nativeOfflineAudioContext);
                if (renderedNativeWaveShaperNode !== undefined) return Promise.resolve(renderedNativeWaveShaperNode);
                return createWaveShaperNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};

},{"../guards/native-audio-node-faker":"fNQvH","../helpers/is-owned-by-context":"1Rud3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dEK7L":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWindow", ()=>createWindow);
const createWindow = ()=>typeof window === "undefined" ? null : window;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bNAxX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWrapAudioBufferCopyChannelMethods", ()=>createWrapAudioBufferCopyChannelMethods);
const createWrapAudioBufferCopyChannelMethods = (convertNumberToUnsignedLong, createIndexSizeError)=>{
    return (audioBuffer)=>{
        audioBuffer.copyFromChannel = (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
            if (channelNumber >= audioBuffer.numberOfChannels) throw createIndexSizeError();
            const audioBufferLength = audioBuffer.length;
            const channelData = audioBuffer.getChannelData(channelNumber);
            const destinationLength = destination.length;
            for(let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < destinationLength; i += 1)destination[i] = channelData[i + bufferOffset];
        };
        audioBuffer.copyToChannel = (source, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
            if (channelNumber >= audioBuffer.numberOfChannels) throw createIndexSizeError();
            const audioBufferLength = audioBuffer.length;
            const channelData = audioBuffer.getChannelData(channelNumber);
            const sourceLength = source.length;
            for(let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < sourceLength; i += 1)channelData[i + bufferOffset] = source[i];
        };
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4XNvu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWrapAudioBufferCopyChannelMethodsOutOfBounds", ()=>createWrapAudioBufferCopyChannelMethodsOutOfBounds);
const createWrapAudioBufferCopyChannelMethodsOutOfBounds = (convertNumberToUnsignedLong)=>{
    return (audioBuffer)=>{
        audioBuffer.copyFromChannel = ((copyFromChannel)=>{
            return (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
                if (bufferOffset < audioBuffer.length) return copyFromChannel.call(audioBuffer, destination, channelNumber, bufferOffset);
            };
        })(audioBuffer.copyFromChannel);
        audioBuffer.copyToChannel = ((copyToChannel)=>{
            return (source, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
                if (bufferOffset < audioBuffer.length) return copyToChannel.call(audioBuffer, source, channelNumber, bufferOffset);
            };
        })(audioBuffer.copyToChannel);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ckaEw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer", ()=>createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer);
const createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer = (overwriteAccessors)=>{
    return (nativeAudioBufferSourceNode, nativeContext)=>{
        const nullifiedBuffer = nativeContext.createBuffer(1, 1, 44100);
        if (nativeAudioBufferSourceNode.buffer === null) nativeAudioBufferSourceNode.buffer = nullifiedBuffer;
        overwriteAccessors(nativeAudioBufferSourceNode, "buffer", (get)=>()=>{
                const value = get.call(nativeAudioBufferSourceNode);
                return value === nullifiedBuffer ? null : value;
            }, (set)=>(value)=>{
                return set.call(nativeAudioBufferSourceNode, value === null ? nullifiedBuffer : value);
            });
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8txzE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWrapChannelMergerNode", ()=>createWrapChannelMergerNode);
const createWrapChannelMergerNode = (createInvalidStateError, monitorConnections)=>{
    return (nativeContext, channelMergerNode)=>{
        // Bug #15: Safari does not return the default properties.
        channelMergerNode.channelCount = 1;
        channelMergerNode.channelCountMode = "explicit";
        // Bug #16: Safari does not throw an error when setting a different channelCount or channelCountMode.
        Object.defineProperty(channelMergerNode, "channelCount", {
            get: ()=>1,
            set: ()=>{
                throw createInvalidStateError();
            }
        });
        Object.defineProperty(channelMergerNode, "channelCountMode", {
            get: ()=>"explicit",
            set: ()=>{
                throw createInvalidStateError();
            }
        });
        // Bug #20: Safari requires a connection of any kind to treat the input signal correctly.
        const audioBufferSourceNode = nativeContext.createBufferSource();
        const whenConnected = ()=>{
            const length = channelMergerNode.numberOfInputs;
            for(let i = 0; i < length; i += 1)audioBufferSourceNode.connect(channelMergerNode, 0, i);
        };
        const whenDisconnected = ()=>audioBufferSourceNode.disconnect(channelMergerNode);
        monitorConnections(channelMergerNode, whenConnected, whenDisconnected);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lprXE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getFirstSample", ()=>getFirstSample);
const getFirstSample = (audioBuffer, buffer, channelNumber)=>{
    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
    if (audioBuffer.copyFromChannel === undefined) return audioBuffer.getChannelData(channelNumber)[0];
    audioBuffer.copyFromChannel(buffer, channelNumber);
    return buffer[0];
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1AlFj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isDCCurve", ()=>isDCCurve);
const isDCCurve = (curve)=>{
    if (curve === null) return false;
    const length = curve.length;
    if (length % 2 !== 0) return curve[Math.floor(length / 2)] !== 0;
    return curve[length / 2 - 1] + curve[length / 2] !== 0;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hfSZZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "overwriteAccessors", ()=>overwriteAccessors);
const overwriteAccessors = (object, property, createGetter, createSetter)=>{
    let prototype = object;
    while(!prototype.hasOwnProperty(property))prototype = Object.getPrototypeOf(prototype);
    const { get, set } = Object.getOwnPropertyDescriptor(prototype, property);
    Object.defineProperty(object, property, {
        get: createGetter(get),
        set: createSetter(set)
    });
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"T7Ytc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "sanitizeAudioWorkletNodeOptions", ()=>sanitizeAudioWorkletNodeOptions);
const sanitizeAudioWorkletNodeOptions = (options)=>{
    return {
        ...options,
        outputChannelCount: options.outputChannelCount !== undefined ? options.outputChannelCount : options.numberOfInputs === 1 && options.numberOfOutputs === 1 ? /*
                   * Bug #61: This should be the computedNumberOfChannels, but unfortunately that is almost impossible to fake. That's why
                   * the channelCountMode is required to be 'explicit' as long as there is not a native implementation in every browser. That
                   * makes sure the computedNumberOfChannels is equivilant to the channelCount which makes it much easier to compute.
                   */ [
            options.channelCount
        ] : Array.from({
            length: options.numberOfOutputs
        }, ()=>1)
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eYcVh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "sanitizeChannelSplitterOptions", ()=>sanitizeChannelSplitterOptions);
const sanitizeChannelSplitterOptions = (options)=>{
    return {
        ...options,
        channelCount: options.numberOfOutputs
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2uUdY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "sanitizePeriodicWaveOptions", ()=>sanitizePeriodicWaveOptions);
const sanitizePeriodicWaveOptions = (options)=>{
    const { imag, real } = options;
    if (imag === undefined) {
        if (real === undefined) return {
            ...options,
            imag: [
                0,
                0
            ],
            real: [
                0,
                0
            ]
        };
        return {
            ...options,
            imag: Array.from(real, ()=>0),
            real
        };
    }
    if (real === undefined) return {
        ...options,
        imag,
        real: Array.from(imag, ()=>0)
    };
    return {
        ...options,
        imag,
        real
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"U9WdO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "setValueAtTimeUntilPossible", ()=>setValueAtTimeUntilPossible);
const setValueAtTimeUntilPossible = (audioParam, value, startTime)=>{
    try {
        audioParam.setValueAtTime(value, startTime);
    } catch (err) {
        if (err.code !== 9) throw err;
        setValueAtTimeUntilPossible(audioParam, value, startTime + 1e-7);
    }
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"d1Bp3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport", ()=>testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport);
const testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    nativeAudioBufferSourceNode.start();
    try {
        nativeAudioBufferSourceNode.start();
    } catch  {
        return true;
    }
    return false;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ljLh5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioBufferSourceNodeStartMethodOffsetClampingSupport", ()=>testAudioBufferSourceNodeStartMethodOffsetClampingSupport);
const testAudioBufferSourceNodeStartMethodOffsetClampingSupport = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);
    nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
    try {
        nativeAudioBufferSourceNode.start(0, 1);
    } catch  {
        return false;
    }
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1AlzI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioBufferSourceNodeStopMethodNullifiedBufferSupport", ()=>testAudioBufferSourceNodeStopMethodNullifiedBufferSupport);
const testAudioBufferSourceNodeStopMethodNullifiedBufferSupport = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    nativeAudioBufferSourceNode.start();
    try {
        nativeAudioBufferSourceNode.stop();
    } catch  {
        return false;
    }
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iXOCC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioScheduledSourceNodeStartMethodNegativeParametersSupport", ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport);
const testAudioScheduledSourceNodeStartMethodNegativeParametersSupport = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createOscillator();
    try {
        nativeAudioBufferSourceNode.start(-1);
    } catch (err) {
        return err instanceof RangeError;
    }
    return false;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6HMSy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport", ()=>testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport);
const testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport = (nativeContext)=>{
    const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
    nativeAudioBufferSourceNode.start();
    nativeAudioBufferSourceNode.stop();
    try {
        nativeAudioBufferSourceNode.stop();
        return true;
    } catch  {
        return false;
    }
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3eDpC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioScheduledSourceNodeStopMethodNegativeParametersSupport", ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport);
const testAudioScheduledSourceNodeStopMethodNegativeParametersSupport = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createOscillator();
    try {
        nativeAudioBufferSourceNode.stop(-1);
    } catch (err) {
        return err instanceof RangeError;
    }
    return false;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cKeDz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioWorkletNodeOptionsClonability", ()=>testAudioWorkletNodeOptionsClonability);
const testAudioWorkletNodeOptionsClonability = (audioWorkletNodeOptions)=>{
    const { port1, port2 } = new MessageChannel();
    try {
        // This will throw an error if the audioWorkletNodeOptions are not clonable.
        port1.postMessage(audioWorkletNodeOptions);
    } finally{
        port1.close();
        port2.close();
    }
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4CH46":[function(require,module,exports) {
/*
 * Bug #122: Edge up to version v18 did not allow to construct a DOMException'. It also had a couple more bugs but since this is easy to
 * test it's used here as a placeholder.
 *
 * Bug #27: Edge up to version v18 did reject an invalid arrayBuffer passed to decodeAudioData() with a DOMException.
 *
 * Bug #50: Edge up to version v18 did not allow to create AudioNodes on a closed context.
 *
 * Bug #57: Edge up to version v18 did not throw an error when assigning the type of an OscillatorNode to 'custom'.
 *
 * Bug #63: Edge up to version v18 did not expose the mediaElement property of a MediaElementAudioSourceNode.
 *
 * Bug #64: Edge up to version v18 did not support the MediaStreamAudioDestinationNode.
 *
 * Bug #71: Edge up to version v18 did not allow to set the buffer of an AudioBufferSourceNode to null.
 *
 * Bug #93: Edge up to version v18 did set the sampleRate of an AudioContext to zero when it was closed.
 *
 * Bug #101: Edge up to version v18 refused to execute decodeAudioData() on a closed context.
 *
 * Bug #106: Edge up to version v18 did not expose the maxValue and minValue properties of the pan AudioParam of a StereoPannerNode.
 *
 * Bug #110: Edge up to version v18 did not expose the maxValue and minValue properties of the attack, knee, ratio, release and threshold AudioParams of a DynamicsCompressorNode.
 *
 * Bug #123: Edge up to version v18 did not support HRTF as the panningModel for a PannerNode.
 *
 * Bug #145: Edge up to version v18 did throw an IndexSizeError when an OfflineAudioContext was created with a sampleRate of zero.
 *
 * Bug #161: Edge up to version v18 did not expose the maxValue and minValue properties of the delayTime AudioParam of a DelayNode.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testDomExceptionConstructorSupport", ()=>testDomExceptionConstructorSupport);
const testDomExceptionConstructorSupport = ()=>{
    try {
        new DOMException(); // tslint:disable-line:no-unused-expression
    } catch  {
        return false;
    }
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5nYF9":[function(require,module,exports) {
// Safari at version 11 did not support transferables.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testTransferablesSupport", ()=>testTransferablesSupport);
const testTransferablesSupport = ()=>new Promise((resolve)=>{
        const arrayBuffer = new ArrayBuffer(0);
        const { port1, port2 } = new MessageChannel();
        port1.onmessage = ({ data })=>resolve(data !== null);
        port2.postMessage(arrayBuffer, [
            arrayBuffer
        ]);
    });

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cWWvc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioBufferSourceNodeStartMethodOffsetClamping", ()=>wrapAudioBufferSourceNodeStartMethodOffsetClamping);
const wrapAudioBufferSourceNodeStartMethodOffsetClamping = (nativeAudioBufferSourceNode)=>{
    nativeAudioBufferSourceNode.start = ((start)=>{
        return (when = 0, offset = 0, duration)=>{
            const buffer = nativeAudioBufferSourceNode.buffer;
            // Bug #154: Safari does not clamp the offset if it is equal to or greater than the duration of the buffer.
            const clampedOffset = buffer === null ? offset : Math.min(buffer.duration, offset);
            // Bug #155: Safari does not handle the offset correctly if it would cause the buffer to be not be played at all.
            if (buffer !== null && clampedOffset > buffer.duration - 0.5 / nativeAudioBufferSourceNode.context.sampleRate) start.call(nativeAudioBufferSourceNode, when, 0, 0);
            else start.call(nativeAudioBufferSourceNode, when, clampedOffset, duration);
        };
    })(nativeAudioBufferSourceNode.start);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fZgIG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls", ()=>wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);
var _interceptConnections = require("./intercept-connections");
const wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls = (nativeAudioScheduledSourceNode, nativeContext)=>{
    const nativeGainNode = nativeContext.createGain();
    nativeAudioScheduledSourceNode.connect(nativeGainNode);
    const disconnectGainNode = ((disconnect)=>{
        return ()=>{
            // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.
            disconnect.call(nativeAudioScheduledSourceNode, nativeGainNode);
            nativeAudioScheduledSourceNode.removeEventListener("ended", disconnectGainNode);
        };
    })(nativeAudioScheduledSourceNode.disconnect);
    nativeAudioScheduledSourceNode.addEventListener("ended", disconnectGainNode);
    (0, _interceptConnections.interceptConnections)(nativeAudioScheduledSourceNode, nativeGainNode);
    nativeAudioScheduledSourceNode.stop = ((stop)=>{
        let isStopped = false;
        return (when = 0)=>{
            if (isStopped) try {
                stop.call(nativeAudioScheduledSourceNode, when);
            } catch  {
                nativeGainNode.gain.setValueAtTime(0, when);
            }
            else {
                stop.call(nativeAudioScheduledSourceNode, when);
                isStopped = true;
            }
        };
    })(nativeAudioScheduledSourceNode.stop);
};

},{"./intercept-connections":"jvEjr","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gbqed":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapEventListener", ()=>wrapEventListener);
const wrapEventListener = (target, eventListener)=>{
    return (event)=>{
        const descriptor = {
            value: target
        };
        Object.defineProperties(event, {
            currentTarget: descriptor,
            target: descriptor
        });
        if (typeof eventListener === "function") return eventListener.call(target, event);
        return eventListener.handleEvent.call(target, event);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bFhB6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _analyserNode = require("./analyser-node");
parcelHelpers.exportAll(_analyserNode, exports);
var _analyserOptions = require("./analyser-options");
parcelHelpers.exportAll(_analyserOptions, exports);
var _audioBuffer = require("./audio-buffer");
parcelHelpers.exportAll(_audioBuffer, exports);
var _audioBufferOptions = require("./audio-buffer-options");
parcelHelpers.exportAll(_audioBufferOptions, exports);
var _audioBufferSourceNode = require("./audio-buffer-source-node");
parcelHelpers.exportAll(_audioBufferSourceNode, exports);
var _audioBufferSourceNodeRenderer = require("./audio-buffer-source-node-renderer");
parcelHelpers.exportAll(_audioBufferSourceNodeRenderer, exports);
var _audioBufferSourceOptions = require("./audio-buffer-source-options");
parcelHelpers.exportAll(_audioBufferSourceOptions, exports);
var _audioContext = require("./audio-context");
parcelHelpers.exportAll(_audioContext, exports);
var _audioContextOptions = require("./audio-context-options");
parcelHelpers.exportAll(_audioContextOptions, exports);
var _audioDestinationNode = require("./audio-destination-node");
parcelHelpers.exportAll(_audioDestinationNode, exports);
var _audioListener = require("./audio-listener");
parcelHelpers.exportAll(_audioListener, exports);
var _audioNode = require("./audio-node");
parcelHelpers.exportAll(_audioNode, exports);
var _audioNodeOptions = require("./audio-node-options");
parcelHelpers.exportAll(_audioNodeOptions, exports);
var _audioNodeRenderer = require("./audio-node-renderer");
parcelHelpers.exportAll(_audioNodeRenderer, exports);
var _audioParam = require("./audio-param");
parcelHelpers.exportAll(_audioParam, exports);
var _audioParamDescriptor = require("./audio-param-descriptor");
parcelHelpers.exportAll(_audioParamDescriptor, exports);
var _audioParamRenderer = require("./audio-param-renderer");
parcelHelpers.exportAll(_audioParamRenderer, exports);
var _audioScheduledSourceNode = require("./audio-scheduled-source-node");
parcelHelpers.exportAll(_audioScheduledSourceNode, exports);
var _audioScheduledSourceNodeEventMap = require("./audio-scheduled-source-node-event-map");
parcelHelpers.exportAll(_audioScheduledSourceNodeEventMap, exports);
var _audioWorklet = require("./audio-worklet");
parcelHelpers.exportAll(_audioWorklet, exports);
var _audioWorkletNode = require("./audio-worklet-node");
parcelHelpers.exportAll(_audioWorkletNode, exports);
var _audioWorkletNodeEventMap = require("./audio-worklet-node-event-map");
parcelHelpers.exportAll(_audioWorkletNodeEventMap, exports);
var _audioWorkletNodeOptions = require("./audio-worklet-node-options");
parcelHelpers.exportAll(_audioWorkletNodeOptions, exports);
var _audioWorkletProcessor = require("./audio-worklet-processor");
parcelHelpers.exportAll(_audioWorkletProcessor, exports);
var _audioWorkletProcessorConstructor = require("./audio-worklet-processor-constructor");
parcelHelpers.exportAll(_audioWorkletProcessorConstructor, exports);
var _automation = require("./automation");
parcelHelpers.exportAll(_automation, exports);
var _baseAudioContext = require("./base-audio-context");
parcelHelpers.exportAll(_baseAudioContext, exports);
var _biquadFilterNode = require("./biquad-filter-node");
parcelHelpers.exportAll(_biquadFilterNode, exports);
var _biquadFilterOptions = require("./biquad-filter-options");
parcelHelpers.exportAll(_biquadFilterOptions, exports);
var _channelMergerOptions = require("./channel-merger-options");
parcelHelpers.exportAll(_channelMergerOptions, exports);
var _channelSplitterOptions = require("./channel-splitter-options");
parcelHelpers.exportAll(_channelSplitterOptions, exports);
var _commonAudioContext = require("./common-audio-context");
parcelHelpers.exportAll(_commonAudioContext, exports);
var _commonOfflineAudioContext = require("./common-offline-audio-context");
parcelHelpers.exportAll(_commonOfflineAudioContext, exports);
var _constantSourceNode = require("./constant-source-node");
parcelHelpers.exportAll(_constantSourceNode, exports);
var _constantSourceNodeRenderer = require("./constant-source-node-renderer");
parcelHelpers.exportAll(_constantSourceNodeRenderer, exports);
var _constantSourceOptions = require("./constant-source-options");
parcelHelpers.exportAll(_constantSourceOptions, exports);
var _convolverNode = require("./convolver-node");
parcelHelpers.exportAll(_convolverNode, exports);
var _convolverOptions = require("./convolver-options");
parcelHelpers.exportAll(_convolverOptions, exports);
var _delayNode = require("./delay-node");
parcelHelpers.exportAll(_delayNode, exports);
var _delayOptions = require("./delay-options");
parcelHelpers.exportAll(_delayOptions, exports);
var _dynamicsCompressorNode = require("./dynamics-compressor-node");
parcelHelpers.exportAll(_dynamicsCompressorNode, exports);
var _dynamicsCompressorOptions = require("./dynamics-compressor-options");
parcelHelpers.exportAll(_dynamicsCompressorOptions, exports);
var _eventTarget = require("./event-target");
parcelHelpers.exportAll(_eventTarget, exports);
var _gainNode = require("./gain-node");
parcelHelpers.exportAll(_gainNode, exports);
var _gainOptions = require("./gain-options");
parcelHelpers.exportAll(_gainOptions, exports);
var _iirFilterNode = require("./iir-filter-node");
parcelHelpers.exportAll(_iirFilterNode, exports);
var _iirFilterOptions = require("./iir-filter-options");
parcelHelpers.exportAll(_iirFilterOptions, exports);
var _mediaElementAudioSourceNode = require("./media-element-audio-source-node");
parcelHelpers.exportAll(_mediaElementAudioSourceNode, exports);
var _mediaElementAudioSourceOptions = require("./media-element-audio-source-options");
parcelHelpers.exportAll(_mediaElementAudioSourceOptions, exports);
var _mediaStreamAudioDestinationNode = require("./media-stream-audio-destination-node");
parcelHelpers.exportAll(_mediaStreamAudioDestinationNode, exports);
var _mediaStreamAudioSourceNode = require("./media-stream-audio-source-node");
parcelHelpers.exportAll(_mediaStreamAudioSourceNode, exports);
var _mediaStreamAudioSourceOptions = require("./media-stream-audio-source-options");
parcelHelpers.exportAll(_mediaStreamAudioSourceOptions, exports);
var _mediaStreamTrackAudioSourceNode = require("./media-stream-track-audio-source-node");
parcelHelpers.exportAll(_mediaStreamTrackAudioSourceNode, exports);
var _mediaStreamTrackAudioSourceOptions = require("./media-stream-track-audio-source-options");
parcelHelpers.exportAll(_mediaStreamTrackAudioSourceOptions, exports);
var _minimalAudioContext = require("./minimal-audio-context");
parcelHelpers.exportAll(_minimalAudioContext, exports);
var _minimalBaseAudioContext = require("./minimal-base-audio-context");
parcelHelpers.exportAll(_minimalBaseAudioContext, exports);
var _minimalBaseAudioContextEventMap = require("./minimal-base-audio-context-event-map");
parcelHelpers.exportAll(_minimalBaseAudioContextEventMap, exports);
var _minimalOfflineAudioContext = require("./minimal-offline-audio-context");
parcelHelpers.exportAll(_minimalOfflineAudioContext, exports);
var _nativeAudioNodeFaker = require("./native-audio-node-faker");
parcelHelpers.exportAll(_nativeAudioNodeFaker, exports);
var _nativeAudioWorkletNodeFaker = require("./native-audio-worklet-node-faker");
parcelHelpers.exportAll(_nativeAudioWorkletNodeFaker, exports);
var _nativeConstantSourceNodeFaker = require("./native-constant-source-node-faker");
parcelHelpers.exportAll(_nativeConstantSourceNodeFaker, exports);
var _nativeConvolverNodeFaker = require("./native-convolver-node-faker");
parcelHelpers.exportAll(_nativeConvolverNodeFaker, exports);
var _nativeIirFilterNodeFaker = require("./native-iir-filter-node-faker");
parcelHelpers.exportAll(_nativeIirFilterNodeFaker, exports);
var _nativePannerNodeFaker = require("./native-panner-node-faker");
parcelHelpers.exportAll(_nativePannerNodeFaker, exports);
var _nativeStereoPannerNodeFaker = require("./native-stereo-panner-node-faker");
parcelHelpers.exportAll(_nativeStereoPannerNodeFaker, exports);
var _nativeWaveShaperNodeFaker = require("./native-wave-shaper-node-faker");
parcelHelpers.exportAll(_nativeWaveShaperNodeFaker, exports);
var _offlineAudioCompletionEvent = require("./offline-audio-completion-event");
parcelHelpers.exportAll(_offlineAudioCompletionEvent, exports);
var _offlineAudioContext = require("./offline-audio-context");
parcelHelpers.exportAll(_offlineAudioContext, exports);
var _offlineAudioContextConstructor = require("./offline-audio-context-constructor");
parcelHelpers.exportAll(_offlineAudioContextConstructor, exports);
var _offlineAudioContextOptions = require("./offline-audio-context-options");
parcelHelpers.exportAll(_offlineAudioContextOptions, exports);
var _oscillatorNode = require("./oscillator-node");
parcelHelpers.exportAll(_oscillatorNode, exports);
var _oscillatorNodeRenderer = require("./oscillator-node-renderer");
parcelHelpers.exportAll(_oscillatorNodeRenderer, exports);
var _oscillatorOptions = require("./oscillator-options");
parcelHelpers.exportAll(_oscillatorOptions, exports);
var _pannerNode = require("./panner-node");
parcelHelpers.exportAll(_pannerNode, exports);
var _pannerOptions = require("./panner-options");
parcelHelpers.exportAll(_pannerOptions, exports);
var _periodicWave = require("./periodic-wave");
parcelHelpers.exportAll(_periodicWave, exports);
var _periodicWaveConstraints = require("./periodic-wave-constraints");
parcelHelpers.exportAll(_periodicWaveConstraints, exports);
var _periodicWaveOptions = require("./periodic-wave-options");
parcelHelpers.exportAll(_periodicWaveOptions, exports);
var _readOnlyMap = require("./read-only-map");
parcelHelpers.exportAll(_readOnlyMap, exports);
var _stereoPannerNode = require("./stereo-panner-node");
parcelHelpers.exportAll(_stereoPannerNode, exports);
var _stereoPannerOptions = require("./stereo-panner-options");
parcelHelpers.exportAll(_stereoPannerOptions, exports);
var _waveShaperNode = require("./wave-shaper-node");
parcelHelpers.exportAll(_waveShaperNode, exports);
var _waveShaperOptions = require("./wave-shaper-options");
parcelHelpers.exportAll(_waveShaperOptions, exports);
var _workletOptions = require("./worklet-options");
parcelHelpers.exportAll(_workletOptions, exports);

},{"./analyser-node":"irip4","./analyser-options":"407dd","./audio-buffer":"a2w0E","./audio-buffer-options":"gD8ck","./audio-buffer-source-node":"9J14C","./audio-buffer-source-node-renderer":"f5yvE","./audio-buffer-source-options":"jZ5wn","./audio-context":"4Ql4z","./audio-context-options":"11QSu","./audio-destination-node":"j3LIz","./audio-listener":"11DgS","./audio-node":"9zzhW","./audio-node-options":"g2swV","./audio-node-renderer":"iQ9Pl","./audio-param":"6UZJ1","./audio-param-descriptor":"kQb0b","./audio-param-renderer":"bAd4u","./audio-scheduled-source-node":"1nbIX","./audio-scheduled-source-node-event-map":"4IdxY","./audio-worklet":"2E4ZJ","./audio-worklet-node":"kcWfA","./audio-worklet-node-event-map":"huz6R","./audio-worklet-node-options":"59iYS","./audio-worklet-processor":"6nNnx","./audio-worklet-processor-constructor":"i4iuB","./automation":"7wfWd","./base-audio-context":"1XbKq","./biquad-filter-node":"UscWb","./biquad-filter-options":"cij3Z","./channel-merger-options":"gxcH3","./channel-splitter-options":"43KPc","./common-audio-context":"c0JmH","./common-offline-audio-context":"4Pmog","./constant-source-node":"eCJAj","./constant-source-node-renderer":"lYpZI","./constant-source-options":"iIPxE","./convolver-node":"hCspv","./convolver-options":"krqat","./delay-node":"atadQ","./delay-options":"j67fL","./dynamics-compressor-node":"89l7X","./dynamics-compressor-options":"H0ZEh","./event-target":"aiSKu","./gain-node":"5edmh","./gain-options":"j4VY1","./iir-filter-node":"asv13","./iir-filter-options":"5tENB","./media-element-audio-source-node":"h2sLz","./media-element-audio-source-options":"fz1u3","./media-stream-audio-destination-node":"8oYR0","./media-stream-audio-source-node":"c11K0","./media-stream-audio-source-options":"jsSN1","./media-stream-track-audio-source-node":"1gMRH","./media-stream-track-audio-source-options":"cgKHP","./minimal-audio-context":"9aLsN","./minimal-base-audio-context":"csZiK","./minimal-base-audio-context-event-map":"ghppE","./minimal-offline-audio-context":"eDC0X","./native-audio-node-faker":"acR9N","./native-audio-worklet-node-faker":"9VN5k","./native-constant-source-node-faker":"8Hy9s","./native-convolver-node-faker":"f9y0g","./native-iir-filter-node-faker":"aMNEV","./native-panner-node-faker":"85Moa","./native-stereo-panner-node-faker":"4co6d","./native-wave-shaper-node-faker":"ftsUG","./offline-audio-completion-event":"cTUZX","./offline-audio-context":"bm9EH","./offline-audio-context-constructor":"12BiK","./offline-audio-context-options":"dK833","./oscillator-node":"5KTXG","./oscillator-node-renderer":"jvqKZ","./oscillator-options":"hbqza","./panner-node":"nCTIs","./panner-options":"k6EmF","./periodic-wave":"bCDWN","./periodic-wave-constraints":"4La5a","./periodic-wave-options":"1CPtS","./read-only-map":"kERIu","./stereo-panner-node":"2nmF4","./stereo-panner-options":"jDlpZ","./wave-shaper-node":"4RRXg","./wave-shaper-options":"kwmsC","./worklet-options":"aaD13","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"irip4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"407dd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"a2w0E":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gD8ck":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9J14C":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"f5yvE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jZ5wn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4Ql4z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"11QSu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j3LIz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"11DgS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9zzhW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g2swV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iQ9Pl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6UZJ1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kQb0b":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bAd4u":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1nbIX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4IdxY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2E4ZJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kcWfA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"huz6R":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"59iYS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6nNnx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"i4iuB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7wfWd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1XbKq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"UscWb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cij3Z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gxcH3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"43KPc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"c0JmH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4Pmog":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eCJAj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lYpZI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iIPxE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hCspv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"krqat":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"atadQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j67fL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"89l7X":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"H0ZEh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aiSKu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5edmh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j4VY1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"asv13":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5tENB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h2sLz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fz1u3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8oYR0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"c11K0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jsSN1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1gMRH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cgKHP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9aLsN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"csZiK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ghppE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eDC0X":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"acR9N":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9VN5k":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8Hy9s":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"f9y0g":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aMNEV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"85Moa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4co6d":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ftsUG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cTUZX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bm9EH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"12BiK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dK833":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5KTXG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jvqKZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hbqza":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"nCTIs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k6EmF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bCDWN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4La5a":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1CPtS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kERIu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2nmF4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jDlpZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4RRXg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kwmsC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aaD13":[function(require,module,exports) {
// @todo This is currently named IWorkletOptions and not IAudioWorkletOptions because it defines the options of a generic Worklet.
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6tI3M":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _abortErrorFactory = require("./abort-error-factory");
parcelHelpers.exportAll(_abortErrorFactory, exports);
var _activeAudioWorkletNodeInputsStore = require("./active-audio-worklet-node-inputs-store");
parcelHelpers.exportAll(_activeAudioWorkletNodeInputsStore, exports);
var _activeInputConnection = require("./active-input-connection");
parcelHelpers.exportAll(_activeInputConnection, exports);
var _addActiveInputConnectionToAudioNodeFactory = require("./add-active-input-connection-to-audio-node-factory");
parcelHelpers.exportAll(_addActiveInputConnectionToAudioNodeFactory, exports);
var _addActiveInputConnectionToAudioNodeFunction = require("./add-active-input-connection-to-audio-node-function");
parcelHelpers.exportAll(_addActiveInputConnectionToAudioNodeFunction, exports);
var _addAudioNodeConnectionsFactory = require("./add-audio-node-connections-factory");
parcelHelpers.exportAll(_addAudioNodeConnectionsFactory, exports);
var _addAudioNodeConnectionsFunction = require("./add-audio-node-connections-function");
parcelHelpers.exportAll(_addAudioNodeConnectionsFunction, exports);
var _addAudioParamConnectionsFactory = require("./add-audio-param-connections-factory");
parcelHelpers.exportAll(_addAudioParamConnectionsFactory, exports);
var _addAudioParamConnectionsFunction = require("./add-audio-param-connections-function");
parcelHelpers.exportAll(_addAudioParamConnectionsFunction, exports);
var _addAudioWorkletModuleFactory = require("./add-audio-worklet-module-factory");
parcelHelpers.exportAll(_addAudioWorkletModuleFactory, exports);
var _addAudioWorkletModuleFunction = require("./add-audio-worklet-module-function");
parcelHelpers.exportAll(_addAudioWorkletModuleFunction, exports);
var _addConnectionToAudioNodeFactory = require("./add-connection-to-audio-node-factory");
parcelHelpers.exportAll(_addConnectionToAudioNodeFactory, exports);
var _addConnectionToAudioNodeFunction = require("./add-connection-to-audio-node-function");
parcelHelpers.exportAll(_addConnectionToAudioNodeFunction, exports);
var _addPassiveInputConnectionToAudioNodeFactory = require("./add-passive-input-connection-to-audio-node-factory");
parcelHelpers.exportAll(_addPassiveInputConnectionToAudioNodeFactory, exports);
var _addPassiveInputConnectionToAudioNodeFunction = require("./add-passive-input-connection-to-audio-node-function");
parcelHelpers.exportAll(_addPassiveInputConnectionToAudioNodeFunction, exports);
var _addSilentConnectionFactory = require("./add-silent-connection-factory");
parcelHelpers.exportAll(_addSilentConnectionFactory, exports);
var _addSilentConnectionFunction = require("./add-silent-connection-function");
parcelHelpers.exportAll(_addSilentConnectionFunction, exports);
var _addUnrenderedAudioWorkletNodeFactory = require("./add-unrendered-audio-worklet-node-factory");
parcelHelpers.exportAll(_addUnrenderedAudioWorkletNodeFactory, exports);
var _addUnrenderedAudioWorkletNodeFunction = require("./add-unrendered-audio-worklet-node-function");
parcelHelpers.exportAll(_addUnrenderedAudioWorkletNodeFunction, exports);
var _analyserNodeConstructor = require("./analyser-node-constructor");
parcelHelpers.exportAll(_analyserNodeConstructor, exports);
var _analyserNodeConstructorFactory = require("./analyser-node-constructor-factory");
parcelHelpers.exportAll(_analyserNodeConstructorFactory, exports);
var _analyserNodeRendererFactory = require("./analyser-node-renderer-factory");
parcelHelpers.exportAll(_analyserNodeRendererFactory, exports);
var _analyserNodeRendererFactoryFactory = require("./analyser-node-renderer-factory-factory");
parcelHelpers.exportAll(_analyserNodeRendererFactoryFactory, exports);
var _anyAudioBuffer = require("./any-audio-buffer");
parcelHelpers.exportAll(_anyAudioBuffer, exports);
var _anyContext = require("./any-context");
parcelHelpers.exportAll(_anyContext, exports);
var _audioBufferConstructor = require("./audio-buffer-constructor");
parcelHelpers.exportAll(_audioBufferConstructor, exports);
var _audioBufferConstructorFactory = require("./audio-buffer-constructor-factory");
parcelHelpers.exportAll(_audioBufferConstructorFactory, exports);
var _audioBufferSourceNodeConstructor = require("./audio-buffer-source-node-constructor");
parcelHelpers.exportAll(_audioBufferSourceNodeConstructor, exports);
var _audioBufferSourceNodeConstructorFactory = require("./audio-buffer-source-node-constructor-factory");
parcelHelpers.exportAll(_audioBufferSourceNodeConstructorFactory, exports);
var _audioBufferSourceNodeRenderer = require("./audio-buffer-source-node-renderer");
parcelHelpers.exportAll(_audioBufferSourceNodeRenderer, exports);
var _audioBufferSourceNodeRendererFactory = require("./audio-buffer-source-node-renderer-factory");
parcelHelpers.exportAll(_audioBufferSourceNodeRendererFactory, exports);
var _audioBufferSourceNodeRendererFactoryFactory = require("./audio-buffer-source-node-renderer-factory-factory");
parcelHelpers.exportAll(_audioBufferSourceNodeRendererFactoryFactory, exports);
var _audioBufferStore = require("./audio-buffer-store");
parcelHelpers.exportAll(_audioBufferStore, exports);
var _audioContextConstructor = require("./audio-context-constructor");
parcelHelpers.exportAll(_audioContextConstructor, exports);
var _audioContextConstructorFactory = require("./audio-context-constructor-factory");
parcelHelpers.exportAll(_audioContextConstructorFactory, exports);
var _audioContextLatencyCategory = require("./audio-context-latency-category");
parcelHelpers.exportAll(_audioContextLatencyCategory, exports);
var _audioContextState = require("./audio-context-state");
parcelHelpers.exportAll(_audioContextState, exports);
var _audioDestinationNodeConstructor = require("./audio-destination-node-constructor");
parcelHelpers.exportAll(_audioDestinationNodeConstructor, exports);
var _audioDestinationNodeConstructorFactory = require("./audio-destination-node-constructor-factory");
parcelHelpers.exportAll(_audioDestinationNodeConstructorFactory, exports);
var _audioDestinationNodeRendererFactory = require("./audio-destination-node-renderer-factory");
parcelHelpers.exportAll(_audioDestinationNodeRendererFactory, exports);
var _audioListenerFactory = require("./audio-listener-factory");
parcelHelpers.exportAll(_audioListenerFactory, exports);
var _audioListenerFactoryFactory = require("./audio-listener-factory-factory");
parcelHelpers.exportAll(_audioListenerFactoryFactory, exports);
var _audioNodeConnections = require("./audio-node-connections");
parcelHelpers.exportAll(_audioNodeConnections, exports);
var _audioNodeConnectionsStore = require("./audio-node-connections-store");
parcelHelpers.exportAll(_audioNodeConnectionsStore, exports);
var _audioNodeConstructor = require("./audio-node-constructor");
parcelHelpers.exportAll(_audioNodeConstructor, exports);
var _audioNodeConstructorFactory = require("./audio-node-constructor-factory");
parcelHelpers.exportAll(_audioNodeConstructorFactory, exports);
var _audioNodeOutputConnection = require("./audio-node-output-connection");
parcelHelpers.exportAll(_audioNodeOutputConnection, exports);
var _audioNodeRenderer = require("./audio-node-renderer");
parcelHelpers.exportAll(_audioNodeRenderer, exports);
var _audioNodeStore = require("./audio-node-store");
parcelHelpers.exportAll(_audioNodeStore, exports);
var _audioNodeTailTimeStore = require("./audio-node-tail-time-store");
parcelHelpers.exportAll(_audioNodeTailTimeStore, exports);
var _audioParamAudioNodeStore = require("./audio-param-audio-node-store");
parcelHelpers.exportAll(_audioParamAudioNodeStore, exports);
var _audioParamConnections = require("./audio-param-connections");
parcelHelpers.exportAll(_audioParamConnections, exports);
var _audioParamConnectionsStore = require("./audio-param-connections-store");
parcelHelpers.exportAll(_audioParamConnectionsStore, exports);
var _audioParamFactory = require("./audio-param-factory");
parcelHelpers.exportAll(_audioParamFactory, exports);
var _audioParamFactoryFactory = require("./audio-param-factory-factory");
parcelHelpers.exportAll(_audioParamFactoryFactory, exports);
var _audioParamMap = require("./audio-param-map");
parcelHelpers.exportAll(_audioParamMap, exports);
var _audioParamOutputConnection = require("./audio-param-output-connection");
parcelHelpers.exportAll(_audioParamOutputConnection, exports);
var _audioParamRendererFactory = require("./audio-param-renderer-factory");
parcelHelpers.exportAll(_audioParamRendererFactory, exports);
var _audioParamStore = require("./audio-param-store");
parcelHelpers.exportAll(_audioParamStore, exports);
var _audioWorkletNodeConstructor = require("./audio-worklet-node-constructor");
parcelHelpers.exportAll(_audioWorkletNodeConstructor, exports);
var _audioWorkletNodeConstructorFactory = require("./audio-worklet-node-constructor-factory");
parcelHelpers.exportAll(_audioWorkletNodeConstructorFactory, exports);
var _audioWorkletNodeRendererFactory = require("./audio-worklet-node-renderer-factory");
parcelHelpers.exportAll(_audioWorkletNodeRendererFactory, exports);
var _audioWorkletNodeRendererFactoryFactory = require("./audio-worklet-node-renderer-factory-factory");
parcelHelpers.exportAll(_audioWorkletNodeRendererFactoryFactory, exports);
var _backupOfflineAudioContextStore = require("./backup-offline-audio-context-store");
parcelHelpers.exportAll(_backupOfflineAudioContextStore, exports);
var _baseAudioContextConstructor = require("./base-audio-context-constructor");
parcelHelpers.exportAll(_baseAudioContextConstructor, exports);
var _baseAudioContextConstructorFactory = require("./base-audio-context-constructor-factory");
parcelHelpers.exportAll(_baseAudioContextConstructorFactory, exports);
var _biquadFilterNodeConstructor = require("./biquad-filter-node-constructor");
parcelHelpers.exportAll(_biquadFilterNodeConstructor, exports);
var _biquadFilterNodeConstructorFactory = require("./biquad-filter-node-constructor-factory");
parcelHelpers.exportAll(_biquadFilterNodeConstructorFactory, exports);
var _biquadFilterNodeRendererFactory = require("./biquad-filter-node-renderer-factory");
parcelHelpers.exportAll(_biquadFilterNodeRendererFactory, exports);
var _biquadFilterNodeRendererFactoryFactory = require("./biquad-filter-node-renderer-factory-factory");
parcelHelpers.exportAll(_biquadFilterNodeRendererFactoryFactory, exports);
var _biquadFilterType = require("./biquad-filter-type");
parcelHelpers.exportAll(_biquadFilterType, exports);
var _channelCountMode = require("./channel-count-mode");
parcelHelpers.exportAll(_channelCountMode, exports);
var _channelInterpretation = require("./channel-interpretation");
parcelHelpers.exportAll(_channelInterpretation, exports);
var _channelMergerNodeConstructor = require("./channel-merger-node-constructor");
parcelHelpers.exportAll(_channelMergerNodeConstructor, exports);
var _channelMergerNodeConstructorFactory = require("./channel-merger-node-constructor-factory");
parcelHelpers.exportAll(_channelMergerNodeConstructorFactory, exports);
var _channelMergerNodeRendererFactory = require("./channel-merger-node-renderer-factory");
parcelHelpers.exportAll(_channelMergerNodeRendererFactory, exports);
var _channelMergerNodeRendererFactoryFactory = require("./channel-merger-node-renderer-factory-factory");
parcelHelpers.exportAll(_channelMergerNodeRendererFactoryFactory, exports);
var _channelSplitterNodeConstructor = require("./channel-splitter-node-constructor");
parcelHelpers.exportAll(_channelSplitterNodeConstructor, exports);
var _channelSplitterNodeConstructorFactory = require("./channel-splitter-node-constructor-factory");
parcelHelpers.exportAll(_channelSplitterNodeConstructorFactory, exports);
var _channelSplitterNodeRendererFactory = require("./channel-splitter-node-renderer-factory");
parcelHelpers.exportAll(_channelSplitterNodeRendererFactory, exports);
var _channelSplitterNodeRendererFactoryFactory = require("./channel-splitter-node-renderer-factory-factory");
parcelHelpers.exportAll(_channelSplitterNodeRendererFactoryFactory, exports);
var _cacheTestResultFactory = require("./cache-test-result-factory");
parcelHelpers.exportAll(_cacheTestResultFactory, exports);
var _cacheTestResultFunction = require("./cache-test-result-function");
parcelHelpers.exportAll(_cacheTestResultFunction, exports);
var _connectAudioParamFactory = require("./connect-audio-param-factory");
parcelHelpers.exportAll(_connectAudioParamFactory, exports);
var _connectAudioParamFunction = require("./connect-audio-param-function");
parcelHelpers.exportAll(_connectAudioParamFunction, exports);
var _connectMultipleOutputsFactory = require("./connect-multiple-outputs-factory");
parcelHelpers.exportAll(_connectMultipleOutputsFactory, exports);
var _connectMultipleOutputsFunction = require("./connect-multiple-outputs-function");
parcelHelpers.exportAll(_connectMultipleOutputsFunction, exports);
var _connectNativeAudioNodeToNativeAudioNodeFunction = require("./connect-native-audio-node-to-native-audio-node-function");
parcelHelpers.exportAll(_connectNativeAudioNodeToNativeAudioNodeFunction, exports);
var _connectedNativeAudioBufferSourceNodeFactory = require("./connected-native-audio-buffer-source-node-factory");
parcelHelpers.exportAll(_connectedNativeAudioBufferSourceNodeFactory, exports);
var _connectedNativeAudioBufferSourceNodeFactoryFactory = require("./connected-native-audio-buffer-source-node-factory-factory");
parcelHelpers.exportAll(_connectedNativeAudioBufferSourceNodeFactoryFactory, exports);
var _constantSourceNodeConstructor = require("./constant-source-node-constructor");
parcelHelpers.exportAll(_constantSourceNodeConstructor, exports);
var _constantSourceNodeConstructorFactory = require("./constant-source-node-constructor-factory");
parcelHelpers.exportAll(_constantSourceNodeConstructorFactory, exports);
var _constantSourceNodeRenderer = require("./constant-source-node-renderer");
parcelHelpers.exportAll(_constantSourceNodeRenderer, exports);
var _constantSourceNodeRendererFactory = require("./constant-source-node-renderer-factory");
parcelHelpers.exportAll(_constantSourceNodeRendererFactory, exports);
var _constantSourceNodeRendererFactoryFactory = require("./constant-source-node-renderer-factory-factory");
parcelHelpers.exportAll(_constantSourceNodeRendererFactoryFactory, exports);
var _constructor = require("./constructor");
parcelHelpers.exportAll(_constructor, exports);
var _context = require("./context");
parcelHelpers.exportAll(_context, exports);
var _contextStore = require("./context-store");
parcelHelpers.exportAll(_contextStore, exports);
var _convertNumberToUnsignedLongFactory = require("./convert-number-to-unsigned-long-factory");
parcelHelpers.exportAll(_convertNumberToUnsignedLongFactory, exports);
var _convertNumberToUnsignedLongFunction = require("./convert-number-to-unsigned-long-function");
parcelHelpers.exportAll(_convertNumberToUnsignedLongFunction, exports);
var _convolverNodeConstructor = require("./convolver-node-constructor");
parcelHelpers.exportAll(_convolverNodeConstructor, exports);
var _convolverNodeConstructorFactory = require("./convolver-node-constructor-factory");
parcelHelpers.exportAll(_convolverNodeConstructorFactory, exports);
var _convolverNodeRendererFactory = require("./convolver-node-renderer-factory");
parcelHelpers.exportAll(_convolverNodeRendererFactory, exports);
var _convolverNodeRendererFactoryFactory = require("./convolver-node-renderer-factory-factory");
parcelHelpers.exportAll(_convolverNodeRendererFactoryFactory, exports);
var _createNativeOfflineAudioContextFactory = require("./create-native-offline-audio-context-factory");
parcelHelpers.exportAll(_createNativeOfflineAudioContextFactory, exports);
var _createNativeOfflineAudioContextFunction = require("./create-native-offline-audio-context-function");
parcelHelpers.exportAll(_createNativeOfflineAudioContextFunction, exports);
var _cycleCounters = require("./cycle-counters");
parcelHelpers.exportAll(_cycleCounters, exports);
var _dataCloneErrorFactory = require("./data-clone-error-factory");
parcelHelpers.exportAll(_dataCloneErrorFactory, exports);
var _decodeAudioDataFactory = require("./decode-audio-data-factory");
parcelHelpers.exportAll(_decodeAudioDataFactory, exports);
var _decodeAudioDataFunction = require("./decode-audio-data-function");
parcelHelpers.exportAll(_decodeAudioDataFunction, exports);
var _decodeErrorCallback = require("./decode-error-callback");
parcelHelpers.exportAll(_decodeErrorCallback, exports);
var _decodeSuccessCallback = require("./decode-success-callback");
parcelHelpers.exportAll(_decodeSuccessCallback, exports);
var _decrementCycleCounterFactory = require("./decrement-cycle-counter-factory");
parcelHelpers.exportAll(_decrementCycleCounterFactory, exports);
var _decrementCycleCounterFunction = require("./decrement-cycle-counter-function");
parcelHelpers.exportAll(_decrementCycleCounterFunction, exports);
var _delayNodeConstructor = require("./delay-node-constructor");
parcelHelpers.exportAll(_delayNodeConstructor, exports);
var _delayNodeConstructorFactory = require("./delay-node-constructor-factory");
parcelHelpers.exportAll(_delayNodeConstructorFactory, exports);
var _delayNodeRendererFactory = require("./delay-node-renderer-factory");
parcelHelpers.exportAll(_delayNodeRendererFactory, exports);
var _delayNodeRendererFactoryFactory = require("./delay-node-renderer-factory-factory");
parcelHelpers.exportAll(_delayNodeRendererFactoryFactory, exports);
var _deleteActiveInputConnectionToAudioNodeFactory = require("./delete-active-input-connection-to-audio-node-factory");
parcelHelpers.exportAll(_deleteActiveInputConnectionToAudioNodeFactory, exports);
var _deleteActiveInputConnectionToAudioNodeFunction = require("./delete-active-input-connection-to-audio-node-function");
parcelHelpers.exportAll(_deleteActiveInputConnectionToAudioNodeFunction, exports);
var _deleteUnrenderedAudioWorkletNodeFactory = require("./delete-unrendered-audio-worklet-node-factory");
parcelHelpers.exportAll(_deleteUnrenderedAudioWorkletNodeFactory, exports);
var _deleteUnrenderedAudioWorkletNodeFunction = require("./delete-unrendered-audio-worklet-node-function");
parcelHelpers.exportAll(_deleteUnrenderedAudioWorkletNodeFunction, exports);
var _detectCyclesFactory = require("./detect-cycles-factory");
parcelHelpers.exportAll(_detectCyclesFactory, exports);
var _detectCyclesFunction = require("./detect-cycles-function");
parcelHelpers.exportAll(_detectCyclesFunction, exports);
var _disconnectMultipleOutputsFactory = require("./disconnect-multiple-outputs-factory");
parcelHelpers.exportAll(_disconnectMultipleOutputsFactory, exports);
var _disconnectMultipleOutputsFunction = require("./disconnect-multiple-outputs-function");
parcelHelpers.exportAll(_disconnectMultipleOutputsFunction, exports);
var _disconnectNativeAudioNodeFromNativeAudioNodeFunction = require("./disconnect-native-audio-node-from-native-audio-node-function");
parcelHelpers.exportAll(_disconnectNativeAudioNodeFromNativeAudioNodeFunction, exports);
var _distanceModelType = require("./distance-model-type");
parcelHelpers.exportAll(_distanceModelType, exports);
var _dynamicsCompressorNodeConstructor = require("./dynamics-compressor-node-constructor");
parcelHelpers.exportAll(_dynamicsCompressorNodeConstructor, exports);
var _dynamicsCompressorNodeConstructorFactory = require("./dynamics-compressor-node-constructor-factory");
parcelHelpers.exportAll(_dynamicsCompressorNodeConstructorFactory, exports);
var _dynamicsCompressorNodeRendererFactory = require("./dynamics-compressor-node-renderer-factory");
parcelHelpers.exportAll(_dynamicsCompressorNodeRendererFactory, exports);
var _dynamicsCompressorNodeRendererFactoryFactory = require("./dynamics-compressor-node-renderer-factory-factory");
parcelHelpers.exportAll(_dynamicsCompressorNodeRendererFactoryFactory, exports);
var _encodingErrorFactory = require("./encoding-error-factory");
parcelHelpers.exportAll(_encodingErrorFactory, exports);
var _errorEventHandler = require("./error-event-handler");
parcelHelpers.exportAll(_errorEventHandler, exports);
var _evaluateAudioWorkletGlobalScopeFunction = require("./evaluate-audio-worklet-global-scope-function");
parcelHelpers.exportAll(_evaluateAudioWorkletGlobalScopeFunction, exports);
var _evaluateSourceFactory = require("./evaluate-source-factory");
parcelHelpers.exportAll(_evaluateSourceFactory, exports);
var _evaluateSourceFunction = require("./evaluate-source-function");
parcelHelpers.exportAll(_evaluateSourceFunction, exports);
var _eventHandler = require("./event-handler");
parcelHelpers.exportAll(_eventHandler, exports);
var _eventTargetConstructor = require("./event-target-constructor");
parcelHelpers.exportAll(_eventTargetConstructor, exports);
var _eventTargetConstructorFactory = require("./event-target-constructor-factory");
parcelHelpers.exportAll(_eventTargetConstructorFactory, exports);
var _exposeCurrentFrameAndCurrentTimeFactory = require("./expose-current-frame-and-current-time-factory");
parcelHelpers.exportAll(_exposeCurrentFrameAndCurrentTimeFactory, exports);
var _exposeCurrentFrameAndCurrentTimeFunction = require("./expose-current-frame-and-current-time-function");
parcelHelpers.exportAll(_exposeCurrentFrameAndCurrentTimeFunction, exports);
var _fetchSourceFactory = require("./fetch-source-factory");
parcelHelpers.exportAll(_fetchSourceFactory, exports);
var _fetchSourceFunction = require("./fetch-source-function");
parcelHelpers.exportAll(_fetchSourceFunction, exports);
var _gainNodeConstructor = require("./gain-node-constructor");
parcelHelpers.exportAll(_gainNodeConstructor, exports);
var _gainNodeConstructorFactory = require("./gain-node-constructor-factory");
parcelHelpers.exportAll(_gainNodeConstructorFactory, exports);
var _gainNodeRendererFactory = require("./gain-node-renderer-factory");
parcelHelpers.exportAll(_gainNodeRendererFactory, exports);
var _gainNodeRendererFactoryFactory = require("./gain-node-renderer-factory-factory");
parcelHelpers.exportAll(_gainNodeRendererFactoryFactory, exports);
var _getActiveAudioWorkletNodeInputsFactory = require("./get-active-audio-worklet-node-inputs-factory");
parcelHelpers.exportAll(_getActiveAudioWorkletNodeInputsFactory, exports);
var _getActiveAudioWorkletNodeInputsFunction = require("./get-active-audio-worklet-node-inputs-function");
parcelHelpers.exportAll(_getActiveAudioWorkletNodeInputsFunction, exports);
var _getAudioNodeConnectionsFunction = require("./get-audio-node-connections-function");
parcelHelpers.exportAll(_getAudioNodeConnectionsFunction, exports);
var _getAudioNodeRendererFactory = require("./get-audio-node-renderer-factory");
parcelHelpers.exportAll(_getAudioNodeRendererFactory, exports);
var _getAudioNodeRendererFunction = require("./get-audio-node-renderer-function");
parcelHelpers.exportAll(_getAudioNodeRendererFunction, exports);
var _getAudioNodeTailTimeFactory = require("./get-audio-node-tail-time-factory");
parcelHelpers.exportAll(_getAudioNodeTailTimeFactory, exports);
var _getAudioNodeTailTimeFunction = require("./get-audio-node-tail-time-function");
parcelHelpers.exportAll(_getAudioNodeTailTimeFunction, exports);
var _getAudioParamConnectionsFunction = require("./get-audio-param-connections-function");
parcelHelpers.exportAll(_getAudioParamConnectionsFunction, exports);
var _getAudioParamRendererFactory = require("./get-audio-param-renderer-factory");
parcelHelpers.exportAll(_getAudioParamRendererFactory, exports);
var _getAudioParamRendererFunction = require("./get-audio-param-renderer-function");
parcelHelpers.exportAll(_getAudioParamRendererFunction, exports);
var _getBackupOfflineAudioContextFactory = require("./get-backup-offline-audio-context-factory");
parcelHelpers.exportAll(_getBackupOfflineAudioContextFactory, exports);
var _getBackupOfflineAudioContextFunction = require("./get-backup-offline-audio-context-function");
parcelHelpers.exportAll(_getBackupOfflineAudioContextFunction, exports);
var _getEventListenersOfAudioNodeFunction = require("./get-event-listeners-of-audio-node-function");
parcelHelpers.exportAll(_getEventListenersOfAudioNodeFunction, exports);
var _getFirstSampleFunction = require("./get-first-sample-function");
parcelHelpers.exportAll(_getFirstSampleFunction, exports);
var _getNativeAudioNodeFunction = require("./get-native-audio-node-function");
parcelHelpers.exportAll(_getNativeAudioNodeFunction, exports);
var _getNativeAudioParamFunction = require("./get-native-audio-param-function");
parcelHelpers.exportAll(_getNativeAudioParamFunction, exports);
var _getNativeContextFactory = require("./get-native-context-factory");
parcelHelpers.exportAll(_getNativeContextFactory, exports);
var _getNativeContextFunction = require("./get-native-context-function");
parcelHelpers.exportAll(_getNativeContextFunction, exports);
var _getOrCreateBackupOfflineAudioContextFactory = require("./get-or-create-backup-offline-audio-context-factory");
parcelHelpers.exportAll(_getOrCreateBackupOfflineAudioContextFactory, exports);
var _getOrCreateBackupOfflineAudioContextFunction = require("./get-or-create-backup-offline-audio-context-function");
parcelHelpers.exportAll(_getOrCreateBackupOfflineAudioContextFunction, exports);
var _getUnrenderedAudioWorkletNodesFactory = require("./get-unrendered-audio-worklet-nodes-factory");
parcelHelpers.exportAll(_getUnrenderedAudioWorkletNodesFactory, exports);
var _getUnrenderedAudioWorkletNodesFunction = require("./get-unrendered-audio-worklet-nodes-function");
parcelHelpers.exportAll(_getUnrenderedAudioWorkletNodesFunction, exports);
var _getValueForKeyFunction = require("./get-value-for-key-function");
parcelHelpers.exportAll(_getValueForKeyFunction, exports);
var _iirFilterNodeConstructor = require("./iir-filter-node-constructor");
parcelHelpers.exportAll(_iirFilterNodeConstructor, exports);
var _iirFilterNodeConstructorFactory = require("./iir-filter-node-constructor-factory");
parcelHelpers.exportAll(_iirFilterNodeConstructorFactory, exports);
var _iirFilterNodeRendererFactory = require("./iir-filter-node-renderer-factory");
parcelHelpers.exportAll(_iirFilterNodeRendererFactory, exports);
var _iirFilterNodeRendererFactoryFactory = require("./iir-filter-node-renderer-factory-factory");
parcelHelpers.exportAll(_iirFilterNodeRendererFactoryFactory, exports);
var _incrementCycleCounterFactory = require("./increment-cycle-counter-factory");
parcelHelpers.exportAll(_incrementCycleCounterFactory, exports);
var _incrementCycleCounterFactoryFactory = require("./increment-cycle-counter-factory-factory");
parcelHelpers.exportAll(_incrementCycleCounterFactoryFactory, exports);
var _incrementCycleCounterFunction = require("./increment-cycle-counter-function");
parcelHelpers.exportAll(_incrementCycleCounterFunction, exports);
var _indexSizeErrorFactory = require("./index-size-error-factory");
parcelHelpers.exportAll(_indexSizeErrorFactory, exports);
var _insertElementInSetFunction = require("./insert-element-in-set-function");
parcelHelpers.exportAll(_insertElementInSetFunction, exports);
var _internalStateEventListener = require("./internal-state-event-listener");
parcelHelpers.exportAll(_internalStateEventListener, exports);
var _invalidAccessErrorFactory = require("./invalid-access-error-factory");
parcelHelpers.exportAll(_invalidAccessErrorFactory, exports);
var _invalidStateErrorFactory = require("./invalid-state-error-factory");
parcelHelpers.exportAll(_invalidStateErrorFactory, exports);
var _isActiveAudioNodeFunction = require("./is-active-audio-node-function");
parcelHelpers.exportAll(_isActiveAudioNodeFunction, exports);
var _isAnyAudioContextFactory = require("./is-any-audio-context-factory");
parcelHelpers.exportAll(_isAnyAudioContextFactory, exports);
var _isAnyAudioContextFunction = require("./is-any-audio-context-function");
parcelHelpers.exportAll(_isAnyAudioContextFunction, exports);
var _isAnyAudioNodeFactory = require("./is-any-audio-node-factory");
parcelHelpers.exportAll(_isAnyAudioNodeFactory, exports);
var _isAnyAudioNodeFunction = require("./is-any-audio-node-function");
parcelHelpers.exportAll(_isAnyAudioNodeFunction, exports);
var _isAnyAudioParamFactory = require("./is-any-audio-param-factory");
parcelHelpers.exportAll(_isAnyAudioParamFactory, exports);
var _isAnyAudioParamFunction = require("./is-any-audio-param-function");
parcelHelpers.exportAll(_isAnyAudioParamFunction, exports);
var _isAnyOfflineAudioContextFactory = require("./is-any-offline-audio-context-factory");
parcelHelpers.exportAll(_isAnyOfflineAudioContextFactory, exports);
var _isAnyOfflineAudioContextFunction = require("./is-any-offline-audio-context-function");
parcelHelpers.exportAll(_isAnyOfflineAudioContextFunction, exports);
var _isDcCurveFunction = require("./is-dc-curve-function");
parcelHelpers.exportAll(_isDcCurveFunction, exports);
var _isNativeAudioContextFactory = require("./is-native-audio-context-factory");
parcelHelpers.exportAll(_isNativeAudioContextFactory, exports);
var _isNativeAudioContextFunction = require("./is-native-audio-context-function");
parcelHelpers.exportAll(_isNativeAudioContextFunction, exports);
var _isNativeAudioNodeFactory = require("./is-native-audio-node-factory");
parcelHelpers.exportAll(_isNativeAudioNodeFactory, exports);
var _isNativeAudioNodeFunction = require("./is-native-audio-node-function");
parcelHelpers.exportAll(_isNativeAudioNodeFunction, exports);
var _isNativeAudioParamFactory = require("./is-native-audio-param-factory");
parcelHelpers.exportAll(_isNativeAudioParamFactory, exports);
var _isNativeAudioParamFunction = require("./is-native-audio-param-function");
parcelHelpers.exportAll(_isNativeAudioParamFunction, exports);
var _isNativeContextFactory = require("./is-native-context-factory");
parcelHelpers.exportAll(_isNativeContextFactory, exports);
var _isNativeContextFunction = require("./is-native-context-function");
parcelHelpers.exportAll(_isNativeContextFunction, exports);
var _isNativeOfflineAudioContextFactory = require("./is-native-offline-audio-context-factory");
parcelHelpers.exportAll(_isNativeOfflineAudioContextFactory, exports);
var _isNativeOfflineAudioContextFunction = require("./is-native-offline-audio-context-function");
parcelHelpers.exportAll(_isNativeOfflineAudioContextFunction, exports);
var _isPartOfACycleFunction = require("./is-part-of-a-cycle-function");
parcelHelpers.exportAll(_isPartOfACycleFunction, exports);
var _isPassiveAudioNodeFunction = require("./is-passive-audio-node-function");
parcelHelpers.exportAll(_isPassiveAudioNodeFunction, exports);
var _isSecureContextFactory = require("./is-secure-context-factory");
parcelHelpers.exportAll(_isSecureContextFactory, exports);
var _isSupportedPromiseFactory = require("./is-supported-promise-factory");
parcelHelpers.exportAll(_isSupportedPromiseFactory, exports);
var _mediaElementAudioSourceNodeConstructor = require("./media-element-audio-source-node-constructor");
parcelHelpers.exportAll(_mediaElementAudioSourceNodeConstructor, exports);
var _mediaElementAudioSourceNodeConstructorFactory = require("./media-element-audio-source-node-constructor-factory");
parcelHelpers.exportAll(_mediaElementAudioSourceNodeConstructorFactory, exports);
var _mediaStreamAudioDestinationNodeConstructor = require("./media-stream-audio-destination-node-constructor");
parcelHelpers.exportAll(_mediaStreamAudioDestinationNodeConstructor, exports);
var _mediaStreamAudioDestinationNodeConstructorFactory = require("./media-stream-audio-destination-node-constructor-factory");
parcelHelpers.exportAll(_mediaStreamAudioDestinationNodeConstructorFactory, exports);
var _mediaStreamAudioSourceNodeConstructor = require("./media-stream-audio-source-node-constructor");
parcelHelpers.exportAll(_mediaStreamAudioSourceNodeConstructor, exports);
var _mediaStreamAudioSourceNodeConstructorFactory = require("./media-stream-audio-source-node-constructor-factory");
parcelHelpers.exportAll(_mediaStreamAudioSourceNodeConstructorFactory, exports);
var _mediaStreamTrackAudioSourceNodeConstructor = require("./media-stream-track-audio-source-node-constructor");
parcelHelpers.exportAll(_mediaStreamTrackAudioSourceNodeConstructor, exports);
var _mediaStreamTrackAudioSourceNodeConstructorFactory = require("./media-stream-track-audio-source-node-constructor-factory");
parcelHelpers.exportAll(_mediaStreamTrackAudioSourceNodeConstructorFactory, exports);
var _minimalAudioContextConstructor = require("./minimal-audio-context-constructor");
parcelHelpers.exportAll(_minimalAudioContextConstructor, exports);
var _minimalAudioContextConstructorFactory = require("./minimal-audio-context-constructor-factory");
parcelHelpers.exportAll(_minimalAudioContextConstructorFactory, exports);
var _minimalBaseAudioContextConstructor = require("./minimal-base-audio-context-constructor");
parcelHelpers.exportAll(_minimalBaseAudioContextConstructor, exports);
var _minimalBaseAudioContextConstructorFactory = require("./minimal-base-audio-context-constructor-factory");
parcelHelpers.exportAll(_minimalBaseAudioContextConstructorFactory, exports);
var _minimalOfflineAudioContextConstructor = require("./minimal-offline-audio-context-constructor");
parcelHelpers.exportAll(_minimalOfflineAudioContextConstructor, exports);
var _minimalOfflineAudioContextConstructorFactory = require("./minimal-offline-audio-context-constructor-factory");
parcelHelpers.exportAll(_minimalOfflineAudioContextConstructorFactory, exports);
var _monitorConnectionsFactory = require("./monitor-connections-factory");
parcelHelpers.exportAll(_monitorConnectionsFactory, exports);
var _monitorConnectionsFunction = require("./monitor-connections-function");
parcelHelpers.exportAll(_monitorConnectionsFunction, exports);
var _nativeAnalyserNode = require("./native-analyser-node");
parcelHelpers.exportAll(_nativeAnalyserNode, exports);
var _nativeAnalyserNodeFactory = require("./native-analyser-node-factory");
parcelHelpers.exportAll(_nativeAnalyserNodeFactory, exports);
var _nativeAnalyserNodeFactoryFactory = require("./native-analyser-node-factory-factory");
parcelHelpers.exportAll(_nativeAnalyserNodeFactoryFactory, exports);
var _nativeAudioBuffer = require("./native-audio-buffer");
parcelHelpers.exportAll(_nativeAudioBuffer, exports);
var _nativeAudioBufferConstructor = require("./native-audio-buffer-constructor");
parcelHelpers.exportAll(_nativeAudioBufferConstructor, exports);
var _nativeAudioBufferConstructorFactory = require("./native-audio-buffer-constructor-factory");
parcelHelpers.exportAll(_nativeAudioBufferConstructorFactory, exports);
var _nativeAudioBufferSourceNode = require("./native-audio-buffer-source-node");
parcelHelpers.exportAll(_nativeAudioBufferSourceNode, exports);
var _nativeAudioBufferSourceNodeFactory = require("./native-audio-buffer-source-node-factory");
parcelHelpers.exportAll(_nativeAudioBufferSourceNodeFactory, exports);
var _nativeAudioBufferSourceNodeFactoryFactory = require("./native-audio-buffer-source-node-factory-factory");
parcelHelpers.exportAll(_nativeAudioBufferSourceNodeFactoryFactory, exports);
var _nativeAudioContext = require("./native-audio-context");
parcelHelpers.exportAll(_nativeAudioContext, exports);
var _nativeAudioContextConstructor = require("./native-audio-context-constructor");
parcelHelpers.exportAll(_nativeAudioContextConstructor, exports);
var _nativeAudioContextConstructorFactory = require("./native-audio-context-constructor-factory");
parcelHelpers.exportAll(_nativeAudioContextConstructorFactory, exports);
var _nativeAudioDestinationNode = require("./native-audio-destination-node");
parcelHelpers.exportAll(_nativeAudioDestinationNode, exports);
var _nativeAudioDestinationNodeFactory = require("./native-audio-destination-node-factory");
parcelHelpers.exportAll(_nativeAudioDestinationNodeFactory, exports);
var _nativeAudioDestinationNodeFactoryFactory = require("./native-audio-destination-node-factory-factory");
parcelHelpers.exportAll(_nativeAudioDestinationNodeFactoryFactory, exports);
var _nativeAudioListener = require("./native-audio-listener");
parcelHelpers.exportAll(_nativeAudioListener, exports);
var _nativeAudioNode = require("./native-audio-node");
parcelHelpers.exportAll(_nativeAudioNode, exports);
var _nativeAudioParam = require("./native-audio-param");
parcelHelpers.exportAll(_nativeAudioParam, exports);
var _nativeAudioParamMap = require("./native-audio-param-map");
parcelHelpers.exportAll(_nativeAudioParamMap, exports);
var _nativeAudioWorklet = require("./native-audio-worklet");
parcelHelpers.exportAll(_nativeAudioWorklet, exports);
var _nativeAudioWorkletNode = require("./native-audio-worklet-node");
parcelHelpers.exportAll(_nativeAudioWorkletNode, exports);
var _nativeAudioWorkletNodeConstructor = require("./native-audio-worklet-node-constructor");
parcelHelpers.exportAll(_nativeAudioWorkletNodeConstructor, exports);
var _nativeAudioWorkletNodeConstructorFactory = require("./native-audio-worklet-node-constructor-factory");
parcelHelpers.exportAll(_nativeAudioWorkletNodeConstructorFactory, exports);
var _nativeAudioWorkletNodeFactory = require("./native-audio-worklet-node-factory");
parcelHelpers.exportAll(_nativeAudioWorkletNodeFactory, exports);
var _nativeAudioWorkletNodeFactoryFactory = require("./native-audio-worklet-node-factory-factory");
parcelHelpers.exportAll(_nativeAudioWorkletNodeFactoryFactory, exports);
var _nativeAudioWorkletNodeFakerFactory = require("./native-audio-worklet-node-faker-factory");
parcelHelpers.exportAll(_nativeAudioWorkletNodeFakerFactory, exports);
var _nativeAudioWorkletNodeFakerFactoryFactory = require("./native-audio-worklet-node-faker-factory-factory");
parcelHelpers.exportAll(_nativeAudioWorkletNodeFakerFactoryFactory, exports);
var _nativeAudioWorkletNodeOptions = require("./native-audio-worklet-node-options");
parcelHelpers.exportAll(_nativeAudioWorkletNodeOptions, exports);
var _nativeBiquadFilterNode = require("./native-biquad-filter-node");
parcelHelpers.exportAll(_nativeBiquadFilterNode, exports);
var _nativeBiquadFilterNodeFactory = require("./native-biquad-filter-node-factory");
parcelHelpers.exportAll(_nativeBiquadFilterNodeFactory, exports);
var _nativeChannelMergerNode = require("./native-channel-merger-node");
parcelHelpers.exportAll(_nativeChannelMergerNode, exports);
var _nativeChannelMergerNodeFactory = require("./native-channel-merger-node-factory");
parcelHelpers.exportAll(_nativeChannelMergerNodeFactory, exports);
var _nativeChannelMergerNodeFactoryFactory = require("./native-channel-merger-node-factory-factory");
parcelHelpers.exportAll(_nativeChannelMergerNodeFactoryFactory, exports);
var _nativeChannelSplitterNode = require("./native-channel-splitter-node");
parcelHelpers.exportAll(_nativeChannelSplitterNode, exports);
var _nativeChannelSplitterNodeFactory = require("./native-channel-splitter-node-factory");
parcelHelpers.exportAll(_nativeChannelSplitterNodeFactory, exports);
var _nativeConstantSourceNode = require("./native-constant-source-node");
parcelHelpers.exportAll(_nativeConstantSourceNode, exports);
var _nativeConstantSourceNodeFactory = require("./native-constant-source-node-factory");
parcelHelpers.exportAll(_nativeConstantSourceNodeFactory, exports);
var _nativeConstantSourceNodeFactoryFactory = require("./native-constant-source-node-factory-factory");
parcelHelpers.exportAll(_nativeConstantSourceNodeFactoryFactory, exports);
var _nativeConstantSourceNodeFakerFactory = require("./native-constant-source-node-faker-factory");
parcelHelpers.exportAll(_nativeConstantSourceNodeFakerFactory, exports);
var _nativeConstantSourceNodeFakerFactoryFactory = require("./native-constant-source-node-faker-factory-factory");
parcelHelpers.exportAll(_nativeConstantSourceNodeFakerFactoryFactory, exports);
var _nativeContext = require("./native-context");
parcelHelpers.exportAll(_nativeContext, exports);
var _nativeConvolverNode = require("./native-convolver-node");
parcelHelpers.exportAll(_nativeConvolverNode, exports);
var _nativeConvolverNodeFactory = require("./native-convolver-node-factory");
parcelHelpers.exportAll(_nativeConvolverNodeFactory, exports);
var _nativeConvolverNodeFactoryFactory = require("./native-convolver-node-factory-factory");
parcelHelpers.exportAll(_nativeConvolverNodeFactoryFactory, exports);
var _nativeDelayNodeFactory = require("./native-delay-node-factory");
parcelHelpers.exportAll(_nativeDelayNodeFactory, exports);
var _nativeDelayNode = require("./native-delay-node");
parcelHelpers.exportAll(_nativeDelayNode, exports);
var _nativeDynamicsCompressorNode = require("./native-dynamics-compressor-node");
parcelHelpers.exportAll(_nativeDynamicsCompressorNode, exports);
var _nativeDynamicsCompressorNodeFactory = require("./native-dynamics-compressor-node-factory");
parcelHelpers.exportAll(_nativeDynamicsCompressorNodeFactory, exports);
var _nativeDynamicsCompressorNodeFactoryFactory = require("./native-dynamics-compressor-node-factory-factory");
parcelHelpers.exportAll(_nativeDynamicsCompressorNodeFactoryFactory, exports);
var _nativeEventTarget = require("./native-event-target");
parcelHelpers.exportAll(_nativeEventTarget, exports);
var _nativeGainNode = require("./native-gain-node");
parcelHelpers.exportAll(_nativeGainNode, exports);
var _nativeGainNodeFactory = require("./native-gain-node-factory");
parcelHelpers.exportAll(_nativeGainNodeFactory, exports);
var _nativeIirFilterNode = require("./native-iir-filter-node");
parcelHelpers.exportAll(_nativeIirFilterNode, exports);
var _nativeIirFilterNodeFactory = require("./native-iir-filter-node-factory");
parcelHelpers.exportAll(_nativeIirFilterNodeFactory, exports);
var _nativeIirFilterNodeFactoryFactory = require("./native-iir-filter-node-factory-factory");
parcelHelpers.exportAll(_nativeIirFilterNodeFactoryFactory, exports);
var _nativeIirFilterNodeFakerFactory = require("./native-iir-filter-node-faker-factory");
parcelHelpers.exportAll(_nativeIirFilterNodeFakerFactory, exports);
var _nativeIirFilterNodeFakerFactoryFactory = require("./native-iir-filter-node-faker-factory-factory");
parcelHelpers.exportAll(_nativeIirFilterNodeFakerFactoryFactory, exports);
var _nativeMediaElementAudioSourceNode = require("./native-media-element-audio-source-node");
parcelHelpers.exportAll(_nativeMediaElementAudioSourceNode, exports);
var _nativeMediaElementAudioSourceNodeFactory = require("./native-media-element-audio-source-node-factory");
parcelHelpers.exportAll(_nativeMediaElementAudioSourceNodeFactory, exports);
var _nativeMediaStreamAudioDestinationNode = require("./native-media-stream-audio-destination-node");
parcelHelpers.exportAll(_nativeMediaStreamAudioDestinationNode, exports);
var _nativeMediaStreamAudioDestinationNodeFactory = require("./native-media-stream-audio-destination-node-factory");
parcelHelpers.exportAll(_nativeMediaStreamAudioDestinationNodeFactory, exports);
var _nativeMediaStreamAudioSourceNode = require("./native-media-stream-audio-source-node");
parcelHelpers.exportAll(_nativeMediaStreamAudioSourceNode, exports);
var _nativeMediaStreamAudioSourceNodeFactory = require("./native-media-stream-audio-source-node-factory");
parcelHelpers.exportAll(_nativeMediaStreamAudioSourceNodeFactory, exports);
var _nativeMediaStreamTrackAudioSourceNode = require("./native-media-stream-track-audio-source-node");
parcelHelpers.exportAll(_nativeMediaStreamTrackAudioSourceNode, exports);
var _nativeMediaStreamTrackAudioSourceNodeFactory = require("./native-media-stream-track-audio-source-node-factory");
parcelHelpers.exportAll(_nativeMediaStreamTrackAudioSourceNodeFactory, exports);
var _nativeMediaStreamTrackAudioSourceNodeFactoryFactory = require("./native-media-stream-track-audio-source-node-factory-factory");
parcelHelpers.exportAll(_nativeMediaStreamTrackAudioSourceNodeFactoryFactory, exports);
var _nativeOfflineAudioContext = require("./native-offline-audio-context");
parcelHelpers.exportAll(_nativeOfflineAudioContext, exports);
var _nativeOfflineAudioContextConstructor = require("./native-offline-audio-context-constructor");
parcelHelpers.exportAll(_nativeOfflineAudioContextConstructor, exports);
var _nativeOfflineAudioContextConstructorFactory = require("./native-offline-audio-context-constructor-factory");
parcelHelpers.exportAll(_nativeOfflineAudioContextConstructorFactory, exports);
var _nativeOscillatorNode = require("./native-oscillator-node");
parcelHelpers.exportAll(_nativeOscillatorNode, exports);
var _nativeOscillatorNodeFactory = require("./native-oscillator-node-factory");
parcelHelpers.exportAll(_nativeOscillatorNodeFactory, exports);
var _nativeOscillatorNodeFactoryFactory = require("./native-oscillator-node-factory-factory");
parcelHelpers.exportAll(_nativeOscillatorNodeFactoryFactory, exports);
var _nativePannerNode = require("./native-panner-node");
parcelHelpers.exportAll(_nativePannerNode, exports);
var _nativePannerNodeFactory = require("./native-panner-node-factory");
parcelHelpers.exportAll(_nativePannerNodeFactory, exports);
var _nativePannerNodeFactoryFactory = require("./native-panner-node-factory-factory");
parcelHelpers.exportAll(_nativePannerNodeFactoryFactory, exports);
var _nativePannerNodeFakerFactory = require("./native-panner-node-faker-factory");
parcelHelpers.exportAll(_nativePannerNodeFakerFactory, exports);
var _nativePannerNodeFakerFactoryFactory = require("./native-panner-node-faker-factory-factory");
parcelHelpers.exportAll(_nativePannerNodeFakerFactoryFactory, exports);
var _nativePeriodicWave = require("./native-periodic-wave");
parcelHelpers.exportAll(_nativePeriodicWave, exports);
var _nativePeriodicWaveFactory = require("./native-periodic-wave-factory");
parcelHelpers.exportAll(_nativePeriodicWaveFactory, exports);
var _nativePeriodicWaveFactoryFactory = require("./native-periodic-wave-factory-factory");
parcelHelpers.exportAll(_nativePeriodicWaveFactoryFactory, exports);
var _nativeScriptProcessorNode = require("./native-script-processor-node");
parcelHelpers.exportAll(_nativeScriptProcessorNode, exports);
var _nativeScriptProcessorNodeFactory = require("./native-script-processor-node-factory");
parcelHelpers.exportAll(_nativeScriptProcessorNodeFactory, exports);
var _nativeStereoPannerNode = require("./native-stereo-panner-node");
parcelHelpers.exportAll(_nativeStereoPannerNode, exports);
var _nativeStereoPannerNodeFactory = require("./native-stereo-panner-node-factory");
parcelHelpers.exportAll(_nativeStereoPannerNodeFactory, exports);
var _nativeStereoPannerNodeFactoryFactory = require("./native-stereo-panner-node-factory-factory");
parcelHelpers.exportAll(_nativeStereoPannerNodeFactoryFactory, exports);
var _nativeStereoPannerNodeFakerFactory = require("./native-stereo-panner-node-faker-factory");
parcelHelpers.exportAll(_nativeStereoPannerNodeFakerFactory, exports);
var _nativeStereoPannerNodeFakerFactoryFactory = require("./native-stereo-panner-node-faker-factory-factory");
parcelHelpers.exportAll(_nativeStereoPannerNodeFakerFactoryFactory, exports);
var _nativeWaveShaperNode = require("./native-wave-shaper-node");
parcelHelpers.exportAll(_nativeWaveShaperNode, exports);
var _nativeWaveShaperNodeFactory = require("./native-wave-shaper-node-factory");
parcelHelpers.exportAll(_nativeWaveShaperNodeFactory, exports);
var _nativeWaveShaperNodeFactoryFactory = require("./native-wave-shaper-node-factory-factory");
parcelHelpers.exportAll(_nativeWaveShaperNodeFactoryFactory, exports);
var _nativeWaveShaperNodeFakerFactory = require("./native-wave-shaper-node-faker-factory");
parcelHelpers.exportAll(_nativeWaveShaperNodeFakerFactory, exports);
var _nativeWaveShaperNodeFakerFactoryFactory = require("./native-wave-shaper-node-faker-factory-factory");
parcelHelpers.exportAll(_nativeWaveShaperNodeFakerFactoryFactory, exports);
var _notSupportedErrorFactory = require("./not-supported-error-factory");
parcelHelpers.exportAll(_notSupportedErrorFactory, exports);
var _offlineAudioContextConstructorFactory = require("./offline-audio-context-constructor-factory");
parcelHelpers.exportAll(_offlineAudioContextConstructorFactory, exports);
var _oscillatorNodeConstructor = require("./oscillator-node-constructor");
parcelHelpers.exportAll(_oscillatorNodeConstructor, exports);
var _oscillatorNodeConstructorFactory = require("./oscillator-node-constructor-factory");
parcelHelpers.exportAll(_oscillatorNodeConstructorFactory, exports);
var _oscillatorNodeRenderer = require("./oscillator-node-renderer");
parcelHelpers.exportAll(_oscillatorNodeRenderer, exports);
var _oscillatorNodeRendererFactory = require("./oscillator-node-renderer-factory");
parcelHelpers.exportAll(_oscillatorNodeRendererFactory, exports);
var _oscillatorNodeRendererFactoryFactory = require("./oscillator-node-renderer-factory-factory");
parcelHelpers.exportAll(_oscillatorNodeRendererFactoryFactory, exports);
var _oscillatorType = require("./oscillator-type");
parcelHelpers.exportAll(_oscillatorType, exports);
var _outputConnection = require("./output-connection");
parcelHelpers.exportAll(_outputConnection, exports);
var _overSampleType = require("./over-sample-type");
parcelHelpers.exportAll(_overSampleType, exports);
var _overwriteAccessorsFunction = require("./overwrite-accessors-function");
parcelHelpers.exportAll(_overwriteAccessorsFunction, exports);
var _pannerNodeConstructor = require("./panner-node-constructor");
parcelHelpers.exportAll(_pannerNodeConstructor, exports);
var _pannerNodeConstructorFactory = require("./panner-node-constructor-factory");
parcelHelpers.exportAll(_pannerNodeConstructorFactory, exports);
var _pannerNodeRendererFactory = require("./panner-node-renderer-factory");
parcelHelpers.exportAll(_pannerNodeRendererFactory, exports);
var _pannerNodeRendererFactoryFactory = require("./panner-node-renderer-factory-factory");
parcelHelpers.exportAll(_pannerNodeRendererFactoryFactory, exports);
var _panningModelType = require("./panning-model-type");
parcelHelpers.exportAll(_panningModelType, exports);
var _passiveAudioNodeInputConnection = require("./passive-audio-node-input-connection");
parcelHelpers.exportAll(_passiveAudioNodeInputConnection, exports);
var _passiveAudioParamInputConnection = require("./passive-audio-param-input-connection");
parcelHelpers.exportAll(_passiveAudioParamInputConnection, exports);
var _periodicWaveConstructor = require("./periodic-wave-constructor");
parcelHelpers.exportAll(_periodicWaveConstructor, exports);
var _periodicWaveConstructorFactory = require("./periodic-wave-constructor-factory");
parcelHelpers.exportAll(_periodicWaveConstructorFactory, exports);
var _pickElementFromSetFunction = require("./pick-element-from-set-function");
parcelHelpers.exportAll(_pickElementFromSetFunction, exports);
var _renderAutomationFactory = require("./render-automation-factory");
parcelHelpers.exportAll(_renderAutomationFactory, exports);
var _renderAutomationFunction = require("./render-automation-function");
parcelHelpers.exportAll(_renderAutomationFunction, exports);
var _renderInputsOfAudioNodeFactory = require("./render-inputs-of-audio-node-factory");
parcelHelpers.exportAll(_renderInputsOfAudioNodeFactory, exports);
var _renderInputsOfAudioNodeFunction = require("./render-inputs-of-audio-node-function");
parcelHelpers.exportAll(_renderInputsOfAudioNodeFunction, exports);
var _renderInputsOfAudioParamFactory = require("./render-inputs-of-audio-param-factory");
parcelHelpers.exportAll(_renderInputsOfAudioParamFactory, exports);
var _renderInputsOfAudioParamFunction = require("./render-inputs-of-audio-param-function");
parcelHelpers.exportAll(_renderInputsOfAudioParamFunction, exports);
var _renderNativeOfflineAudioContextFactory = require("./render-native-offline-audio-context-factory");
parcelHelpers.exportAll(_renderNativeOfflineAudioContextFactory, exports);
var _renderNativeOfflineAudioContextFunction = require("./render-native-offline-audio-context-function");
parcelHelpers.exportAll(_renderNativeOfflineAudioContextFunction, exports);
var _sanitizeAudioWorkletNodeOptionsFunction = require("./sanitize-audio-worklet-node-options-function");
parcelHelpers.exportAll(_sanitizeAudioWorkletNodeOptionsFunction, exports);
var _sanitizeChannelSplitterOptionsFunction = require("./sanitize-channel-splitter-options-function");
parcelHelpers.exportAll(_sanitizeChannelSplitterOptionsFunction, exports);
var _sanitizePeriodicWaveOptionsFunction = require("./sanitize-periodic-wave-options-function");
parcelHelpers.exportAll(_sanitizePeriodicWaveOptionsFunction, exports);
var _setActiveAudioWorkletNodeInputsFactory = require("./set-active-audio-worklet-node-inputs-factory");
parcelHelpers.exportAll(_setActiveAudioWorkletNodeInputsFactory, exports);
var _setActiveAudioWorkletNodeInputsFunction = require("./set-active-audio-worklet-node-inputs-function");
parcelHelpers.exportAll(_setActiveAudioWorkletNodeInputsFunction, exports);
var _setAudioNodeTailTimeFactory = require("./set-audio-node-tail-time-factory");
parcelHelpers.exportAll(_setAudioNodeTailTimeFactory, exports);
var _setAudioNodeTailTimeFunction = require("./set-audio-node-tail-time-function");
parcelHelpers.exportAll(_setAudioNodeTailTimeFunction, exports);
var _setValueAtTimeUntilPossibleFunction = require("./set-value-at-time-until-possible-function");
parcelHelpers.exportAll(_setValueAtTimeUntilPossibleFunction, exports);
var _startRenderingFactory = require("./start-rendering-factory");
parcelHelpers.exportAll(_startRenderingFactory, exports);
var _startRenderingFunction = require("./start-rendering-function");
parcelHelpers.exportAll(_startRenderingFunction, exports);
var _stereoPannerNodeConstructor = require("./stereo-panner-node-constructor");
parcelHelpers.exportAll(_stereoPannerNodeConstructor, exports);
var _stereoPannerNodeConstructorFactory = require("./stereo-panner-node-constructor-factory");
parcelHelpers.exportAll(_stereoPannerNodeConstructorFactory, exports);
var _stereoPannerNodeRendererFactoryFactory = require("./stereo-panner-node-renderer-factory-factory");
parcelHelpers.exportAll(_stereoPannerNodeRendererFactoryFactory, exports);
var _stereoPannerNodeRendererFactory = require("./stereo-panner-node-renderer-factory");
parcelHelpers.exportAll(_stereoPannerNodeRendererFactory, exports);
var _testAudioBufferCopyChannelMethodsSubarraySupportFactory = require("./test-audio-buffer-copy-channel-methods-subarray-support-factory");
parcelHelpers.exportAll(_testAudioBufferCopyChannelMethodsSubarraySupportFactory, exports);
var _testAudioBufferConstructorSupportFactory = require("./test-audio-buffer-constructor-support-factory");
parcelHelpers.exportAll(_testAudioBufferConstructorSupportFactory, exports);
var _testAudioContextCloseMethodSupportFactory = require("./test-audio-context-close-method-support-factory");
parcelHelpers.exportAll(_testAudioContextCloseMethodSupportFactory, exports);
var _testAudioContextDecodeAudioDataMethodTypeErrorSupportFactory = require("./test-audio-context-decode-audio-data-method-type-error-support-factory");
parcelHelpers.exportAll(_testAudioContextDecodeAudioDataMethodTypeErrorSupportFactory, exports);
var _testAudioContextOptionsSupportFactory = require("./test-audio-context-options-support-factory");
parcelHelpers.exportAll(_testAudioContextOptionsSupportFactory, exports);
var _testAudioNodeConnectMethodSupportFactory = require("./test-audio-node-connect-method-support-factory");
parcelHelpers.exportAll(_testAudioNodeConnectMethodSupportFactory, exports);
var _testAudioWorkletNodeOptionsClonabilityFunction = require("./test-audio-worklet-node-options-clonability-function");
parcelHelpers.exportAll(_testAudioWorkletNodeOptionsClonabilityFunction, exports);
var _testAudioWorkletProcessorNoOutputsSupportFactory = require("./test-audio-worklet-processor-no-outputs-support-factory");
parcelHelpers.exportAll(_testAudioWorkletProcessorNoOutputsSupportFactory, exports);
var _testAudioWorkletProcessorPostMessageSupportFactory = require("./test-audio-worklet-processor-post-message-support-factory");
parcelHelpers.exportAll(_testAudioWorkletProcessorPostMessageSupportFactory, exports);
var _testChannelMergerNodeChannelCountSupportFactory = require("./test-channel-merger-node-channel-count-support-factory");
parcelHelpers.exportAll(_testChannelMergerNodeChannelCountSupportFactory, exports);
var _testConstantSourceNodeAccurateSchedulingSupportFactory = require("./test-constant-source-node-accurate-scheduling-support-factory");
parcelHelpers.exportAll(_testConstantSourceNodeAccurateSchedulingSupportFactory, exports);
var _testConvolverNodeBufferReassignabilitySupportFactory = require("./test-convolver-node-buffer-reassignability-support-factory");
parcelHelpers.exportAll(_testConvolverNodeBufferReassignabilitySupportFactory, exports);
var _testConvolverNodeChannelCountSupportFactory = require("./test-convolver-node-channel-count-support-factory");
parcelHelpers.exportAll(_testConvolverNodeChannelCountSupportFactory, exports);
var _testIsSecureContextSupportFactory = require("./test-is-secure-context-support-factory");
parcelHelpers.exportAll(_testIsSecureContextSupportFactory, exports);
var _testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport = require("./test-media-stream-audio-source-node-media-stream-without-audio-track-support");
parcelHelpers.exportAll(_testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, exports);
var _testOfflineAudioContextCurrentTimeSupportFactory = require("./test-offline-audio-context-current-time-support-factory");
parcelHelpers.exportAll(_testOfflineAudioContextCurrentTimeSupportFactory, exports);
var _testStereoPannerNodeDefaultValueSupportFactory = require("./test-stereo-panner-node-default-value-support-factory");
parcelHelpers.exportAll(_testStereoPannerNodeDefaultValueSupportFactory, exports);
var _unknownErrorFactory = require("./unknown-error-factory");
parcelHelpers.exportAll(_unknownErrorFactory, exports);
var _unrenderedAudioWorkletNodeStore = require("./unrendered-audio-worklet-node-store");
parcelHelpers.exportAll(_unrenderedAudioWorkletNodeStore, exports);
var _unrenderedAudioWorkletNodes = require("./unrendered-audio-worklet-nodes");
parcelHelpers.exportAll(_unrenderedAudioWorkletNodes, exports);
var _waveShaperNodeConstructor = require("./wave-shaper-node-constructor");
parcelHelpers.exportAll(_waveShaperNodeConstructor, exports);
var _waveShaperNodeConstructorFactory = require("./wave-shaper-node-constructor-factory");
parcelHelpers.exportAll(_waveShaperNodeConstructorFactory, exports);
var _waveShaperNodeRendererFactoryFactory = require("./wave-shaper-node-renderer-factory-factory");
parcelHelpers.exportAll(_waveShaperNodeRendererFactoryFactory, exports);
var _waveShaperNodeRendererFactory = require("./wave-shaper-node-renderer-factory");
parcelHelpers.exportAll(_waveShaperNodeRendererFactory, exports);
var _window = require("./window");
parcelHelpers.exportAll(_window, exports);
var _windowFactory = require("./window-factory");
parcelHelpers.exportAll(_windowFactory, exports);
var _wrapAudioBufferCopyChannelMethodsFactory = require("./wrap-audio-buffer-copy-channel-methods-factory");
parcelHelpers.exportAll(_wrapAudioBufferCopyChannelMethodsFactory, exports);
var _wrapAudioBufferCopyChannelMethodsFunction = require("./wrap-audio-buffer-copy-channel-methods-function");
parcelHelpers.exportAll(_wrapAudioBufferCopyChannelMethodsFunction, exports);
var _wrapAudioBufferCopyChannelMethodsOutOfBoundsFactory = require("./wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory");
parcelHelpers.exportAll(_wrapAudioBufferCopyChannelMethodsOutOfBoundsFactory, exports);
var _wrapAudioBufferCopyChannelMethodsOutOfBoundsFunction = require("./wrap-audio-buffer-copy-channel-methods-out-of-bounds-function");
parcelHelpers.exportAll(_wrapAudioBufferCopyChannelMethodsOutOfBoundsFunction, exports);
var _wrapAudioBufferSourceNodeStartMethodOffsetClampingFunction = require("./wrap-audio-buffer-source-node-start-method-offset-clamping-function");
parcelHelpers.exportAll(_wrapAudioBufferSourceNodeStartMethodOffsetClampingFunction, exports);
var _wrapAudioBufferSourceNodeStopMethodNullifiedBufferFactory = require("./wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory");
parcelHelpers.exportAll(_wrapAudioBufferSourceNodeStopMethodNullifiedBufferFactory, exports);
var _wrapAudioBufferSourceNodeStopMethodNullifiedBufferFunction = require("./wrap-audio-buffer-source-node-stop-method-nullified-buffer-function");
parcelHelpers.exportAll(_wrapAudioBufferSourceNodeStopMethodNullifiedBufferFunction, exports);
var _wrapAudioScheduledSourceNodeStopMethodConsecutiveCallsFunction = require("./wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function");
parcelHelpers.exportAll(_wrapAudioScheduledSourceNodeStopMethodConsecutiveCallsFunction, exports);
var _wrapChannelMergerNodeFactory = require("./wrap-channel-merger-node-factory");
parcelHelpers.exportAll(_wrapChannelMergerNodeFactory, exports);
var _wrapChannelMergerNodeFunction = require("./wrap-channel-merger-node-function");
parcelHelpers.exportAll(_wrapChannelMergerNodeFunction, exports);
var _wrapEventListenerFunction = require("./wrap-event-listener-function");
parcelHelpers.exportAll(_wrapEventListenerFunction, exports);

},{"./abort-error-factory":"aUzMT","./active-audio-worklet-node-inputs-store":"ipST9","./active-input-connection":"btFkQ","./add-active-input-connection-to-audio-node-factory":"h43ad","./add-active-input-connection-to-audio-node-function":"bcRwN","./add-audio-node-connections-factory":"8rdil","./add-audio-node-connections-function":"fycj1","./add-audio-param-connections-factory":"e922S","./add-audio-param-connections-function":"aYJk2","./add-audio-worklet-module-factory":"cfV2t","./add-audio-worklet-module-function":"6RF9e","./add-connection-to-audio-node-factory":"iEM54","./add-connection-to-audio-node-function":"kWGv7","./add-passive-input-connection-to-audio-node-factory":"8MgBI","./add-passive-input-connection-to-audio-node-function":"aob1I","./add-silent-connection-factory":"lsQXn","./add-silent-connection-function":"dwiGY","./add-unrendered-audio-worklet-node-factory":"8vfjw","./add-unrendered-audio-worklet-node-function":"cXbOc","./analyser-node-constructor":"aOh6U","./analyser-node-constructor-factory":"8IsgL","./analyser-node-renderer-factory":"1pvk4","./analyser-node-renderer-factory-factory":"7XeJZ","./any-audio-buffer":"3ReL8","./any-context":"iBO2q","./audio-buffer-constructor":"dY71H","./audio-buffer-constructor-factory":"grM37","./audio-buffer-source-node-constructor":"4Y6lE","./audio-buffer-source-node-constructor-factory":"9dE6w","./audio-buffer-source-node-renderer":"aIlHX","./audio-buffer-source-node-renderer-factory":"bRjks","./audio-buffer-source-node-renderer-factory-factory":"jpODf","./audio-buffer-store":"z9Huw","./audio-context-constructor":"43r8p","./audio-context-constructor-factory":"liVbb","./audio-context-latency-category":"5otJq","./audio-context-state":"h5TOs","./audio-destination-node-constructor":"e0IdR","./audio-destination-node-constructor-factory":"bGj1m","./audio-destination-node-renderer-factory":"cYPRl","./audio-listener-factory":"dNHzm","./audio-listener-factory-factory":"9FBG1","./audio-node-connections":"37pv2","./audio-node-connections-store":"k0jVQ","./audio-node-constructor":"1F99O","./audio-node-constructor-factory":"iXs9h","./audio-node-output-connection":"eVR8v","./audio-node-renderer":"agskS","./audio-node-store":"3ftN3","./audio-node-tail-time-store":"5TtnK","./audio-param-audio-node-store":"byH9A","./audio-param-connections":"iH0XN","./audio-param-connections-store":"jNm5d","./audio-param-factory":"bAKDY","./audio-param-factory-factory":"2Bpih","./audio-param-map":"8a2QH","./audio-param-output-connection":"AUoGC","./audio-param-renderer-factory":"giW9q","./audio-param-store":"fDz5Y","./audio-worklet-node-constructor":"Iki1i","./audio-worklet-node-constructor-factory":"inNLm","./audio-worklet-node-renderer-factory":"7L2QS","./audio-worklet-node-renderer-factory-factory":"bR9k1","./backup-offline-audio-context-store":"RZxmA","./base-audio-context-constructor":"dEwjR","./base-audio-context-constructor-factory":"4Hjoo","./biquad-filter-node-constructor":"VAUlp","./biquad-filter-node-constructor-factory":"9i7OD","./biquad-filter-node-renderer-factory":"bZUmk","./biquad-filter-node-renderer-factory-factory":"bvmmC","./biquad-filter-type":"daxR7","./channel-count-mode":"gzXtD","./channel-interpretation":"g2UHY","./channel-merger-node-constructor":"hec1Q","./channel-merger-node-constructor-factory":"2dXLF","./channel-merger-node-renderer-factory":"epfg3","./channel-merger-node-renderer-factory-factory":"8hx8D","./channel-splitter-node-constructor":"kuZZp","./channel-splitter-node-constructor-factory":"2BOWF","./channel-splitter-node-renderer-factory":"2ABfM","./channel-splitter-node-renderer-factory-factory":"5YBN4","./cache-test-result-factory":"9TZ4M","./cache-test-result-function":"9mT4a","./connect-audio-param-factory":"3j0Fz","./connect-audio-param-function":"1VapG","./connect-multiple-outputs-factory":"lynAY","./connect-multiple-outputs-function":"9Ye60","./connect-native-audio-node-to-native-audio-node-function":"cIcob","./connected-native-audio-buffer-source-node-factory":"1r9h0","./connected-native-audio-buffer-source-node-factory-factory":"iYpbn","./constant-source-node-constructor":"aVPMc","./constant-source-node-constructor-factory":"7zJLN","./constant-source-node-renderer":"cYHXj","./constant-source-node-renderer-factory":"b0xJa","./constant-source-node-renderer-factory-factory":"asPCi","./constructor":"85AkH","./context":"iFJ4I","./context-store":"2fWln","./convert-number-to-unsigned-long-factory":"bB75W","./convert-number-to-unsigned-long-function":"2zqY6","./convolver-node-constructor":"7GS88","./convolver-node-constructor-factory":"fkTV8","./convolver-node-renderer-factory":"gyFuK","./convolver-node-renderer-factory-factory":"4cgV6","./create-native-offline-audio-context-factory":"6hAz0","./create-native-offline-audio-context-function":"8Mgf4","./cycle-counters":"cVUmO","./data-clone-error-factory":"4qo74","./decode-audio-data-factory":"j5Xnd","./decode-audio-data-function":"5tc3T","./decode-error-callback":"kk7W8","./decode-success-callback":"7iMlm","./decrement-cycle-counter-factory":"2go5R","./decrement-cycle-counter-function":"dGsRM","./delay-node-constructor":"dr51p","./delay-node-constructor-factory":"bPUha","./delay-node-renderer-factory":"3NK02","./delay-node-renderer-factory-factory":"bNs0r","./delete-active-input-connection-to-audio-node-factory":"emkUU","./delete-active-input-connection-to-audio-node-function":"bo4Th","./delete-unrendered-audio-worklet-node-factory":"7fAKj","./delete-unrendered-audio-worklet-node-function":"cWU4H","./detect-cycles-factory":"iJ10j","./detect-cycles-function":"5Qnyy","./disconnect-multiple-outputs-factory":"kXTb4","./disconnect-multiple-outputs-function":"6xi4t","./disconnect-native-audio-node-from-native-audio-node-function":"gCc0T","./distance-model-type":"ez0hd","./dynamics-compressor-node-constructor":"8p4l6","./dynamics-compressor-node-constructor-factory":"a5sok","./dynamics-compressor-node-renderer-factory":"jmfWE","./dynamics-compressor-node-renderer-factory-factory":"dxs58","./encoding-error-factory":"gPedL","./error-event-handler":"9Kodl","./evaluate-audio-worklet-global-scope-function":"8wIrB","./evaluate-source-factory":"5EsFh","./evaluate-source-function":"cRC9C","./event-handler":"hnJvg","./event-target-constructor":"8Osko","./event-target-constructor-factory":"991bA","./expose-current-frame-and-current-time-factory":"4ymhr","./expose-current-frame-and-current-time-function":"6J2MV","./fetch-source-factory":"kGcp0","./fetch-source-function":"cEMI9","./gain-node-constructor":"jNG9s","./gain-node-constructor-factory":"abuOG","./gain-node-renderer-factory":"9Sq68","./gain-node-renderer-factory-factory":"RYc3F","./get-active-audio-worklet-node-inputs-factory":"f5A22","./get-active-audio-worklet-node-inputs-function":"9w1aG","./get-audio-node-connections-function":"jwL3Y","./get-audio-node-renderer-factory":"ew43P","./get-audio-node-renderer-function":"34VMw","./get-audio-node-tail-time-factory":"8Flkc","./get-audio-node-tail-time-function":"hq7VA","./get-audio-param-connections-function":"koaAs","./get-audio-param-renderer-factory":"2L1gx","./get-audio-param-renderer-function":"jPUYK","./get-backup-offline-audio-context-factory":"kvSLR","./get-backup-offline-audio-context-function":"5dcsg","./get-event-listeners-of-audio-node-function":"9Domk","./get-first-sample-function":"5xCU5","./get-native-audio-node-function":"lGpbL","./get-native-audio-param-function":"4ajPV","./get-native-context-factory":"fydra","./get-native-context-function":"gyIoo","./get-or-create-backup-offline-audio-context-factory":"j1x9L","./get-or-create-backup-offline-audio-context-function":"hUe17","./get-unrendered-audio-worklet-nodes-factory":"52fJP","./get-unrendered-audio-worklet-nodes-function":"jFSsh","./get-value-for-key-function":"kxk38","./iir-filter-node-constructor":"fyaBJ","./iir-filter-node-constructor-factory":"jK2Xx","./iir-filter-node-renderer-factory":"2M4Hm","./iir-filter-node-renderer-factory-factory":"hbggM","./increment-cycle-counter-factory":"avEQI","./increment-cycle-counter-factory-factory":"4gE9N","./increment-cycle-counter-function":"eLv80","./index-size-error-factory":"g4wUZ","./insert-element-in-set-function":"1WXQU","./internal-state-event-listener":"7nv9f","./invalid-access-error-factory":"c1fU7","./invalid-state-error-factory":"1iowR","./is-active-audio-node-function":"95ze9","./is-any-audio-context-factory":"4croT","./is-any-audio-context-function":"4Z5rT","./is-any-audio-node-factory":"1VZ6r","./is-any-audio-node-function":"5Eutv","./is-any-audio-param-factory":"35EJS","./is-any-audio-param-function":"62Ied","./is-any-offline-audio-context-factory":"9PKQz","./is-any-offline-audio-context-function":"eTYGv","./is-dc-curve-function":"gDS2w","./is-native-audio-context-factory":"3lCEX","./is-native-audio-context-function":"3r8qm","./is-native-audio-node-factory":"dyo3w","./is-native-audio-node-function":"fFlug","./is-native-audio-param-factory":"5Hnm8","./is-native-audio-param-function":"aqXyY","./is-native-context-factory":"kT94m","./is-native-context-function":"arod4","./is-native-offline-audio-context-factory":"cHtQP","./is-native-offline-audio-context-function":"k1nf2","./is-part-of-a-cycle-function":"9Hux4","./is-passive-audio-node-function":"jpyfX","./is-secure-context-factory":"8gy3Q","./is-supported-promise-factory":"4QnYx","./media-element-audio-source-node-constructor":"4KNOm","./media-element-audio-source-node-constructor-factory":"jVYaK","./media-stream-audio-destination-node-constructor":"8WwsT","./media-stream-audio-destination-node-constructor-factory":"esFJ9","./media-stream-audio-source-node-constructor":"ePEDx","./media-stream-audio-source-node-constructor-factory":"3C8PS","./media-stream-track-audio-source-node-constructor":"hldCL","./media-stream-track-audio-source-node-constructor-factory":"k8Nya","./minimal-audio-context-constructor":"Yv1Sc","./minimal-audio-context-constructor-factory":"6Xbcb","./minimal-base-audio-context-constructor":"3XZ5M","./minimal-base-audio-context-constructor-factory":"lkVu3","./minimal-offline-audio-context-constructor":"py1MV","./minimal-offline-audio-context-constructor-factory":"8J5Nr","./monitor-connections-factory":"isyVz","./monitor-connections-function":"6LxAr","./native-analyser-node":"5fHCU","./native-analyser-node-factory":"l0Vzb","./native-analyser-node-factory-factory":"ai7cN","./native-audio-buffer":"ftwXI","./native-audio-buffer-constructor":"iJb7j","./native-audio-buffer-constructor-factory":"eGJ6K","./native-audio-buffer-source-node":"bOMHn","./native-audio-buffer-source-node-factory":"ftaWc","./native-audio-buffer-source-node-factory-factory":"h0GNd","./native-audio-context":"lgwDo","./native-audio-context-constructor":"8OLrd","./native-audio-context-constructor-factory":"1O4wn","./native-audio-destination-node":"5yVzS","./native-audio-destination-node-factory":"hJjCG","./native-audio-destination-node-factory-factory":"lyLPE","./native-audio-listener":"gKzj4","./native-audio-node":"6dE2I","./native-audio-param":"eccBR","./native-audio-param-map":"g8U1T","./native-audio-worklet":"jhxAL","./native-audio-worklet-node":"4BSDJ","./native-audio-worklet-node-constructor":"dvaEu","./native-audio-worklet-node-constructor-factory":"8GFKD","./native-audio-worklet-node-factory":"7vIBc","./native-audio-worklet-node-factory-factory":"aQlrl","./native-audio-worklet-node-faker-factory":"27287","./native-audio-worklet-node-faker-factory-factory":"2Qvzo","./native-audio-worklet-node-options":"iLEdF","./native-biquad-filter-node":"sX4hL","./native-biquad-filter-node-factory":"1rr36","./native-channel-merger-node":"gq9JB","./native-channel-merger-node-factory":"dkKJM","./native-channel-merger-node-factory-factory":"cAh2d","./native-channel-splitter-node":"c6qsA","./native-channel-splitter-node-factory":"cCUrb","./native-constant-source-node":"8od1O","./native-constant-source-node-factory":"dgRS0","./native-constant-source-node-factory-factory":"ha1Db","./native-constant-source-node-faker-factory":"chZTo","./native-constant-source-node-faker-factory-factory":"ak3OM","./native-context":"9SfLF","./native-convolver-node":"3Fxtv","./native-convolver-node-factory":"1Dy1V","./native-convolver-node-factory-factory":"dcQrS","./native-delay-node-factory":"g2gNy","./native-delay-node":"4LVjO","./native-dynamics-compressor-node":"4kiTv","./native-dynamics-compressor-node-factory":"hhZZQ","./native-dynamics-compressor-node-factory-factory":"98MUd","./native-event-target":"fj2c8","./native-gain-node":"joI9B","./native-gain-node-factory":"YeBQx","./native-iir-filter-node":"48gZR","./native-iir-filter-node-factory":"7Uaqw","./native-iir-filter-node-factory-factory":"76OdY","./native-iir-filter-node-faker-factory":"iCcpI","./native-iir-filter-node-faker-factory-factory":"3CH8G","./native-media-element-audio-source-node":"4dzZN","./native-media-element-audio-source-node-factory":"jNR0H","./native-media-stream-audio-destination-node":"i8Gzz","./native-media-stream-audio-destination-node-factory":"isv7n","./native-media-stream-audio-source-node":"fFxbg","./native-media-stream-audio-source-node-factory":"7dDEQ","./native-media-stream-track-audio-source-node":"89UdU","./native-media-stream-track-audio-source-node-factory":"jpjXG","./native-media-stream-track-audio-source-node-factory-factory":"4LSMG","./native-offline-audio-context":"fKZTC","./native-offline-audio-context-constructor":"HTJeH","./native-offline-audio-context-constructor-factory":"a9MY1","./native-oscillator-node":"6iCPg","./native-oscillator-node-factory":"5MgM0","./native-oscillator-node-factory-factory":"h39Dr","./native-panner-node":"d2MhQ","./native-panner-node-factory":"kOBiN","./native-panner-node-factory-factory":"chkg8","./native-panner-node-faker-factory":"5CYpg","./native-panner-node-faker-factory-factory":"bMtpM","./native-periodic-wave":"fnNVE","./native-periodic-wave-factory":"h33BO","./native-periodic-wave-factory-factory":"7SbgB","./native-script-processor-node":"eELQS","./native-script-processor-node-factory":"esp1w","./native-stereo-panner-node":"eHmJb","./native-stereo-panner-node-factory":"lWqsp","./native-stereo-panner-node-factory-factory":"bcWkB","./native-stereo-panner-node-faker-factory":"gw6Sp","./native-stereo-panner-node-faker-factory-factory":"gabS5","./native-wave-shaper-node":"b8Q3J","./native-wave-shaper-node-factory":"dj2rV","./native-wave-shaper-node-factory-factory":"jIoWv","./native-wave-shaper-node-faker-factory":"1eUGR","./native-wave-shaper-node-faker-factory-factory":"PL3J1","./not-supported-error-factory":"4ou1B","./offline-audio-context-constructor-factory":"2nMEr","./oscillator-node-constructor":"igviH","./oscillator-node-constructor-factory":"iW0sZ","./oscillator-node-renderer":"7kfAL","./oscillator-node-renderer-factory":"2IfGU","./oscillator-node-renderer-factory-factory":"3Xgsk","./oscillator-type":"aiz22","./output-connection":"gkfN3","./over-sample-type":"5Al8v","./overwrite-accessors-function":"2gdGV","./panner-node-constructor":"9M5hV","./panner-node-constructor-factory":"6CGrv","./panner-node-renderer-factory":"fp4vW","./panner-node-renderer-factory-factory":"2ddUV","./panning-model-type":"7wghh","./passive-audio-node-input-connection":"2ue4y","./passive-audio-param-input-connection":"cZfB9","./periodic-wave-constructor":"egwKh","./periodic-wave-constructor-factory":"dS3aZ","./pick-element-from-set-function":"dp1DX","./render-automation-factory":"5XE1m","./render-automation-function":"idqSi","./render-inputs-of-audio-node-factory":"4DoVL","./render-inputs-of-audio-node-function":"dJbcY","./render-inputs-of-audio-param-factory":"19FsI","./render-inputs-of-audio-param-function":"65pUG","./render-native-offline-audio-context-factory":"gZsiJ","./render-native-offline-audio-context-function":"iwuDH","./sanitize-audio-worklet-node-options-function":"60Syy","./sanitize-channel-splitter-options-function":"EGeCu","./sanitize-periodic-wave-options-function":"kv52Q","./set-active-audio-worklet-node-inputs-factory":"8bUBr","./set-active-audio-worklet-node-inputs-function":"ll24L","./set-audio-node-tail-time-factory":"9IPtR","./set-audio-node-tail-time-function":"jzeBP","./set-value-at-time-until-possible-function":"euRQ6","./start-rendering-factory":"kp1Mr","./start-rendering-function":"jnwbU","./stereo-panner-node-constructor":"lWpSG","./stereo-panner-node-constructor-factory":"cT1l0","./stereo-panner-node-renderer-factory-factory":"axKiB","./stereo-panner-node-renderer-factory":"lvNSy","./test-audio-buffer-copy-channel-methods-subarray-support-factory":"frcUD","./test-audio-buffer-constructor-support-factory":"96UOT","./test-audio-context-close-method-support-factory":"hSxba","./test-audio-context-decode-audio-data-method-type-error-support-factory":"60HtJ","./test-audio-context-options-support-factory":"j65CQ","./test-audio-node-connect-method-support-factory":"gkWR3","./test-audio-worklet-node-options-clonability-function":"c8hBt","./test-audio-worklet-processor-no-outputs-support-factory":"e3Hr0","./test-audio-worklet-processor-post-message-support-factory":"d9Pdm","./test-channel-merger-node-channel-count-support-factory":"aJgeT","./test-constant-source-node-accurate-scheduling-support-factory":"6kbpN","./test-convolver-node-buffer-reassignability-support-factory":"7obSE","./test-convolver-node-channel-count-support-factory":"dk0SD","./test-is-secure-context-support-factory":"59xUC","./test-media-stream-audio-source-node-media-stream-without-audio-track-support":"kEqp3","./test-offline-audio-context-current-time-support-factory":"2Jdp7","./test-stereo-panner-node-default-value-support-factory":"1gJUr","./unknown-error-factory":"eauik","./unrendered-audio-worklet-node-store":"4PmYP","./unrendered-audio-worklet-nodes":"8GJHC","./wave-shaper-node-constructor":"9AzvI","./wave-shaper-node-constructor-factory":"cElf2","./wave-shaper-node-renderer-factory-factory":"iKZcM","./wave-shaper-node-renderer-factory":"A5RWt","./window":"j77wm","./window-factory":"a3p4t","./wrap-audio-buffer-copy-channel-methods-factory":"bSNo3","./wrap-audio-buffer-copy-channel-methods-function":"fS9TF","./wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory":"dP834","./wrap-audio-buffer-copy-channel-methods-out-of-bounds-function":"2F4QJ","./wrap-audio-buffer-source-node-start-method-offset-clamping-function":"lf7QF","./wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory":"l7G2Q","./wrap-audio-buffer-source-node-stop-method-nullified-buffer-function":"bBwY3","./wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function":"gND3m","./wrap-channel-merger-node-factory":"ghFAN","./wrap-channel-merger-node-function":"k9n1J","./wrap-event-listener-function":"fcfNo","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aUzMT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ipST9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"btFkQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h43ad":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bcRwN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8rdil":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fycj1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"e922S":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aYJk2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cfV2t":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6RF9e":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iEM54":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kWGv7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8MgBI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aob1I":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lsQXn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dwiGY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8vfjw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cXbOc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aOh6U":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8IsgL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1pvk4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7XeJZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3ReL8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iBO2q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dY71H":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"grM37":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4Y6lE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9dE6w":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aIlHX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bRjks":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jpODf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"z9Huw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"43r8p":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"liVbb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5otJq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h5TOs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"e0IdR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bGj1m":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cYPRl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dNHzm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9FBG1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"37pv2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k0jVQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1F99O":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iXs9h":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eVR8v":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"agskS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3ftN3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5TtnK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"byH9A":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iH0XN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jNm5d":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bAKDY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2Bpih":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8a2QH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"AUoGC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"giW9q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fDz5Y":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"Iki1i":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"inNLm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7L2QS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bR9k1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"RZxmA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dEwjR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4Hjoo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"VAUlp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9i7OD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bZUmk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bvmmC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"daxR7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gzXtD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g2UHY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hec1Q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2dXLF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"epfg3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8hx8D":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kuZZp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2BOWF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2ABfM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5YBN4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9TZ4M":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9mT4a":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3j0Fz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1VapG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lynAY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9Ye60":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cIcob":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1r9h0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iYpbn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aVPMc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7zJLN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cYHXj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"b0xJa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"asPCi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"85AkH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iFJ4I":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2fWln":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bB75W":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2zqY6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7GS88":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fkTV8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gyFuK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4cgV6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6hAz0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8Mgf4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cVUmO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4qo74":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j5Xnd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5tc3T":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kk7W8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7iMlm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2go5R":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dGsRM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dr51p":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bPUha":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3NK02":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bNs0r":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"emkUU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bo4Th":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7fAKj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cWU4H":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iJ10j":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5Qnyy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kXTb4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6xi4t":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gCc0T":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ez0hd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8p4l6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"a5sok":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jmfWE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dxs58":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gPedL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9Kodl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8wIrB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5EsFh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cRC9C":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hnJvg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8Osko":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"991bA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4ymhr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6J2MV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kGcp0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cEMI9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jNG9s":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"abuOG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9Sq68":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"RYc3F":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"f5A22":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9w1aG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jwL3Y":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ew43P":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"34VMw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8Flkc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hq7VA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"koaAs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2L1gx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jPUYK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kvSLR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5dcsg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9Domk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5xCU5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lGpbL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4ajPV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fydra":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gyIoo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j1x9L":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hUe17":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"52fJP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jFSsh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kxk38":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fyaBJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jK2Xx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2M4Hm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hbggM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"avEQI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4gE9N":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eLv80":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g4wUZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1WXQU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7nv9f":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"c1fU7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1iowR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"95ze9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4croT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4Z5rT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1VZ6r":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5Eutv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"35EJS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"62Ied":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9PKQz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eTYGv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gDS2w":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3lCEX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3r8qm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dyo3w":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fFlug":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5Hnm8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aqXyY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kT94m":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"arod4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cHtQP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k1nf2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9Hux4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jpyfX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8gy3Q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4QnYx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4KNOm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jVYaK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8WwsT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"esFJ9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ePEDx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3C8PS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hldCL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k8Nya":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"Yv1Sc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6Xbcb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3XZ5M":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lkVu3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"py1MV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8J5Nr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"isyVz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6LxAr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5fHCU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"l0Vzb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ai7cN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ftwXI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iJb7j":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eGJ6K":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bOMHn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ftaWc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h0GNd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lgwDo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8OLrd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1O4wn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5yVzS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hJjCG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lyLPE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gKzj4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6dE2I":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eccBR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g8U1T":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jhxAL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4BSDJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dvaEu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8GFKD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7vIBc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aQlrl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"27287":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2Qvzo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iLEdF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"sX4hL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1rr36":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gq9JB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dkKJM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cAh2d":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"c6qsA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cCUrb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8od1O":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dgRS0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ha1Db":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"chZTo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ak3OM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9SfLF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3Fxtv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1Dy1V":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dcQrS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g2gNy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4LVjO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4kiTv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hhZZQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"98MUd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fj2c8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"joI9B":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"YeBQx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"48gZR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7Uaqw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"76OdY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iCcpI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3CH8G":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4dzZN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jNR0H":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"i8Gzz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"isv7n":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fFxbg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7dDEQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"89UdU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jpjXG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4LSMG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fKZTC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"HTJeH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"a9MY1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6iCPg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5MgM0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h39Dr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"d2MhQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kOBiN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"chkg8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5CYpg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bMtpM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fnNVE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h33BO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7SbgB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eELQS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"esp1w":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eHmJb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lWqsp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bcWkB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gw6Sp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gabS5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"b8Q3J":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dj2rV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jIoWv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1eUGR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"PL3J1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4ou1B":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2nMEr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"igviH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iW0sZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7kfAL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2IfGU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3Xgsk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aiz22":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gkfN3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5Al8v":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2gdGV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9M5hV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6CGrv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fp4vW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2ddUV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7wghh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2ue4y":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cZfB9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"egwKh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dS3aZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dp1DX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5XE1m":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"idqSi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4DoVL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dJbcY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"19FsI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"65pUG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gZsiJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iwuDH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"60Syy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"EGeCu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kv52Q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8bUBr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ll24L":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9IPtR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jzeBP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"euRQ6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kp1Mr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jnwbU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lWpSG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cT1l0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"axKiB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lvNSy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"frcUD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"96UOT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hSxba":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"60HtJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j65CQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gkWR3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"c8hBt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"e3Hr0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"d9Pdm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aJgeT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6kbpN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7obSE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dk0SD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"59xUC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kEqp3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2Jdp7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1gJUr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eauik":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4PmYP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8GJHC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9AzvI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cElf2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iKZcM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"A5RWt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j77wm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"a3p4t":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bSNo3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fS9TF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dP834":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2F4QJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lf7QF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"l7G2Q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bBwY3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gND3m":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ghFAN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k9n1J":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fcfNo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2lOIQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Assert that the statement is true, otherwise invoke the error.
 * @param statement
 * @param error The message which is passed into an Error
 */ parcelHelpers.export(exports, "assert", ()=>assert);
/**
 * Make sure that the given value is within the range
 */ parcelHelpers.export(exports, "assertRange", ()=>assertRange);
/**
 * Warn if the context is not running.
 */ parcelHelpers.export(exports, "assertContextRunning", ()=>assertContextRunning);
/**
 * Notify that the following block of code is occurring inside a Transport callback.
 */ parcelHelpers.export(exports, "enterScheduledCallback", ()=>enterScheduledCallback);
/**
 * Make sure that a time was passed into
 */ parcelHelpers.export(exports, "assertUsedScheduleTime", ()=>assertUsedScheduleTime);
/**
 * Set the logging interface
 */ parcelHelpers.export(exports, "setLogger", ()=>setLogger);
/**
 * Log anything
 */ parcelHelpers.export(exports, "log", ()=>log);
/**
 * Warn anything
 */ parcelHelpers.export(exports, "warn", ()=>warn);
var _typeCheckJs = require("./TypeCheck.js");
function assert(statement, error) {
    if (!statement) throw new Error(error);
}
function assertRange(value, gte, lte = Infinity) {
    if (!(gte <= value && value <= lte)) throw new RangeError(`Value must be within [${gte}, ${lte}], got: ${value}`);
}
function assertContextRunning(context) {
    // add a warning if the context is not started
    if (!context.isOffline && context.state !== "running") warn('The AudioContext is "suspended". Invoke Tone.start() from a user action to start the audio.');
}
/**
 * If it is currently inside a scheduled callback
 */ let isInsideScheduledCallback = false;
let printedScheduledWarning = false;
function enterScheduledCallback(insideCallback) {
    isInsideScheduledCallback = insideCallback;
}
function assertUsedScheduleTime(time) {
    if ((0, _typeCheckJs.isUndef)(time) && isInsideScheduledCallback && !printedScheduledWarning) {
        printedScheduledWarning = true;
        warn("Events scheduled inside of scheduled callbacks should use the passed in scheduling time. See https://github.com/Tonejs/Tone.js/wiki/Accurate-Timing");
    }
}
/**
 * The default logger is the console
 */ let defaultLogger = console;
function setLogger(logger) {
    defaultLogger = logger;
}
function log(...args) {
    defaultLogger.log(...args);
}
function warn(...args) {
    defaultLogger.warn(...args);
}

},{"./TypeCheck.js":"eMH5A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eMH5A":[function(require,module,exports) {
/**
 * Test if the arg is undefined
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isUndef", ()=>isUndef);
/**
 * Test if the arg is not undefined
 */ parcelHelpers.export(exports, "isDefined", ()=>isDefined);
/**
 * Test if the arg is a function
 */ parcelHelpers.export(exports, "isFunction", ()=>isFunction);
/**
 * Test if the argument is a number.
 */ parcelHelpers.export(exports, "isNumber", ()=>isNumber);
/**
 * Test if the given argument is an object literal (i.e. `{}`);
 */ parcelHelpers.export(exports, "isObject", ()=>isObject);
/**
 * Test if the argument is a boolean.
 */ parcelHelpers.export(exports, "isBoolean", ()=>isBoolean);
/**
 * Test if the argument is an Array
 */ parcelHelpers.export(exports, "isArray", ()=>isArray);
/**
 * Test if the argument is a string.
 */ parcelHelpers.export(exports, "isString", ()=>isString);
/**
 * Test if the argument is in the form of a note in scientific pitch notation.
 * e.g. "C4"
 */ parcelHelpers.export(exports, "isNote", ()=>isNote);
function isUndef(arg) {
    return arg === undefined;
}
function isDefined(arg) {
    return arg !== undefined;
}
function isFunction(arg) {
    return typeof arg === "function";
}
function isNumber(arg) {
    return typeof arg === "number";
}
function isObject(arg) {
    return Object.prototype.toString.call(arg) === "[object Object]" && arg.constructor === Object;
}
function isBoolean(arg) {
    return typeof arg === "boolean";
}
function isArray(arg) {
    return Array.isArray(arg);
}
function isString(arg) {
    return typeof arg === "string";
}
function isNote(arg) {
    return isString(arg) && /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i.test(arg);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1CuCx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the native AudioContext.
 * @category Core
 */ parcelHelpers.export(exports, "Context", ()=>Context);
var _tslib = require("tslib");
var _tickerJs = require("../clock/Ticker.js");
var _advancedTypeCheckJs = require("../util/AdvancedTypeCheck.js");
var _defaultsJs = require("../util/Defaults.js");
var _timelineJs = require("../util/Timeline.js");
var _typeCheckJs = require("../util/TypeCheck.js");
var _audioContextJs = require("./AudioContext.js");
var _contextInitializationJs = require("./ContextInitialization.js");
var _baseContextJs = require("./BaseContext.js");
var _debugJs = require("../util/Debug.js");
class Context extends (0, _baseContextJs.BaseContext) {
    constructor(){
        var _a, _b;
        super();
        this.name = "Context";
        /**
         * An object containing all of the constants AudioBufferSourceNodes
         */ this._constants = new Map();
        /**
         * All of the setTimeout events.
         */ this._timeouts = new (0, _timelineJs.Timeline)();
        /**
         * The timeout id counter
         */ this._timeoutIds = 0;
        /**
         * Private indicator if the context has been initialized
         */ this._initialized = false;
        /**
         * Private indicator if a close() has been called on the context, since close is async
         */ this._closeStarted = false;
        /**
         * Indicates if the context is an OfflineAudioContext or an AudioContext
         */ this.isOffline = false;
        //--------------------------------------------
        // AUDIO WORKLET
        //--------------------------------------------
        /**
         * Maps a module name to promise of the addModule method
         */ this._workletPromise = null;
        const options = (0, _defaultsJs.optionsFromArguments)(Context.getDefaults(), arguments, [
            "context"
        ]);
        if (options.context) {
            this._context = options.context;
            // custom context provided, latencyHint unknown (unless explicitly provided in options)
            this._latencyHint = ((_a = arguments[0]) === null || _a === void 0 ? void 0 : _a.latencyHint) || "";
        } else {
            this._context = (0, _audioContextJs.createAudioContext)({
                latencyHint: options.latencyHint
            });
            this._latencyHint = options.latencyHint;
        }
        this._ticker = new (0, _tickerJs.Ticker)(this.emit.bind(this, "tick"), options.clockSource, options.updateInterval, this._context.sampleRate);
        this.on("tick", this._timeoutLoop.bind(this));
        // fwd events from the context
        this._context.onstatechange = ()=>{
            this.emit("statechange", this.state);
        };
        // if no custom updateInterval provided, updateInterval will be derived by lookAhead setter
        this[((_b = arguments[0]) === null || _b === void 0 ? void 0 : _b.hasOwnProperty("updateInterval")) ? "_lookAhead" : "lookAhead"] = options.lookAhead;
    }
    static getDefaults() {
        return {
            clockSource: "worker",
            latencyHint: "interactive",
            lookAhead: 0.1,
            updateInterval: 0.05
        };
    }
    /**
     * Finish setting up the context. **You usually do not need to do this manually.**
     */ initialize() {
        if (!this._initialized) {
            // add any additional modules
            (0, _contextInitializationJs.initializeContext)(this);
            this._initialized = true;
        }
        return this;
    }
    //---------------------------
    // BASE AUDIO CONTEXT METHODS
    //---------------------------
    createAnalyser() {
        return this._context.createAnalyser();
    }
    createOscillator() {
        return this._context.createOscillator();
    }
    createBufferSource() {
        return this._context.createBufferSource();
    }
    createBiquadFilter() {
        return this._context.createBiquadFilter();
    }
    createBuffer(numberOfChannels, length, sampleRate) {
        return this._context.createBuffer(numberOfChannels, length, sampleRate);
    }
    createChannelMerger(numberOfInputs) {
        return this._context.createChannelMerger(numberOfInputs);
    }
    createChannelSplitter(numberOfOutputs) {
        return this._context.createChannelSplitter(numberOfOutputs);
    }
    createConstantSource() {
        return this._context.createConstantSource();
    }
    createConvolver() {
        return this._context.createConvolver();
    }
    createDelay(maxDelayTime) {
        return this._context.createDelay(maxDelayTime);
    }
    createDynamicsCompressor() {
        return this._context.createDynamicsCompressor();
    }
    createGain() {
        return this._context.createGain();
    }
    createIIRFilter(feedForward, feedback) {
        // @ts-ignore
        return this._context.createIIRFilter(feedForward, feedback);
    }
    createPanner() {
        return this._context.createPanner();
    }
    createPeriodicWave(real, imag, constraints) {
        return this._context.createPeriodicWave(real, imag, constraints);
    }
    createStereoPanner() {
        return this._context.createStereoPanner();
    }
    createWaveShaper() {
        return this._context.createWaveShaper();
    }
    createMediaStreamSource(stream) {
        (0, _debugJs.assert)((0, _advancedTypeCheckJs.isAudioContext)(this._context), "Not available if OfflineAudioContext");
        const context = this._context;
        return context.createMediaStreamSource(stream);
    }
    createMediaElementSource(element) {
        (0, _debugJs.assert)((0, _advancedTypeCheckJs.isAudioContext)(this._context), "Not available if OfflineAudioContext");
        const context = this._context;
        return context.createMediaElementSource(element);
    }
    createMediaStreamDestination() {
        (0, _debugJs.assert)((0, _advancedTypeCheckJs.isAudioContext)(this._context), "Not available if OfflineAudioContext");
        const context = this._context;
        return context.createMediaStreamDestination();
    }
    decodeAudioData(audioData) {
        return this._context.decodeAudioData(audioData);
    }
    /**
     * The current time in seconds of the AudioContext.
     */ get currentTime() {
        return this._context.currentTime;
    }
    /**
     * The current time in seconds of the AudioContext.
     */ get state() {
        return this._context.state;
    }
    /**
     * The current time in seconds of the AudioContext.
     */ get sampleRate() {
        return this._context.sampleRate;
    }
    /**
     * The listener
     */ get listener() {
        this.initialize();
        return this._listener;
    }
    set listener(l) {
        (0, _debugJs.assert)(!this._initialized, "The listener cannot be set after initialization.");
        this._listener = l;
    }
    /**
     * There is only one Transport per Context. It is created on initialization.
     */ get transport() {
        this.initialize();
        return this._transport;
    }
    set transport(t) {
        (0, _debugJs.assert)(!this._initialized, "The transport cannot be set after initialization.");
        this._transport = t;
    }
    /**
     * This is the Draw object for the context which is useful for synchronizing the draw frame with the Tone.js clock.
     */ get draw() {
        this.initialize();
        return this._draw;
    }
    set draw(d) {
        (0, _debugJs.assert)(!this._initialized, "Draw cannot be set after initialization.");
        this._draw = d;
    }
    /**
     * A reference to the Context's destination node.
     */ get destination() {
        this.initialize();
        return this._destination;
    }
    set destination(d) {
        (0, _debugJs.assert)(!this._initialized, "The destination cannot be set after initialization.");
        this._destination = d;
    }
    /**
     * Create an audio worklet node from a name and options. The module
     * must first be loaded using {@link addAudioWorkletModule}.
     */ createAudioWorkletNode(name, options) {
        return (0, _audioContextJs.createAudioWorkletNode)(this.rawContext, name, options);
    }
    /**
     * Add an AudioWorkletProcessor module
     * @param url The url of the module
     */ addAudioWorkletModule(url) {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            (0, _debugJs.assert)((0, _typeCheckJs.isDefined)(this.rawContext.audioWorklet), "AudioWorkletNode is only available in a secure context (https or localhost)");
            if (!this._workletPromise) this._workletPromise = this.rawContext.audioWorklet.addModule(url);
            yield this._workletPromise;
        });
    }
    /**
     * Returns a promise which resolves when all of the worklets have been loaded on this context
     */ workletsAreReady() {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            (yield this._workletPromise) ? this._workletPromise : Promise.resolve();
        });
    }
    //---------------------------
    // TICKER
    //---------------------------
    /**
     * How often the interval callback is invoked.
     * This number corresponds to how responsive the scheduling
     * can be. Setting to 0 will result in the lowest practial interval
     * based on context properties. context.updateInterval + context.lookAhead
     * gives you the total latency between scheduling an event and hearing it.
     */ get updateInterval() {
        return this._ticker.updateInterval;
    }
    set updateInterval(interval) {
        this._ticker.updateInterval = interval;
    }
    /**
     * What the source of the clock is, either "worker" (default),
     * "timeout", or "offline" (none).
     */ get clockSource() {
        return this._ticker.type;
    }
    set clockSource(type) {
        this._ticker.type = type;
    }
    /**
     * The amount of time into the future events are scheduled. Giving Web Audio
     * a short amount of time into the future to schedule events can reduce clicks and
     * improve performance. This value can be set to 0 to get the lowest latency.
     * Adjusting this value also affects the {@link updateInterval}.
     */ get lookAhead() {
        return this._lookAhead;
    }
    set lookAhead(time) {
        this._lookAhead = time;
        // if lookAhead is 0, default to .01 updateInterval
        this.updateInterval = time ? time / 2 : 0.01;
    }
    /**
     * The type of playback, which affects tradeoffs between audio
     * output latency and responsiveness.
     * In addition to setting the value in seconds, the latencyHint also
     * accepts the strings "interactive" (prioritizes low latency),
     * "playback" (prioritizes sustained playback), "balanced" (balances
     * latency and performance).
     * @example
     * // prioritize sustained playback
     * const context = new Tone.Context({ latencyHint: "playback" });
     * // set this context as the global Context
     * Tone.setContext(context);
     * // the global context is gettable with Tone.getContext()
     * console.log(Tone.getContext().latencyHint);
     */ get latencyHint() {
        return this._latencyHint;
    }
    /**
     * The unwrapped AudioContext or OfflineAudioContext
     */ get rawContext() {
        return this._context;
    }
    /**
     * The current audio context time plus a short {@link lookAhead}.
     * @example
     * setInterval(() => {
     * 	console.log("now", Tone.now());
     * }, 100);
     */ now() {
        return this._context.currentTime + this._lookAhead;
    }
    /**
     * The current audio context time without the {@link lookAhead}.
     * In most cases it is better to use {@link now} instead of {@link immediate} since
     * with {@link now} the {@link lookAhead} is applied equally to _all_ components including internal components,
     * to making sure that everything is scheduled in sync. Mixing {@link now} and {@link immediate}
     * can cause some timing issues. If no lookAhead is desired, you can set the {@link lookAhead} to `0`.
     */ immediate() {
        return this._context.currentTime;
    }
    /**
     * Starts the audio context from a suspended state. This is required
     * to initially start the AudioContext.
     * @see {@link start}
     */ resume() {
        if ((0, _advancedTypeCheckJs.isAudioContext)(this._context)) return this._context.resume();
        else return Promise.resolve();
    }
    /**
     * Close the context. Once closed, the context can no longer be used and
     * any AudioNodes created from the context will be silent.
     */ close() {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            if ((0, _advancedTypeCheckJs.isAudioContext)(this._context) && this.state !== "closed" && !this._closeStarted) {
                this._closeStarted = true;
                yield this._context.close();
            }
            if (this._initialized) (0, _contextInitializationJs.closeContext)(this);
        });
    }
    /**
     * **Internal** Generate a looped buffer at some constant value.
     */ getConstant(val) {
        if (this._constants.has(val)) return this._constants.get(val);
        else {
            const buffer = this._context.createBuffer(1, 128, this._context.sampleRate);
            const arr = buffer.getChannelData(0);
            for(let i = 0; i < arr.length; i++)arr[i] = val;
            const constant = this._context.createBufferSource();
            constant.channelCount = 1;
            constant.channelCountMode = "explicit";
            constant.buffer = buffer;
            constant.loop = true;
            constant.start(0);
            this._constants.set(val, constant);
            return constant;
        }
    }
    /**
     * Clean up. Also closes the audio context.
     */ dispose() {
        super.dispose();
        this._ticker.dispose();
        this._timeouts.dispose();
        Object.keys(this._constants).map((val)=>this._constants[val].disconnect());
        this.close();
        return this;
    }
    //---------------------------
    // TIMEOUTS
    //---------------------------
    /**
     * The private loop which keeps track of the context scheduled timeouts
     * Is invoked from the clock source
     */ _timeoutLoop() {
        const now = this.now();
        let firstEvent = this._timeouts.peek();
        while(this._timeouts.length && firstEvent && firstEvent.time <= now){
            // invoke the callback
            firstEvent.callback();
            // shift the first event off
            this._timeouts.shift();
            // get the next one
            firstEvent = this._timeouts.peek();
        }
    }
    /**
     * A setTimeout which is guaranteed by the clock source.
     * Also runs in the offline context.
     * @param  fn       The callback to invoke
     * @param  timeout  The timeout in seconds
     * @returns ID to use when invoking Context.clearTimeout
     */ setTimeout(fn, timeout) {
        this._timeoutIds++;
        const now = this.now();
        this._timeouts.add({
            callback: fn,
            id: this._timeoutIds,
            time: now + timeout
        });
        return this._timeoutIds;
    }
    /**
     * Clears a previously scheduled timeout with Tone.context.setTimeout
     * @param  id  The ID returned from setTimeout
     */ clearTimeout(id) {
        this._timeouts.forEach((event)=>{
            if (event.id === id) this._timeouts.remove(event);
        });
        return this;
    }
    /**
     * Clear the function scheduled by {@link setInterval}
     */ clearInterval(id) {
        return this.clearTimeout(id);
    }
    /**
     * Adds a repeating event to the context's callback clock
     */ setInterval(fn, interval) {
        const id = ++this._timeoutIds;
        const intervalFn = ()=>{
            const now = this.now();
            this._timeouts.add({
                callback: ()=>{
                    // invoke the callback
                    fn();
                    // invoke the event to repeat it
                    intervalFn();
                },
                id,
                time: now + interval
            });
        };
        // kick it off
        intervalFn();
        return id;
    }
}

},{"tslib":"lRdW5","../clock/Ticker.js":"jj5sD","../util/AdvancedTypeCheck.js":"gKVc7","../util/Defaults.js":"a9M5s","../util/Timeline.js":"36KJ4","../util/TypeCheck.js":"eMH5A","./AudioContext.js":"1NjF0","./ContextInitialization.js":"iapnw","./BaseContext.js":"bktf5","../util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lRdW5":[function(require,module,exports) {
/******************************************************************************
Copyright (c) Microsoft Corporation.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
***************************************************************************** */ /* global Reflect, Promise, SuppressedError, Symbol */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "__extends", ()=>__extends);
parcelHelpers.export(exports, "__assign", ()=>__assign);
parcelHelpers.export(exports, "__rest", ()=>__rest);
parcelHelpers.export(exports, "__decorate", ()=>__decorate);
parcelHelpers.export(exports, "__param", ()=>__param);
parcelHelpers.export(exports, "__esDecorate", ()=>__esDecorate);
parcelHelpers.export(exports, "__runInitializers", ()=>__runInitializers);
parcelHelpers.export(exports, "__propKey", ()=>__propKey);
parcelHelpers.export(exports, "__setFunctionName", ()=>__setFunctionName);
parcelHelpers.export(exports, "__metadata", ()=>__metadata);
parcelHelpers.export(exports, "__awaiter", ()=>__awaiter);
parcelHelpers.export(exports, "__generator", ()=>__generator);
parcelHelpers.export(exports, "__createBinding", ()=>__createBinding);
parcelHelpers.export(exports, "__exportStar", ()=>__exportStar);
parcelHelpers.export(exports, "__values", ()=>__values);
parcelHelpers.export(exports, "__read", ()=>__read);
/** @deprecated */ parcelHelpers.export(exports, "__spread", ()=>__spread);
/** @deprecated */ parcelHelpers.export(exports, "__spreadArrays", ()=>__spreadArrays);
parcelHelpers.export(exports, "__spreadArray", ()=>__spreadArray);
parcelHelpers.export(exports, "__await", ()=>__await);
parcelHelpers.export(exports, "__asyncGenerator", ()=>__asyncGenerator);
parcelHelpers.export(exports, "__asyncDelegator", ()=>__asyncDelegator);
parcelHelpers.export(exports, "__asyncValues", ()=>__asyncValues);
parcelHelpers.export(exports, "__makeTemplateObject", ()=>__makeTemplateObject);
parcelHelpers.export(exports, "__importStar", ()=>__importStar);
parcelHelpers.export(exports, "__importDefault", ()=>__importDefault);
parcelHelpers.export(exports, "__classPrivateFieldGet", ()=>__classPrivateFieldGet);
parcelHelpers.export(exports, "__classPrivateFieldSet", ()=>__classPrivateFieldSet);
parcelHelpers.export(exports, "__classPrivateFieldIn", ()=>__classPrivateFieldIn);
parcelHelpers.export(exports, "__addDisposableResource", ()=>__addDisposableResource);
parcelHelpers.export(exports, "__disposeResources", ()=>__disposeResources);
var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d, b) {
        d.__proto__ = b;
    } || function(d, b) {
        for(var p in b)if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    if (typeof b !== "function" && b !== null) throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var __assign = function() {
    __assign = Object.assign || function __assign(t) {
        for(var s, i = 1, n = arguments.length; i < n; i++){
            s = arguments[i];
            for(var p in s)if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};
function __rest(s, e) {
    var t = {};
    for(var p in s)if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0) t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function") {
        for(var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++)if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i])) t[p[i]] = s[p[i]];
    }
    return t;
}
function __decorate(decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for(var i = decorators.length - 1; i >= 0; i--)if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
}
function __param(paramIndex, decorator) {
    return function(target, key) {
        decorator(target, key, paramIndex);
    };
}
function __esDecorate(ctor, descriptorIn, decorators, contextIn, initializers, extraInitializers) {
    function accept(f) {
        if (f !== void 0 && typeof f !== "function") throw new TypeError("Function expected");
        return f;
    }
    var kind = contextIn.kind, key = kind === "getter" ? "get" : kind === "setter" ? "set" : "value";
    var target = !descriptorIn && ctor ? contextIn["static"] ? ctor : ctor.prototype : null;
    var descriptor = descriptorIn || (target ? Object.getOwnPropertyDescriptor(target, contextIn.name) : {});
    var _, done = false;
    for(var i = decorators.length - 1; i >= 0; i--){
        var context = {};
        for(var p in contextIn)context[p] = p === "access" ? {} : contextIn[p];
        for(var p in contextIn.access)context.access[p] = contextIn.access[p];
        context.addInitializer = function(f) {
            if (done) throw new TypeError("Cannot add initializers after decoration has completed");
            extraInitializers.push(accept(f || null));
        };
        var result = (0, decorators[i])(kind === "accessor" ? {
            get: descriptor.get,
            set: descriptor.set
        } : descriptor[key], context);
        if (kind === "accessor") {
            if (result === void 0) continue;
            if (result === null || typeof result !== "object") throw new TypeError("Object expected");
            if (_ = accept(result.get)) descriptor.get = _;
            if (_ = accept(result.set)) descriptor.set = _;
            if (_ = accept(result.init)) initializers.unshift(_);
        } else if (_ = accept(result)) {
            if (kind === "field") initializers.unshift(_);
            else descriptor[key] = _;
        }
    }
    if (target) Object.defineProperty(target, contextIn.name, descriptor);
    done = true;
}
function __runInitializers(thisArg, initializers, value) {
    var useValue = arguments.length > 2;
    for(var i = 0; i < initializers.length; i++)value = useValue ? initializers[i].call(thisArg, value) : initializers[i].call(thisArg);
    return useValue ? value : void 0;
}
function __propKey(x) {
    return typeof x === "symbol" ? x : "".concat(x);
}
function __setFunctionName(f, name, prefix) {
    if (typeof name === "symbol") name = name.description ? "[".concat(name.description, "]") : "";
    return Object.defineProperty(f, "name", {
        configurable: true,
        value: prefix ? "".concat(prefix, " ", name) : name
    });
}
function __metadata(metadataKey, metadataValue) {
    if (typeof Reflect === "object" && typeof Reflect.metadata === "function") return Reflect.metadata(metadataKey, metadataValue);
}
function __awaiter(thisArg, _arguments, P, generator) {
    function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
            resolve(value);
        });
    }
    return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        }
        function rejected(value) {
            try {
                step(generator["throw"](value));
            } catch (e) {
                reject(e);
            }
        }
        function step(result) {
            result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
}
function __generator(thisArg, body) {
    var _ = {
        label: 0,
        sent: function() {
            if (t[0] & 1) throw t[1];
            return t[1];
        },
        trys: [],
        ops: []
    }, f, y, t, g;
    return g = {
        next: verb(0),
        "throw": verb(1),
        "return": verb(2)
    }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
    }), g;
    function verb(n) {
        return function(v) {
            return step([
                n,
                v
            ]);
        };
    }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while(g && (g = 0, op[0] && (_ = 0)), _)try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [
                op[0] & 2,
                t.value
            ];
            switch(op[0]){
                case 0:
                case 1:
                    t = op;
                    break;
                case 4:
                    _.label++;
                    return {
                        value: op[1],
                        done: false
                    };
                case 5:
                    _.label++;
                    y = op[1];
                    op = [
                        0
                    ];
                    continue;
                case 7:
                    op = _.ops.pop();
                    _.trys.pop();
                    continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                        _ = 0;
                        continue;
                    }
                    if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                        _.label = op[1];
                        break;
                    }
                    if (op[0] === 6 && _.label < t[1]) {
                        _.label = t[1];
                        t = op;
                        break;
                    }
                    if (t && _.label < t[2]) {
                        _.label = t[2];
                        _.ops.push(op);
                        break;
                    }
                    if (t[2]) _.ops.pop();
                    _.trys.pop();
                    continue;
            }
            op = body.call(thisArg, _);
        } catch (e) {
            op = [
                6,
                e
            ];
            y = 0;
        } finally{
            f = t = 0;
        }
        if (op[0] & 5) throw op[1];
        return {
            value: op[0] ? op[1] : void 0,
            done: true
        };
    }
}
var __createBinding = Object.create ? function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) desc = {
        enumerable: true,
        get: function() {
            return m[k];
        }
    };
    Object.defineProperty(o, k2, desc);
} : function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
};
function __exportStar(m, o) {
    for(var p in m)if (p !== "default" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);
}
function __values(o) {
    var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
    if (m) return m.call(o);
    if (o && typeof o.length === "number") return {
        next: function() {
            if (o && i >= o.length) o = void 0;
            return {
                value: o && o[i++],
                done: !o
            };
        }
    };
    throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
}
function __read(o, n) {
    var m = typeof Symbol === "function" && o[Symbol.iterator];
    if (!m) return o;
    var i = m.call(o), r, ar = [], e;
    try {
        while((n === void 0 || n-- > 0) && !(r = i.next()).done)ar.push(r.value);
    } catch (error) {
        e = {
            error: error
        };
    } finally{
        try {
            if (r && !r.done && (m = i["return"])) m.call(i);
        } finally{
            if (e) throw e.error;
        }
    }
    return ar;
}
function __spread() {
    for(var ar = [], i = 0; i < arguments.length; i++)ar = ar.concat(__read(arguments[i]));
    return ar;
}
function __spreadArrays() {
    for(var s = 0, i = 0, il = arguments.length; i < il; i++)s += arguments[i].length;
    for(var r = Array(s), k = 0, i = 0; i < il; i++)for(var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)r[k] = a[j];
    return r;
}
function __spreadArray(to, from, pack) {
    if (pack || arguments.length === 2) {
        for(var i = 0, l = from.length, ar; i < l; i++)if (ar || !(i in from)) {
            if (!ar) ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
        }
    }
    return to.concat(ar || Array.prototype.slice.call(from));
}
function __await(v) {
    return this instanceof __await ? (this.v = v, this) : new __await(v);
}
function __asyncGenerator(thisArg, _arguments, generator) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var g = generator.apply(thisArg, _arguments || []), i, q = [];
    return i = {}, verb("next"), verb("throw"), verb("return", awaitReturn), i[Symbol.asyncIterator] = function() {
        return this;
    }, i;
    function awaitReturn(f) {
        return function(v) {
            return Promise.resolve(v).then(f, reject);
        };
    }
    function verb(n, f) {
        if (g[n]) {
            i[n] = function(v) {
                return new Promise(function(a, b) {
                    q.push([
                        n,
                        v,
                        a,
                        b
                    ]) > 1 || resume(n, v);
                });
            };
            if (f) i[n] = f(i[n]);
        }
    }
    function resume(n, v) {
        try {
            step(g[n](v));
        } catch (e) {
            settle(q[0][3], e);
        }
    }
    function step(r) {
        r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r);
    }
    function fulfill(value) {
        resume("next", value);
    }
    function reject(value) {
        resume("throw", value);
    }
    function settle(f, v) {
        if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]);
    }
}
function __asyncDelegator(o) {
    var i, p;
    return i = {}, verb("next"), verb("throw", function(e) {
        throw e;
    }), verb("return"), i[Symbol.iterator] = function() {
        return this;
    }, i;
    function verb(n, f) {
        i[n] = o[n] ? function(v) {
            return (p = !p) ? {
                value: __await(o[n](v)),
                done: false
            } : f ? f(v) : v;
        } : f;
    }
}
function __asyncValues(o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
        return this;
    }, i);
    function verb(n) {
        i[n] = o[n] && function(v) {
            return new Promise(function(resolve, reject) {
                v = o[n](v), settle(resolve, reject, v.done, v.value);
            });
        };
    }
    function settle(resolve, reject, d, v) {
        Promise.resolve(v).then(function(v) {
            resolve({
                value: v,
                done: d
            });
        }, reject);
    }
}
function __makeTemplateObject(cooked, raw) {
    if (Object.defineProperty) Object.defineProperty(cooked, "raw", {
        value: raw
    });
    else cooked.raw = raw;
    return cooked;
}
var __setModuleDefault = Object.create ? function(o, v) {
    Object.defineProperty(o, "default", {
        enumerable: true,
        value: v
    });
} : function(o, v) {
    o["default"] = v;
};
function __importStar(mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) {
        for(var k in mod)if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    }
    __setModuleDefault(result, mod);
    return result;
}
function __importDefault(mod) {
    return mod && mod.__esModule ? mod : {
        default: mod
    };
}
function __classPrivateFieldGet(receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
}
function __classPrivateFieldSet(receiver, state, value, kind, f) {
    if (kind === "m") throw new TypeError("Private method is not writable");
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
    return kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value), value;
}
function __classPrivateFieldIn(state, receiver) {
    if (receiver === null || typeof receiver !== "object" && typeof receiver !== "function") throw new TypeError("Cannot use 'in' operator on non-object");
    return typeof state === "function" ? receiver === state : state.has(receiver);
}
function __addDisposableResource(env, value, async) {
    if (value !== null && value !== void 0) {
        if (typeof value !== "object" && typeof value !== "function") throw new TypeError("Object expected.");
        var dispose, inner;
        if (async) {
            if (!Symbol.asyncDispose) throw new TypeError("Symbol.asyncDispose is not defined.");
            dispose = value[Symbol.asyncDispose];
        }
        if (dispose === void 0) {
            if (!Symbol.dispose) throw new TypeError("Symbol.dispose is not defined.");
            dispose = value[Symbol.dispose];
            if (async) inner = dispose;
        }
        if (typeof dispose !== "function") throw new TypeError("Object not disposable.");
        if (inner) dispose = function() {
            try {
                inner.call(this);
            } catch (e) {
                return Promise.reject(e);
            }
        };
        env.stack.push({
            value: value,
            dispose: dispose,
            async: async
        });
    } else if (async) env.stack.push({
        async: true
    });
    return value;
}
var _SuppressedError = typeof SuppressedError === "function" ? SuppressedError : function(error, suppressed, message) {
    var e = new Error(message);
    return e.name = "SuppressedError", e.error = error, e.suppressed = suppressed, e;
};
function __disposeResources(env) {
    function fail(e) {
        env.error = env.hasError ? new _SuppressedError(e, env.error, "An error was suppressed during disposal.") : e;
        env.hasError = true;
    }
    function next() {
        while(env.stack.length){
            var rec = env.stack.pop();
            try {
                var result = rec.dispose && rec.dispose.call(rec.value);
                if (rec.async) return Promise.resolve(result).then(next, function(e) {
                    fail(e);
                    return next();
                });
            } catch (e) {
                fail(e);
            }
        }
        if (env.hasError) throw env.error;
    }
    return next();
}
exports.default = {
    __extends: __extends,
    __assign: __assign,
    __rest: __rest,
    __decorate: __decorate,
    __param: __param,
    __metadata: __metadata,
    __awaiter: __awaiter,
    __generator: __generator,
    __createBinding: __createBinding,
    __exportStar: __exportStar,
    __values: __values,
    __read: __read,
    __spread: __spread,
    __spreadArrays: __spreadArrays,
    __spreadArray: __spreadArray,
    __await: __await,
    __asyncGenerator: __asyncGenerator,
    __asyncDelegator: __asyncDelegator,
    __asyncValues: __asyncValues,
    __makeTemplateObject: __makeTemplateObject,
    __importStar: __importStar,
    __importDefault: __importDefault,
    __classPrivateFieldGet: __classPrivateFieldGet,
    __classPrivateFieldSet: __classPrivateFieldSet,
    __classPrivateFieldIn: __classPrivateFieldIn,
    __addDisposableResource: __addDisposableResource,
    __disposeResources: __disposeResources
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jj5sD":[function(require,module,exports) {
/**
 * A class which provides a reliable callback using either
 * a Web Worker, or if that isn't supported, falls back to setTimeout.
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Ticker", ()=>Ticker);
class Ticker {
    constructor(callback, type, updateInterval, contextSampleRate){
        this._callback = callback;
        this._type = type;
        this._minimumUpdateInterval = Math.max(128 / (contextSampleRate || 44100), 0.001);
        this.updateInterval = updateInterval;
        // create the clock source for the first time
        this._createClock();
    }
    /**
     * Generate a web worker
     */ _createWorker() {
        const blob = new Blob([
            /* javascript */ `
			// the initial timeout time
			let timeoutTime =  ${(this._updateInterval * 1000).toFixed(1)};
			// onmessage callback
			self.onmessage = function(msg){
				timeoutTime = parseInt(msg.data);
			};
			// the tick function which posts a message
			// and schedules a new tick
			function tick(){
				setTimeout(tick, timeoutTime);
				self.postMessage('tick');
			}
			// call tick initially
			tick();
			`
        ], {
            type: "text/javascript"
        });
        const blobUrl = URL.createObjectURL(blob);
        const worker = new Worker(blobUrl);
        worker.onmessage = this._callback.bind(this);
        this._worker = worker;
    }
    /**
     * Create a timeout loop
     */ _createTimeout() {
        this._timeout = setTimeout(()=>{
            this._createTimeout();
            this._callback();
        }, this._updateInterval * 1000);
    }
    /**
     * Create the clock source.
     */ _createClock() {
        if (this._type === "worker") try {
            this._createWorker();
        } catch (e) {
            // workers not supported, fallback to timeout
            this._type = "timeout";
            this._createClock();
        }
        else if (this._type === "timeout") this._createTimeout();
    }
    /**
     * Clean up the current clock source
     */ _disposeClock() {
        if (this._timeout) clearTimeout(this._timeout);
        if (this._worker) {
            this._worker.terminate();
            this._worker.onmessage = null;
        }
    }
    /**
     * The rate in seconds the ticker will update
     */ get updateInterval() {
        return this._updateInterval;
    }
    set updateInterval(interval) {
        var _a;
        this._updateInterval = Math.max(interval, this._minimumUpdateInterval);
        if (this._type === "worker") (_a = this._worker) === null || _a === void 0 || _a.postMessage(this._updateInterval * 1000);
    }
    /**
     * The type of the ticker, either a worker or a timeout
     */ get type() {
        return this._type;
    }
    set type(type) {
        this._disposeClock();
        this._type = type;
        this._createClock();
    }
    /**
     * Clean up
     */ dispose() {
        this._disposeClock();
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gKVc7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Test if the given value is an instanceof AudioParam
 */ parcelHelpers.export(exports, "isAudioParam", ()=>isAudioParam);
/**
 * Test if the given value is an instanceof AudioNode
 */ parcelHelpers.export(exports, "isAudioNode", ()=>isAudioNode);
/**
 * Test if the arg is instanceof an OfflineAudioContext
 */ parcelHelpers.export(exports, "isOfflineAudioContext", ()=>isOfflineAudioContext);
/**
 * Test if the arg is an instanceof AudioContext
 */ parcelHelpers.export(exports, "isAudioContext", ()=>isAudioContext);
/**
 * Test if the arg is instanceof an AudioBuffer
 */ parcelHelpers.export(exports, "isAudioBuffer", ()=>isAudioBuffer);
var _standardizedAudioContext = require("standardized-audio-context");
function isAudioParam(arg) {
    return (0, _standardizedAudioContext.isAnyAudioParam)(arg);
}
function isAudioNode(arg) {
    return (0, _standardizedAudioContext.isAnyAudioNode)(arg);
}
function isOfflineAudioContext(arg) {
    return (0, _standardizedAudioContext.isAnyOfflineAudioContext)(arg);
}
function isAudioContext(arg) {
    return (0, _standardizedAudioContext.isAnyAudioContext)(arg);
}
function isAudioBuffer(arg) {
    return arg instanceof (0, _standardizedAudioContext.AudioBuffer);
}

},{"standardized-audio-context":"J0Z3v","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"a9M5s":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Recursively merge an object
 * @param target the object to merge into
 * @param sources the source objects to merge
 */ parcelHelpers.export(exports, "deepMerge", ()=>deepMerge);
/**
 * Returns true if the two arrays have the same value for each of the elements
 */ parcelHelpers.export(exports, "deepEquals", ()=>deepEquals);
/**
 * Convert an args array into an object.
 * @internal
 */ parcelHelpers.export(exports, "optionsFromArguments", ()=>optionsFromArguments);
/**
 * Return this instances default values by calling Constructor.getDefaults()
 */ parcelHelpers.export(exports, "getDefaultsFromInstance", ()=>getDefaultsFromInstance);
/**
 * Returns the fallback if the given object is undefined.
 * Take an array of arguments and return a formatted options object.
 * @internal
 */ parcelHelpers.export(exports, "defaultArg", ()=>defaultArg);
/**
 * Remove all of the properties belonging to omit from obj.
 */ parcelHelpers.export(exports, "omitFromObject", ()=>omitFromObject);
var _advancedTypeCheckJs = require("./AdvancedTypeCheck.js");
var _typeCheckJs = require("./TypeCheck.js");
/**
 * Some objects should not be merged
 */ function noCopy(key, arg) {
    return key === "value" || (0, _advancedTypeCheckJs.isAudioParam)(arg) || (0, _advancedTypeCheckJs.isAudioNode)(arg) || (0, _advancedTypeCheckJs.isAudioBuffer)(arg);
}
function deepMerge(target, ...sources) {
    if (!sources.length) return target;
    const source = sources.shift();
    if ((0, _typeCheckJs.isObject)(target) && (0, _typeCheckJs.isObject)(source)) for(const key in source){
        if (noCopy(key, source[key])) target[key] = source[key];
        else if ((0, _typeCheckJs.isObject)(source[key])) {
            if (!target[key]) Object.assign(target, {
                [key]: {}
            });
            deepMerge(target[key], source[key]);
        } else Object.assign(target, {
            [key]: source[key]
        });
    }
    // @ts-ignore
    return deepMerge(target, ...sources);
}
function deepEquals(arrayA, arrayB) {
    return arrayA.length === arrayB.length && arrayA.every((element, index)=>arrayB[index] === element);
}
function optionsFromArguments(defaults, argsArray, keys = [], objKey) {
    const opts = {};
    const args = Array.from(argsArray);
    // if the first argument is an object and has an object key
    if ((0, _typeCheckJs.isObject)(args[0]) && objKey && !Reflect.has(args[0], objKey)) {
        // if it's not part of the defaults
        const partOfDefaults = Object.keys(args[0]).some((key)=>Reflect.has(defaults, key));
        if (!partOfDefaults) {
            // merge that key
            deepMerge(opts, {
                [objKey]: args[0]
            });
            // remove the obj key from the keys
            keys.splice(keys.indexOf(objKey), 1);
            // shift the first argument off
            args.shift();
        }
    }
    if (args.length === 1 && (0, _typeCheckJs.isObject)(args[0])) deepMerge(opts, args[0]);
    else {
        for(let i = 0; i < keys.length; i++)if ((0, _typeCheckJs.isDefined)(args[i])) opts[keys[i]] = args[i];
    }
    return deepMerge(defaults, opts);
}
function getDefaultsFromInstance(instance) {
    return instance.constructor.getDefaults();
}
function defaultArg(given, fallback) {
    if ((0, _typeCheckJs.isUndef)(given)) return fallback;
    else return given;
}
function omitFromObject(obj, omit) {
    omit.forEach((prop)=>{
        if (Reflect.has(obj, prop)) delete obj[prop];
    });
    return obj;
}

},{"./AdvancedTypeCheck.js":"gKVc7","./TypeCheck.js":"eMH5A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"36KJ4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A Timeline class for scheduling and maintaining state
 * along a timeline. All events must have a "time" property.
 * Internally, events are stored in time order for fast
 * retrieval.
 * @internal
 */ parcelHelpers.export(exports, "Timeline", ()=>Timeline);
var _toneJs = require("../Tone.js");
var _defaultsJs = require("./Defaults.js");
var _debugJs = require("./Debug.js");
var _mathJs = require("./Math.js");
class Timeline extends (0, _toneJs.Tone) {
    constructor(){
        super();
        this.name = "Timeline";
        /**
         * The array of scheduled timeline events
         */ this._timeline = [];
        const options = (0, _defaultsJs.optionsFromArguments)(Timeline.getDefaults(), arguments, [
            "memory"
        ]);
        this.memory = options.memory;
        this.increasing = options.increasing;
    }
    static getDefaults() {
        return {
            memory: Infinity,
            increasing: false
        };
    }
    /**
     * The number of items in the timeline.
     */ get length() {
        return this._timeline.length;
    }
    /**
     * Insert an event object onto the timeline. Events must have a "time" attribute.
     * @param event  The event object to insert into the timeline.
     */ add(event) {
        // the event needs to have a time attribute
        (0, _debugJs.assert)(Reflect.has(event, "time"), "Timeline: events must have a time attribute");
        event.time = event.time.valueOf();
        if (this.increasing && this.length) {
            const lastValue = this._timeline[this.length - 1];
            (0, _debugJs.assert)((0, _mathJs.GTE)(event.time, lastValue.time), "The time must be greater than or equal to the last scheduled time");
            this._timeline.push(event);
        } else {
            const index = this._search(event.time);
            this._timeline.splice(index + 1, 0, event);
        }
        // if the length is more than the memory, remove the previous ones
        if (this.length > this.memory) {
            const diff = this.length - this.memory;
            this._timeline.splice(0, diff);
        }
        return this;
    }
    /**
     * Remove an event from the timeline.
     * @param  {Object}  event  The event object to remove from the list.
     * @returns {Timeline} this
     */ remove(event) {
        const index = this._timeline.indexOf(event);
        if (index !== -1) this._timeline.splice(index, 1);
        return this;
    }
    /**
     * Get the nearest event whose time is less than or equal to the given time.
     * @param  time  The time to query.
     */ get(time, param = "time") {
        const index = this._search(time, param);
        if (index !== -1) return this._timeline[index];
        else return null;
    }
    /**
     * Return the first event in the timeline without removing it
     * @returns {Object} The first event object
     */ peek() {
        return this._timeline[0];
    }
    /**
     * Return the first event in the timeline and remove it
     */ shift() {
        return this._timeline.shift();
    }
    /**
     * Get the event which is scheduled after the given time.
     * @param  time  The time to query.
     */ getAfter(time, param = "time") {
        const index = this._search(time, param);
        if (index + 1 < this._timeline.length) return this._timeline[index + 1];
        else return null;
    }
    /**
     * Get the event before the event at the given time.
     * @param  time  The time to query.
     */ getBefore(time) {
        const len = this._timeline.length;
        // if it's after the last item, return the last item
        if (len > 0 && this._timeline[len - 1].time < time) return this._timeline[len - 1];
        const index = this._search(time);
        if (index - 1 >= 0) return this._timeline[index - 1];
        else return null;
    }
    /**
     * Cancel events at and after the given time
     * @param  after  The time to query.
     */ cancel(after) {
        if (this._timeline.length > 1) {
            let index = this._search(after);
            if (index >= 0) {
                if ((0, _mathJs.EQ)(this._timeline[index].time, after)) {
                    // get the first item with that time
                    for(let i = index; i >= 0; i--){
                        if ((0, _mathJs.EQ)(this._timeline[i].time, after)) index = i;
                        else break;
                    }
                    this._timeline = this._timeline.slice(0, index);
                } else this._timeline = this._timeline.slice(0, index + 1);
            } else this._timeline = [];
        } else if (this._timeline.length === 1) // the first item's time
        {
            if ((0, _mathJs.GTE)(this._timeline[0].time, after)) this._timeline = [];
        }
        return this;
    }
    /**
     * Cancel events before or equal to the given time.
     * @param  time  The time to cancel before.
     */ cancelBefore(time) {
        const index = this._search(time);
        if (index >= 0) this._timeline = this._timeline.slice(index + 1);
        return this;
    }
    /**
     * Returns the previous event if there is one. null otherwise
     * @param  event The event to find the previous one of
     * @return The event right before the given event
     */ previousEvent(event) {
        const index = this._timeline.indexOf(event);
        if (index > 0) return this._timeline[index - 1];
        else return null;
    }
    /**
     * Does a binary search on the timeline array and returns the
     * nearest event index whose time is after or equal to the given time.
     * If a time is searched before the first index in the timeline, -1 is returned.
     * If the time is after the end, the index of the last item is returned.
     */ _search(time, param = "time") {
        if (this._timeline.length === 0) return -1;
        let beginning = 0;
        const len = this._timeline.length;
        let end = len;
        if (len > 0 && this._timeline[len - 1][param] <= time) return len - 1;
        while(beginning < end){
            // calculate the midpoint for roughly equal partition
            let midPoint = Math.floor(beginning + (end - beginning) / 2);
            const event = this._timeline[midPoint];
            const nextEvent = this._timeline[midPoint + 1];
            if ((0, _mathJs.EQ)(event[param], time)) {
                // choose the last one that has the same time
                for(let i = midPoint; i < this._timeline.length; i++){
                    const testEvent = this._timeline[i];
                    if ((0, _mathJs.EQ)(testEvent[param], time)) midPoint = i;
                    else break;
                }
                return midPoint;
            } else if ((0, _mathJs.LT)(event[param], time) && (0, _mathJs.GT)(nextEvent[param], time)) return midPoint;
            else if ((0, _mathJs.GT)(event[param], time)) // search lower
            end = midPoint;
            else // search upper
            beginning = midPoint + 1;
        }
        return -1;
    }
    /**
     * Internal iterator. Applies extra safety checks for
     * removing items from the array.
     */ _iterate(callback, lowerBound = 0, upperBound = this._timeline.length - 1) {
        this._timeline.slice(lowerBound, upperBound + 1).forEach(callback);
    }
    /**
     * Iterate over everything in the array
     * @param  callback The callback to invoke with every item
     */ forEach(callback) {
        this._iterate(callback);
        return this;
    }
    /**
     * Iterate over everything in the array at or before the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachBefore(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        const upperBound = this._search(time);
        if (upperBound !== -1) this._iterate(callback, 0, upperBound);
        return this;
    }
    /**
     * Iterate over everything in the array after the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachAfter(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        const lowerBound = this._search(time);
        this._iterate(callback, lowerBound + 1);
        return this;
    }
    /**
     * Iterate over everything in the array between the startTime and endTime.
     * The timerange is inclusive of the startTime, but exclusive of the endTime.
     * range = [startTime, endTime).
     * @param  startTime The time to check if items are before
     * @param  endTime The end of the test interval.
     * @param  callback The callback to invoke with every item
     */ forEachBetween(startTime, endTime, callback) {
        let lowerBound = this._search(startTime);
        let upperBound = this._search(endTime);
        if (lowerBound !== -1 && upperBound !== -1) {
            if (this._timeline[lowerBound].time !== startTime) lowerBound += 1;
            // exclusive of the end time
            if (this._timeline[upperBound].time === endTime) upperBound -= 1;
            this._iterate(callback, lowerBound, upperBound);
        } else if (lowerBound === -1) this._iterate(callback, 0, upperBound);
        return this;
    }
    /**
     * Iterate over everything in the array at or after the given time. Similar to
     * forEachAfter, but includes the item(s) at the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachFrom(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        let lowerBound = this._search(time);
        // work backwards until the event time is less than time
        while(lowerBound >= 0 && this._timeline[lowerBound].time >= time)lowerBound--;
        this._iterate(callback, lowerBound + 1);
        return this;
    }
    /**
     * Iterate over everything in the array at the given time
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachAtTime(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        const upperBound = this._search(time);
        if (upperBound !== -1 && (0, _mathJs.EQ)(this._timeline[upperBound].time, time)) {
            let lowerBound = upperBound;
            for(let i = upperBound; i >= 0; i--){
                if ((0, _mathJs.EQ)(this._timeline[i].time, time)) lowerBound = i;
                else break;
            }
            this._iterate((event)=>{
                callback(event);
            }, lowerBound, upperBound);
        }
        return this;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._timeline = [];
        return this;
    }
}

},{"../Tone.js":"6Gzxl","./Defaults.js":"a9M5s","./Debug.js":"2lOIQ","./Math.js":"7mtt2","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6Gzxl":[function(require,module,exports) {
/**
 * Tone.js
 * @author Yotam Mann
 * @license http://opensource.org/licenses/MIT MIT License
 * @copyright 2014-2024 Yotam Mann
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone is the base class of all other classes.
 *
 * @category Core
 * @constructor
 */ parcelHelpers.export(exports, "Tone", ()=>Tone);
var _versionJs = require("../version.js");
var _audioContextJs = require("./context/AudioContext.js");
var _debugJs = require("./util/Debug.js");
class Tone {
    constructor(){
        //-------------------------------------
        // 	DEBUGGING
        //-------------------------------------
        /**
         * Set this debug flag to log all events that happen in this class.
         */ this.debug = false;
        //-------------------------------------
        // 	DISPOSING
        //-------------------------------------
        /**
         * Indicates if the instance was disposed
         */ this._wasDisposed = false;
    }
    /**
     * Returns all of the default options belonging to the class.
     */ static getDefaults() {
        return {};
    }
    /**
     * Prints the outputs to the console log for debugging purposes.
     * Prints the contents only if either the object has a property
     * called `debug` set to true, or a variable called TONE_DEBUG_CLASS
     * is set to the name of the class.
     * @example
     * const osc = new Tone.Oscillator();
     * // prints all logs originating from this oscillator
     * osc.debug = true;
     * // calls to start/stop will print in the console
     * osc.start();
     */ log(...args) {
        // if the object is either set to debug = true
        // or if there is a string on the Tone.global.with the class name
        if (this.debug || (0, _audioContextJs.theWindow) && this.toString() === (0, _audioContextJs.theWindow).TONE_DEBUG_CLASS) (0, _debugJs.log)(this, ...args);
    }
    /**
     * disconnect and dispose.
     */ dispose() {
        this._wasDisposed = true;
        return this;
    }
    /**
     * Indicates if the instance was disposed. 'Disposing' an
     * instance means that all of the Web Audio nodes that were
     * created for the instance are disconnected and freed for garbage collection.
     */ get disposed() {
        return this._wasDisposed;
    }
    /**
     * Convert the class to a string
     * @example
     * const osc = new Tone.Oscillator();
     * console.log(osc.toString());
     */ toString() {
        return this.name;
    }
}
/**
 * The version number semver
 */ Tone.version = (0, _versionJs.version);

},{"../version.js":"kWqOI","./context/AudioContext.js":"1NjF0","./util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7mtt2":[function(require,module,exports) {
/**
 * The threshold for correctness for operators. Less than one sample even
 * at very high sampling rates (e.g. `1e-6 < 1 / 192000`).
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Test if A is greater than B
 */ parcelHelpers.export(exports, "GT", ()=>GT);
/**
 * Test if A is greater than or equal to B
 */ parcelHelpers.export(exports, "GTE", ()=>GTE);
/**
 * Test if A is less than B
 */ parcelHelpers.export(exports, "LT", ()=>LT);
/**
 * Test if A is less than B
 */ parcelHelpers.export(exports, "EQ", ()=>EQ);
/**
 * Clamp the value within the given range
 */ parcelHelpers.export(exports, "clamp", ()=>clamp);
const EPSILON = 1e-6;
function GT(a, b) {
    return a > b + EPSILON;
}
function GTE(a, b) {
    return GT(a, b) || EQ(a, b);
}
function LT(a, b) {
    return a + EPSILON < b;
}
function EQ(a, b) {
    return Math.abs(a - b) < EPSILON;
}
function clamp(value, min, max) {
    return Math.max(Math.min(value, max), min);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iapnw":[function(require,module,exports) {
/**
 * Array of callbacks to invoke when a new context is created
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Used internally to setup a new Context
 */ parcelHelpers.export(exports, "onContextInit", ()=>onContextInit);
/**
 * Invoke any classes which need to also be initialized when a new context is created.
 */ parcelHelpers.export(exports, "initializeContext", ()=>initializeContext);
/**
 * Used internally to tear down a Context
 */ parcelHelpers.export(exports, "onContextClose", ()=>onContextClose);
parcelHelpers.export(exports, "closeContext", ()=>closeContext);
const notifyNewContext = [];
function onContextInit(cb) {
    notifyNewContext.push(cb);
}
function initializeContext(ctx) {
    // add any additional modules
    notifyNewContext.forEach((cb)=>cb(ctx));
}
/**
 * Array of callbacks to invoke when a new context is closed
 */ const notifyCloseContext = [];
function onContextClose(cb) {
    notifyCloseContext.push(cb);
}
function closeContext(ctx) {
    // remove any additional modules
    notifyCloseContext.forEach((cb)=>cb(ctx));
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bktf5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BaseContext", ()=>BaseContext);
var _emitterJs = require("../util/Emitter.js");
class BaseContext extends (0, _emitterJs.Emitter) {
    constructor(){
        super(...arguments);
        this.isOffline = false;
    }
    /*
     * This is a placeholder so that JSON.stringify does not throw an error
     * This matches what JSON.stringify(audioContext) returns on a native
     * audioContext instance.
     */ toJSON() {
        return {};
    }
}

},{"../util/Emitter.js":"4ROyf","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4ROyf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Emitter gives classes which extend it
 * the ability to listen for and emit events.
 * Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).
 * MIT (c) 2011 Jerome Etienne.
 * @category Core
 */ parcelHelpers.export(exports, "Emitter", ()=>Emitter);
var _toneJs = require("../Tone.js");
var _typeCheckJs = require("./TypeCheck.js");
class Emitter extends (0, _toneJs.Tone) {
    constructor(){
        super(...arguments);
        this.name = "Emitter";
    }
    /**
     * Bind a callback to a specific event.
     * @param  event     The name of the event to listen for.
     * @param  callback  The callback to invoke when the event is emitted
     */ on(event, callback) {
        // split the event
        const events = event.split(/\W+/);
        events.forEach((eventName)=>{
            if ((0, _typeCheckJs.isUndef)(this._events)) this._events = {};
            if (!this._events.hasOwnProperty(eventName)) this._events[eventName] = [];
            this._events[eventName].push(callback);
        });
        return this;
    }
    /**
     * Bind a callback which is only invoked once
     * @param  event     The name of the event to listen for.
     * @param  callback  The callback to invoke when the event is emitted
     */ once(event, callback) {
        const boundCallback = (...args)=>{
            // invoke the callback
            callback(...args);
            // remove the event
            this.off(event, boundCallback);
        };
        this.on(event, boundCallback);
        return this;
    }
    /**
     * Remove the event listener.
     * @param  event     The event to stop listening to.
     * @param  callback  The callback which was bound to the event with Emitter.on.
     *                   If no callback is given, all callbacks events are removed.
     */ off(event, callback) {
        const events = event.split(/\W+/);
        events.forEach((eventName)=>{
            if ((0, _typeCheckJs.isUndef)(this._events)) this._events = {};
            if (this._events.hasOwnProperty(eventName)) {
                if ((0, _typeCheckJs.isUndef)(callback)) this._events[eventName] = [];
                else {
                    const eventList = this._events[eventName];
                    for(let i = eventList.length - 1; i >= 0; i--)if (eventList[i] === callback) eventList.splice(i, 1);
                }
            }
        });
        return this;
    }
    /**
     * Invoke all of the callbacks bound to the event
     * with any arguments passed in.
     * @param  event  The name of the event.
     * @param args The arguments to pass to the functions listening.
     */ emit(event, ...args) {
        if (this._events) {
            if (this._events.hasOwnProperty(event)) {
                const eventList = this._events[event].slice(0);
                for(let i = 0, len = eventList.length; i < len; i++)eventList[i].apply(this, args);
            }
        }
        return this;
    }
    /**
     * Add Emitter functions (on/off/emit) to the object
     */ static mixin(constr) {
        // instance._events = {};
        [
            "on",
            "once",
            "off",
            "emit"
        ].forEach((name)=>{
            const property = Object.getOwnPropertyDescriptor(Emitter.prototype, name);
            Object.defineProperty(constr.prototype, name, property);
        });
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._events = undefined;
        return this;
    }
}

},{"../Tone.js":"6Gzxl","./TypeCheck.js":"eMH5A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lf5qO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "DummyContext", ()=>DummyContext);
var _tslib = require("tslib");
var _baseContextJs = require("./BaseContext.js");
class DummyContext extends (0, _baseContextJs.BaseContext) {
    constructor(){
        super(...arguments);
        this.lookAhead = 0;
        this.latencyHint = 0;
        this.isOffline = false;
    }
    //---------------------------
    // BASE AUDIO CONTEXT METHODS
    //---------------------------
    createAnalyser() {
        return {};
    }
    createOscillator() {
        return {};
    }
    createBufferSource() {
        return {};
    }
    createBiquadFilter() {
        return {};
    }
    createBuffer(_numberOfChannels, _length, _sampleRate) {
        return {};
    }
    createChannelMerger(_numberOfInputs) {
        return {};
    }
    createChannelSplitter(_numberOfOutputs) {
        return {};
    }
    createConstantSource() {
        return {};
    }
    createConvolver() {
        return {};
    }
    createDelay(_maxDelayTime) {
        return {};
    }
    createDynamicsCompressor() {
        return {};
    }
    createGain() {
        return {};
    }
    createIIRFilter(_feedForward, _feedback) {
        return {};
    }
    createPanner() {
        return {};
    }
    createPeriodicWave(_real, _imag, _constraints) {
        return {};
    }
    createStereoPanner() {
        return {};
    }
    createWaveShaper() {
        return {};
    }
    createMediaStreamSource(_stream) {
        return {};
    }
    createMediaElementSource(_element) {
        return {};
    }
    createMediaStreamDestination() {
        return {};
    }
    decodeAudioData(_audioData) {
        return Promise.resolve({});
    }
    //---------------------------
    // TONE AUDIO CONTEXT METHODS
    //---------------------------
    createAudioWorkletNode(_name, _options) {
        return {};
    }
    get rawContext() {
        return {};
    }
    addAudioWorkletModule(_url) {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            return Promise.resolve();
        });
    }
    resume() {
        return Promise.resolve();
    }
    setTimeout(_fn, _timeout) {
        return 0;
    }
    clearTimeout(_id) {
        return this;
    }
    setInterval(_fn, _interval) {
        return 0;
    }
    clearInterval(_id) {
        return this;
    }
    getConstant(_val) {
        return {};
    }
    get currentTime() {
        return 0;
    }
    get state() {
        return {};
    }
    get sampleRate() {
        return 0;
    }
    get listener() {
        return {};
    }
    get transport() {
        return {};
    }
    get draw() {
        return {};
    }
    set draw(_d) {}
    get destination() {
        return {};
    }
    set destination(_d) {}
    now() {
        return 0;
    }
    immediate() {
        return 0;
    }
}

},{"tslib":"lRdW5","./BaseContext.js":"bktf5","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8VnAL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the OfflineAudioContext
 * @category Core
 * @example
 * // generate a single channel, 0.5 second buffer
 * const context = new Tone.OfflineContext(1, 0.5, 44100);
 * const osc = new Tone.Oscillator({ context });
 * context.render().then(buffer => {
 * 	console.log(buffer.numberOfChannels, buffer.duration);
 * });
 */ parcelHelpers.export(exports, "OfflineContext", ()=>OfflineContext);
var _tslib = require("tslib");
var _audioContextJs = require("../context/AudioContext.js");
var _contextJs = require("../context/Context.js");
var _advancedTypeCheckJs = require("../util/AdvancedTypeCheck.js");
var _toneAudioBufferJs = require("./ToneAudioBuffer.js");
class OfflineContext extends (0, _contextJs.Context) {
    constructor(){
        super({
            clockSource: "offline",
            context: (0, _advancedTypeCheckJs.isOfflineAudioContext)(arguments[0]) ? arguments[0] : (0, _audioContextJs.createOfflineAudioContext)(arguments[0], arguments[1] * arguments[2], arguments[2]),
            lookAhead: 0,
            updateInterval: (0, _advancedTypeCheckJs.isOfflineAudioContext)(arguments[0]) ? 128 / arguments[0].sampleRate : 128 / arguments[2]
        });
        this.name = "OfflineContext";
        /**
         * An artificial clock source
         */ this._currentTime = 0;
        this.isOffline = true;
        this._duration = (0, _advancedTypeCheckJs.isOfflineAudioContext)(arguments[0]) ? arguments[0].length / arguments[0].sampleRate : arguments[1];
    }
    /**
     * Override the now method to point to the internal clock time
     */ now() {
        return this._currentTime;
    }
    /**
     * Same as this.now()
     */ get currentTime() {
        return this._currentTime;
    }
    /**
     * Render just the clock portion of the audio context.
     */ _renderClock(asynchronous) {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            let index = 0;
            while(this._duration - this._currentTime >= 0){
                // invoke all the callbacks on that time
                this.emit("tick");
                // increment the clock in block-sized chunks
                this._currentTime += 128 / this.sampleRate;
                // yield once a second of audio
                index++;
                const yieldEvery = Math.floor(this.sampleRate / 128);
                if (asynchronous && index % yieldEvery === 0) yield new Promise((done)=>setTimeout(done, 1));
            }
        });
    }
    /**
     * Render the output of the OfflineContext
     * @param asynchronous If the clock should be rendered asynchronously, which will not block the main thread, but be slightly slower.
     */ render() {
        return (0, _tslib.__awaiter)(this, arguments, void 0, function*(asynchronous = true) {
            yield this.workletsAreReady();
            yield this._renderClock(asynchronous);
            const buffer = yield this._context.startRendering();
            return new (0, _toneAudioBufferJs.ToneAudioBuffer)(buffer);
        });
    }
    /**
     * Close the context
     */ close() {
        return Promise.resolve();
    }
}

},{"tslib":"lRdW5","../context/AudioContext.js":"1NjF0","../context/Context.js":"1CuCx","../util/AdvancedTypeCheck.js":"gKVc7","./ToneAudioBuffer.js":"8aSPC","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8aSPC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AudioBuffer loading and storage. ToneAudioBuffer is used internally by all
 * classes that make requests for audio files such as Tone.Player,
 * Tone.Sampler and Tone.Convolver.
 * @example
 * const buffer = new Tone.ToneAudioBuffer("https://tonejs.github.io/audio/casio/A1.mp3", () => {
 * 	console.log("loaded");
 * });
 * @category Core
 */ parcelHelpers.export(exports, "ToneAudioBuffer", ()=>ToneAudioBuffer);
var _tslib = require("tslib");
var _globalJs = require("../Global.js");
var _toneJs = require("../Tone.js");
var _defaultsJs = require("../util/Defaults.js");
var _interfaceJs = require("../util/Interface.js");
var _typeCheckJs = require("../util/TypeCheck.js");
var _debugJs = require("../util/Debug.js");
class ToneAudioBuffer extends (0, _toneJs.Tone) {
    constructor(){
        super();
        this.name = "ToneAudioBuffer";
        /**
         * Callback when the buffer is loaded.
         */ this.onload = (0, _interfaceJs.noOp);
        const options = (0, _defaultsJs.optionsFromArguments)(ToneAudioBuffer.getDefaults(), arguments, [
            "url",
            "onload",
            "onerror"
        ]);
        this.reverse = options.reverse;
        this.onload = options.onload;
        if ((0, _typeCheckJs.isString)(options.url)) // initiate the download
        this.load(options.url).catch(options.onerror);
        else if (options.url) this.set(options.url);
    }
    static getDefaults() {
        return {
            onerror: (0, _interfaceJs.noOp),
            onload: (0, _interfaceJs.noOp),
            reverse: false
        };
    }
    /**
     * The sample rate of the AudioBuffer
     */ get sampleRate() {
        if (this._buffer) return this._buffer.sampleRate;
        else return (0, _globalJs.getContext)().sampleRate;
    }
    /**
     * Pass in an AudioBuffer or ToneAudioBuffer to set the value of this buffer.
     */ set(buffer) {
        if (buffer instanceof ToneAudioBuffer) {
            // if it's loaded, set it
            if (buffer.loaded) this._buffer = buffer.get();
            else // otherwise when it's loaded, invoke it's callback
            buffer.onload = ()=>{
                this.set(buffer);
                this.onload(this);
            };
        } else this._buffer = buffer;
        // reverse it initially
        if (this._reversed) this._reverse();
        return this;
    }
    /**
     * The audio buffer stored in the object.
     */ get() {
        return this._buffer;
    }
    /**
     * Makes an fetch request for the selected url then decodes the file as an audio buffer.
     * Invokes the callback once the audio buffer loads.
     * @param url The url of the buffer to load. filetype support depends on the browser.
     * @returns A Promise which resolves with this ToneAudioBuffer
     */ load(url) {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            const doneLoading = ToneAudioBuffer.load(url).then((audioBuffer)=>{
                this.set(audioBuffer);
                // invoke the onload method
                this.onload(this);
            });
            ToneAudioBuffer.downloads.push(doneLoading);
            try {
                yield doneLoading;
            } finally{
                // remove the downloaded file
                const index = ToneAudioBuffer.downloads.indexOf(doneLoading);
                ToneAudioBuffer.downloads.splice(index, 1);
            }
            return this;
        });
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._buffer = undefined;
        return this;
    }
    /**
     * Set the audio buffer from the array.
     * To create a multichannel AudioBuffer, pass in a multidimensional array.
     * @param array The array to fill the audio buffer
     */ fromArray(array) {
        const isMultidimensional = (0, _typeCheckJs.isArray)(array) && array[0].length > 0;
        const channels = isMultidimensional ? array.length : 1;
        const len = isMultidimensional ? array[0].length : array.length;
        const context = (0, _globalJs.getContext)();
        const buffer = context.createBuffer(channels, len, context.sampleRate);
        const multiChannelArray = !isMultidimensional && channels === 1 ? [
            array
        ] : array;
        for(let c = 0; c < channels; c++)buffer.copyToChannel(multiChannelArray[c], c);
        this._buffer = buffer;
        return this;
    }
    /**
     * Sums multiple channels into 1 channel
     * @param chanNum Optionally only copy a single channel from the array.
     */ toMono(chanNum) {
        if ((0, _typeCheckJs.isNumber)(chanNum)) this.fromArray(this.toArray(chanNum));
        else {
            let outputArray = new Float32Array(this.length);
            const numChannels = this.numberOfChannels;
            for(let channel = 0; channel < numChannels; channel++){
                const channelArray = this.toArray(channel);
                for(let i = 0; i < channelArray.length; i++)outputArray[i] += channelArray[i];
            }
            // divide by the number of channels
            outputArray = outputArray.map((sample)=>sample / numChannels);
            this.fromArray(outputArray);
        }
        return this;
    }
    /**
     * Get the buffer as an array. Single channel buffers will return a 1-dimensional
     * Float32Array, and multichannel buffers will return multidimensional arrays.
     * @param channel Optionally only copy a single channel from the array.
     */ toArray(channel) {
        if ((0, _typeCheckJs.isNumber)(channel)) return this.getChannelData(channel);
        else if (this.numberOfChannels === 1) return this.toArray(0);
        else {
            const ret = [];
            for(let c = 0; c < this.numberOfChannels; c++)ret[c] = this.getChannelData(c);
            return ret;
        }
    }
    /**
     * Returns the Float32Array representing the PCM audio data for the specific channel.
     * @param  channel  The channel number to return
     * @return The audio as a TypedArray
     */ getChannelData(channel) {
        if (this._buffer) return this._buffer.getChannelData(channel);
        else return new Float32Array(0);
    }
    /**
     * Cut a subsection of the array and return a buffer of the
     * subsection. Does not modify the original buffer
     * @param start The time to start the slice
     * @param end The end time to slice. If none is given will default to the end of the buffer
     */ slice(start, end = this.duration) {
        (0, _debugJs.assert)(this.loaded, "Buffer is not loaded");
        const startSamples = Math.floor(start * this.sampleRate);
        const endSamples = Math.floor(end * this.sampleRate);
        (0, _debugJs.assert)(startSamples < endSamples, "The start time must be less than the end time");
        const length = endSamples - startSamples;
        const retBuffer = (0, _globalJs.getContext)().createBuffer(this.numberOfChannels, length, this.sampleRate);
        for(let channel = 0; channel < this.numberOfChannels; channel++)retBuffer.copyToChannel(this.getChannelData(channel).subarray(startSamples, endSamples), channel);
        return new ToneAudioBuffer(retBuffer);
    }
    /**
     * Reverse the buffer.
     */ _reverse() {
        if (this.loaded) for(let i = 0; i < this.numberOfChannels; i++)this.getChannelData(i).reverse();
        return this;
    }
    /**
     * If the buffer is loaded or not
     */ get loaded() {
        return this.length > 0;
    }
    /**
     * The duration of the buffer in seconds.
     */ get duration() {
        if (this._buffer) return this._buffer.duration;
        else return 0;
    }
    /**
     * The length of the buffer in samples
     */ get length() {
        if (this._buffer) return this._buffer.length;
        else return 0;
    }
    /**
     * The number of discrete audio channels. Returns 0 if no buffer is loaded.
     */ get numberOfChannels() {
        if (this._buffer) return this._buffer.numberOfChannels;
        else return 0;
    }
    /**
     * Reverse the buffer.
     */ get reverse() {
        return this._reversed;
    }
    set reverse(rev) {
        if (this._reversed !== rev) {
            this._reversed = rev;
            this._reverse();
        }
    }
    /**
     * Create a ToneAudioBuffer from the array. To create a multichannel AudioBuffer,
     * pass in a multidimensional array.
     * @param array The array to fill the audio buffer
     * @return A ToneAudioBuffer created from the array
     */ static fromArray(array) {
        return new ToneAudioBuffer().fromArray(array);
    }
    /**
     * Creates a ToneAudioBuffer from a URL, returns a promise which resolves to a ToneAudioBuffer
     * @param  url The url to load.
     * @return A promise which resolves to a ToneAudioBuffer
     */ static fromUrl(url) {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            const buffer = new ToneAudioBuffer();
            return yield buffer.load(url);
        });
    }
    /**
     * Loads a url using fetch and returns the AudioBuffer.
     */ static load(url) {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            // test if the url contains multiple extensions
            const matches = url.match(/\[([^\]\[]+\|.+)\]$/);
            if (matches) {
                const extensions = matches[1].split("|");
                let extension = extensions[0];
                for (const ext of extensions)if (ToneAudioBuffer.supportsType(ext)) {
                    extension = ext;
                    break;
                }
                url = url.replace(matches[0], extension);
            }
            // make sure there is a slash between the baseUrl and the url
            const baseUrl = ToneAudioBuffer.baseUrl === "" || ToneAudioBuffer.baseUrl.endsWith("/") ? ToneAudioBuffer.baseUrl : ToneAudioBuffer.baseUrl + "/";
            // encode special characters in file path
            const location = document.createElement("a");
            location.href = baseUrl + url;
            location.pathname = (location.pathname + location.hash).split("/").map(encodeURIComponent).join("/");
            const response = yield fetch(location.href);
            if (!response.ok) throw new Error(`could not load url: ${url}`);
            const arrayBuffer = yield response.arrayBuffer();
            const audioBuffer = yield (0, _globalJs.getContext)().decodeAudioData(arrayBuffer);
            return audioBuffer;
        });
    }
    /**
     * Checks a url's extension to see if the current browser can play that file type.
     * @param url The url/extension to test
     * @return If the file extension can be played
     * @static
     * @example
     * Tone.ToneAudioBuffer.supportsType("wav"); // returns true
     * Tone.ToneAudioBuffer.supportsType("path/to/file.wav"); // returns true
     */ static supportsType(url) {
        const extensions = url.split(".");
        const extension = extensions[extensions.length - 1];
        const response = document.createElement("audio").canPlayType("audio/" + extension);
        return response !== "";
    }
    /**
     * Returns a Promise which resolves when all of the buffers have loaded
     */ static loaded() {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            // this makes sure that the function is always async
            yield Promise.resolve();
            while(ToneAudioBuffer.downloads.length)yield ToneAudioBuffer.downloads[0];
        });
    }
}
//-------------------------------------
// STATIC METHODS
//-------------------------------------
/**
 * A path which is prefixed before every url.
 */ ToneAudioBuffer.baseUrl = "";
/**
 * All of the downloads
 */ ToneAudioBuffer.downloads = [];

},{"tslib":"lRdW5","../Global.js":"79THw","../Tone.js":"6Gzxl","../util/Defaults.js":"a9M5s","../util/Interface.js":"hVOjA","../util/TypeCheck.js":"eMH5A","../util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hVOjA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Make the property not writable using `defineProperty`. Internal use only.
 */ parcelHelpers.export(exports, "readOnly", ()=>readOnly);
/**
 * Make an attribute writeable. Internal use only.
 */ parcelHelpers.export(exports, "writable", ()=>writable);
parcelHelpers.export(exports, "noOp", ()=>noOp);
var _typeCheckJs = require("./TypeCheck.js");
function readOnly(target, property) {
    if ((0, _typeCheckJs.isArray)(property)) property.forEach((str)=>readOnly(target, str));
    else Object.defineProperty(target, property, {
        enumerable: true,
        writable: false
    });
}
function writable(target, property) {
    if ((0, _typeCheckJs.isArray)(property)) property.forEach((str)=>writable(target, str));
    else Object.defineProperty(target, property, {
        writable: true
    });
}
const noOp = ()=>{
// no operation here!
};

},{"./TypeCheck.js":"eMH5A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bbfCi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _indexJs = require("./core/index.js");
parcelHelpers.exportAll(_indexJs, exports);
var _indexJs1 = require("./source/index.js");
parcelHelpers.exportAll(_indexJs1, exports);
var _indexJs2 = require("./signal/index.js");
parcelHelpers.exportAll(_indexJs2, exports);
var _indexJs3 = require("./instrument/index.js");
parcelHelpers.exportAll(_indexJs3, exports);
var _indexJs4 = require("./event/index.js");
parcelHelpers.exportAll(_indexJs4, exports);
var _indexJs5 = require("./effect/index.js");
parcelHelpers.exportAll(_indexJs5, exports);
var _indexJs6 = require("./component/index.js");
parcelHelpers.exportAll(_indexJs6, exports);

},{"./core/index.js":"leLmE","./source/index.js":"1mJV8","./signal/index.js":"kDXus","./instrument/index.js":"ed4wq","./event/index.js":"eiKIt","./effect/index.js":"hRVtA","./component/index.js":"ab9jt","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"leLmE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "dbToGain", ()=>(0, _conversionsJs.dbToGain));
parcelHelpers.export(exports, "gainToDb", ()=>(0, _conversionsJs.gainToDb));
parcelHelpers.export(exports, "intervalToFrequencyRatio", ()=>(0, _conversionsJs.intervalToFrequencyRatio));
parcelHelpers.export(exports, "ftom", ()=>(0, _conversionsJs.ftom));
parcelHelpers.export(exports, "mtof", ()=>(0, _conversionsJs.mtof));
parcelHelpers.export(exports, "optionsFromArguments", ()=>(0, _defaultsJs.optionsFromArguments));
parcelHelpers.export(exports, "defaultArg", ()=>(0, _defaultsJs.defaultArg));
parcelHelpers.export(exports, "Unit", ()=>_unitsJs);
/** @internal */ parcelHelpers.export(exports, "debug", ()=>_debugJs);
var _clockJs = require("./clock/Clock.js");
parcelHelpers.exportAll(_clockJs, exports);
// export * from "./clock/Transport";
var _contextJs = require("./context/Context.js");
parcelHelpers.exportAll(_contextJs, exports);
var _baseContextJs = require("./context/BaseContext.js");
parcelHelpers.exportAll(_baseContextJs, exports);
var _delayJs = require("./context/Delay.js");
parcelHelpers.exportAll(_delayJs, exports);
// export * from "./context/Destination";
var _gainJs = require("./context/Gain.js");
parcelHelpers.exportAll(_gainJs, exports);
var _offlineJs = require("./context/Offline.js");
parcelHelpers.exportAll(_offlineJs, exports);
var _offlineContextJs = require("./context/OfflineContext.js");
parcelHelpers.exportAll(_offlineContextJs, exports);
var _paramJs = require("./context/Param.js");
parcelHelpers.exportAll(_paramJs, exports);
var _toneAudioBufferJs = require("./context/ToneAudioBuffer.js");
parcelHelpers.exportAll(_toneAudioBufferJs, exports);
var _toneAudioBuffersJs = require("./context/ToneAudioBuffers.js");
parcelHelpers.exportAll(_toneAudioBuffersJs, exports);
var _toneAudioNodeJs = require("./context/ToneAudioNode.js");
parcelHelpers.exportAll(_toneAudioNodeJs, exports);
var _frequencyJs = require("./type/Frequency.js");
parcelHelpers.exportAll(_frequencyJs, exports);
var _midiJs = require("./type/Midi.js");
parcelHelpers.exportAll(_midiJs, exports);
var _timeJs = require("./type/Time.js");
parcelHelpers.exportAll(_timeJs, exports);
var _ticksJs = require("./type/Ticks.js");
parcelHelpers.exportAll(_ticksJs, exports);
var _transportTimeJs = require("./type/TransportTime.js");
parcelHelpers.exportAll(_transportTimeJs, exports);
var _drawJs = require("./util/Draw.js");
var _emitterJs = require("./util/Emitter.js");
parcelHelpers.exportAll(_emitterJs, exports);
var _intervalTimelineJs = require("./util/IntervalTimeline.js");
parcelHelpers.exportAll(_intervalTimelineJs, exports);
var _stateTimelineJs = require("./util/StateTimeline.js");
parcelHelpers.exportAll(_stateTimelineJs, exports);
var _timelineJs = require("./util/Timeline.js");
parcelHelpers.exportAll(_timelineJs, exports);
var _typeCheckJs = require("./util/TypeCheck.js");
parcelHelpers.exportAll(_typeCheckJs, exports);
var _conversionsJs = require("./type/Conversions.js");
var _defaultsJs = require("./util/Defaults.js");
// get the units and export them under the "Unit" namespace
var _unitsJs = require("./type/Units.js");
// export the debug stuff as Debug
var _debugJs = require("./util/Debug.js");

},{"./clock/Clock.js":"52dVv","./context/Context.js":"1CuCx","./context/BaseContext.js":"bktf5","./context/Delay.js":"1qHQA","./context/Gain.js":"kj68Y","./context/Offline.js":"fDjd0","./context/OfflineContext.js":"8VnAL","./context/Param.js":"5PVlJ","./context/ToneAudioBuffer.js":"8aSPC","./context/ToneAudioBuffers.js":"8zO1I","./context/ToneAudioNode.js":"kZ3Kj","./type/Frequency.js":"bObwr","./type/Midi.js":"kST2k","./type/Time.js":"9A3Zu","./type/Ticks.js":"BGGsE","./type/TransportTime.js":"a6yW0","./util/Draw.js":"9CgWk","./util/Emitter.js":"4ROyf","./util/IntervalTimeline.js":"4FYQZ","./util/StateTimeline.js":"hkouL","./util/Timeline.js":"36KJ4","./util/TypeCheck.js":"eMH5A","./type/Conversions.js":"iww1u","./util/Defaults.js":"a9M5s","./type/Units.js":"gjqPS","./util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"52dVv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A sample accurate clock which provides a callback at the given rate.
 * While the callback is not sample-accurate (it is still susceptible to
 * loose JS timing), the time passed in as the argument to the callback
 * is precise. For most applications, it is better to use Tone.Transport
 * instead of the Clock by itself since you can synchronize multiple callbacks.
 * @example
 * // the callback will be invoked approximately once a second
 * // and will print the time exactly once a second apart.
 * const clock = new Tone.Clock(time => {
 * 	console.log(time);
 * }, 1);
 * clock.start();
 * @category Core
 */ parcelHelpers.export(exports, "Clock", ()=>Clock);
var _toneWithContextJs = require("../context/ToneWithContext.js");
var _defaultsJs = require("../util/Defaults.js");
var _emitterJs = require("../util/Emitter.js");
var _interfaceJs = require("../util/Interface.js");
var _stateTimelineJs = require("../util/StateTimeline.js");
var _tickSourceJs = require("./TickSource.js");
var _debugJs = require("../util/Debug.js");
class Clock extends (0, _toneWithContextJs.ToneWithContext) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Clock.getDefaults(), arguments, [
            "callback",
            "frequency"
        ]);
        super(options);
        this.name = "Clock";
        /**
         * The callback function to invoke at the scheduled tick.
         */ this.callback = (0, _interfaceJs.noOp);
        /**
         * The last time the loop callback was invoked
         */ this._lastUpdate = 0;
        /**
         * Keep track of the playback state
         */ this._state = new (0, _stateTimelineJs.StateTimeline)("stopped");
        /**
         * Context bound reference to the _loop method
         * This is necessary to remove the event in the end.
         */ this._boundLoop = this._loop.bind(this);
        this.callback = options.callback;
        this._tickSource = new (0, _tickSourceJs.TickSource)({
            context: this.context,
            frequency: options.frequency,
            units: options.units
        });
        this._lastUpdate = 0;
        this.frequency = this._tickSource.frequency;
        (0, _interfaceJs.readOnly)(this, "frequency");
        // add an initial state
        this._state.setStateAtTime("stopped", 0);
        // bind a callback to the worker thread
        this.context.on("tick", this._boundLoop);
    }
    static getDefaults() {
        return Object.assign((0, _toneWithContextJs.ToneWithContext).getDefaults(), {
            callback: (0, _interfaceJs.noOp),
            frequency: 1,
            units: "hertz"
        });
    }
    /**
     * Returns the playback state of the source, either "started", "stopped" or "paused".
     */ get state() {
        return this._state.getValueAtTime(this.now());
    }
    /**
     * Start the clock at the given time. Optionally pass in an offset
     * of where to start the tick counter from.
     * @param  time    The time the clock should start
     * @param offset  Where the tick counter starts counting from.
     */ start(time, offset) {
        // make sure the context is running
        (0, _debugJs.assertContextRunning)(this.context);
        // start the loop
        const computedTime = this.toSeconds(time);
        this.log("start", computedTime);
        if (this._state.getValueAtTime(computedTime) !== "started") {
            this._state.setStateAtTime("started", computedTime);
            this._tickSource.start(computedTime, offset);
            if (computedTime < this._lastUpdate) this.emit("start", computedTime, offset);
        }
        return this;
    }
    /**
     * Stop the clock. Stopping the clock resets the tick counter to 0.
     * @param time The time when the clock should stop.
     * @example
     * const clock = new Tone.Clock(time => {
     * 	console.log(time);
     * }, 1);
     * clock.start();
     * // stop the clock after 10 seconds
     * clock.stop("+10");
     */ stop(time) {
        const computedTime = this.toSeconds(time);
        this.log("stop", computedTime);
        this._state.cancel(computedTime);
        this._state.setStateAtTime("stopped", computedTime);
        this._tickSource.stop(computedTime);
        if (computedTime < this._lastUpdate) this.emit("stop", computedTime);
        return this;
    }
    /**
     * Pause the clock. Pausing does not reset the tick counter.
     * @param time The time when the clock should stop.
     */ pause(time) {
        const computedTime = this.toSeconds(time);
        if (this._state.getValueAtTime(computedTime) === "started") {
            this._state.setStateAtTime("paused", computedTime);
            this._tickSource.pause(computedTime);
            if (computedTime < this._lastUpdate) this.emit("pause", computedTime);
        }
        return this;
    }
    /**
     * The number of times the callback was invoked. Starts counting at 0
     * and increments after the callback was invoked.
     */ get ticks() {
        return Math.ceil(this.getTicksAtTime(this.now()));
    }
    set ticks(t) {
        this._tickSource.ticks = t;
    }
    /**
     * The time since ticks=0 that the Clock has been running. Accounts for tempo curves
     */ get seconds() {
        return this._tickSource.seconds;
    }
    set seconds(s) {
        this._tickSource.seconds = s;
    }
    /**
     * Return the elapsed seconds at the given time.
     * @param  time  When to get the elapsed seconds
     * @return  The number of elapsed seconds
     */ getSecondsAtTime(time) {
        return this._tickSource.getSecondsAtTime(time);
    }
    /**
     * Set the clock's ticks at the given time.
     * @param  ticks The tick value to set
     * @param  time  When to set the tick value
     */ setTicksAtTime(ticks, time) {
        this._tickSource.setTicksAtTime(ticks, time);
        return this;
    }
    /**
     * Get the time of the given tick. The second argument
     * is when to test before. Since ticks can be set (with setTicksAtTime)
     * there may be multiple times for a given tick value.
     * @param  tick The tick number.
     * @param  before When to measure the tick value from.
     * @return The time of the tick
     */ getTimeOfTick(tick, before = this.now()) {
        return this._tickSource.getTimeOfTick(tick, before);
    }
    /**
     * Get the clock's ticks at the given time.
     * @param  time  When to get the tick value
     * @return The tick value at the given time.
     */ getTicksAtTime(time) {
        return this._tickSource.getTicksAtTime(time);
    }
    /**
     * Get the time of the next tick
     * @param  offset The tick number.
     */ nextTickTime(offset, when) {
        const computedTime = this.toSeconds(when);
        const currentTick = this.getTicksAtTime(computedTime);
        return this._tickSource.getTimeOfTick(currentTick + offset, computedTime);
    }
    /**
     * The scheduling loop.
     */ _loop() {
        const startTime = this._lastUpdate;
        const endTime = this.now();
        this._lastUpdate = endTime;
        this.log("loop", startTime, endTime);
        if (startTime !== endTime) {
            // the state change events
            this._state.forEachBetween(startTime, endTime, (e)=>{
                switch(e.state){
                    case "started":
                        const offset = this._tickSource.getTicksAtTime(e.time);
                        this.emit("start", e.time, offset);
                        break;
                    case "stopped":
                        if (e.time !== 0) this.emit("stop", e.time);
                        break;
                    case "paused":
                        this.emit("pause", e.time);
                        break;
                }
            });
            // the tick callbacks
            this._tickSource.forEachTickBetween(startTime, endTime, (time, ticks)=>{
                this.callback(time, ticks);
            });
        }
    }
    /**
     * Returns the scheduled state at the given time.
     * @param  time  The time to query.
     * @return  The name of the state input in setStateAtTime.
     * @example
     * const clock = new Tone.Clock();
     * clock.start("+0.1");
     * clock.getStateAtTime("+0.1"); // returns "started"
     */ getStateAtTime(time) {
        const computedTime = this.toSeconds(time);
        return this._state.getValueAtTime(computedTime);
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this.context.off("tick", this._boundLoop);
        this._tickSource.dispose();
        this._state.dispose();
        return this;
    }
}
(0, _emitterJs.Emitter).mixin(Clock);

},{"../context/ToneWithContext.js":"gAuzg","../util/Defaults.js":"a9M5s","../util/Emitter.js":"4ROyf","../util/Interface.js":"hVOjA","../util/StateTimeline.js":"hkouL","./TickSource.js":"7GTFV","../util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gAuzg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * The Base class for all nodes that have an AudioContext.
 */ parcelHelpers.export(exports, "ToneWithContext", ()=>ToneWithContext);
var _globalJs = require("../Global.js");
var _toneJs = require("../Tone.js");
var _frequencyJs = require("../type/Frequency.js");
var _timeJs = require("../type/Time.js");
var _transportTimeJs = require("../type/TransportTime.js");
var _debugJs = require("../util/Debug.js");
var _defaultsJs = require("../util/Defaults.js");
var _typeCheckJs = require("../util/TypeCheck.js");
class ToneWithContext extends (0, _toneJs.Tone) {
    constructor(){
        super();
        const options = (0, _defaultsJs.optionsFromArguments)(ToneWithContext.getDefaults(), arguments, [
            "context"
        ]);
        if (this.defaultContext) this.context = this.defaultContext;
        else this.context = options.context;
    }
    static getDefaults() {
        return {
            context: (0, _globalJs.getContext)()
        };
    }
    /**
     * Return the current time of the Context clock plus the lookAhead.
     * @example
     * setInterval(() => {
     * 	console.log(Tone.now());
     * }, 100);
     */ now() {
        return this.context.currentTime + this.context.lookAhead;
    }
    /**
     * Return the current time of the Context clock without any lookAhead.
     * @example
     * setInterval(() => {
     * 	console.log(Tone.immediate());
     * }, 100);
     */ immediate() {
        return this.context.currentTime;
    }
    /**
     * The duration in seconds of one sample.
     */ get sampleTime() {
        return 1 / this.context.sampleRate;
    }
    /**
     * The number of seconds of 1 processing block (128 samples)
     * @example
     * console.log(Tone.Destination.blockTime);
     */ get blockTime() {
        return 128 / this.context.sampleRate;
    }
    /**
     * Convert the incoming time to seconds.
     * This is calculated against the current {@link TransportClass} bpm
     * @example
     * const gain = new Tone.Gain();
     * setInterval(() => console.log(gain.toSeconds("4n")), 100);
     * // ramp the tempo to 60 bpm over 30 seconds
     * Tone.getTransport().bpm.rampTo(60, 30);
     */ toSeconds(time) {
        (0, _debugJs.assertUsedScheduleTime)(time);
        return new (0, _timeJs.TimeClass)(this.context, time).toSeconds();
    }
    /**
     * Convert the input to a frequency number
     * @example
     * const gain = new Tone.Gain();
     * console.log(gain.toFrequency("4n"));
     */ toFrequency(freq) {
        return new (0, _frequencyJs.FrequencyClass)(this.context, freq).toFrequency();
    }
    /**
     * Convert the input time into ticks
     * @example
     * const gain = new Tone.Gain();
     * console.log(gain.toTicks("4n"));
     */ toTicks(time) {
        return new (0, _transportTimeJs.TransportTimeClass)(this.context, time).toTicks();
    }
    //-------------------------------------
    // 	GET/SET
    //-------------------------------------
    /**
     * Get a subset of the properties which are in the partial props
     */ _getPartialProperties(props) {
        const options = this.get();
        // remove attributes from the prop that are not in the partial
        Object.keys(options).forEach((name)=>{
            if ((0, _typeCheckJs.isUndef)(props[name])) delete options[name];
        });
        return options;
    }
    /**
     * Get the object's attributes.
     * @example
     * const osc = new Tone.Oscillator();
     * console.log(osc.get());
     */ get() {
        const defaults = (0, _defaultsJs.getDefaultsFromInstance)(this);
        Object.keys(defaults).forEach((attribute)=>{
            if (Reflect.has(this, attribute)) {
                const member = this[attribute];
                if ((0, _typeCheckJs.isDefined)(member) && (0, _typeCheckJs.isDefined)(member.value) && (0, _typeCheckJs.isDefined)(member.setValueAtTime)) defaults[attribute] = member.value;
                else if (member instanceof ToneWithContext) defaults[attribute] = member._getPartialProperties(defaults[attribute]);
                else if ((0, _typeCheckJs.isArray)(member) || (0, _typeCheckJs.isNumber)(member) || (0, _typeCheckJs.isString)(member) || (0, _typeCheckJs.isBoolean)(member)) defaults[attribute] = member;
                else // remove all undefined and unserializable attributes
                delete defaults[attribute];
            }
        });
        return defaults;
    }
    /**
     * Set multiple properties at once with an object.
     * @example
     * const filter = new Tone.Filter().toDestination();
     * // set values using an object
     * filter.set({
     * 	frequency: "C6",
     * 	type: "highpass"
     * });
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/Analogsynth_octaves_highmid.mp3").connect(filter);
     * player.autostart = true;
     */ set(props) {
        Object.keys(props).forEach((attribute)=>{
            if (Reflect.has(this, attribute) && (0, _typeCheckJs.isDefined)(this[attribute])) {
                if (this[attribute] && (0, _typeCheckJs.isDefined)(this[attribute].value) && (0, _typeCheckJs.isDefined)(this[attribute].setValueAtTime)) // small optimization
                {
                    if (this[attribute].value !== props[attribute]) this[attribute].value = props[attribute];
                } else if (this[attribute] instanceof ToneWithContext) this[attribute].set(props[attribute]);
                else this[attribute] = props[attribute];
            }
        });
        return this;
    }
}

},{"../Global.js":"79THw","../Tone.js":"6Gzxl","../type/Frequency.js":"bObwr","../type/Time.js":"9A3Zu","../type/TransportTime.js":"a6yW0","../util/Debug.js":"2lOIQ","../util/Defaults.js":"a9M5s","../util/TypeCheck.js":"eMH5A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bObwr":[function(require,module,exports) {
/* eslint-disable key-spacing */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Frequency is a primitive type for encoding Frequency values.
 * Eventually all time values are evaluated to hertz using the `valueOf` method.
 * @example
 * Tone.Frequency("C3"); // 261
 * Tone.Frequency(38, "midi");
 * Tone.Frequency("C3").transpose(4);
 * @category Unit
 */ parcelHelpers.export(exports, "FrequencyClass", ()=>FrequencyClass);
/**
 * Convert a value into a FrequencyClass object.
 * @category Unit
 * @example
 * const midi = Tone.Frequency("C3").toMidi();
 * console.log(midi);
 * @example
 * const hertz = Tone.Frequency(38, "midi").toFrequency();
 * console.log(hertz);
 */ parcelHelpers.export(exports, "Frequency", ()=>Frequency);
var _globalJs = require("../Global.js");
var _conversionsJs = require("./Conversions.js");
var _timeJs = require("./Time.js");
class FrequencyClass extends (0, _timeJs.TimeClass) {
    constructor(){
        super(...arguments);
        this.name = "Frequency";
        this.defaultUnits = "hz";
    }
    /**
     * The [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used
     * to generate all the other pitch values from notes. A4's values in Hertz.
     */ static get A4() {
        return (0, _conversionsJs.getA4)();
    }
    static set A4(freq) {
        (0, _conversionsJs.setA4)(freq);
    }
    //-------------------------------------
    // 	AUGMENT BASE EXPRESSIONS
    //-------------------------------------
    _getExpressions() {
        return Object.assign({}, super._getExpressions(), {
            midi: {
                regexp: /^(\d+(?:\.\d+)?midi)/,
                method (value) {
                    if (this.defaultUnits === "midi") return value;
                    else return FrequencyClass.mtof(value);
                }
            },
            note: {
                regexp: /^([a-g]{1}(?:b|#|##|x|bb|###|#x|x#|bbb)?)(-?[0-9]+)/i,
                method (pitch, octave) {
                    const index = noteToScaleIndex[pitch.toLowerCase()];
                    const noteNumber = index + (parseInt(octave, 10) + 1) * 12;
                    if (this.defaultUnits === "midi") return noteNumber;
                    else return FrequencyClass.mtof(noteNumber);
                }
            },
            tr: {
                regexp: /^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?/,
                method (m, q, s) {
                    let total = 1;
                    if (m && m !== "0") total *= this._beatsToUnits(this._getTimeSignature() * parseFloat(m));
                    if (q && q !== "0") total *= this._beatsToUnits(parseFloat(q));
                    if (s && s !== "0") total *= this._beatsToUnits(parseFloat(s) / 4);
                    return total;
                }
            }
        });
    }
    //-------------------------------------
    // 	EXPRESSIONS
    //-------------------------------------
    /**
     * Transposes the frequency by the given number of semitones.
     * @return  A new transposed frequency
     * @example
     * Tone.Frequency("A4").transpose(3); // "C5"
     */ transpose(interval) {
        return new FrequencyClass(this.context, this.valueOf() * (0, _conversionsJs.intervalToFrequencyRatio)(interval));
    }
    /**
     * Takes an array of semitone intervals and returns
     * an array of frequencies transposed by those intervals.
     * @return  Returns an array of Frequencies
     * @example
     * Tone.Frequency("A4").harmonize([0, 3, 7]); // ["A4", "C5", "E5"]
     */ harmonize(intervals) {
        return intervals.map((interval)=>{
            return this.transpose(interval);
        });
    }
    //-------------------------------------
    // 	UNIT CONVERSIONS
    //-------------------------------------
    /**
     * Return the value of the frequency as a MIDI note
     * @example
     * Tone.Frequency("C4").toMidi(); // 60
     */ toMidi() {
        return (0, _conversionsJs.ftom)(this.valueOf());
    }
    /**
     * Return the value of the frequency in Scientific Pitch Notation
     * @example
     * Tone.Frequency(69, "midi").toNote(); // "A4"
     */ toNote() {
        const freq = this.toFrequency();
        const log = Math.log2(freq / FrequencyClass.A4);
        let noteNumber = Math.round(12 * log) + 57;
        const octave = Math.floor(noteNumber / 12);
        if (octave < 0) noteNumber += -12 * octave;
        const noteName = scaleIndexToNote[noteNumber % 12];
        return noteName + octave.toString();
    }
    /**
     * Return the duration of one cycle in seconds.
     */ toSeconds() {
        return 1 / super.toSeconds();
    }
    /**
     * Return the duration of one cycle in ticks
     */ toTicks() {
        const quarterTime = this._beatsToUnits(1);
        const quarters = this.valueOf() / quarterTime;
        return Math.floor(quarters * this._getPPQ());
    }
    //-------------------------------------
    // 	UNIT CONVERSIONS HELPERS
    //-------------------------------------
    /**
     * With no arguments, return 0
     */ _noArg() {
        return 0;
    }
    /**
     * Returns the value of a frequency in the current units
     */ _frequencyToUnits(freq) {
        return freq;
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return 1 / (ticks * 60 / (this._getBpm() * this._getPPQ()));
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return 1 / super._beatsToUnits(beats);
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return 1 / seconds;
    }
    /**
     * Convert a MIDI note to frequency value.
     * @param  midi The midi number to convert.
     * @return The corresponding frequency value
     */ static mtof(midi) {
        return (0, _conversionsJs.mtof)(midi);
    }
    /**
     * Convert a frequency value to a MIDI note.
     * @param frequency The value to frequency value to convert.
     */ static ftom(frequency) {
        return (0, _conversionsJs.ftom)(frequency);
    }
}
//-------------------------------------
// 	FREQUENCY CONVERSIONS
//-------------------------------------
/**
 * Note to scale index.
 * @hidden
 */ const noteToScaleIndex = {
    cbbb: -3,
    cbb: -2,
    cb: -1,
    c: 0,
    "c#": 1,
    cx: 2,
    "c##": 2,
    "c###": 3,
    "cx#": 3,
    "c#x": 3,
    dbbb: -1,
    dbb: 0,
    db: 1,
    d: 2,
    "d#": 3,
    dx: 4,
    "d##": 4,
    "d###": 5,
    "dx#": 5,
    "d#x": 5,
    ebbb: 1,
    ebb: 2,
    eb: 3,
    e: 4,
    "e#": 5,
    ex: 6,
    "e##": 6,
    "e###": 7,
    "ex#": 7,
    "e#x": 7,
    fbbb: 2,
    fbb: 3,
    fb: 4,
    f: 5,
    "f#": 6,
    fx: 7,
    "f##": 7,
    "f###": 8,
    "fx#": 8,
    "f#x": 8,
    gbbb: 4,
    gbb: 5,
    gb: 6,
    g: 7,
    "g#": 8,
    gx: 9,
    "g##": 9,
    "g###": 10,
    "gx#": 10,
    "g#x": 10,
    abbb: 6,
    abb: 7,
    ab: 8,
    a: 9,
    "a#": 10,
    ax: 11,
    "a##": 11,
    "a###": 12,
    "ax#": 12,
    "a#x": 12,
    bbbb: 8,
    bbb: 9,
    bb: 10,
    b: 11,
    "b#": 12,
    bx: 13,
    "b##": 13,
    "b###": 14,
    "bx#": 14,
    "b#x": 14
};
/**
 * scale index to note (sharps)
 * @hidden
 */ const scaleIndexToNote = [
    "C",
    "C#",
    "D",
    "D#",
    "E",
    "F",
    "F#",
    "G",
    "G#",
    "A",
    "A#",
    "B"
];
function Frequency(value, units) {
    return new FrequencyClass((0, _globalJs.getContext)(), value, units);
}

},{"../Global.js":"79THw","./Conversions.js":"iww1u","./Time.js":"9A3Zu","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iww1u":[function(require,module,exports) {
/**
 * Equal power gain scale. Good for cross-fading.
 * @param  percent (0-1)
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "equalPowerScale", ()=>equalPowerScale);
/**
 * Convert decibels into gain.
 */ parcelHelpers.export(exports, "dbToGain", ()=>dbToGain);
/**
 * Convert gain to decibels.
 */ parcelHelpers.export(exports, "gainToDb", ()=>gainToDb);
/**
 * Convert an interval (in semitones) to a frequency ratio.
 * @param interval the number of semitones above the base note
 * @example
 * Tone.intervalToFrequencyRatio(0); // 1
 * Tone.intervalToFrequencyRatio(12); // 2
 * Tone.intervalToFrequencyRatio(-12); // 0.5
 */ parcelHelpers.export(exports, "intervalToFrequencyRatio", ()=>intervalToFrequencyRatio);
parcelHelpers.export(exports, "getA4", ()=>getA4);
parcelHelpers.export(exports, "setA4", ()=>setA4);
/**
 * Convert a frequency value to a MIDI note.
 * @param frequency The value to frequency value to convert.
 * @example
 * Tone.ftom(440); // returns 69
 */ parcelHelpers.export(exports, "ftom", ()=>ftom);
/**
 * Convert a frequency to a floating point midi value
 */ parcelHelpers.export(exports, "ftomf", ()=>ftomf);
/**
 * Convert a MIDI note to frequency value.
 * @param  midi The midi number to convert.
 * @return The corresponding frequency value
 * @example
 * Tone.mtof(69); // 440
 */ parcelHelpers.export(exports, "mtof", ()=>mtof);
function equalPowerScale(percent) {
    const piFactor = 0.5 * Math.PI;
    return Math.sin(percent * piFactor);
}
function dbToGain(db) {
    return Math.pow(10, db / 20);
}
function gainToDb(gain) {
    return 20 * (Math.log(gain) / Math.LN10);
}
function intervalToFrequencyRatio(interval) {
    return Math.pow(2, interval / 12);
}
/**
 * The Global [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used
 * to generate all the other pitch values from notes. A4's values in Hertz.
 */ let A4 = 440;
function getA4() {
    return A4;
}
function setA4(freq) {
    A4 = freq;
}
function ftom(frequency) {
    return Math.round(ftomf(frequency));
}
function ftomf(frequency) {
    return 69 + 12 * Math.log2(frequency / A4);
}
function mtof(midi) {
    return A4 * Math.pow(2, (midi - 69) / 12);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9A3Zu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TimeClass is a primitive type for encoding and decoding Time values.
 * TimeClass can be passed into the parameter of any method which takes time as an argument.
 * @param  val    The time value.
 * @param  units  The units of the value.
 * @example
 * const time = Tone.Time("4n"); // a quarter note
 * @category Unit
 */ parcelHelpers.export(exports, "TimeClass", ()=>TimeClass);
/**
 * Create a TimeClass from a time string or number. The time is computed against the
 * global Tone.Context. To use a specific context, use {@link TimeClass}
 * @param value A value which represents time
 * @param units The value's units if they can't be inferred by the value.
 * @category Unit
 * @example
 * const time = Tone.Time("4n").toSeconds();
 * console.log(time);
 * @example
 * const note = Tone.Time(1).toNotation();
 * console.log(note);
 * @example
 * const freq = Tone.Time(0.5).toFrequency();
 * console.log(freq);
 */ parcelHelpers.export(exports, "Time", ()=>Time);
var _globalJs = require("../Global.js");
var _conversionsJs = require("./Conversions.js");
var _timeBaseJs = require("./TimeBase.js");
class TimeClass extends (0, _timeBaseJs.TimeBaseClass) {
    constructor(){
        super(...arguments);
        this.name = "TimeClass";
    }
    _getExpressions() {
        return Object.assign(super._getExpressions(), {
            now: {
                method: (capture)=>{
                    return this._now() + new this.constructor(this.context, capture).valueOf();
                },
                regexp: /^\+(.+)/
            },
            quantize: {
                method: (capture)=>{
                    const quantTo = new TimeClass(this.context, capture).valueOf();
                    return this._secondsToUnits(this.context.transport.nextSubdivision(quantTo));
                },
                regexp: /^@(.+)/
            }
        });
    }
    /**
     * Quantize the time by the given subdivision. Optionally add a
     * percentage which will move the time value towards the ideal
     * quantized value by that percentage.
     * @param  subdiv    The subdivision to quantize to
     * @param  percent  Move the time value towards the quantized value by a percentage.
     * @example
     * Tone.Time(21).quantize(2); // returns 22
     * Tone.Time(0.6).quantize("4n", 0.5); // returns 0.55
     */ quantize(subdiv, percent = 1) {
        const subdivision = new this.constructor(this.context, subdiv).valueOf();
        const value = this.valueOf();
        const multiple = Math.round(value / subdivision);
        const ideal = multiple * subdivision;
        const diff = ideal - value;
        return value + diff * percent;
    }
    //-------------------------------------
    // CONVERSIONS
    //-------------------------------------
    /**
     * Convert a Time to Notation. The notation values are will be the
     * closest representation between 1m to 128th note.
     * @return {Notation}
     * @example
     * // if the Transport is at 120bpm:
     * Tone.Time(2).toNotation(); // returns "1m"
     */ toNotation() {
        const time = this.toSeconds();
        const testNotations = [
            "1m"
        ];
        for(let power = 1; power < 9; power++){
            const subdiv = Math.pow(2, power);
            testNotations.push(subdiv + "n.");
            testNotations.push(subdiv + "n");
            testNotations.push(subdiv + "t");
        }
        testNotations.push("0");
        // find the closets notation representation
        let closest = testNotations[0];
        let closestSeconds = new TimeClass(this.context, testNotations[0]).toSeconds();
        testNotations.forEach((notation)=>{
            const notationSeconds = new TimeClass(this.context, notation).toSeconds();
            if (Math.abs(notationSeconds - time) < Math.abs(closestSeconds - time)) {
                closest = notation;
                closestSeconds = notationSeconds;
            }
        });
        return closest;
    }
    /**
     * Return the time encoded as Bars:Beats:Sixteenths.
     */ toBarsBeatsSixteenths() {
        const quarterTime = this._beatsToUnits(1);
        let quarters = this.valueOf() / quarterTime;
        quarters = parseFloat(quarters.toFixed(4));
        const measures = Math.floor(quarters / this._getTimeSignature());
        let sixteenths = quarters % 1 * 4;
        quarters = Math.floor(quarters) % this._getTimeSignature();
        const sixteenthString = sixteenths.toString();
        if (sixteenthString.length > 3) // the additional parseFloat removes insignificant trailing zeroes
        sixteenths = parseFloat(parseFloat(sixteenthString).toFixed(3));
        const progress = [
            measures,
            quarters,
            sixteenths
        ];
        return progress.join(":");
    }
    /**
     * Return the time in ticks.
     */ toTicks() {
        const quarterTime = this._beatsToUnits(1);
        const quarters = this.valueOf() / quarterTime;
        return quarters * this._getPPQ();
    }
    /**
     * Return the time in seconds.
     */ toSeconds() {
        return this.valueOf();
    }
    /**
     * Return the value as a midi note.
     */ toMidi() {
        return (0, _conversionsJs.ftom)(this.toFrequency());
    }
    _now() {
        return this.context.now();
    }
}
function Time(value, units) {
    return new TimeClass((0, _globalJs.getContext)(), value, units);
}

},{"../Global.js":"79THw","./Conversions.js":"iww1u","./TimeBase.js":"1rDQh","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1rDQh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TimeBase is a flexible encoding of time which can be evaluated to and from a string.
 */ parcelHelpers.export(exports, "TimeBaseClass", ()=>TimeBaseClass);
var _toneJs = require("../Tone.js");
var _typeCheckJs = require("../util/TypeCheck.js");
class TimeBaseClass extends (0, _toneJs.Tone) {
    /**
     * @param context The context associated with the time value. Used to compute
     * Transport and context-relative timing.
     * @param  value  The time value as a number, string or object
     * @param  units  Unit values
     */ constructor(context, value, units){
        super();
        /**
         * The default units
         */ this.defaultUnits = "s";
        this._val = value;
        this._units = units;
        this.context = context;
        this._expressions = this._getExpressions();
    }
    /**
     * All of the time encoding expressions
     */ _getExpressions() {
        return {
            hz: {
                method: (value)=>{
                    return this._frequencyToUnits(parseFloat(value));
                },
                regexp: /^(\d+(?:\.\d+)?)hz$/i
            },
            i: {
                method: (value)=>{
                    return this._ticksToUnits(parseInt(value, 10));
                },
                regexp: /^(\d+)i$/i
            },
            m: {
                method: (value)=>{
                    return this._beatsToUnits(parseInt(value, 10) * this._getTimeSignature());
                },
                regexp: /^(\d+)m$/i
            },
            n: {
                method: (value, dot)=>{
                    const numericValue = parseInt(value, 10);
                    const scalar = dot === "." ? 1.5 : 1;
                    if (numericValue === 1) return this._beatsToUnits(this._getTimeSignature()) * scalar;
                    else return this._beatsToUnits(4 / numericValue) * scalar;
                },
                regexp: /^(\d+)n(\.?)$/i
            },
            number: {
                method: (value)=>{
                    return this._expressions[this.defaultUnits].method.call(this, value);
                },
                regexp: /^(\d+(?:\.\d+)?)$/
            },
            s: {
                method: (value)=>{
                    return this._secondsToUnits(parseFloat(value));
                },
                regexp: /^(\d+(?:\.\d+)?)s$/
            },
            samples: {
                method: (value)=>{
                    return parseInt(value, 10) / this.context.sampleRate;
                },
                regexp: /^(\d+)samples$/
            },
            t: {
                method: (value)=>{
                    const numericValue = parseInt(value, 10);
                    return this._beatsToUnits(8 / (Math.floor(numericValue) * 3));
                },
                regexp: /^(\d+)t$/i
            },
            tr: {
                method: (m, q, s)=>{
                    let total = 0;
                    if (m && m !== "0") total += this._beatsToUnits(this._getTimeSignature() * parseFloat(m));
                    if (q && q !== "0") total += this._beatsToUnits(parseFloat(q));
                    if (s && s !== "0") total += this._beatsToUnits(parseFloat(s) / 4);
                    return total;
                },
                regexp: /^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?$/
            }
        };
    }
    //-------------------------------------
    // 	VALUE OF
    //-------------------------------------
    /**
     * Evaluate the time value. Returns the time in seconds.
     */ valueOf() {
        if (this._val instanceof TimeBaseClass) this.fromType(this._val);
        if ((0, _typeCheckJs.isUndef)(this._val)) return this._noArg();
        else if ((0, _typeCheckJs.isString)(this._val) && (0, _typeCheckJs.isUndef)(this._units)) {
            for(const units in this._expressions)if (this._expressions[units].regexp.test(this._val.trim())) {
                this._units = units;
                break;
            }
        } else if ((0, _typeCheckJs.isObject)(this._val)) {
            let total = 0;
            for(const typeName in this._val)if ((0, _typeCheckJs.isDefined)(this._val[typeName])) {
                const quantity = this._val[typeName];
                const time = // @ts-ignore
                new this.constructor(this.context, typeName).valueOf() * quantity;
                total += time;
            }
            return total;
        }
        if ((0, _typeCheckJs.isDefined)(this._units)) {
            const expr = this._expressions[this._units];
            const matching = this._val.toString().trim().match(expr.regexp);
            if (matching) return expr.method.apply(this, matching.slice(1));
            else return expr.method.call(this, this._val);
        } else if ((0, _typeCheckJs.isString)(this._val)) return parseFloat(this._val);
        else return this._val;
    }
    //-------------------------------------
    // 	UNIT CONVERSIONS
    //-------------------------------------
    /**
     * Returns the value of a frequency in the current units
     */ _frequencyToUnits(freq) {
        return 1 / freq;
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return 60 / this._getBpm() * beats;
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return seconds;
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return ticks * this._beatsToUnits(1) / this._getPPQ();
    }
    /**
     * With no arguments, return 'now'
     */ _noArg() {
        return this._now();
    }
    //-------------------------------------
    // 	TEMPO CONVERSIONS
    //-------------------------------------
    /**
     * Return the bpm
     */ _getBpm() {
        return this.context.transport.bpm.value;
    }
    /**
     * Return the timeSignature
     */ _getTimeSignature() {
        return this.context.transport.timeSignature;
    }
    /**
     * Return the PPQ or 192 if Transport is not available
     */ _getPPQ() {
        return this.context.transport.PPQ;
    }
    //-------------------------------------
    // 	CONVERSION INTERFACE
    //-------------------------------------
    /**
     * Coerce a time type into this units type.
     * @param type Any time type units
     */ fromType(type) {
        this._units = undefined;
        switch(this.defaultUnits){
            case "s":
                this._val = type.toSeconds();
                break;
            case "i":
                this._val = type.toTicks();
                break;
            case "hz":
                this._val = type.toFrequency();
                break;
            case "midi":
                this._val = type.toMidi();
                break;
        }
        return this;
    }
    /**
     * Return the value in hertz
     */ toFrequency() {
        return 1 / this.toSeconds();
    }
    /**
     * Return the time in samples
     */ toSamples() {
        return this.toSeconds() * this.context.sampleRate;
    }
    /**
     * Return the time in milliseconds.
     */ toMilliseconds() {
        return this.toSeconds() * 1000;
    }
}

},{"../Tone.js":"6Gzxl","../util/TypeCheck.js":"eMH5A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"a6yW0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TransportTime is a time along the Transport's
 * timeline. It is similar to Tone.Time, but instead of evaluating
 * against the AudioContext's clock, it is evaluated against
 * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).
 * @category Unit
 */ parcelHelpers.export(exports, "TransportTimeClass", ()=>TransportTimeClass);
/**
 * TransportTime is a time along the Transport's
 * timeline. It is similar to Tone.Time, but instead of evaluating
 * against the AudioContext's clock, it is evaluated against
 * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).
 * @category Unit
 */ parcelHelpers.export(exports, "TransportTime", ()=>TransportTime);
var _globalJs = require("../Global.js");
var _timeJs = require("./Time.js");
class TransportTimeClass extends (0, _timeJs.TimeClass) {
    constructor(){
        super(...arguments);
        this.name = "TransportTime";
    }
    /**
     * Return the current time in whichever context is relevant
     */ _now() {
        return this.context.transport.seconds;
    }
}
function TransportTime(value, units) {
    return new TransportTimeClass((0, _globalJs.getContext)(), value, units);
}

},{"../Global.js":"79THw","./Time.js":"9A3Zu","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hkouL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A Timeline State. Provides the methods: `setStateAtTime("state", time)` and `getValueAtTime(time)`
 * @param initial The initial state of the StateTimeline.  Defaults to `undefined`
 * @internal
 */ parcelHelpers.export(exports, "StateTimeline", ()=>StateTimeline);
var _timelineJs = require("./Timeline.js");
var _debugJs = require("./Debug.js");
class StateTimeline extends (0, _timelineJs.Timeline) {
    constructor(initial = "stopped"){
        super();
        this.name = "StateTimeline";
        this._initial = initial;
        this.setStateAtTime(this._initial, 0);
    }
    /**
     * Returns the scheduled state scheduled before or at
     * the given time.
     * @param  time  The time to query.
     * @return  The name of the state input in setStateAtTime.
     */ getValueAtTime(time) {
        const event = this.get(time);
        if (event !== null) return event.state;
        else return this._initial;
    }
    /**
     * Add a state to the timeline.
     * @param  state The name of the state to set.
     * @param  time  The time to query.
     * @param options Any additional options that are needed in the timeline.
     */ setStateAtTime(state, time, options) {
        (0, _debugJs.assertRange)(time, 0);
        this.add(Object.assign({}, options, {
            state,
            time
        }));
        return this;
    }
    /**
     * Return the event before the time with the given state
     * @param  state The state to look for
     * @param  time  When to check before
     * @return  The event with the given state before the time
     */ getLastState(state, time) {
        // time = this.toSeconds(time);
        const index = this._search(time);
        for(let i = index; i >= 0; i--){
            const event = this._timeline[i];
            if (event.state === state) return event;
        }
    }
    /**
     * Return the event after the time with the given state
     * @param  state The state to look for
     * @param  time  When to check from
     * @return  The event with the given state after the time
     */ getNextState(state, time) {
        // time = this.toSeconds(time);
        const index = this._search(time);
        if (index !== -1) for(let i = index; i < this._timeline.length; i++){
            const event = this._timeline[i];
            if (event.state === state) return event;
        }
    }
}

},{"./Timeline.js":"36KJ4","./Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7GTFV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Uses [TickSignal](TickSignal) to track elapsed ticks with complex automation curves.
 */ parcelHelpers.export(exports, "TickSource", ()=>TickSource);
var _toneWithContextJs = require("../context/ToneWithContext.js");
var _defaultsJs = require("../util/Defaults.js");
var _interfaceJs = require("../util/Interface.js");
var _stateTimelineJs = require("../util/StateTimeline.js");
var _timelineJs = require("../util/Timeline.js");
var _typeCheckJs = require("../util/TypeCheck.js");
var _tickSignalJs = require("./TickSignal.js");
var _mathJs = require("../util/Math.js");
class TickSource extends (0, _toneWithContextJs.ToneWithContext) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(TickSource.getDefaults(), arguments, [
            "frequency"
        ]);
        super(options);
        this.name = "TickSource";
        /**
         * The state timeline
         */ this._state = new (0, _stateTimelineJs.StateTimeline)();
        /**
         * The offset values of the ticks
         */ this._tickOffset = new (0, _timelineJs.Timeline)();
        /**
         * Memoized values of getTicksAtTime at events with state other than "started"
         */ this._ticksAtTime = new (0, _timelineJs.Timeline)();
        /**
         * Memoized values of getSecondsAtTime at events with state other than "started"
         */ this._secondsAtTime = new (0, _timelineJs.Timeline)();
        this.frequency = new (0, _tickSignalJs.TickSignal)({
            context: this.context,
            units: options.units,
            value: options.frequency
        });
        (0, _interfaceJs.readOnly)(this, "frequency");
        // set the initial state
        this._state.setStateAtTime("stopped", 0);
        // add the first event
        this.setTicksAtTime(0, 0);
    }
    static getDefaults() {
        return Object.assign({
            frequency: 1,
            units: "hertz"
        }, (0, _toneWithContextJs.ToneWithContext).getDefaults());
    }
    /**
     * Returns the playback state of the source, either "started", "stopped" or "paused".
     */ get state() {
        return this.getStateAtTime(this.now());
    }
    /**
     * Start the clock at the given time. Optionally pass in an offset
     * of where to start the tick counter from.
     * @param  time    The time the clock should start
     * @param offset The number of ticks to start the source at
     */ start(time, offset) {
        const computedTime = this.toSeconds(time);
        if (this._state.getValueAtTime(computedTime) !== "started") {
            this._state.setStateAtTime("started", computedTime);
            if ((0, _typeCheckJs.isDefined)(offset)) this.setTicksAtTime(offset, computedTime);
            this._ticksAtTime.cancel(computedTime);
            this._secondsAtTime.cancel(computedTime);
        }
        return this;
    }
    /**
     * Stop the clock. Stopping the clock resets the tick counter to 0.
     * @param time The time when the clock should stop.
     */ stop(time) {
        const computedTime = this.toSeconds(time);
        // cancel the previous stop
        if (this._state.getValueAtTime(computedTime) === "stopped") {
            const event = this._state.get(computedTime);
            if (event && event.time > 0) {
                this._tickOffset.cancel(event.time);
                this._state.cancel(event.time);
            }
        }
        this._state.cancel(computedTime);
        this._state.setStateAtTime("stopped", computedTime);
        this.setTicksAtTime(0, computedTime);
        this._ticksAtTime.cancel(computedTime);
        this._secondsAtTime.cancel(computedTime);
        return this;
    }
    /**
     * Pause the clock. Pausing does not reset the tick counter.
     * @param time The time when the clock should stop.
     */ pause(time) {
        const computedTime = this.toSeconds(time);
        if (this._state.getValueAtTime(computedTime) === "started") {
            this._state.setStateAtTime("paused", computedTime);
            this._ticksAtTime.cancel(computedTime);
            this._secondsAtTime.cancel(computedTime);
        }
        return this;
    }
    /**
     * Cancel start/stop/pause and setTickAtTime events scheduled after the given time.
     * @param time When to clear the events after
     */ cancel(time) {
        time = this.toSeconds(time);
        this._state.cancel(time);
        this._tickOffset.cancel(time);
        this._ticksAtTime.cancel(time);
        this._secondsAtTime.cancel(time);
        return this;
    }
    /**
     * Get the elapsed ticks at the given time
     * @param  time  When to get the tick value
     * @return The number of ticks
     */ getTicksAtTime(time) {
        const computedTime = this.toSeconds(time);
        const stopEvent = this._state.getLastState("stopped", computedTime);
        // get previously memoized ticks if available
        const memoizedEvent = this._ticksAtTime.get(computedTime);
        // this event allows forEachBetween to iterate until the current time
        const tmpEvent = {
            state: "paused",
            time: computedTime
        };
        this._state.add(tmpEvent);
        // keep track of the previous offset event
        let lastState = memoizedEvent ? memoizedEvent : stopEvent;
        let elapsedTicks = memoizedEvent ? memoizedEvent.ticks : 0;
        let eventToMemoize = null;
        // iterate through all the events since the last stop
        this._state.forEachBetween(lastState.time, computedTime + this.sampleTime, (e)=>{
            let periodStartTime = lastState.time;
            // if there is an offset event in this period use that
            const offsetEvent = this._tickOffset.get(e.time);
            if (offsetEvent && offsetEvent.time >= lastState.time) {
                elapsedTicks = offsetEvent.ticks;
                periodStartTime = offsetEvent.time;
            }
            if (lastState.state === "started" && e.state !== "started") {
                elapsedTicks += this.frequency.getTicksAtTime(e.time) - this.frequency.getTicksAtTime(periodStartTime);
                // do not memoize the temporary event
                if (e.time !== tmpEvent.time) eventToMemoize = {
                    state: e.state,
                    time: e.time,
                    ticks: elapsedTicks
                };
            }
            lastState = e;
        });
        // remove the temporary event
        this._state.remove(tmpEvent);
        // memoize the ticks at the most recent event with state other than "started"
        if (eventToMemoize) this._ticksAtTime.add(eventToMemoize);
        // return the ticks
        return elapsedTicks;
    }
    /**
     * The number of times the callback was invoked. Starts counting at 0
     * and increments after the callback was invoked. Returns -1 when stopped.
     */ get ticks() {
        return this.getTicksAtTime(this.now());
    }
    set ticks(t) {
        this.setTicksAtTime(t, this.now());
    }
    /**
     * The time since ticks=0 that the TickSource has been running. Accounts
     * for tempo curves
     */ get seconds() {
        return this.getSecondsAtTime(this.now());
    }
    set seconds(s) {
        const now = this.now();
        const ticks = this.frequency.timeToTicks(s, now);
        this.setTicksAtTime(ticks, now);
    }
    /**
     * Return the elapsed seconds at the given time.
     * @param  time  When to get the elapsed seconds
     * @return  The number of elapsed seconds
     */ getSecondsAtTime(time) {
        time = this.toSeconds(time);
        const stopEvent = this._state.getLastState("stopped", time);
        // this event allows forEachBetween to iterate until the current time
        const tmpEvent = {
            state: "paused",
            time
        };
        this._state.add(tmpEvent);
        // get previously memoized seconds if available
        const memoizedEvent = this._secondsAtTime.get(time);
        // keep track of the previous offset event
        let lastState = memoizedEvent ? memoizedEvent : stopEvent;
        let elapsedSeconds = memoizedEvent ? memoizedEvent.seconds : 0;
        let eventToMemoize = null;
        // iterate through all the events since the last stop
        this._state.forEachBetween(lastState.time, time + this.sampleTime, (e)=>{
            let periodStartTime = lastState.time;
            // if there is an offset event in this period use that
            const offsetEvent = this._tickOffset.get(e.time);
            if (offsetEvent && offsetEvent.time >= lastState.time) {
                elapsedSeconds = offsetEvent.seconds;
                periodStartTime = offsetEvent.time;
            }
            if (lastState.state === "started" && e.state !== "started") {
                elapsedSeconds += e.time - periodStartTime;
                // do not memoize the temporary event
                if (e.time !== tmpEvent.time) eventToMemoize = {
                    state: e.state,
                    time: e.time,
                    seconds: elapsedSeconds
                };
            }
            lastState = e;
        });
        // remove the temporary event
        this._state.remove(tmpEvent);
        // memoize the seconds at the most recent event with state other than "started"
        if (eventToMemoize) this._secondsAtTime.add(eventToMemoize);
        // return the seconds
        return elapsedSeconds;
    }
    /**
     * Set the clock's ticks at the given time.
     * @param  ticks The tick value to set
     * @param  time  When to set the tick value
     */ setTicksAtTime(ticks, time) {
        time = this.toSeconds(time);
        this._tickOffset.cancel(time);
        this._tickOffset.add({
            seconds: this.frequency.getDurationOfTicks(ticks, time),
            ticks,
            time
        });
        this._ticksAtTime.cancel(time);
        this._secondsAtTime.cancel(time);
        return this;
    }
    /**
     * Returns the scheduled state at the given time.
     * @param  time  The time to query.
     */ getStateAtTime(time) {
        time = this.toSeconds(time);
        return this._state.getValueAtTime(time);
    }
    /**
     * Get the time of the given tick. The second argument
     * is when to test before. Since ticks can be set (with setTicksAtTime)
     * there may be multiple times for a given tick value.
     * @param  tick The tick number.
     * @param  before When to measure the tick value from.
     * @return The time of the tick
     */ getTimeOfTick(tick, before = this.now()) {
        const offset = this._tickOffset.get(before);
        const event = this._state.get(before);
        const startTime = Math.max(offset.time, event.time);
        const absoluteTicks = this.frequency.getTicksAtTime(startTime) + tick - offset.ticks;
        return this.frequency.getTimeOfTick(absoluteTicks);
    }
    /**
     * Invoke the callback event at all scheduled ticks between the
     * start time and the end time
     * @param  startTime  The beginning of the search range
     * @param  endTime    The end of the search range
     * @param  callback   The callback to invoke with each tick
     */ forEachTickBetween(startTime, endTime, callback) {
        // only iterate through the sections where it is "started"
        let lastStateEvent = this._state.get(startTime);
        this._state.forEachBetween(startTime, endTime, (event)=>{
            if (lastStateEvent && lastStateEvent.state === "started" && event.state !== "started") this.forEachTickBetween(Math.max(lastStateEvent.time, startTime), event.time - this.sampleTime, callback);
            lastStateEvent = event;
        });
        let error = null;
        if (lastStateEvent && lastStateEvent.state === "started") {
            const maxStartTime = Math.max(lastStateEvent.time, startTime);
            // figure out the difference between the frequency ticks and the
            const startTicks = this.frequency.getTicksAtTime(maxStartTime);
            const ticksAtStart = this.frequency.getTicksAtTime(lastStateEvent.time);
            const diff = startTicks - ticksAtStart;
            let offset = Math.ceil(diff) - diff;
            // guard against floating point issues
            offset = (0, _mathJs.EQ)(offset, 1) ? 0 : offset;
            let nextTickTime = this.frequency.getTimeOfTick(startTicks + offset);
            while(nextTickTime < endTime){
                try {
                    callback(nextTickTime, Math.round(this.getTicksAtTime(nextTickTime)));
                } catch (e) {
                    error = e;
                    break;
                }
                nextTickTime += this.frequency.getDurationOfTicks(1, nextTickTime);
            }
        }
        if (error) throw error;
        return this;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._state.dispose();
        this._tickOffset.dispose();
        this._ticksAtTime.dispose();
        this._secondsAtTime.dispose();
        this.frequency.dispose();
        return this;
    }
}

},{"../context/ToneWithContext.js":"gAuzg","../util/Defaults.js":"a9M5s","../util/Interface.js":"hVOjA","../util/StateTimeline.js":"hkouL","../util/Timeline.js":"36KJ4","../util/TypeCheck.js":"eMH5A","./TickSignal.js":"2rtQf","../util/Math.js":"7mtt2","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2rtQf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TickSignal extends Tone.Signal, but adds the capability
 * to calculate the number of elapsed ticks. exponential and target curves
 * are approximated with multiple linear ramps.
 *
 * Thank you Bruno Dias, H. Sofia Pinto, and David M. Matos,
 * for your [WAC paper](https://smartech.gatech.edu/bitstream/handle/1853/54588/WAC2016-49.pdf)
 * describing integrating timing functions for tempo calculations.
 */ parcelHelpers.export(exports, "TickSignal", ()=>TickSignal);
var _signalJs = require("../../signal/Signal.js");
var _defaultsJs = require("../util/Defaults.js");
var _tickParamJs = require("./TickParam.js");
class TickSignal extends (0, _signalJs.Signal) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(TickSignal.getDefaults(), arguments, [
            "value"
        ]);
        super(options);
        this.name = "TickSignal";
        this.input = this._param = new (0, _tickParamJs.TickParam)({
            context: this.context,
            convert: options.convert,
            multiplier: options.multiplier,
            param: this._constantSource.offset,
            units: options.units,
            value: options.value
        });
    }
    static getDefaults() {
        return Object.assign((0, _signalJs.Signal).getDefaults(), {
            multiplier: 1,
            units: "hertz",
            value: 1
        });
    }
    ticksToTime(ticks, when) {
        return this._param.ticksToTime(ticks, when);
    }
    timeToTicks(duration, when) {
        return this._param.timeToTicks(duration, when);
    }
    getTimeOfTick(tick) {
        return this._param.getTimeOfTick(tick);
    }
    getDurationOfTicks(ticks, time) {
        return this._param.getDurationOfTicks(ticks, time);
    }
    getTicksAtTime(time) {
        return this._param.getTicksAtTime(time);
    }
    /**
     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.
     */ get multiplier() {
        return this._param.multiplier;
    }
    set multiplier(m) {
        this._param.multiplier = m;
    }
    dispose() {
        super.dispose();
        this._param.dispose();
        return this;
    }
}

},{"../../signal/Signal.js":"980ri","../util/Defaults.js":"a9M5s","./TickParam.js":"5sGSd","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"980ri":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A signal is an audio-rate value. Tone.Signal is a core component of the library.
 * Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal
 * has all of the methods available to native Web Audio
 * [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)
 * as well as additional conveniences. Read more about working with signals
 * [here](https://github.com/Tonejs/Tone.js/wiki/Signals).
 *
 * @example
 * const osc = new Tone.Oscillator().toDestination().start();
 * // a scheduleable signal which can be connected to control an AudioParam or another Signal
 * const signal = new Tone.Signal({
 * 	value: "C4",
 * 	units: "frequency"
 * }).connect(osc.frequency);
 * // the scheduled ramp controls the connected signal
 * signal.rampTo("C2", 4, "+0.5");
 * @category Signal
 */ parcelHelpers.export(exports, "Signal", ()=>Signal);
/**
 * When connecting from a signal, it's necessary to zero out the node destination
 * node if that node is also a signal. If the destination is not 0, then the values
 * will be summed. This method insures that the output of the destination signal will
 * be the same as the source signal, making the destination signal a pass through node.
 * @param signal The output signal to connect from
 * @param destination the destination to connect to
 * @param outputNum the optional output number
 * @param inputNum the input number
 */ parcelHelpers.export(exports, "connectSignal", ()=>connectSignal);
var _paramJs = require("../core/context/Param.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _advancedTypeCheckJs = require("../core/util/AdvancedTypeCheck.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _toneConstantSourceJs = require("./ToneConstantSource.js");
class Signal extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Signal.getDefaults(), arguments, [
            "value",
            "units"
        ]);
        super(options);
        this.name = "Signal";
        /**
         * Indicates if the value should be overridden on connection.
         */ this.override = true;
        this.output = this._constantSource = new (0, _toneConstantSourceJs.ToneConstantSource)({
            context: this.context,
            convert: options.convert,
            offset: options.value,
            units: options.units,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
        this._constantSource.start(0);
        this.input = this._param = this._constantSource.offset;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            convert: true,
            units: "number",
            value: 0
        });
    }
    connect(destination, outputNum = 0, inputNum = 0) {
        // start it only when connected to something
        connectSignal(this, destination, outputNum, inputNum);
        return this;
    }
    dispose() {
        super.dispose();
        this._param.dispose();
        this._constantSource.dispose();
        return this;
    }
    //-------------------------------------
    // ABSTRACT PARAM INTERFACE
    // just a proxy for the ConstantSourceNode's offset AudioParam
    // all docs are generated from AbstractParam.ts
    //-------------------------------------
    setValueAtTime(value, time) {
        this._param.setValueAtTime(value, time);
        return this;
    }
    getValueAtTime(time) {
        return this._param.getValueAtTime(time);
    }
    setRampPoint(time) {
        this._param.setRampPoint(time);
        return this;
    }
    linearRampToValueAtTime(value, time) {
        this._param.linearRampToValueAtTime(value, time);
        return this;
    }
    exponentialRampToValueAtTime(value, time) {
        this._param.exponentialRampToValueAtTime(value, time);
        return this;
    }
    exponentialRampTo(value, rampTime, startTime) {
        this._param.exponentialRampTo(value, rampTime, startTime);
        return this;
    }
    linearRampTo(value, rampTime, startTime) {
        this._param.linearRampTo(value, rampTime, startTime);
        return this;
    }
    targetRampTo(value, rampTime, startTime) {
        this._param.targetRampTo(value, rampTime, startTime);
        return this;
    }
    exponentialApproachValueAtTime(value, time, rampTime) {
        this._param.exponentialApproachValueAtTime(value, time, rampTime);
        return this;
    }
    setTargetAtTime(value, startTime, timeConstant) {
        this._param.setTargetAtTime(value, startTime, timeConstant);
        return this;
    }
    setValueCurveAtTime(values, startTime, duration, scaling) {
        this._param.setValueCurveAtTime(values, startTime, duration, scaling);
        return this;
    }
    cancelScheduledValues(time) {
        this._param.cancelScheduledValues(time);
        return this;
    }
    cancelAndHoldAtTime(time) {
        this._param.cancelAndHoldAtTime(time);
        return this;
    }
    rampTo(value, rampTime, startTime) {
        this._param.rampTo(value, rampTime, startTime);
        return this;
    }
    get value() {
        return this._param.value;
    }
    set value(value) {
        this._param.value = value;
    }
    get convert() {
        return this._param.convert;
    }
    set convert(convert) {
        this._param.convert = convert;
    }
    get units() {
        return this._param.units;
    }
    get overridden() {
        return this._param.overridden;
    }
    set overridden(overridden) {
        this._param.overridden = overridden;
    }
    get maxValue() {
        return this._param.maxValue;
    }
    get minValue() {
        return this._param.minValue;
    }
    /**
     * @see {@link Param.apply}.
     */ apply(param) {
        this._param.apply(param);
        return this;
    }
}
function connectSignal(signal, destination, outputNum, inputNum) {
    if (destination instanceof (0, _paramJs.Param) || (0, _advancedTypeCheckJs.isAudioParam)(destination) || destination instanceof Signal && destination.override) {
        // cancel changes
        destination.cancelScheduledValues(0);
        // reset the value
        destination.setValueAtTime(0, 0);
        // mark the value as overridden
        if (destination instanceof Signal) destination.overridden = true;
    }
    (0, _toneAudioNodeJs.connect)(signal, destination, outputNum, inputNum);
}

},{"../core/context/Param.js":"5PVlJ","../core/context/ToneAudioNode.js":"kZ3Kj","../core/util/AdvancedTypeCheck.js":"gKVc7","../core/util/Defaults.js":"a9M5s","./ToneConstantSource.js":"aU7Ju","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5PVlJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Param wraps the native Web Audio's AudioParam to provide
 * additional unit conversion functionality. It also
 * serves as a base-class for classes which have a single,
 * automatable parameter.
 * @category Core
 */ parcelHelpers.export(exports, "Param", ()=>Param);
var _conversionsJs = require("../type/Conversions.js");
var _advancedTypeCheckJs = require("../util/AdvancedTypeCheck.js");
var _defaultsJs = require("../util/Defaults.js");
var _timelineJs = require("../util/Timeline.js");
var _typeCheckJs = require("../util/TypeCheck.js");
var _toneWithContextJs = require("./ToneWithContext.js");
var _mathJs = require("../util/Math.js");
var _debugJs = require("../util/Debug.js");
class Param extends (0, _toneWithContextJs.ToneWithContext) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Param.getDefaults(), arguments, [
            "param",
            "units",
            "convert"
        ]);
        super(options);
        this.name = "Param";
        this.overridden = false;
        /**
         * The minimum output value
         */ this._minOutput = 1e-7;
        (0, _debugJs.assert)((0, _typeCheckJs.isDefined)(options.param) && ((0, _advancedTypeCheckJs.isAudioParam)(options.param) || options.param instanceof Param), "param must be an AudioParam");
        while(!(0, _advancedTypeCheckJs.isAudioParam)(options.param))options.param = options.param._param;
        this._swappable = (0, _typeCheckJs.isDefined)(options.swappable) ? options.swappable : false;
        if (this._swappable) {
            this.input = this.context.createGain();
            // initialize
            this._param = options.param;
            this.input.connect(this._param);
        } else this._param = this.input = options.param;
        this._events = new (0, _timelineJs.Timeline)(1000);
        this._initialValue = this._param.defaultValue;
        this.units = options.units;
        this.convert = options.convert;
        this._minValue = options.minValue;
        this._maxValue = options.maxValue;
        // if the value is defined, set it immediately
        if ((0, _typeCheckJs.isDefined)(options.value) && options.value !== this._toType(this._initialValue)) this.setValueAtTime(options.value, 0);
    }
    static getDefaults() {
        return Object.assign((0, _toneWithContextJs.ToneWithContext).getDefaults(), {
            convert: true,
            units: "number"
        });
    }
    get value() {
        const now = this.now();
        return this.getValueAtTime(now);
    }
    set value(value) {
        this.cancelScheduledValues(this.now());
        this.setValueAtTime(value, this.now());
    }
    get minValue() {
        // if it's not the default minValue, return it
        if ((0, _typeCheckJs.isDefined)(this._minValue)) return this._minValue;
        else if (this.units === "time" || this.units === "frequency" || this.units === "normalRange" || this.units === "positive" || this.units === "transportTime" || this.units === "ticks" || this.units === "bpm" || this.units === "hertz" || this.units === "samples") return 0;
        else if (this.units === "audioRange") return -1;
        else if (this.units === "decibels") return -Infinity;
        else return this._param.minValue;
    }
    get maxValue() {
        if ((0, _typeCheckJs.isDefined)(this._maxValue)) return this._maxValue;
        else if (this.units === "normalRange" || this.units === "audioRange") return 1;
        else return this._param.maxValue;
    }
    /**
     * Type guard based on the unit name
     */ _is(arg, type) {
        return this.units === type;
    }
    /**
     * Make sure the value is always in the defined range
     */ _assertRange(value) {
        if ((0, _typeCheckJs.isDefined)(this.maxValue) && (0, _typeCheckJs.isDefined)(this.minValue)) (0, _debugJs.assertRange)(value, this._fromType(this.minValue), this._fromType(this.maxValue));
        return value;
    }
    /**
     * Convert the given value from the type specified by Param.units
     * into the destination value (such as Gain or Frequency).
     */ _fromType(val) {
        if (this.convert && !this.overridden) {
            if (this._is(val, "time")) return this.toSeconds(val);
            else if (this._is(val, "decibels")) return (0, _conversionsJs.dbToGain)(val);
            else if (this._is(val, "frequency")) return this.toFrequency(val);
            else return val;
        } else if (this.overridden) // if it's overridden, should only schedule 0s
        return 0;
        else return val;
    }
    /**
     * Convert the parameters value into the units specified by Param.units.
     */ _toType(val) {
        if (this.convert && this.units === "decibels") return (0, _conversionsJs.gainToDb)(val);
        else return val;
    }
    //-------------------------------------
    // ABSTRACT PARAM INTERFACE
    // all docs are generated from ParamInterface.ts
    //-------------------------------------
    setValueAtTime(value, time) {
        const computedTime = this.toSeconds(time);
        const numericValue = this._fromType(value);
        (0, _debugJs.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(time)}`);
        this._assertRange(numericValue);
        this.log(this.units, "setValueAtTime", value, computedTime);
        this._events.add({
            time: computedTime,
            type: "setValueAtTime",
            value: numericValue
        });
        this._param.setValueAtTime(numericValue, computedTime);
        return this;
    }
    getValueAtTime(time) {
        const computedTime = Math.max(this.toSeconds(time), 0);
        const after = this._events.getAfter(computedTime);
        const before = this._events.get(computedTime);
        let value = this._initialValue;
        // if it was set by
        if (before === null) value = this._initialValue;
        else if (before.type === "setTargetAtTime" && (after === null || after.type === "setValueAtTime")) {
            const previous = this._events.getBefore(before.time);
            let previousVal;
            if (previous === null) previousVal = this._initialValue;
            else previousVal = previous.value;
            if (before.type === "setTargetAtTime") value = this._exponentialApproach(before.time, previousVal, before.value, before.constant, computedTime);
        } else if (after === null) value = before.value;
        else if (after.type === "linearRampToValueAtTime" || after.type === "exponentialRampToValueAtTime") {
            let beforeValue = before.value;
            if (before.type === "setTargetAtTime") {
                const previous = this._events.getBefore(before.time);
                if (previous === null) beforeValue = this._initialValue;
                else beforeValue = previous.value;
            }
            if (after.type === "linearRampToValueAtTime") value = this._linearInterpolate(before.time, beforeValue, after.time, after.value, computedTime);
            else value = this._exponentialInterpolate(before.time, beforeValue, after.time, after.value, computedTime);
        } else value = before.value;
        return this._toType(value);
    }
    setRampPoint(time) {
        time = this.toSeconds(time);
        let currentVal = this.getValueAtTime(time);
        this.cancelAndHoldAtTime(time);
        if (this._fromType(currentVal) === 0) currentVal = this._toType(this._minOutput);
        this.setValueAtTime(currentVal, time);
        return this;
    }
    linearRampToValueAtTime(value, endTime) {
        const numericValue = this._fromType(value);
        const computedTime = this.toSeconds(endTime);
        (0, _debugJs.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to linearRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);
        this._assertRange(numericValue);
        this._events.add({
            time: computedTime,
            type: "linearRampToValueAtTime",
            value: numericValue
        });
        this.log(this.units, "linearRampToValueAtTime", value, computedTime);
        this._param.linearRampToValueAtTime(numericValue, computedTime);
        return this;
    }
    exponentialRampToValueAtTime(value, endTime) {
        let numericValue = this._fromType(value);
        // the value can't be 0
        numericValue = (0, _mathJs.EQ)(numericValue, 0) ? this._minOutput : numericValue;
        this._assertRange(numericValue);
        const computedTime = this.toSeconds(endTime);
        (0, _debugJs.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to exponentialRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);
        // store the event
        this._events.add({
            time: computedTime,
            type: "exponentialRampToValueAtTime",
            value: numericValue
        });
        this.log(this.units, "exponentialRampToValueAtTime", value, computedTime);
        this._param.exponentialRampToValueAtTime(numericValue, computedTime);
        return this;
    }
    exponentialRampTo(value, rampTime, startTime) {
        startTime = this.toSeconds(startTime);
        this.setRampPoint(startTime);
        this.exponentialRampToValueAtTime(value, startTime + this.toSeconds(rampTime));
        return this;
    }
    linearRampTo(value, rampTime, startTime) {
        startTime = this.toSeconds(startTime);
        this.setRampPoint(startTime);
        this.linearRampToValueAtTime(value, startTime + this.toSeconds(rampTime));
        return this;
    }
    targetRampTo(value, rampTime, startTime) {
        startTime = this.toSeconds(startTime);
        this.setRampPoint(startTime);
        this.exponentialApproachValueAtTime(value, startTime, rampTime);
        return this;
    }
    exponentialApproachValueAtTime(value, time, rampTime) {
        time = this.toSeconds(time);
        rampTime = this.toSeconds(rampTime);
        const timeConstant = Math.log(rampTime + 1) / Math.log(200);
        this.setTargetAtTime(value, time, timeConstant);
        // at 90% start a linear ramp to the final value
        this.cancelAndHoldAtTime(time + rampTime * 0.9);
        this.linearRampToValueAtTime(value, time + rampTime);
        return this;
    }
    setTargetAtTime(value, startTime, timeConstant) {
        const numericValue = this._fromType(value);
        // The value will never be able to approach without timeConstant > 0.
        (0, _debugJs.assert)(isFinite(timeConstant) && timeConstant > 0, "timeConstant must be a number greater than 0");
        const computedTime = this.toSeconds(startTime);
        this._assertRange(numericValue);
        (0, _debugJs.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setTargetAtTime: ${JSON.stringify(value)}, ${JSON.stringify(startTime)}`);
        this._events.add({
            constant: timeConstant,
            time: computedTime,
            type: "setTargetAtTime",
            value: numericValue
        });
        this.log(this.units, "setTargetAtTime", value, computedTime, timeConstant);
        this._param.setTargetAtTime(numericValue, computedTime, timeConstant);
        return this;
    }
    setValueCurveAtTime(values, startTime, duration, scaling = 1) {
        duration = this.toSeconds(duration);
        startTime = this.toSeconds(startTime);
        const startingValue = this._fromType(values[0]) * scaling;
        this.setValueAtTime(this._toType(startingValue), startTime);
        const segTime = duration / (values.length - 1);
        for(let i = 1; i < values.length; i++){
            const numericValue = this._fromType(values[i]) * scaling;
            this.linearRampToValueAtTime(this._toType(numericValue), startTime + i * segTime);
        }
        return this;
    }
    cancelScheduledValues(time) {
        const computedTime = this.toSeconds(time);
        (0, _debugJs.assert)(isFinite(computedTime), `Invalid argument to cancelScheduledValues: ${JSON.stringify(time)}`);
        this._events.cancel(computedTime);
        this._param.cancelScheduledValues(computedTime);
        this.log(this.units, "cancelScheduledValues", computedTime);
        return this;
    }
    cancelAndHoldAtTime(time) {
        const computedTime = this.toSeconds(time);
        const valueAtTime = this._fromType(this.getValueAtTime(computedTime));
        // remove the schedule events
        (0, _debugJs.assert)(isFinite(computedTime), `Invalid argument to cancelAndHoldAtTime: ${JSON.stringify(time)}`);
        this.log(this.units, "cancelAndHoldAtTime", computedTime, "value=" + valueAtTime);
        // if there is an event at the given computedTime
        // and that even is not a "set"
        const before = this._events.get(computedTime);
        const after = this._events.getAfter(computedTime);
        if (before && (0, _mathJs.EQ)(before.time, computedTime)) {
            // remove everything after
            if (after) {
                this._param.cancelScheduledValues(after.time);
                this._events.cancel(after.time);
            } else {
                this._param.cancelAndHoldAtTime(computedTime);
                this._events.cancel(computedTime + this.sampleTime);
            }
        } else if (after) {
            this._param.cancelScheduledValues(after.time);
            // cancel the next event(s)
            this._events.cancel(after.time);
            if (after.type === "linearRampToValueAtTime") this.linearRampToValueAtTime(this._toType(valueAtTime), computedTime);
            else if (after.type === "exponentialRampToValueAtTime") this.exponentialRampToValueAtTime(this._toType(valueAtTime), computedTime);
        }
        // set the value at the given time
        this._events.add({
            time: computedTime,
            type: "setValueAtTime",
            value: valueAtTime
        });
        this._param.setValueAtTime(valueAtTime, computedTime);
        return this;
    }
    rampTo(value, rampTime = 0.1, startTime) {
        if (this.units === "frequency" || this.units === "bpm" || this.units === "decibels") this.exponentialRampTo(value, rampTime, startTime);
        else this.linearRampTo(value, rampTime, startTime);
        return this;
    }
    /**
     * Apply all of the previously scheduled events to the passed in Param or AudioParam.
     * The applied values will start at the context's current time and schedule
     * all of the events which are scheduled on this Param onto the passed in param.
     */ apply(param) {
        const now = this.context.currentTime;
        // set the param's value at the current time and schedule everything else
        param.setValueAtTime(this.getValueAtTime(now), now);
        // if the previous event was a curve, then set the rest of it
        const previousEvent = this._events.get(now);
        if (previousEvent && previousEvent.type === "setTargetAtTime") {
            // approx it until the next event with linear ramps
            const nextEvent = this._events.getAfter(previousEvent.time);
            // or for 2 seconds if there is no event
            const endTime = nextEvent ? nextEvent.time : now + 2;
            const subdivisions = (endTime - now) / 10;
            for(let i = now; i < endTime; i += subdivisions)param.linearRampToValueAtTime(this.getValueAtTime(i), i);
        }
        this._events.forEachAfter(this.context.currentTime, (event)=>{
            if (event.type === "cancelScheduledValues") param.cancelScheduledValues(event.time);
            else if (event.type === "setTargetAtTime") param.setTargetAtTime(event.value, event.time, event.constant);
            else param[event.type](event.value, event.time);
        });
        return this;
    }
    /**
     * Replace the Param's internal AudioParam. Will apply scheduled curves
     * onto the parameter and replace the connections.
     */ setParam(param) {
        (0, _debugJs.assert)(this._swappable, "The Param must be assigned as 'swappable' in the constructor");
        const input = this.input;
        input.disconnect(this._param);
        this.apply(param);
        this._param = param;
        input.connect(this._param);
        return this;
    }
    dispose() {
        super.dispose();
        this._events.dispose();
        return this;
    }
    get defaultValue() {
        return this._toType(this._param.defaultValue);
    }
    //-------------------------------------
    // 	AUTOMATION CURVE CALCULATIONS
    // 	MIT License, copyright (c) 2014 Jordan Santell
    //-------------------------------------
    // Calculates the the value along the curve produced by setTargetAtTime
    _exponentialApproach(t0, v0, v1, timeConstant, t) {
        return v1 + (v0 - v1) * Math.exp(-(t - t0) / timeConstant);
    }
    // Calculates the the value along the curve produced by linearRampToValueAtTime
    _linearInterpolate(t0, v0, t1, v1, t) {
        return v0 + (v1 - v0) * ((t - t0) / (t1 - t0));
    }
    // Calculates the the value along the curve produced by exponentialRampToValueAtTime
    _exponentialInterpolate(t0, v0, t1, v1, t) {
        return v0 * Math.pow(v1 / v0, (t - t0) / (t1 - t0));
    }
}

},{"../type/Conversions.js":"iww1u","../util/AdvancedTypeCheck.js":"gKVc7","../util/Defaults.js":"a9M5s","../util/Timeline.js":"36KJ4","../util/TypeCheck.js":"eMH5A","./ToneWithContext.js":"gAuzg","../util/Math.js":"7mtt2","../util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kZ3Kj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * ToneAudioNode is the base class for classes which process audio.
 * @category Core
 */ parcelHelpers.export(exports, "ToneAudioNode", ()=>ToneAudioNode);
//-------------------------------------
// CONNECTIONS
//-------------------------------------
/**
 * connect together all of the arguments in series
 * @param nodes
 */ parcelHelpers.export(exports, "connectSeries", ()=>connectSeries);
/**
 * Connect two nodes together so that signal flows from the
 * first node to the second. Optionally specify the input and output channels.
 * @param srcNode The source node
 * @param dstNode The destination node
 * @param outputNumber The output channel of the srcNode
 * @param inputNumber The input channel of the dstNode
 */ parcelHelpers.export(exports, "connect", ()=>connect);
/**
 * Disconnect a node from all nodes or optionally include a destination node and input/output channels.
 * @param srcNode The source node
 * @param dstNode The destination node
 * @param outputNumber The output channel of the srcNode
 * @param inputNumber The input channel of the dstNode
 */ parcelHelpers.export(exports, "disconnect", ()=>disconnect);
/**
 * Connect the output of one or more source nodes to a single destination node
 * @param nodes One or more source nodes followed by one destination node
 * @example
 * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3");
 * const player1 = new Tone.Player("https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3");
 * const filter = new Tone.Filter("G5").toDestination();
 * // connect nodes to a common destination
 * Tone.fanIn(player, player1, filter);
 */ parcelHelpers.export(exports, "fanIn", ()=>fanIn);
var _advancedTypeCheckJs = require("../util/AdvancedTypeCheck.js");
var _typeCheckJs = require("../util/TypeCheck.js");
var _paramJs = require("./Param.js");
var _toneWithContextJs = require("./ToneWithContext.js");
var _debugJs = require("../util/Debug.js");
class ToneAudioNode extends (0, _toneWithContextJs.ToneWithContext) {
    constructor(){
        super(...arguments);
        /**
         * List all of the node that must be set to match the ChannelProperties
         */ this._internalChannels = [];
    }
    /**
     * The number of inputs feeding into the AudioNode.
     * For source nodes, this will be 0.
     * @example
     * const node = new Tone.Gain();
     * console.log(node.numberOfInputs);
     */ get numberOfInputs() {
        if ((0, _typeCheckJs.isDefined)(this.input)) {
            if ((0, _advancedTypeCheckJs.isAudioParam)(this.input) || this.input instanceof (0, _paramJs.Param)) return 1;
            else return this.input.numberOfInputs;
        } else return 0;
    }
    /**
     * The number of outputs of the AudioNode.
     * @example
     * const node = new Tone.Gain();
     * console.log(node.numberOfOutputs);
     */ get numberOfOutputs() {
        if ((0, _typeCheckJs.isDefined)(this.output)) return this.output.numberOfOutputs;
        else return 0;
    }
    //-------------------------------------
    // AUDIO PROPERTIES
    //-------------------------------------
    /**
     * Used to decide which nodes to get/set properties on
     */ _isAudioNode(node) {
        return (0, _typeCheckJs.isDefined)(node) && (node instanceof ToneAudioNode || (0, _advancedTypeCheckJs.isAudioNode)(node));
    }
    /**
     * Get all of the audio nodes (either internal or input/output) which together
     * make up how the class node responds to channel input/output
     */ _getInternalNodes() {
        const nodeList = this._internalChannels.slice(0);
        if (this._isAudioNode(this.input)) nodeList.push(this.input);
        if (this._isAudioNode(this.output)) {
            if (this.input !== this.output) nodeList.push(this.output);
        }
        return nodeList;
    }
    /**
     * Set the audio options for this node such as channelInterpretation
     * channelCount, etc.
     * @param options
     */ _setChannelProperties(options) {
        const nodeList = this._getInternalNodes();
        nodeList.forEach((node)=>{
            node.channelCount = options.channelCount;
            node.channelCountMode = options.channelCountMode;
            node.channelInterpretation = options.channelInterpretation;
        });
    }
    /**
     * Get the current audio options for this node such as channelInterpretation
     * channelCount, etc.
     */ _getChannelProperties() {
        const nodeList = this._getInternalNodes();
        (0, _debugJs.assert)(nodeList.length > 0, "ToneAudioNode does not have any internal nodes");
        // use the first node to get properties
        // they should all be the same
        const node = nodeList[0];
        return {
            channelCount: node.channelCount,
            channelCountMode: node.channelCountMode,
            channelInterpretation: node.channelInterpretation
        };
    }
    /**
     * channelCount is the number of channels used when up-mixing and down-mixing
     * connections to any inputs to the node. The default value is 2 except for
     * specific nodes where its value is specially determined.
     */ get channelCount() {
        return this._getChannelProperties().channelCount;
    }
    set channelCount(channelCount) {
        const props = this._getChannelProperties();
        // merge it with the other properties
        this._setChannelProperties(Object.assign(props, {
            channelCount
        }));
    }
    /**
     * channelCountMode determines how channels will be counted when up-mixing and
     * down-mixing connections to any inputs to the node.
     * The default value is "max". This attribute has no effect for nodes with no inputs.
     * * "max" - computedNumberOfChannels is the maximum of the number of channels of all connections to an input. In this mode channelCount is ignored.
     * * "clamped-max" - computedNumberOfChannels is determined as for "max" and then clamped to a maximum value of the given channelCount.
     * * "explicit" - computedNumberOfChannels is the exact value as specified by the channelCount.
     */ get channelCountMode() {
        return this._getChannelProperties().channelCountMode;
    }
    set channelCountMode(channelCountMode) {
        const props = this._getChannelProperties();
        // merge it with the other properties
        this._setChannelProperties(Object.assign(props, {
            channelCountMode
        }));
    }
    /**
     * channelInterpretation determines how individual channels will be treated
     * when up-mixing and down-mixing connections to any inputs to the node.
     * The default value is "speakers".
     */ get channelInterpretation() {
        return this._getChannelProperties().channelInterpretation;
    }
    set channelInterpretation(channelInterpretation) {
        const props = this._getChannelProperties();
        // merge it with the other properties
        this._setChannelProperties(Object.assign(props, {
            channelInterpretation
        }));
    }
    //-------------------------------------
    // CONNECTIONS
    //-------------------------------------
    /**
     * connect the output of a ToneAudioNode to an AudioParam, AudioNode, or ToneAudioNode
     * @param destination The output to connect to
     * @param outputNum The output to connect from
     * @param inputNum The input to connect to
     */ connect(destination, outputNum = 0, inputNum = 0) {
        connect(this, destination, outputNum, inputNum);
        return this;
    }
    /**
     * Connect the output to the context's destination node.
     * @example
     * const osc = new Tone.Oscillator("C2").start();
     * osc.toDestination();
     */ toDestination() {
        this.connect(this.context.destination);
        return this;
    }
    /**
     * Connect the output to the context's destination node.
     * @see {@link toDestination}
     * @deprecated
     */ toMaster() {
        (0, _debugJs.warn)("toMaster() has been renamed toDestination()");
        return this.toDestination();
    }
    /**
     * disconnect the output
     */ disconnect(destination, outputNum = 0, inputNum = 0) {
        disconnect(this, destination, outputNum, inputNum);
        return this;
    }
    /**
     * Connect the output of this node to the rest of the nodes in series.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/handdrum-loop.mp3");
     * player.autostart = true;
     * const filter = new Tone.AutoFilter(4).start();
     * const distortion = new Tone.Distortion(0.5);
     * // connect the player to the filter, distortion and then to the master output
     * player.chain(filter, distortion, Tone.Destination);
     */ chain(...nodes) {
        connectSeries(this, ...nodes);
        return this;
    }
    /**
     * connect the output of this node to the rest of the nodes in parallel.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3");
     * player.autostart = true;
     * const pitchShift = new Tone.PitchShift(4).toDestination();
     * const filter = new Tone.Filter("G5").toDestination();
     * // connect a node to the pitch shift and filter in parallel
     * player.fan(pitchShift, filter);
     */ fan(...nodes) {
        nodes.forEach((node)=>this.connect(node));
        return this;
    }
    /**
     * Dispose and disconnect
     */ dispose() {
        super.dispose();
        if ((0, _typeCheckJs.isDefined)(this.input)) {
            if (this.input instanceof ToneAudioNode) this.input.dispose();
            else if ((0, _advancedTypeCheckJs.isAudioNode)(this.input)) this.input.disconnect();
        }
        if ((0, _typeCheckJs.isDefined)(this.output)) {
            if (this.output instanceof ToneAudioNode) this.output.dispose();
            else if ((0, _advancedTypeCheckJs.isAudioNode)(this.output)) this.output.disconnect();
        }
        this._internalChannels = [];
        return this;
    }
}
function connectSeries(...nodes) {
    const first = nodes.shift();
    nodes.reduce((prev, current)=>{
        if (prev instanceof ToneAudioNode) prev.connect(current);
        else if ((0, _advancedTypeCheckJs.isAudioNode)(prev)) connect(prev, current);
        return current;
    }, first);
}
function connect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {
    (0, _debugJs.assert)((0, _typeCheckJs.isDefined)(srcNode), "Cannot connect from undefined node");
    (0, _debugJs.assert)((0, _typeCheckJs.isDefined)(dstNode), "Cannot connect to undefined node");
    if (dstNode instanceof ToneAudioNode || (0, _advancedTypeCheckJs.isAudioNode)(dstNode)) (0, _debugJs.assert)(dstNode.numberOfInputs > 0, "Cannot connect to node with no inputs");
    (0, _debugJs.assert)(srcNode.numberOfOutputs > 0, "Cannot connect from node with no outputs");
    // resolve the input of the dstNode
    while(dstNode instanceof ToneAudioNode || dstNode instanceof (0, _paramJs.Param))if ((0, _typeCheckJs.isDefined)(dstNode.input)) dstNode = dstNode.input;
    while(srcNode instanceof ToneAudioNode)if ((0, _typeCheckJs.isDefined)(srcNode.output)) srcNode = srcNode.output;
    // make the connection
    if ((0, _advancedTypeCheckJs.isAudioParam)(dstNode)) srcNode.connect(dstNode, outputNumber);
    else srcNode.connect(dstNode, outputNumber, inputNumber);
}
function disconnect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {
    // resolve the destination node
    if ((0, _typeCheckJs.isDefined)(dstNode)) while(dstNode instanceof ToneAudioNode)dstNode = dstNode.input;
    // resolve the src node
    while(!(0, _advancedTypeCheckJs.isAudioNode)(srcNode))if ((0, _typeCheckJs.isDefined)(srcNode.output)) srcNode = srcNode.output;
    if ((0, _advancedTypeCheckJs.isAudioParam)(dstNode)) srcNode.disconnect(dstNode, outputNumber);
    else if ((0, _advancedTypeCheckJs.isAudioNode)(dstNode)) srcNode.disconnect(dstNode, outputNumber, inputNumber);
    else srcNode.disconnect();
}
function fanIn(...nodes) {
    const dstNode = nodes.pop();
    if ((0, _typeCheckJs.isDefined)(dstNode)) nodes.forEach((node)=>connect(node, dstNode));
}

},{"../util/AdvancedTypeCheck.js":"gKVc7","../util/TypeCheck.js":"eMH5A","./Param.js":"5PVlJ","./ToneWithContext.js":"gAuzg","../util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aU7Ju":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the native fire-and-forget ConstantSource.
 * Adds the ability to reschedule the stop method.
 * @category Signal
 */ parcelHelpers.export(exports, "ToneConstantSource", ()=>ToneConstantSource);
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _paramJs = require("../core/context/Param.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _oneShotSourceJs = require("../source/OneShotSource.js");
class ToneConstantSource extends (0, _oneShotSourceJs.OneShotSource) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(ToneConstantSource.getDefaults(), arguments, [
            "offset"
        ]);
        super(options);
        this.name = "ToneConstantSource";
        /**
         * The signal generator
         */ this._source = this.context.createConstantSource();
        (0, _toneAudioNodeJs.connect)(this._source, this._gainNode);
        this.offset = new (0, _paramJs.Param)({
            context: this.context,
            convert: options.convert,
            param: this._source.offset,
            units: options.units,
            value: options.offset,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
    }
    static getDefaults() {
        return Object.assign((0, _oneShotSourceJs.OneShotSource).getDefaults(), {
            convert: true,
            offset: 1,
            units: "number"
        });
    }
    /**
     * Start the source node at the given time
     * @param  time When to start the source
     */ start(time) {
        const computedTime = this.toSeconds(time);
        this.log("start", computedTime);
        this._startGain(computedTime);
        this._source.start(computedTime);
        return this;
    }
    _stopSource(time) {
        this._source.stop(time);
    }
    dispose() {
        super.dispose();
        if (this.state === "started") this.stop();
        this._source.disconnect();
        this.offset.dispose();
        return this;
    }
}

},{"../core/context/ToneAudioNode.js":"kZ3Kj","../core/context/Param.js":"5PVlJ","../core/util/Defaults.js":"a9M5s","../source/OneShotSource.js":"iVQxd","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iVQxd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for fire-and-forget nodes
 */ parcelHelpers.export(exports, "OneShotSource", ()=>OneShotSource);
var _gainJs = require("../core/context/Gain.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _interfaceJs = require("../core/util/Interface.js");
var _debugJs = require("../core/util/Debug.js");
class OneShotSource extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(options){
        super(options);
        /**
         * The callback to invoke after the
         * source is done playing.
         */ this.onended = (0, _interfaceJs.noOp);
        /**
         * The start time
         */ this._startTime = -1;
        /**
         * The stop time
         */ this._stopTime = -1;
        /**
         * The id of the timeout
         */ this._timeout = -1;
        /**
         * The public output node
         */ this.output = new (0, _gainJs.Gain)({
            context: this.context,
            gain: 0
        });
        /**
         * The output gain node.
         */ this._gainNode = this.output;
        /**
         * Get the playback state at the given time
         */ this.getStateAtTime = function(time) {
            const computedTime = this.toSeconds(time);
            if (this._startTime !== -1 && computedTime >= this._startTime && (this._stopTime === -1 || computedTime <= this._stopTime)) return "started";
            else return "stopped";
        };
        this._fadeIn = options.fadeIn;
        this._fadeOut = options.fadeOut;
        this._curve = options.curve;
        this.onended = options.onended;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            curve: "linear",
            fadeIn: 0,
            fadeOut: 0,
            onended: (0, _interfaceJs.noOp)
        });
    }
    /**
     * Start the source at the given time
     * @param  time When to start the source
     */ _startGain(time, gain = 1) {
        (0, _debugJs.assert)(this._startTime === -1, "Source cannot be started more than once");
        // apply a fade in envelope
        const fadeInTime = this.toSeconds(this._fadeIn);
        // record the start time
        this._startTime = time + fadeInTime;
        this._startTime = Math.max(this._startTime, this.context.currentTime);
        // schedule the envelope
        if (fadeInTime > 0) {
            this._gainNode.gain.setValueAtTime(0, time);
            if (this._curve === "linear") this._gainNode.gain.linearRampToValueAtTime(gain, time + fadeInTime);
            else this._gainNode.gain.exponentialApproachValueAtTime(gain, time, fadeInTime);
        } else this._gainNode.gain.setValueAtTime(gain, time);
        return this;
    }
    /**
     * Stop the source node at the given time.
     * @param time When to stop the source
     */ stop(time) {
        this.log("stop", time);
        this._stopGain(this.toSeconds(time));
        return this;
    }
    /**
     * Stop the source at the given time
     * @param  time When to stop the source
     */ _stopGain(time) {
        (0, _debugJs.assert)(this._startTime !== -1, "'start' must be called before 'stop'");
        // cancel the previous stop
        this.cancelStop();
        // the fadeOut time
        const fadeOutTime = this.toSeconds(this._fadeOut);
        // schedule the stop callback
        this._stopTime = this.toSeconds(time) + fadeOutTime;
        this._stopTime = Math.max(this._stopTime, this.now());
        if (fadeOutTime > 0) {
            // start the fade out curve at the given time
            if (this._curve === "linear") this._gainNode.gain.linearRampTo(0, fadeOutTime, time);
            else this._gainNode.gain.targetRampTo(0, fadeOutTime, time);
        } else {
            // stop any ongoing ramps, and set the value to 0
            this._gainNode.gain.cancelAndHoldAtTime(time);
            this._gainNode.gain.setValueAtTime(0, time);
        }
        this.context.clearTimeout(this._timeout);
        this._timeout = this.context.setTimeout(()=>{
            // allow additional time for the exponential curve to fully decay
            const additionalTail = this._curve === "exponential" ? fadeOutTime * 2 : 0;
            this._stopSource(this.now() + additionalTail);
            this._onended();
        }, this._stopTime - this.context.currentTime);
        return this;
    }
    /**
     * Invoke the onended callback
     */ _onended() {
        if (this.onended !== (0, _interfaceJs.noOp)) {
            this.onended(this);
            // overwrite onended to make sure it only is called once
            this.onended = (0, _interfaceJs.noOp);
            // dispose when it's ended to free up for garbage collection only in the online context
            if (!this.context.isOffline) {
                const disposeCallback = ()=>this.dispose();
                // @ts-ignore
                if (typeof window.requestIdleCallback !== "undefined") // @ts-ignore
                window.requestIdleCallback(disposeCallback);
                else setTimeout(disposeCallback, 1000);
            }
        }
    }
    /**
     * Get the playback state at the current time
     */ get state() {
        return this.getStateAtTime(this.now());
    }
    /**
     * Cancel a scheduled stop event
     */ cancelStop() {
        this.log("cancelStop");
        (0, _debugJs.assert)(this._startTime !== -1, "Source is not started");
        // cancel the stop envelope
        this._gainNode.gain.cancelScheduledValues(this._startTime + this.sampleTime);
        this.context.clearTimeout(this._timeout);
        this._stopTime = -1;
        return this;
    }
    dispose() {
        super.dispose();
        this._gainNode.dispose();
        this.onended = (0, _interfaceJs.noOp);
        return this;
    }
}

},{"../core/context/Gain.js":"kj68Y","../core/context/ToneAudioNode.js":"kZ3Kj","../core/util/Interface.js":"hVOjA","../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kj68Y":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A thin wrapper around the Native Web Audio GainNode.
 * The GainNode is a basic building block of the Web Audio
 * API and is useful for routing audio and adjusting gains.
 * @category Core
 * @example
 * return Tone.Offline(() => {
 * 	const gainNode = new Tone.Gain(0).toDestination();
 * 	const osc = new Tone.Oscillator(30).connect(gainNode).start();
 * 	gainNode.gain.rampTo(1, 0.1);
 * 	gainNode.gain.rampTo(0, 0.4, 0.2);
 * }, 0.7, 1);
 */ parcelHelpers.export(exports, "Gain", ()=>Gain);
var _paramJs = require("../context/Param.js");
var _defaultsJs = require("../util/Defaults.js");
var _interfaceJs = require("../util/Interface.js");
var _toneAudioNodeJs = require("./ToneAudioNode.js");
class Gain extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Gain.getDefaults(), arguments, [
            "gain",
            "units"
        ]);
        super(options);
        this.name = "Gain";
        /**
         * The wrapped GainNode.
         */ this._gainNode = this.context.createGain();
        // input = output
        this.input = this._gainNode;
        this.output = this._gainNode;
        this.gain = new (0, _paramJs.Param)({
            context: this.context,
            convert: options.convert,
            param: this._gainNode.gain,
            units: options.units,
            value: options.gain,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
        (0, _interfaceJs.readOnly)(this, "gain");
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            convert: true,
            gain: 1,
            units: "gain"
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._gainNode.disconnect();
        this.gain.dispose();
        return this;
    }
}

},{"../context/Param.js":"5PVlJ","../util/Defaults.js":"a9M5s","../util/Interface.js":"hVOjA","./ToneAudioNode.js":"kZ3Kj","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5sGSd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A Param class just for computing ticks. Similar to the {@link Param} class,
 * but offers conversion to BPM values as well as ability to compute tick
 * duration and elapsed ticks
 */ parcelHelpers.export(exports, "TickParam", ()=>TickParam);
var _paramJs = require("../context/Param.js");
var _defaultsJs = require("../util/Defaults.js");
var _timelineJs = require("../util/Timeline.js");
var _typeCheckJs = require("../util/TypeCheck.js");
class TickParam extends (0, _paramJs.Param) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(TickParam.getDefaults(), arguments, [
            "value"
        ]);
        super(options);
        this.name = "TickParam";
        /**
         * The timeline which tracks all of the automations.
         */ this._events = new (0, _timelineJs.Timeline)(Infinity);
        /**
         * The internal holder for the multiplier value
         */ this._multiplier = 1;
        // set the multiplier
        this._multiplier = options.multiplier;
        // clear the ticks from the beginning
        this._events.cancel(0);
        // set an initial event
        this._events.add({
            ticks: 0,
            time: 0,
            type: "setValueAtTime",
            value: this._fromType(options.value)
        });
        this.setValueAtTime(options.value, 0);
    }
    static getDefaults() {
        return Object.assign((0, _paramJs.Param).getDefaults(), {
            multiplier: 1,
            units: "hertz",
            value: 1
        });
    }
    setTargetAtTime(value, time, constant) {
        // approximate it with multiple linear ramps
        time = this.toSeconds(time);
        this.setRampPoint(time);
        const computedValue = this._fromType(value);
        // start from previously scheduled value
        const prevEvent = this._events.get(time);
        const segments = Math.round(Math.max(1 / constant, 1));
        for(let i = 0; i <= segments; i++){
            const segTime = constant * i + time;
            const rampVal = this._exponentialApproach(prevEvent.time, prevEvent.value, computedValue, constant, segTime);
            this.linearRampToValueAtTime(this._toType(rampVal), segTime);
        }
        return this;
    }
    setValueAtTime(value, time) {
        const computedTime = this.toSeconds(time);
        super.setValueAtTime(value, time);
        const event = this._events.get(computedTime);
        const previousEvent = this._events.previousEvent(event);
        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);
        event.ticks = Math.max(ticksUntilTime, 0);
        return this;
    }
    linearRampToValueAtTime(value, time) {
        const computedTime = this.toSeconds(time);
        super.linearRampToValueAtTime(value, time);
        const event = this._events.get(computedTime);
        const previousEvent = this._events.previousEvent(event);
        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);
        event.ticks = Math.max(ticksUntilTime, 0);
        return this;
    }
    exponentialRampToValueAtTime(value, time) {
        // aproximate it with multiple linear ramps
        time = this.toSeconds(time);
        const computedVal = this._fromType(value);
        // start from previously scheduled value
        const prevEvent = this._events.get(time);
        // approx 10 segments per second
        const segments = Math.round(Math.max((time - prevEvent.time) * 10, 1));
        const segmentDur = (time - prevEvent.time) / segments;
        for(let i = 0; i <= segments; i++){
            const segTime = segmentDur * i + prevEvent.time;
            const rampVal = this._exponentialInterpolate(prevEvent.time, prevEvent.value, time, computedVal, segTime);
            this.linearRampToValueAtTime(this._toType(rampVal), segTime);
        }
        return this;
    }
    /**
     * Returns the tick value at the time. Takes into account
     * any automation curves scheduled on the signal.
     * @param  event The time to get the tick count at
     * @return The number of ticks which have elapsed at the time given any automations.
     */ _getTicksUntilEvent(event, time) {
        if (event === null) event = {
            ticks: 0,
            time: 0,
            type: "setValueAtTime",
            value: 0
        };
        else if ((0, _typeCheckJs.isUndef)(event.ticks)) {
            const previousEvent = this._events.previousEvent(event);
            event.ticks = this._getTicksUntilEvent(previousEvent, event.time);
        }
        const val0 = this._fromType(this.getValueAtTime(event.time));
        let val1 = this._fromType(this.getValueAtTime(time));
        // if it's right on the line, take the previous value
        const onTheLineEvent = this._events.get(time);
        if (onTheLineEvent && onTheLineEvent.time === time && onTheLineEvent.type === "setValueAtTime") val1 = this._fromType(this.getValueAtTime(time - this.sampleTime));
        return 0.5 * (time - event.time) * (val0 + val1) + event.ticks;
    }
    /**
     * Returns the tick value at the time. Takes into account
     * any automation curves scheduled on the signal.
     * @param  time The time to get the tick count at
     * @return The number of ticks which have elapsed at the time given any automations.
     */ getTicksAtTime(time) {
        const computedTime = this.toSeconds(time);
        const event = this._events.get(computedTime);
        return Math.max(this._getTicksUntilEvent(event, computedTime), 0);
    }
    /**
     * Return the elapsed time of the number of ticks from the given time
     * @param ticks The number of ticks to calculate
     * @param  time The time to get the next tick from
     * @return The duration of the number of ticks from the given time in seconds
     */ getDurationOfTicks(ticks, time) {
        const computedTime = this.toSeconds(time);
        const currentTick = this.getTicksAtTime(time);
        return this.getTimeOfTick(currentTick + ticks) - computedTime;
    }
    /**
     * Given a tick, returns the time that tick occurs at.
     * @return The time that the tick occurs.
     */ getTimeOfTick(tick) {
        const before = this._events.get(tick, "ticks");
        const after = this._events.getAfter(tick, "ticks");
        if (before && before.ticks === tick) return before.time;
        else if (before && after && after.type === "linearRampToValueAtTime" && before.value !== after.value) {
            const val0 = this._fromType(this.getValueAtTime(before.time));
            const val1 = this._fromType(this.getValueAtTime(after.time));
            const delta = (val1 - val0) / (after.time - before.time);
            const k = Math.sqrt(Math.pow(val0, 2) - 2 * delta * (before.ticks - tick));
            const sol1 = (-val0 + k) / delta;
            const sol2 = (-val0 - k) / delta;
            return (sol1 > 0 ? sol1 : sol2) + before.time;
        } else if (before) {
            if (before.value === 0) return Infinity;
            else return before.time + (tick - before.ticks) / before.value;
        } else return tick / this._initialValue;
    }
    /**
     * Convert some number of ticks their the duration in seconds accounting
     * for any automation curves starting at the given time.
     * @param  ticks The number of ticks to convert to seconds.
     * @param  when  When along the automation timeline to convert the ticks.
     * @return The duration in seconds of the ticks.
     */ ticksToTime(ticks, when) {
        return this.getDurationOfTicks(ticks, when);
    }
    /**
     * The inverse of {@link ticksToTime}. Convert a duration in
     * seconds to the corresponding number of ticks accounting for any
     * automation curves starting at the given time.
     * @param  duration The time interval to convert to ticks.
     * @param  when When along the automation timeline to convert the ticks.
     * @return The duration in ticks.
     */ timeToTicks(duration, when) {
        const computedTime = this.toSeconds(when);
        const computedDuration = this.toSeconds(duration);
        const startTicks = this.getTicksAtTime(computedTime);
        const endTicks = this.getTicksAtTime(computedTime + computedDuration);
        return endTicks - startTicks;
    }
    /**
     * Convert from the type when the unit value is BPM
     */ _fromType(val) {
        if (this.units === "bpm" && this.multiplier) return 1 / (60 / val / this.multiplier);
        else return super._fromType(val);
    }
    /**
     * Special case of type conversion where the units === "bpm"
     */ _toType(val) {
        if (this.units === "bpm" && this.multiplier) return val / this.multiplier * 60;
        else return super._toType(val);
    }
    /**
     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.
     */ get multiplier() {
        return this._multiplier;
    }
    set multiplier(m) {
        // get and reset the current value with the new multiplier
        // might be necessary to clear all the previous values
        const currentVal = this.value;
        this._multiplier = m;
        this.cancelScheduledValues(0);
        this.setValueAtTime(currentVal, 0);
    }
}

},{"../context/Param.js":"5PVlJ","../util/Defaults.js":"a9M5s","../util/Timeline.js":"36KJ4","../util/TypeCheck.js":"eMH5A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1qHQA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around Web Audio's native [DelayNode](http://webaudio.github.io/web-audio-api/#the-delaynode-interface).
 * @category Core
 * @example
 * return Tone.Offline(() => {
 * 	const delay = new Tone.Delay(0.1).toDestination();
 * 	// connect the signal to both the delay and the destination
 * 	const pulse = new Tone.PulseOscillator().connect(delay).toDestination();
 * 	// start and stop the pulse
 * 	pulse.start(0).stop(0.01);
 * }, 0.5, 1);
 */ parcelHelpers.export(exports, "Delay", ()=>Delay);
var _paramJs = require("../context/Param.js");
var _defaultsJs = require("../util/Defaults.js");
var _interfaceJs = require("../util/Interface.js");
var _toneAudioNodeJs = require("./ToneAudioNode.js");
class Delay extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Delay.getDefaults(), arguments, [
            "delayTime",
            "maxDelay"
        ]);
        super(options);
        this.name = "Delay";
        const maxDelayInSeconds = this.toSeconds(options.maxDelay);
        this._maxDelay = Math.max(maxDelayInSeconds, this.toSeconds(options.delayTime));
        this._delayNode = this.input = this.output = this.context.createDelay(maxDelayInSeconds);
        this.delayTime = new (0, _paramJs.Param)({
            context: this.context,
            param: this._delayNode.delayTime,
            units: "time",
            value: options.delayTime,
            minValue: 0,
            maxValue: this.maxDelay
        });
        (0, _interfaceJs.readOnly)(this, "delayTime");
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            delayTime: 0,
            maxDelay: 1
        });
    }
    /**
     * The maximum delay time. This cannot be changed after
     * the value is passed into the constructor.
     */ get maxDelay() {
        return this._maxDelay;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._delayNode.disconnect();
        this.delayTime.dispose();
        return this;
    }
}

},{"../context/Param.js":"5PVlJ","../util/Defaults.js":"a9M5s","../util/Interface.js":"hVOjA","./ToneAudioNode.js":"kZ3Kj","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fDjd0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Generate a buffer by rendering all of the Tone.js code within the callback using the OfflineAudioContext.
 * The OfflineAudioContext is capable of rendering much faster than real time in many cases.
 * The callback function also passes in an offline instance of {@link Context} which can be used
 * to schedule events along the Transport.
 * @param  callback  All Tone.js nodes which are created and scheduled within this callback are recorded into the output Buffer.
 * @param  duration     the amount of time to record for.
 * @return  The promise which is invoked with the ToneAudioBuffer of the recorded output.
 * @example
 * // render 2 seconds of the oscillator
 * Tone.Offline(() => {
 * 	// only nodes created in this callback will be recorded
 * 	const oscillator = new Tone.Oscillator().toDestination().start(0);
 * }, 2).then((buffer) => {
 * 	// do something with the output buffer
 * 	console.log(buffer);
 * });
 * @example
 * // can also schedule events along the Transport
 * // using the passed in Offline Transport
 * Tone.Offline(({ transport }) => {
 * 	const osc = new Tone.Oscillator().toDestination();
 * 	transport.schedule(time => {
 * 		osc.start(time).stop(time + 0.1);
 * 	}, 1);
 * 	// make sure to start the transport
 * 	transport.start(0.2);
 * }, 4).then((buffer) => {
 * 	// do something with the output buffer
 * 	console.log(buffer);
 * });
 * @category Core
 */ parcelHelpers.export(exports, "Offline", ()=>Offline);
var _tslib = require("tslib");
var _globalJs = require("../Global.js");
var _offlineContextJs = require("./OfflineContext.js");
var _toneAudioBufferJs = require("./ToneAudioBuffer.js");
var _destinationJs = require("./Destination.js");
var _listenerJs = require("./Listener.js");
function Offline(callback_1, duration_1) {
    return (0, _tslib.__awaiter)(this, arguments, void 0, function*(callback, duration, channels = 2, sampleRate = (0, _globalJs.getContext)().sampleRate) {
        // set the OfflineAudioContext based on the current context
        const originalContext = (0, _globalJs.getContext)();
        const context = new (0, _offlineContextJs.OfflineContext)(channels, duration, sampleRate);
        (0, _globalJs.setContext)(context);
        // invoke the callback/scheduling
        yield callback(context);
        // then render the audio
        const bufferPromise = context.render();
        // return the original AudioContext
        (0, _globalJs.setContext)(originalContext);
        // await the rendering
        const buffer = yield bufferPromise;
        // return the audio
        return new (0, _toneAudioBufferJs.ToneAudioBuffer)(buffer);
    });
}

},{"tslib":"lRdW5","../Global.js":"79THw","./OfflineContext.js":"8VnAL","./ToneAudioBuffer.js":"8aSPC","./Destination.js":"fSNpu","./Listener.js":"beTyX","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fSNpu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A single master output which is connected to the
 * AudioDestinationNode (aka your speakers).
 * It provides useful conveniences such as the ability
 * to set the volume and mute the entire application.
 * It also gives you the ability to apply master effects to your application.
 *
 * @example
 * const oscillator = new Tone.Oscillator().start();
 * // the audio will go from the oscillator to the speakers
 * oscillator.connect(Tone.getDestination());
 * // a convenience for connecting to the master output is also provided:
 * oscillator.toDestination();
 * @category Core
 */ parcelHelpers.export(exports, "DestinationClass", ()=>DestinationClass);
var _volumeJs = require("../../component/channel/Volume.js");
var _defaultsJs = require("../util/Defaults.js");
var _contextInitializationJs = require("./ContextInitialization.js");
var _gainJs = require("./Gain.js");
var _toneAudioNodeJs = require("./ToneAudioNode.js");
class DestinationClass extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(DestinationClass.getDefaults(), arguments);
        super(options);
        this.name = "Destination";
        this.input = new (0, _volumeJs.Volume)({
            context: this.context
        });
        this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        /**
         * The volume of the master output in decibels. -Infinity is silent, and 0 is no change.
         * @example
         * const osc = new Tone.Oscillator().toDestination();
         * osc.start();
         * // ramp the volume down to silent over 10 seconds
         * Tone.getDestination().volume.rampTo(-Infinity, 10);
         */ this.volume = this.input.volume;
        (0, _toneAudioNodeJs.connectSeries)(this.input, this.output, this.context.rawContext.destination);
        this.mute = options.mute;
        this._internalChannels = [
            this.input,
            this.context.rawContext.destination,
            this.output
        ];
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            mute: false,
            volume: 0
        });
    }
    /**
     * Mute the output.
     * @example
     * const oscillator = new Tone.Oscillator().start().toDestination();
     * setTimeout(() => {
     * 	// mute the output
     * 	Tone.Destination.mute = true;
     * }, 1000);
     */ get mute() {
        return this.input.mute;
    }
    set mute(mute) {
        this.input.mute = mute;
    }
    /**
     * Add a master effects chain. NOTE: this will disconnect any nodes which were previously
     * chained in the master effects chain.
     * @param args All arguments will be connected in a row and the Master will be routed through it.
     * @example
     * // route all audio through a filter and compressor
     * const lowpass = new Tone.Filter(800, "lowpass");
     * const compressor = new Tone.Compressor(-18);
     * Tone.Destination.chain(lowpass, compressor);
     */ chain(...args) {
        this.input.disconnect();
        args.unshift(this.input);
        args.push(this.output);
        (0, _toneAudioNodeJs.connectSeries)(...args);
        return this;
    }
    /**
     * The maximum number of channels the system can output
     * @example
     * console.log(Tone.Destination.maxChannelCount);
     */ get maxChannelCount() {
        return this.context.rawContext.destination.maxChannelCount;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this.volume.dispose();
        return this;
    }
}
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
(0, _contextInitializationJs.onContextInit)((context)=>{
    context.destination = new DestinationClass({
        context
    });
});
(0, _contextInitializationJs.onContextClose)((context)=>{
    context.destination.dispose();
});

},{"../../component/channel/Volume.js":"7Ooeo","../util/Defaults.js":"a9M5s","./ContextInitialization.js":"iapnw","./Gain.js":"kj68Y","./ToneAudioNode.js":"kZ3Kj","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7Ooeo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Volume is a simple volume node, useful for creating a volume fader.
 *
 * @example
 * const vol = new Tone.Volume(-12).toDestination();
 * const osc = new Tone.Oscillator().connect(vol).start();
 * @category Component
 */ parcelHelpers.export(exports, "Volume", ()=>Volume);
var _gainJs = require("../../core/context/Gain.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
class Volume extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Volume.getDefaults(), arguments, [
            "volume"
        ]);
        super(options);
        this.name = "Volume";
        this.input = this.output = new (0, _gainJs.Gain)({
            context: this.context,
            gain: options.volume,
            units: "decibels"
        });
        this.volume = this.output.gain;
        (0, _interfaceJs.readOnly)(this, "volume");
        this._unmutedVolume = options.volume;
        // set the mute initially
        this.mute = options.mute;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            mute: false,
            volume: 0
        });
    }
    /**
     * Mute the output.
     * @example
     * const vol = new Tone.Volume(-12).toDestination();
     * const osc = new Tone.Oscillator().connect(vol).start();
     * // mute the output
     * vol.mute = true;
     */ get mute() {
        return this.volume.value === -Infinity;
    }
    set mute(mute) {
        if (!this.mute && mute) {
            this._unmutedVolume = this.volume.value;
            // maybe it should ramp here?
            this.volume.value = -Infinity;
        } else if (this.mute && !mute) this.volume.value = this._unmutedVolume;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this.input.dispose();
        this.volume.dispose();
        return this;
    }
}

},{"../../core/context/Gain.js":"kj68Y","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"beTyX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone.Listener is a thin wrapper around the AudioListener. Listener combined
 * with {@link Panner3D} makes up the Web Audio API's 3D panning system. Panner3D allows you
 * to place sounds in 3D and Listener allows you to navigate the 3D sound environment from
 * a first-person perspective. There is only one listener per audio context.
 */ parcelHelpers.export(exports, "ListenerClass", ()=>ListenerClass);
var _toneAudioNodeJs = require("./ToneAudioNode.js");
var _paramJs = require("./Param.js");
var _contextInitializationJs = require("./ContextInitialization.js");
class ListenerClass extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        super(...arguments);
        this.name = "Listener";
        this.positionX = new (0, _paramJs.Param)({
            context: this.context,
            param: this.context.rawContext.listener.positionX
        });
        this.positionY = new (0, _paramJs.Param)({
            context: this.context,
            param: this.context.rawContext.listener.positionY
        });
        this.positionZ = new (0, _paramJs.Param)({
            context: this.context,
            param: this.context.rawContext.listener.positionZ
        });
        this.forwardX = new (0, _paramJs.Param)({
            context: this.context,
            param: this.context.rawContext.listener.forwardX
        });
        this.forwardY = new (0, _paramJs.Param)({
            context: this.context,
            param: this.context.rawContext.listener.forwardY
        });
        this.forwardZ = new (0, _paramJs.Param)({
            context: this.context,
            param: this.context.rawContext.listener.forwardZ
        });
        this.upX = new (0, _paramJs.Param)({
            context: this.context,
            param: this.context.rawContext.listener.upX
        });
        this.upY = new (0, _paramJs.Param)({
            context: this.context,
            param: this.context.rawContext.listener.upY
        });
        this.upZ = new (0, _paramJs.Param)({
            context: this.context,
            param: this.context.rawContext.listener.upZ
        });
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            positionX: 0,
            positionY: 0,
            positionZ: 0,
            forwardX: 0,
            forwardY: 0,
            forwardZ: -1,
            upX: 0,
            upY: 1,
            upZ: 0
        });
    }
    dispose() {
        super.dispose();
        this.positionX.dispose();
        this.positionY.dispose();
        this.positionZ.dispose();
        this.forwardX.dispose();
        this.forwardY.dispose();
        this.forwardZ.dispose();
        this.upX.dispose();
        this.upY.dispose();
        this.upZ.dispose();
        return this;
    }
}
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
(0, _contextInitializationJs.onContextInit)((context)=>{
    context.listener = new ListenerClass({
        context
    });
});
(0, _contextInitializationJs.onContextClose)((context)=>{
    context.listener.dispose();
});

},{"./ToneAudioNode.js":"kZ3Kj","./Param.js":"5PVlJ","./ContextInitialization.js":"iapnw","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8zO1I":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A data structure for holding multiple buffers in a Map-like datastructure.
 *
 * @example
 * const pianoSamples = new Tone.ToneAudioBuffers({
 * 	A1: "https://tonejs.github.io/audio/casio/A1.mp3",
 * 	A2: "https://tonejs.github.io/audio/casio/A2.mp3",
 * }, () => {
 * 	const player = new Tone.Player().toDestination();
 * 	// play one of the samples when they all load
 * 	player.buffer = pianoSamples.get("A2");
 * 	player.start();
 * });
 * @example
 * // To pass in additional parameters in the second parameter
 * const buffers = new Tone.ToneAudioBuffers({
 * 	 urls: {
 * 		 A1: "A1.mp3",
 * 		 A2: "A2.mp3",
 * 	 },
 * 	 onload: () => console.log("loaded"),
 * 	 baseUrl: "https://tonejs.github.io/audio/casio/"
 * });
 * @category Core
 */ parcelHelpers.export(exports, "ToneAudioBuffers", ()=>ToneAudioBuffers);
var _toneJs = require("../Tone.js");
var _defaultsJs = require("../util/Defaults.js");
var _interfaceJs = require("../util/Interface.js");
var _typeCheckJs = require("../util/TypeCheck.js");
var _toneAudioBufferJs = require("./ToneAudioBuffer.js");
var _debugJs = require("../util/Debug.js");
class ToneAudioBuffers extends (0, _toneJs.Tone) {
    constructor(){
        super();
        this.name = "ToneAudioBuffers";
        /**
         * All of the buffers
         */ this._buffers = new Map();
        /**
         * Keep track of the number of loaded buffers
         */ this._loadingCount = 0;
        const options = (0, _defaultsJs.optionsFromArguments)(ToneAudioBuffers.getDefaults(), arguments, [
            "urls",
            "onload",
            "baseUrl"
        ], "urls");
        this.baseUrl = options.baseUrl;
        // add each one
        Object.keys(options.urls).forEach((name)=>{
            this._loadingCount++;
            const url = options.urls[name];
            this.add(name, url, this._bufferLoaded.bind(this, options.onload), options.onerror);
        });
    }
    static getDefaults() {
        return {
            baseUrl: "",
            onerror: (0, _interfaceJs.noOp),
            onload: (0, _interfaceJs.noOp),
            urls: {}
        };
    }
    /**
     * True if the buffers object has a buffer by that name.
     * @param  name  The key or index of the buffer.
     */ has(name) {
        return this._buffers.has(name.toString());
    }
    /**
     * Get a buffer by name. If an array was loaded,
     * then use the array index.
     * @param  name  The key or index of the buffer.
     */ get(name) {
        (0, _debugJs.assert)(this.has(name), `ToneAudioBuffers has no buffer named: ${name}`);
        return this._buffers.get(name.toString());
    }
    /**
     * A buffer was loaded. decrement the counter.
     */ _bufferLoaded(callback) {
        this._loadingCount--;
        if (this._loadingCount === 0 && callback) callback();
    }
    /**
     * If the buffers are loaded or not
     */ get loaded() {
        return Array.from(this._buffers).every(([_, buffer])=>buffer.loaded);
    }
    /**
     * Add a buffer by name and url to the Buffers
     * @param  name      A unique name to give the buffer
     * @param  url  Either the url of the bufer, or a buffer which will be added with the given name.
     * @param  callback  The callback to invoke when the url is loaded.
     * @param  onerror  Invoked if the buffer can't be loaded
     */ add(name, url, callback = (0, _interfaceJs.noOp), onerror = (0, _interfaceJs.noOp)) {
        if ((0, _typeCheckJs.isString)(url)) {
            // don't include the baseUrl if the url is a base64 encoded sound
            if (this.baseUrl && url.trim().substring(0, 11).toLowerCase() === "data:audio/") this.baseUrl = "";
            this._buffers.set(name.toString(), new (0, _toneAudioBufferJs.ToneAudioBuffer)(this.baseUrl + url, callback, onerror));
        } else this._buffers.set(name.toString(), new (0, _toneAudioBufferJs.ToneAudioBuffer)(url, callback, onerror));
        return this;
    }
    dispose() {
        super.dispose();
        this._buffers.forEach((buffer)=>buffer.dispose());
        this._buffers.clear();
        return this;
    }
}

},{"../Tone.js":"6Gzxl","../util/Defaults.js":"a9M5s","../util/Interface.js":"hVOjA","../util/TypeCheck.js":"eMH5A","./ToneAudioBuffer.js":"8aSPC","../util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kST2k":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Midi is a primitive type for encoding Time values.
 * Midi can be constructed with or without the `new` keyword. Midi can be passed
 * into the parameter of any method which takes time as an argument.
 * @category Unit
 */ parcelHelpers.export(exports, "MidiClass", ()=>MidiClass);
/**
 * Convert a value into a FrequencyClass object.
 * @category Unit
 */ parcelHelpers.export(exports, "Midi", ()=>Midi);
var _globalJs = require("../Global.js");
var _conversionsJs = require("./Conversions.js");
var _frequencyJs = require("./Frequency.js");
class MidiClass extends (0, _frequencyJs.FrequencyClass) {
    constructor(){
        super(...arguments);
        this.name = "MidiClass";
        this.defaultUnits = "midi";
    }
    /**
     * Returns the value of a frequency in the current units
     */ _frequencyToUnits(freq) {
        return (0, _conversionsJs.ftom)(super._frequencyToUnits(freq));
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return (0, _conversionsJs.ftom)(super._ticksToUnits(ticks));
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return (0, _conversionsJs.ftom)(super._beatsToUnits(beats));
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return (0, _conversionsJs.ftom)(super._secondsToUnits(seconds));
    }
    /**
     * Return the value of the frequency as a MIDI note
     * @example
     * Tone.Midi(60).toMidi(); // 60
     */ toMidi() {
        return this.valueOf();
    }
    /**
     * Return the value of the frequency as a MIDI note
     * @example
     * Tone.Midi(60).toFrequency(); // 261.6255653005986
     */ toFrequency() {
        return (0, _conversionsJs.mtof)(this.toMidi());
    }
    /**
     * Transposes the frequency by the given number of semitones.
     * @return A new transposed MidiClass
     * @example
     * Tone.Midi("A4").transpose(3); // "C5"
     */ transpose(interval) {
        return new MidiClass(this.context, this.toMidi() + interval);
    }
}
function Midi(value, units) {
    return new MidiClass((0, _globalJs.getContext)(), value, units);
}

},{"../Global.js":"79THw","./Conversions.js":"iww1u","./Frequency.js":"bObwr","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"BGGsE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Ticks is a primitive type for encoding Time values.
 * Ticks can be constructed with or without the `new` keyword. Ticks can be passed
 * into the parameter of any method which takes time as an argument.
 * @example
 * const t = Tone.Ticks("4n"); // a quarter note as ticks
 * @category Unit
 */ parcelHelpers.export(exports, "TicksClass", ()=>TicksClass);
/**
 * Convert a time representation to ticks
 * @category Unit
 */ parcelHelpers.export(exports, "Ticks", ()=>Ticks);
var _globalJs = require("../Global.js");
var _transportTimeJs = require("./TransportTime.js");
class TicksClass extends (0, _transportTimeJs.TransportTimeClass) {
    constructor(){
        super(...arguments);
        this.name = "Ticks";
        this.defaultUnits = "i";
    }
    /**
     * Get the current time in the given units
     */ _now() {
        return this.context.transport.ticks;
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return this._getPPQ() * beats;
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return Math.floor(seconds / (60 / this._getBpm()) * this._getPPQ());
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return ticks;
    }
    /**
     * Return the time in ticks
     */ toTicks() {
        return this.valueOf();
    }
    /**
     * Return the time in seconds
     */ toSeconds() {
        return this.valueOf() / this._getPPQ() * (60 / this._getBpm());
    }
}
function Ticks(value, units) {
    return new TicksClass((0, _globalJs.getContext)(), value, units);
}

},{"../Global.js":"79THw","./TransportTime.js":"a6yW0","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9CgWk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Draw is useful for synchronizing visuals and audio events.
 * Callbacks from Tone.Transport or any of the Tone.Event classes
 * always happen _before_ the scheduled time and are not synchronized
 * to the animation frame so they are not good for triggering tightly
 * synchronized visuals and sound. Draw makes it easy to schedule
 * callbacks using the AudioContext time and uses requestAnimationFrame.
 * @example
 * Tone.Transport.schedule((time) => {
 * 	// use the time argument to schedule a callback with Draw
 * 	Tone.Draw.schedule(() => {
 * 		// do drawing or DOM manipulation here
 * 		console.log(time);
 * 	}, time);
 * }, "+0.5");
 * Tone.Transport.start();
 * @category Core
 */ parcelHelpers.export(exports, "DrawClass", ()=>DrawClass);
var _toneWithContextJs = require("../context/ToneWithContext.js");
var _timelineJs = require("./Timeline.js");
var _contextInitializationJs = require("../context/ContextInitialization.js");
class DrawClass extends (0, _toneWithContextJs.ToneWithContext) {
    constructor(){
        super(...arguments);
        this.name = "Draw";
        /**
         * The duration after which events are not invoked.
         */ this.expiration = 0.25;
        /**
         * The amount of time before the scheduled time
         * that the callback can be invoked. Default is
         * half the time of an animation frame (0.008 seconds).
         */ this.anticipation = 0.008;
        /**
         * All of the events.
         */ this._events = new (0, _timelineJs.Timeline)();
        /**
         * The draw loop
         */ this._boundDrawLoop = this._drawLoop.bind(this);
        /**
         * The animation frame id
         */ this._animationFrame = -1;
    }
    /**
     * Schedule a function at the given time to be invoked
     * on the nearest animation frame.
     * @param  callback  Callback is invoked at the given time.
     * @param  time      The time relative to the AudioContext time to invoke the callback.
     * @example
     * Tone.Transport.scheduleRepeat(time => {
     * 	Tone.Draw.schedule(() => console.log(time), time);
     * }, 1);
     * Tone.Transport.start();
     */ schedule(callback, time) {
        this._events.add({
            callback,
            time: this.toSeconds(time)
        });
        // start the draw loop on the first event
        if (this._events.length === 1) this._animationFrame = requestAnimationFrame(this._boundDrawLoop);
        return this;
    }
    /**
     * Cancel events scheduled after the given time
     * @param  after  Time after which scheduled events will be removed from the scheduling timeline.
     */ cancel(after) {
        this._events.cancel(this.toSeconds(after));
        return this;
    }
    /**
     * The draw loop
     */ _drawLoop() {
        const now = this.context.currentTime;
        while(this._events.length && this._events.peek().time - this.anticipation <= now){
            const event = this._events.shift();
            if (event && now - event.time <= this.expiration) event.callback();
        }
        if (this._events.length > 0) this._animationFrame = requestAnimationFrame(this._boundDrawLoop);
    }
    dispose() {
        super.dispose();
        this._events.dispose();
        cancelAnimationFrame(this._animationFrame);
        return this;
    }
}
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
(0, _contextInitializationJs.onContextInit)((context)=>{
    context.draw = new DrawClass({
        context
    });
});
(0, _contextInitializationJs.onContextClose)((context)=>{
    context.draw.dispose();
});

},{"../context/ToneWithContext.js":"gAuzg","./Timeline.js":"36KJ4","../context/ContextInitialization.js":"iapnw","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4FYQZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Similar to Tone.Timeline, but all events represent
 * intervals with both "time" and "duration" times. The
 * events are placed in a tree structure optimized
 * for querying an intersection point with the timeline
 * events. Internally uses an [Interval Tree](https://en.wikipedia.org/wiki/Interval_tree)
 * to represent the data.
 * @internal
 */ parcelHelpers.export(exports, "IntervalTimeline", ()=>IntervalTimeline);
var _toneJs = require("../Tone.js");
var _typeCheckJs = require("./TypeCheck.js");
var _debugJs = require("./Debug.js");
class IntervalTimeline extends (0, _toneJs.Tone) {
    constructor(){
        super(...arguments);
        this.name = "IntervalTimeline";
        /**
         * The root node of the inteval tree
         */ this._root = null;
        /**
         * Keep track of the length of the timeline.
         */ this._length = 0;
    }
    /**
     * The event to add to the timeline. All events must
     * have a time and duration value
     * @param  event  The event to add to the timeline
     */ add(event) {
        (0, _debugJs.assert)((0, _typeCheckJs.isDefined)(event.time), "Events must have a time property");
        (0, _debugJs.assert)((0, _typeCheckJs.isDefined)(event.duration), "Events must have a duration parameter");
        event.time = event.time.valueOf();
        let node = new IntervalNode(event.time, event.time + event.duration, event);
        if (this._root === null) this._root = node;
        else this._root.insert(node);
        this._length++;
        // Restructure tree to be balanced
        while(node !== null){
            node.updateHeight();
            node.updateMax();
            this._rebalance(node);
            node = node.parent;
        }
        return this;
    }
    /**
     * Remove an event from the timeline.
     * @param  event  The event to remove from the timeline
     */ remove(event) {
        if (this._root !== null) {
            const results = [];
            this._root.search(event.time, results);
            for (const node of results)if (node.event === event) {
                this._removeNode(node);
                this._length--;
                break;
            }
        }
        return this;
    }
    /**
     * The number of items in the timeline.
     * @readOnly
     */ get length() {
        return this._length;
    }
    /**
     * Remove events whose time time is after the given time
     * @param  after  The time to query.
     */ cancel(after) {
        this.forEachFrom(after, (event)=>this.remove(event));
        return this;
    }
    /**
     * Set the root node as the given node
     */ _setRoot(node) {
        this._root = node;
        if (this._root !== null) this._root.parent = null;
    }
    /**
     * Replace the references to the node in the node's parent
     * with the replacement node.
     */ _replaceNodeInParent(node, replacement) {
        if (node.parent !== null) {
            if (node.isLeftChild()) node.parent.left = replacement;
            else node.parent.right = replacement;
            this._rebalance(node.parent);
        } else this._setRoot(replacement);
    }
    /**
     * Remove the node from the tree and replace it with
     * a successor which follows the schema.
     */ _removeNode(node) {
        if (node.left === null && node.right === null) this._replaceNodeInParent(node, null);
        else if (node.right === null) this._replaceNodeInParent(node, node.left);
        else if (node.left === null) this._replaceNodeInParent(node, node.right);
        else {
            const balance = node.getBalance();
            let replacement;
            let temp = null;
            if (balance > 0) {
                if (node.left.right === null) {
                    replacement = node.left;
                    replacement.right = node.right;
                    temp = replacement;
                } else {
                    replacement = node.left.right;
                    while(replacement.right !== null)replacement = replacement.right;
                    if (replacement.parent) {
                        replacement.parent.right = replacement.left;
                        temp = replacement.parent;
                        replacement.left = node.left;
                        replacement.right = node.right;
                    }
                }
            } else if (node.right.left === null) {
                replacement = node.right;
                replacement.left = node.left;
                temp = replacement;
            } else {
                replacement = node.right.left;
                while(replacement.left !== null)replacement = replacement.left;
                if (replacement.parent) {
                    replacement.parent.left = replacement.right;
                    temp = replacement.parent;
                    replacement.left = node.left;
                    replacement.right = node.right;
                }
            }
            if (node.parent !== null) {
                if (node.isLeftChild()) node.parent.left = replacement;
                else node.parent.right = replacement;
            } else this._setRoot(replacement);
            if (temp) this._rebalance(temp);
        }
        node.dispose();
    }
    /**
     * Rotate the tree to the left
     */ _rotateLeft(node) {
        const parent = node.parent;
        const isLeftChild = node.isLeftChild();
        // Make node.right the new root of this sub tree (instead of node)
        const pivotNode = node.right;
        if (pivotNode) {
            node.right = pivotNode.left;
            pivotNode.left = node;
        }
        if (parent !== null) {
            if (isLeftChild) parent.left = pivotNode;
            else parent.right = pivotNode;
        } else this._setRoot(pivotNode);
    }
    /**
     * Rotate the tree to the right
     */ _rotateRight(node) {
        const parent = node.parent;
        const isLeftChild = node.isLeftChild();
        // Make node.left the new root of this sub tree (instead of node)
        const pivotNode = node.left;
        if (pivotNode) {
            node.left = pivotNode.right;
            pivotNode.right = node;
        }
        if (parent !== null) {
            if (isLeftChild) parent.left = pivotNode;
            else parent.right = pivotNode;
        } else this._setRoot(pivotNode);
    }
    /**
     * Balance the BST
     */ _rebalance(node) {
        const balance = node.getBalance();
        if (balance > 1 && node.left) {
            if (node.left.getBalance() < 0) this._rotateLeft(node.left);
            else this._rotateRight(node);
        } else if (balance < -1 && node.right) {
            if (node.right.getBalance() > 0) this._rotateRight(node.right);
            else this._rotateLeft(node);
        }
    }
    /**
     * Get an event whose time and duration span the give time. Will
     * return the match whose "time" value is closest to the given time.
     * @return  The event which spans the desired time
     */ get(time) {
        if (this._root !== null) {
            const results = [];
            this._root.search(time, results);
            if (results.length > 0) {
                let max = results[0];
                for(let i = 1; i < results.length; i++)if (results[i].low > max.low) max = results[i];
                return max.event;
            }
        }
        return null;
    }
    /**
     * Iterate over everything in the timeline.
     * @param  callback The callback to invoke with every item
     */ forEach(callback) {
        if (this._root !== null) {
            const allNodes = [];
            this._root.traverse((node)=>allNodes.push(node));
            allNodes.forEach((node)=>{
                if (node.event) callback(node.event);
            });
        }
        return this;
    }
    /**
     * Iterate over everything in the array in which the given time
     * overlaps with the time and duration time of the event.
     * @param  time The time to check if items are overlapping
     * @param  callback The callback to invoke with every item
     */ forEachAtTime(time, callback) {
        if (this._root !== null) {
            const results = [];
            this._root.search(time, results);
            results.forEach((node)=>{
                if (node.event) callback(node.event);
            });
        }
        return this;
    }
    /**
     * Iterate over everything in the array in which the time is greater
     * than or equal to the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachFrom(time, callback) {
        if (this._root !== null) {
            const results = [];
            this._root.searchAfter(time, results);
            results.forEach((node)=>{
                if (node.event) callback(node.event);
            });
        }
        return this;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        if (this._root !== null) this._root.traverse((node)=>node.dispose());
        this._root = null;
        return this;
    }
}
//-------------------------------------
// 	INTERVAL NODE HELPER
//-------------------------------------
/**
 * Represents a node in the binary search tree, with the addition
 * of a "high" value which keeps track of the highest value of
 * its children.
 * References:
 * https://brooknovak.wordpress.com/2013/12/07/augmented-interval-tree-in-c/
 * http://www.mif.vu.lt/~valdas/ALGORITMAI/LITERATURA/Cormen/Cormen.pdf
 * @param low
 * @param high
 */ class IntervalNode {
    constructor(low, high, event){
        // the nodes to the left
        this._left = null;
        // the nodes to the right
        this._right = null;
        // the parent node
        this.parent = null;
        // the number of child nodes
        this.height = 0;
        this.event = event;
        // the low value
        this.low = low;
        // the high value
        this.high = high;
        // the high value for this and all child nodes
        this.max = this.high;
    }
    /**
     * Insert a node into the correct spot in the tree
     */ insert(node) {
        if (node.low <= this.low) {
            if (this.left === null) this.left = node;
            else this.left.insert(node);
        } else if (this.right === null) this.right = node;
        else this.right.insert(node);
    }
    /**
     * Search the tree for nodes which overlap
     * with the given point
     * @param  point  The point to query
     * @param  results  The array to put the results
     */ search(point, results) {
        // If p is to the right of the rightmost point of any interval
        // in this node and all children, there won't be any matches.
        if (point > this.max) return;
        // Search left children
        if (this.left !== null) this.left.search(point, results);
        // Check this node
        if (this.low <= point && this.high > point) results.push(this);
        // If p is to the left of the time of this interval,
        // then it can't be in any child to the right.
        if (this.low > point) return;
        // Search right children
        if (this.right !== null) this.right.search(point, results);
    }
    /**
     * Search the tree for nodes which are less
     * than the given point
     * @param  point  The point to query
     * @param  results  The array to put the results
     */ searchAfter(point, results) {
        // Check this node
        if (this.low >= point) {
            results.push(this);
            if (this.left !== null) this.left.searchAfter(point, results);
        }
        // search the right side
        if (this.right !== null) this.right.searchAfter(point, results);
    }
    /**
     * Invoke the callback on this element and both it's branches
     * @param  {Function}  callback
     */ traverse(callback) {
        callback(this);
        if (this.left !== null) this.left.traverse(callback);
        if (this.right !== null) this.right.traverse(callback);
    }
    /**
     * Update the height of the node
     */ updateHeight() {
        if (this.left !== null && this.right !== null) this.height = Math.max(this.left.height, this.right.height) + 1;
        else if (this.right !== null) this.height = this.right.height + 1;
        else if (this.left !== null) this.height = this.left.height + 1;
        else this.height = 0;
    }
    /**
     * Update the height of the node
     */ updateMax() {
        this.max = this.high;
        if (this.left !== null) this.max = Math.max(this.max, this.left.max);
        if (this.right !== null) this.max = Math.max(this.max, this.right.max);
    }
    /**
     * The balance is how the leafs are distributed on the node
     * @return  Negative numbers are balanced to the right
     */ getBalance() {
        let balance = 0;
        if (this.left !== null && this.right !== null) balance = this.left.height - this.right.height;
        else if (this.left !== null) balance = this.left.height + 1;
        else if (this.right !== null) balance = -(this.right.height + 1);
        return balance;
    }
    /**
     * @returns true if this node is the left child of its parent
     */ isLeftChild() {
        return this.parent !== null && this.parent.left === this;
    }
    /**
     * get/set the left node
     */ get left() {
        return this._left;
    }
    set left(node) {
        this._left = node;
        if (node !== null) node.parent = this;
        this.updateHeight();
        this.updateMax();
    }
    /**
     * get/set the right node
     */ get right() {
        return this._right;
    }
    set right(node) {
        this._right = node;
        if (node !== null) node.parent = this;
        this.updateHeight();
        this.updateMax();
    }
    /**
     * null out references.
     */ dispose() {
        this.parent = null;
        this._left = null;
        this._right = null;
        this.event = null;
    }
}

},{"../Tone.js":"6Gzxl","./TypeCheck.js":"eMH5A","./Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gjqPS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _noteUnitsJs = require("./NoteUnits.js");
parcelHelpers.exportAll(_noteUnitsJs, exports);

},{"./NoteUnits.js":"dBjsJ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dBjsJ":[function(require,module,exports) {
// This file contains all of the valid note names for all pitches between C-4 and C11
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"1mJV8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _noiseJs = require("./Noise.js");
parcelHelpers.exportAll(_noiseJs, exports);
var _userMediaJs = require("./UserMedia.js");
parcelHelpers.exportAll(_userMediaJs, exports);
var _oscillatorJs = require("./oscillator/Oscillator.js");
parcelHelpers.exportAll(_oscillatorJs, exports);
var _amoscillatorJs = require("./oscillator/AMOscillator.js");
parcelHelpers.exportAll(_amoscillatorJs, exports);
var _fmoscillatorJs = require("./oscillator/FMOscillator.js");
parcelHelpers.exportAll(_fmoscillatorJs, exports);
var _pulseOscillatorJs = require("./oscillator/PulseOscillator.js");
parcelHelpers.exportAll(_pulseOscillatorJs, exports);
var _fatOscillatorJs = require("./oscillator/FatOscillator.js");
parcelHelpers.exportAll(_fatOscillatorJs, exports);
var _pwmoscillatorJs = require("./oscillator/PWMOscillator.js");
parcelHelpers.exportAll(_pwmoscillatorJs, exports);
var _omniOscillatorJs = require("./oscillator/OmniOscillator.js");
parcelHelpers.exportAll(_omniOscillatorJs, exports);
var _toneOscillatorNodeJs = require("./oscillator/ToneOscillatorNode.js");
parcelHelpers.exportAll(_toneOscillatorNodeJs, exports);
var _lfoJs = require("./oscillator/LFO.js");
parcelHelpers.exportAll(_lfoJs, exports);
var _toneBufferSourceJs = require("./buffer/ToneBufferSource.js");
parcelHelpers.exportAll(_toneBufferSourceJs, exports);
var _playerJs = require("./buffer/Player.js");
parcelHelpers.exportAll(_playerJs, exports);
var _playersJs = require("./buffer/Players.js");
parcelHelpers.exportAll(_playersJs, exports);
var _grainPlayerJs = require("./buffer/GrainPlayer.js");
parcelHelpers.exportAll(_grainPlayerJs, exports);

},{"./Noise.js":"cOpzx","./UserMedia.js":"f1Txo","./oscillator/Oscillator.js":"204g3","./oscillator/AMOscillator.js":"9mU3E","./oscillator/FMOscillator.js":"3UNlG","./oscillator/PulseOscillator.js":"g3ood","./oscillator/FatOscillator.js":"2aUtm","./oscillator/PWMOscillator.js":"8eNKU","./oscillator/OmniOscillator.js":"7bzEJ","./oscillator/ToneOscillatorNode.js":"gLw4W","./oscillator/LFO.js":"jsBJT","./buffer/ToneBufferSource.js":"9FxEt","./buffer/Player.js":"4UJCG","./buffer/Players.js":"17BMn","./buffer/GrainPlayer.js":"opCGx","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cOpzx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Noise is a noise generator. It uses looped noise buffers to save on performance.
 * Noise supports the noise types: "pink", "white", and "brown". Read more about
 * colors of noise on [Wikipedia](https://en.wikipedia.org/wiki/Colors_of_noise).
 *
 * @example
 * // initialize the noise and start
 * const noise = new Tone.Noise("pink").start();
 * // make an autofilter to shape the noise
 * const autoFilter = new Tone.AutoFilter({
 * 	frequency: "8n",
 * 	baseFrequency: 200,
 * 	octaves: 8
 * }).toDestination().start();
 * // connect the noise
 * noise.connect(autoFilter);
 * // start the autofilter LFO
 * autoFilter.start();
 * @category Source
 */ parcelHelpers.export(exports, "Noise", ()=>Noise);
var _toneAudioBufferJs = require("../core/context/ToneAudioBuffer.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _debugJs = require("../core/util/Debug.js");
var _sourceJs = require("../source/Source.js");
var _toneBufferSourceJs = require("./buffer/ToneBufferSource.js");
class Noise extends (0, _sourceJs.Source) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Noise.getDefaults(), arguments, [
            "type"
        ]);
        super(options);
        this.name = "Noise";
        /**
         * Private reference to the source
         */ this._source = null;
        this._playbackRate = options.playbackRate;
        this.type = options.type;
        this._fadeIn = options.fadeIn;
        this._fadeOut = options.fadeOut;
    }
    static getDefaults() {
        return Object.assign((0, _sourceJs.Source).getDefaults(), {
            fadeIn: 0,
            fadeOut: 0,
            playbackRate: 1,
            type: "white"
        });
    }
    /**
     * The type of the noise. Can be "white", "brown", or "pink".
     * @example
     * const noise = new Tone.Noise().toDestination().start();
     * noise.type = "brown";
     */ get type() {
        return this._type;
    }
    set type(type) {
        (0, _debugJs.assert)(type in _noiseBuffers, "Noise: invalid type: " + type);
        if (this._type !== type) {
            this._type = type;
            // if it's playing, stop and restart it
            if (this.state === "started") {
                const now = this.now();
                this._stop(now);
                this._start(now);
            }
        }
    }
    /**
     * The playback rate of the noise. Affects
     * the "frequency" of the noise.
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        if (this._source) this._source.playbackRate.value = rate;
    }
    /**
     * internal start method
     */ _start(time) {
        const buffer = _noiseBuffers[this._type];
        this._source = new (0, _toneBufferSourceJs.ToneBufferSource)({
            url: buffer,
            context: this.context,
            fadeIn: this._fadeIn,
            fadeOut: this._fadeOut,
            loop: true,
            onended: ()=>this.onstop(this),
            playbackRate: this._playbackRate
        }).connect(this.output);
        this._source.start(this.toSeconds(time), Math.random() * (buffer.duration - 0.001));
    }
    /**
     * internal stop method
     */ _stop(time) {
        if (this._source) {
            this._source.stop(this.toSeconds(time));
            this._source = null;
        }
    }
    /**
     * The fadeIn time of the amplitude envelope.
     */ get fadeIn() {
        return this._fadeIn;
    }
    set fadeIn(time) {
        this._fadeIn = time;
        if (this._source) this._source.fadeIn = this._fadeIn;
    }
    /**
     * The fadeOut time of the amplitude envelope.
     */ get fadeOut() {
        return this._fadeOut;
    }
    set fadeOut(time) {
        this._fadeOut = time;
        if (this._source) this._source.fadeOut = this._fadeOut;
    }
    _restart(time) {
        // TODO could be optimized by cancelling the buffer source 'stop'
        this._stop(time);
        this._start(time);
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        if (this._source) this._source.disconnect();
        return this;
    }
}
//--------------------
// THE NOISE BUFFERS
//--------------------
// Noise buffer stats
const BUFFER_LENGTH = 220500;
const NUM_CHANNELS = 2;
/**
 * Cache the noise buffers
 */ const _noiseCache = {
    brown: null,
    pink: null,
    white: null
};
/**
 * The noise arrays. Generated on initialization.
 * borrowed heavily from https://github.com/zacharydenton/noise.js
 * (c) 2013 Zach Denton (MIT)
 */ const _noiseBuffers = {
    get brown () {
        if (!_noiseCache.brown) {
            const buffer = [];
            for(let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++){
                const channel = new Float32Array(BUFFER_LENGTH);
                buffer[channelNum] = channel;
                let lastOut = 0.0;
                for(let i = 0; i < BUFFER_LENGTH; i++){
                    const white = Math.random() * 2 - 1;
                    channel[i] = (lastOut + 0.02 * white) / 1.02;
                    lastOut = channel[i];
                    channel[i] *= 3.5; // (roughly) compensate for gain
                }
            }
            _noiseCache.brown = new (0, _toneAudioBufferJs.ToneAudioBuffer)().fromArray(buffer);
        }
        return _noiseCache.brown;
    },
    get pink () {
        if (!_noiseCache.pink) {
            const buffer = [];
            for(let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++){
                const channel = new Float32Array(BUFFER_LENGTH);
                buffer[channelNum] = channel;
                let b0, b1, b2, b3, b4, b5, b6;
                b0 = b1 = b2 = b3 = b4 = b5 = b6 = 0.0;
                for(let i = 0; i < BUFFER_LENGTH; i++){
                    const white = Math.random() * 2 - 1;
                    b0 = 0.99886 * b0 + white * 0.0555179;
                    b1 = 0.99332 * b1 + white * 0.0750759;
                    b2 = 0.969 * b2 + white * 0.153852;
                    b3 = 0.8665 * b3 + white * 0.3104856;
                    b4 = 0.55 * b4 + white * 0.5329522;
                    b5 = -0.7616 * b5 - white * 0.016898;
                    channel[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;
                    channel[i] *= 0.11; // (roughly) compensate for gain
                    b6 = white * 0.115926;
                }
            }
            _noiseCache.pink = new (0, _toneAudioBufferJs.ToneAudioBuffer)().fromArray(buffer);
        }
        return _noiseCache.pink;
    },
    get white () {
        if (!_noiseCache.white) {
            const buffer = [];
            for(let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++){
                const channel = new Float32Array(BUFFER_LENGTH);
                buffer[channelNum] = channel;
                for(let i = 0; i < BUFFER_LENGTH; i++)channel[i] = Math.random() * 2 - 1;
            }
            _noiseCache.white = new (0, _toneAudioBufferJs.ToneAudioBuffer)().fromArray(buffer);
        }
        return _noiseCache.white;
    }
};

},{"../core/context/ToneAudioBuffer.js":"8aSPC","../core/util/Defaults.js":"a9M5s","../core/util/Debug.js":"2lOIQ","../source/Source.js":"eBYFz","./buffer/ToneBufferSource.js":"9FxEt","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eBYFz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for sources.
 * start/stop of this.context.transport.
 *
 * ```
 * // Multiple state change events can be chained together,
 * // but must be set in the correct order and with ascending times
 * // OK
 * state.start().stop("+0.2");
 * // OK
 * state.start().stop("+0.2").start("+0.4").stop("+0.7")
 * // BAD
 * state.stop("+0.2").start();
 * // BAD
 * state.start("+0.3").stop("+0.2");
 * ```
 */ parcelHelpers.export(exports, "Source", ()=>Source);
var _volumeJs = require("../component/channel/Volume.js");
var _destinationJs = require("../core/context/Destination.js");
var _transportJs = require("../core/clock/Transport.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _stateTimelineJs = require("../core/util/StateTimeline.js");
var _typeCheckJs = require("../core/util/TypeCheck.js");
var _debugJs = require("../core/util/Debug.js");
var _mathJs = require("../core/util/Math.js");
class Source extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(options){
        super(options);
        /**
         * Sources have no inputs
         */ this.input = undefined;
        /**
         * Keep track of the scheduled state.
         */ this._state = new (0, _stateTimelineJs.StateTimeline)("stopped");
        /**
         * The synced `start` callback function from the transport
         */ this._synced = false;
        /**
         * Keep track of all of the scheduled event ids
         */ this._scheduled = [];
        /**
         * Placeholder functions for syncing/unsyncing to transport
         */ this._syncedStart = (0, _interfaceJs.noOp);
        this._syncedStop = (0, _interfaceJs.noOp);
        this._state.memory = 100;
        this._state.increasing = true;
        this._volume = this.output = new (0, _volumeJs.Volume)({
            context: this.context,
            mute: options.mute,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        (0, _interfaceJs.readOnly)(this, "volume");
        this.onstop = options.onstop;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            mute: false,
            onstop: (0, _interfaceJs.noOp),
            volume: 0
        });
    }
    /**
     * Returns the playback state of the source, either "started" or "stopped".
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/ahntone_c3.mp3", () => {
     * 	player.start();
     * 	console.log(player.state);
     * }).toDestination();
     */ get state() {
        if (this._synced) {
            if (this.context.transport.state === "started") return this._state.getValueAtTime(this.context.transport.seconds);
            else return "stopped";
        } else return this._state.getValueAtTime(this.now());
    }
    /**
     * Mute the output.
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * // mute the output
     * osc.mute = true;
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    /**
     * Ensure that the scheduled time is not before the current time.
     * Should only be used when scheduled unsynced.
     */ _clampToCurrentTime(time) {
        if (this._synced) return time;
        else return Math.max(time, this.context.currentTime);
    }
    /**
     * Start the source at the specified time. If no time is given,
     * start the source now.
     * @param  time When the source should be started.
     * @example
     * const source = new Tone.Oscillator().toDestination();
     * source.start("+0.5"); // starts the source 0.5 seconds from now
     */ start(time, offset, duration) {
        let computedTime = (0, _typeCheckJs.isUndef)(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);
        computedTime = this._clampToCurrentTime(computedTime);
        // if it's started, stop it and restart it
        if (!this._synced && this._state.getValueAtTime(computedTime) === "started") {
            // time should be strictly greater than the previous start time
            (0, _debugJs.assert)((0, _mathJs.GT)(computedTime, this._state.get(computedTime).time), "Start time must be strictly greater than previous start time");
            this._state.cancel(computedTime);
            this._state.setStateAtTime("started", computedTime);
            this.log("restart", computedTime);
            this.restart(computedTime, offset, duration);
        } else {
            this.log("start", computedTime);
            this._state.setStateAtTime("started", computedTime);
            if (this._synced) {
                // add the offset time to the event
                const event = this._state.get(computedTime);
                if (event) {
                    event.offset = this.toSeconds((0, _defaultsJs.defaultArg)(offset, 0));
                    event.duration = duration ? this.toSeconds(duration) : undefined;
                }
                const sched = this.context.transport.schedule((t)=>{
                    this._start(t, offset, duration);
                }, computedTime);
                this._scheduled.push(sched);
                // if the transport is already started
                // and the time is greater than where the transport is
                if (this.context.transport.state === "started" && this.context.transport.getSecondsAtTime(this.immediate()) > computedTime) this._syncedStart(this.now(), this.context.transport.seconds);
            } else {
                (0, _debugJs.assertContextRunning)(this.context);
                this._start(computedTime, offset, duration);
            }
        }
        return this;
    }
    /**
     * Stop the source at the specified time. If no time is given,
     * stop the source now.
     * @param  time When the source should be stopped.
     * @example
     * const source = new Tone.Oscillator().toDestination();
     * source.start();
     * source.stop("+0.5"); // stops the source 0.5 seconds from now
     */ stop(time) {
        let computedTime = (0, _typeCheckJs.isUndef)(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);
        computedTime = this._clampToCurrentTime(computedTime);
        if (this._state.getValueAtTime(computedTime) === "started" || (0, _typeCheckJs.isDefined)(this._state.getNextState("started", computedTime))) {
            this.log("stop", computedTime);
            if (!this._synced) this._stop(computedTime);
            else {
                const sched = this.context.transport.schedule(this._stop.bind(this), computedTime);
                this._scheduled.push(sched);
            }
            this._state.cancel(computedTime);
            this._state.setStateAtTime("stopped", computedTime);
        }
        return this;
    }
    /**
     * Restart the source.
     */ restart(time, offset, duration) {
        time = this.toSeconds(time);
        if (this._state.getValueAtTime(time) === "started") {
            this._state.cancel(time);
            this._restart(time, offset, duration);
        }
        return this;
    }
    /**
     * Sync the source to the Transport so that all subsequent
     * calls to `start` and `stop` are synced to the TransportTime
     * instead of the AudioContext time.
     *
     * @example
     * const osc = new Tone.Oscillator().toDestination();
     * // sync the source so that it plays between 0 and 0.3 on the Transport's timeline
     * osc.sync().start(0).stop(0.3);
     * // start the transport.
     * Tone.Transport.start();
     * // set it to loop once a second
     * Tone.Transport.loop = true;
     * Tone.Transport.loopEnd = 1;
     */ sync() {
        if (!this._synced) {
            this._synced = true;
            this._syncedStart = (time, offset)=>{
                if ((0, _mathJs.GT)(offset, 0)) {
                    // get the playback state at that time
                    const stateEvent = this._state.get(offset);
                    // listen for start events which may occur in the middle of the sync'ed time
                    if (stateEvent && stateEvent.state === "started" && stateEvent.time !== offset) {
                        // get the offset
                        const startOffset = offset - this.toSeconds(stateEvent.time);
                        let duration;
                        if (stateEvent.duration) duration = this.toSeconds(stateEvent.duration) - startOffset;
                        this._start(time, this.toSeconds(stateEvent.offset) + startOffset, duration);
                    }
                }
            };
            this._syncedStop = (time)=>{
                const seconds = this.context.transport.getSecondsAtTime(Math.max(time - this.sampleTime, 0));
                if (this._state.getValueAtTime(seconds) === "started") this._stop(time);
            };
            this.context.transport.on("start", this._syncedStart);
            this.context.transport.on("loopStart", this._syncedStart);
            this.context.transport.on("stop", this._syncedStop);
            this.context.transport.on("pause", this._syncedStop);
            this.context.transport.on("loopEnd", this._syncedStop);
        }
        return this;
    }
    /**
     * Unsync the source to the Transport.
     * @see {@link sync}
     */ unsync() {
        if (this._synced) {
            this.context.transport.off("stop", this._syncedStop);
            this.context.transport.off("pause", this._syncedStop);
            this.context.transport.off("loopEnd", this._syncedStop);
            this.context.transport.off("start", this._syncedStart);
            this.context.transport.off("loopStart", this._syncedStart);
        }
        this._synced = false;
        // clear all of the scheduled ids
        this._scheduled.forEach((id)=>this.context.transport.clear(id));
        this._scheduled = [];
        this._state.cancel(0);
        // stop it also
        this._stop(0);
        return this;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.onstop = (0, _interfaceJs.noOp);
        this.unsync();
        this._volume.dispose();
        this._state.dispose();
        return this;
    }
}

},{"../component/channel/Volume.js":"7Ooeo","../core/context/Destination.js":"fSNpu","../core/clock/Transport.js":"2kVaU","../core/context/ToneAudioNode.js":"kZ3Kj","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","../core/util/StateTimeline.js":"hkouL","../core/util/TypeCheck.js":"eMH5A","../core/util/Debug.js":"2lOIQ","../core/util/Math.js":"7mtt2","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2kVaU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Transport for timing musical events.
 * Supports tempo curves and time changes. Unlike browser-based timing (setInterval, requestAnimationFrame)
 * Transport timing events pass in the exact time of the scheduled event
 * in the argument of the callback function. Pass that time value to the object
 * you're scheduling. <br><br>
 * A single transport is created for you when the library is initialized.
 * <br><br>
 * The transport emits the events: "start", "stop", "pause", and "loop" which are
 * called with the time of that event as the argument.
 *
 * @example
 * const osc = new Tone.Oscillator().toDestination();
 * // repeated event every 8th note
 * Tone.getTransport().scheduleRepeat((time) => {
 * 	// use the callback time to schedule events
 * 	osc.start(time).stop(time + 0.1);
 * }, "8n");
 * // transport must be started before it starts invoking events
 * Tone.getTransport().start();
 * @category Core
 */ parcelHelpers.export(exports, "TransportClass", ()=>TransportClass);
var _timeJs = require("../../core/type/Time.js");
var _timelineValueJs = require("../../core/util/TimelineValue.js");
var _powJs = require("../../signal/Pow.js");
var _contextInitializationJs = require("../context/ContextInitialization.js");
var _gainJs = require("../context/Gain.js");
var _toneWithContextJs = require("../context/ToneWithContext.js");
var _ticksJs = require("../type/Ticks.js");
var _transportTimeJs = require("../type/TransportTime.js");
var _debugJs = require("../util/Debug.js");
var _defaultsJs = require("../util/Defaults.js");
var _emitterJs = require("../util/Emitter.js");
var _interfaceJs = require("../util/Interface.js");
var _intervalTimelineJs = require("../util/IntervalTimeline.js");
var _timelineJs = require("../util/Timeline.js");
var _typeCheckJs = require("../util/TypeCheck.js");
var _clockJs = require("./Clock.js");
var _transportEventJs = require("./TransportEvent.js");
var _transportRepeatEventJs = require("./TransportRepeatEvent.js");
class TransportClass extends (0, _toneWithContextJs.ToneWithContext) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(TransportClass.getDefaults(), arguments);
        super(options);
        this.name = "Transport";
        //-------------------------------------
        // 	LOOPING
        //-------------------------------------
        /**
         * If the transport loops or not.
         */ this._loop = new (0, _timelineValueJs.TimelineValue)(false);
        /**
         * The loop start position in ticks
         */ this._loopStart = 0;
        /**
         * The loop end position in ticks
         */ this._loopEnd = 0;
        //-------------------------------------
        // 	TIMELINE EVENTS
        //-------------------------------------
        /**
         * All the events in an object to keep track by ID
         */ this._scheduledEvents = {};
        /**
         * The scheduled events.
         */ this._timeline = new (0, _timelineJs.Timeline)();
        /**
         * Repeated events
         */ this._repeatedEvents = new (0, _intervalTimelineJs.IntervalTimeline)();
        /**
         * All of the synced Signals
         */ this._syncedSignals = [];
        /**
         * The swing amount
         */ this._swingAmount = 0;
        // CLOCK/TEMPO
        this._ppq = options.ppq;
        this._clock = new (0, _clockJs.Clock)({
            callback: this._processTick.bind(this),
            context: this.context,
            frequency: 0,
            units: "bpm"
        });
        this._bindClockEvents();
        this.bpm = this._clock.frequency;
        this._clock.frequency.multiplier = options.ppq;
        this.bpm.setValueAtTime(options.bpm, 0);
        (0, _interfaceJs.readOnly)(this, "bpm");
        this._timeSignature = options.timeSignature;
        // SWING
        this._swingTicks = options.ppq / 2; // 8n
    }
    static getDefaults() {
        return Object.assign((0, _toneWithContextJs.ToneWithContext).getDefaults(), {
            bpm: 120,
            loopEnd: "4m",
            loopStart: 0,
            ppq: 192,
            swing: 0,
            swingSubdivision: "8n",
            timeSignature: 4
        });
    }
    //-------------------------------------
    // 	TICKS
    //-------------------------------------
    /**
     * called on every tick
     * @param  tickTime clock relative tick time
     */ _processTick(tickTime, ticks) {
        // do the loop test
        if (this._loop.get(tickTime)) {
            if (ticks >= this._loopEnd) {
                this.emit("loopEnd", tickTime);
                this._clock.setTicksAtTime(this._loopStart, tickTime);
                ticks = this._loopStart;
                this.emit("loopStart", tickTime, this._clock.getSecondsAtTime(tickTime));
                this.emit("loop", tickTime);
            }
        }
        // handle swing
        if (this._swingAmount > 0 && ticks % this._ppq !== 0 && // not on a downbeat
        ticks % (this._swingTicks * 2) !== 0) {
            // add some swing
            const progress = ticks % (this._swingTicks * 2) / (this._swingTicks * 2);
            const amount = Math.sin(progress * Math.PI) * this._swingAmount;
            tickTime += new (0, _ticksJs.TicksClass)(this.context, this._swingTicks * 2 / 3).toSeconds() * amount;
        }
        // invoke the timeline events scheduled on this tick
        (0, _debugJs.enterScheduledCallback)(true);
        this._timeline.forEachAtTime(ticks, (event)=>event.invoke(tickTime));
        (0, _debugJs.enterScheduledCallback)(false);
    }
    //-------------------------------------
    // 	SCHEDULABLE EVENTS
    //-------------------------------------
    /**
     * Schedule an event along the timeline.
     * @param callback The callback to be invoked at the time.
     * @param time The time to invoke the callback at.
     * @return The id of the event which can be used for canceling the event.
     * @example
     * // schedule an event on the 16th measure
     * Tone.getTransport().schedule((time) => {
     * 	// invoked on measure 16
     * 	console.log("measure 16!");
     * }, "16:0:0");
     */ schedule(callback, time) {
        const event = new (0, _transportEventJs.TransportEvent)(this, {
            callback,
            time: new (0, _transportTimeJs.TransportTimeClass)(this.context, time).toTicks()
        });
        return this._addEvent(event, this._timeline);
    }
    /**
     * Schedule a repeated event along the timeline. The event will fire
     * at the `interval` starting at the `startTime` and for the specified
     * `duration`.
     * @param  callback   The callback to invoke.
     * @param  interval   The duration between successive callbacks. Must be a positive number.
     * @param  startTime  When along the timeline the events should start being invoked.
     * @param  duration How long the event should repeat.
     * @return  The ID of the scheduled event. Use this to cancel the event.
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * // a callback invoked every eighth note after the first measure
     * Tone.getTransport().scheduleRepeat((time) => {
     * 	osc.start(time).stop(time + 0.1);
     * }, "8n", "1m");
     */ scheduleRepeat(callback, interval, startTime, duration = Infinity) {
        const event = new (0, _transportRepeatEventJs.TransportRepeatEvent)(this, {
            callback,
            duration: new (0, _timeJs.TimeClass)(this.context, duration).toTicks(),
            interval: new (0, _timeJs.TimeClass)(this.context, interval).toTicks(),
            time: new (0, _transportTimeJs.TransportTimeClass)(this.context, startTime).toTicks()
        });
        // kick it off if the Transport is started
        // @ts-ignore
        return this._addEvent(event, this._repeatedEvents);
    }
    /**
     * Schedule an event that will be removed after it is invoked.
     * @param callback The callback to invoke once.
     * @param time The time the callback should be invoked.
     * @returns The ID of the scheduled event.
     */ scheduleOnce(callback, time) {
        const event = new (0, _transportEventJs.TransportEvent)(this, {
            callback,
            once: true,
            time: new (0, _transportTimeJs.TransportTimeClass)(this.context, time).toTicks()
        });
        return this._addEvent(event, this._timeline);
    }
    /**
     * Clear the passed in event id from the timeline
     * @param eventId The id of the event.
     */ clear(eventId) {
        if (this._scheduledEvents.hasOwnProperty(eventId)) {
            const item = this._scheduledEvents[eventId.toString()];
            item.timeline.remove(item.event);
            item.event.dispose();
            delete this._scheduledEvents[eventId.toString()];
        }
        return this;
    }
    /**
     * Add an event to the correct timeline. Keep track of the
     * timeline it was added to.
     * @returns the event id which was just added
     */ _addEvent(event, timeline) {
        this._scheduledEvents[event.id.toString()] = {
            event,
            timeline
        };
        timeline.add(event);
        return event.id;
    }
    /**
     * Remove scheduled events from the timeline after
     * the given time. Repeated events will be removed
     * if their startTime is after the given time
     * @param after Clear all events after this time.
     */ cancel(after = 0) {
        const computedAfter = this.toTicks(after);
        this._timeline.forEachFrom(computedAfter, (event)=>this.clear(event.id));
        this._repeatedEvents.forEachFrom(computedAfter, (event)=>this.clear(event.id));
        return this;
    }
    //-------------------------------------
    // 	START/STOP/PAUSE
    //-------------------------------------
    /**
     * Bind start/stop/pause events from the clock and emit them.
     */ _bindClockEvents() {
        this._clock.on("start", (time, offset)=>{
            offset = new (0, _ticksJs.TicksClass)(this.context, offset).toSeconds();
            this.emit("start", time, offset);
        });
        this._clock.on("stop", (time)=>{
            this.emit("stop", time);
        });
        this._clock.on("pause", (time)=>{
            this.emit("pause", time);
        });
    }
    /**
     * Returns the playback state of the source, either "started", "stopped", or "paused"
     */ get state() {
        return this._clock.getStateAtTime(this.now());
    }
    /**
     * Start the transport and all sources synced to the transport.
     * @param  time The time when the transport should start.
     * @param  offset The timeline offset to start the transport.
     * @example
     * // start the transport in one second starting at beginning of the 5th measure.
     * Tone.getTransport().start("+1", "4:0:0");
     */ start(time, offset) {
        // start the context
        this.context.resume();
        let offsetTicks;
        if ((0, _typeCheckJs.isDefined)(offset)) offsetTicks = this.toTicks(offset);
        // start the clock
        this._clock.start(time, offsetTicks);
        return this;
    }
    /**
     * Stop the transport and all sources synced to the transport.
     * @param time The time when the transport should stop.
     * @example
     * Tone.getTransport().stop();
     */ stop(time) {
        this._clock.stop(time);
        return this;
    }
    /**
     * Pause the transport and all sources synced to the transport.
     */ pause(time) {
        this._clock.pause(time);
        return this;
    }
    /**
     * Toggle the current state of the transport. If it is
     * started, it will stop it, otherwise it will start the Transport.
     * @param  time The time of the event
     */ toggle(time) {
        time = this.toSeconds(time);
        if (this._clock.getStateAtTime(time) !== "started") this.start(time);
        else this.stop(time);
        return this;
    }
    //-------------------------------------
    // 	SETTERS/GETTERS
    //-------------------------------------
    /**
     * The time signature as just the numerator over 4.
     * For example 4/4 would be just 4 and 6/8 would be 3.
     * @example
     * // common time
     * Tone.getTransport().timeSignature = 4;
     * // 7/8
     * Tone.getTransport().timeSignature = [7, 8];
     * // this will be reduced to a single number
     * Tone.getTransport().timeSignature; // returns 3.5
     */ get timeSignature() {
        return this._timeSignature;
    }
    set timeSignature(timeSig) {
        if ((0, _typeCheckJs.isArray)(timeSig)) timeSig = timeSig[0] / timeSig[1] * 4;
        this._timeSignature = timeSig;
    }
    /**
     * When the Transport.loop = true, this is the starting position of the loop.
     */ get loopStart() {
        return new (0, _timeJs.TimeClass)(this.context, this._loopStart, "i").toSeconds();
    }
    set loopStart(startPosition) {
        this._loopStart = this.toTicks(startPosition);
    }
    /**
     * When the Transport.loop = true, this is the ending position of the loop.
     */ get loopEnd() {
        return new (0, _timeJs.TimeClass)(this.context, this._loopEnd, "i").toSeconds();
    }
    set loopEnd(endPosition) {
        this._loopEnd = this.toTicks(endPosition);
    }
    /**
     * If the transport loops or not.
     */ get loop() {
        return this._loop.get(this.now());
    }
    set loop(loop) {
        this._loop.set(loop, this.now());
    }
    /**
     * Set the loop start and stop at the same time.
     * @example
     * // loop over the first measure
     * Tone.getTransport().setLoopPoints(0, "1m");
     * Tone.getTransport().loop = true;
     */ setLoopPoints(startPosition, endPosition) {
        this.loopStart = startPosition;
        this.loopEnd = endPosition;
        return this;
    }
    /**
     * The swing value. Between 0-1 where 1 equal to the note + half the subdivision.
     */ get swing() {
        return this._swingAmount;
    }
    set swing(amount) {
        // scale the values to a normal range
        this._swingAmount = amount;
    }
    /**
     * Set the subdivision which the swing will be applied to.
     * The default value is an 8th note. Value must be less
     * than a quarter note.
     */ get swingSubdivision() {
        return new (0, _ticksJs.TicksClass)(this.context, this._swingTicks).toNotation();
    }
    set swingSubdivision(subdivision) {
        this._swingTicks = this.toTicks(subdivision);
    }
    /**
     * The Transport's position in Bars:Beats:Sixteenths.
     * Setting the value will jump to that position right away.
     */ get position() {
        const now = this.now();
        const ticks = this._clock.getTicksAtTime(now);
        return new (0, _ticksJs.TicksClass)(this.context, ticks).toBarsBeatsSixteenths();
    }
    set position(progress) {
        const ticks = this.toTicks(progress);
        this.ticks = ticks;
    }
    /**
     * The Transport's position in seconds.
     * Setting the value will jump to that position right away.
     */ get seconds() {
        return this._clock.seconds;
    }
    set seconds(s) {
        const now = this.now();
        const ticks = this._clock.frequency.timeToTicks(s, now);
        this.ticks = ticks;
    }
    /**
     * The Transport's loop position as a normalized value. Always
     * returns 0 if the Transport.loop = false.
     */ get progress() {
        if (this.loop) {
            const now = this.now();
            const ticks = this._clock.getTicksAtTime(now);
            return (ticks - this._loopStart) / (this._loopEnd - this._loopStart);
        } else return 0;
    }
    /**
     * The Transport's current tick position.
     */ get ticks() {
        return this._clock.ticks;
    }
    set ticks(t) {
        if (this._clock.ticks !== t) {
            const now = this.now();
            // stop everything synced to the transport
            if (this.state === "started") {
                const ticks = this._clock.getTicksAtTime(now);
                // schedule to start on the next tick, #573
                const remainingTick = this._clock.frequency.getDurationOfTicks(Math.ceil(ticks) - ticks, now);
                const time = now + remainingTick;
                this.emit("stop", time);
                this._clock.setTicksAtTime(t, time);
                // restart it with the new time
                this.emit("start", time, this._clock.getSecondsAtTime(time));
            } else {
                this.emit("ticks", now);
                this._clock.setTicksAtTime(t, now);
            }
        }
    }
    /**
     * Get the clock's ticks at the given time.
     * @param  time  When to get the tick value
     * @return The tick value at the given time.
     */ getTicksAtTime(time) {
        return this._clock.getTicksAtTime(time);
    }
    /**
     * Return the elapsed seconds at the given time.
     * @param  time  When to get the elapsed seconds
     * @return  The number of elapsed seconds
     */ getSecondsAtTime(time) {
        return this._clock.getSecondsAtTime(time);
    }
    /**
     * Pulses Per Quarter note. This is the smallest resolution
     * the Transport timing supports. This should be set once
     * on initialization and not set again. Changing this value
     * after other objects have been created can cause problems.
     */ get PPQ() {
        return this._clock.frequency.multiplier;
    }
    set PPQ(ppq) {
        this._clock.frequency.multiplier = ppq;
    }
    //-------------------------------------
    // 	SYNCING
    //-------------------------------------
    /**
     * Returns the time aligned to the next subdivision
     * of the Transport. If the Transport is not started,
     * it will return 0.
     * Note: this will not work precisely during tempo ramps.
     * @param  subdivision  The subdivision to quantize to
     * @return  The context time of the next subdivision.
     * @example
     * // the transport must be started, otherwise returns 0
     * Tone.getTransport().start();
     * Tone.getTransport().nextSubdivision("4n");
     */ nextSubdivision(subdivision) {
        subdivision = this.toTicks(subdivision);
        if (this.state !== "started") // if the transport's not started, return 0
        return 0;
        else {
            const now = this.now();
            // the remainder of the current ticks and the subdivision
            const transportPos = this.getTicksAtTime(now);
            const remainingTicks = subdivision - transportPos % subdivision;
            return this._clock.nextTickTime(remainingTicks, now);
        }
    }
    /**
     * Attaches the signal to the tempo control signal so that
     * any changes in the tempo will change the signal in the same
     * ratio.
     *
     * @param signal
     * @param ratio Optionally pass in the ratio between the two signals.
     * 			Otherwise it will be computed based on their current values.
     */ syncSignal(signal, ratio) {
        const now = this.now();
        let source = this.bpm;
        let sourceValue = 1 / (60 / source.getValueAtTime(now) / this.PPQ);
        let nodes = [];
        // If the signal is in the time domain, sync it to the reciprocal of
        // the tempo instead of the tempo.
        if (signal.units === "time") {
            // The input to Pow should be in the range [1 / 4096, 1], where
            // where 4096 is half of the buffer size of Pow's waveshaper.
            // Pick a scaling factor based on the initial tempo that ensures
            // that the initial input is in this range, while leaving room for
            // tempo changes.
            const scaleFactor = 1 / 64 / sourceValue;
            const scaleBefore = new (0, _gainJs.Gain)(scaleFactor);
            const reciprocal = new (0, _powJs.Pow)(-1);
            const scaleAfter = new (0, _gainJs.Gain)(scaleFactor);
            // @ts-ignore
            source.chain(scaleBefore, reciprocal, scaleAfter);
            source = scaleAfter;
            sourceValue = 1 / sourceValue;
            nodes = [
                scaleBefore,
                reciprocal,
                scaleAfter
            ];
        }
        if (!ratio) {
            // get the sync ratio
            if (signal.getValueAtTime(now) !== 0) ratio = signal.getValueAtTime(now) / sourceValue;
            else ratio = 0;
        }
        const ratioSignal = new (0, _gainJs.Gain)(ratio);
        // @ts-ignore
        source.connect(ratioSignal);
        // @ts-ignore
        ratioSignal.connect(signal._param);
        nodes.push(ratioSignal);
        this._syncedSignals.push({
            initial: signal.value,
            nodes: nodes,
            signal
        });
        signal.value = 0;
        return this;
    }
    /**
     * Unsyncs a previously synced signal from the transport's control.
     * @see {@link syncSignal}.
     */ unsyncSignal(signal) {
        for(let i = this._syncedSignals.length - 1; i >= 0; i--){
            const syncedSignal = this._syncedSignals[i];
            if (syncedSignal.signal === signal) {
                syncedSignal.nodes.forEach((node)=>node.dispose());
                syncedSignal.signal.value = syncedSignal.initial;
                this._syncedSignals.splice(i, 1);
            }
        }
        return this;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._clock.dispose();
        (0, _interfaceJs.writable)(this, "bpm");
        this._timeline.dispose();
        this._repeatedEvents.dispose();
        return this;
    }
}
(0, _emitterJs.Emitter).mixin(TransportClass);
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
(0, _contextInitializationJs.onContextInit)((context)=>{
    context.transport = new TransportClass({
        context
    });
});
(0, _contextInitializationJs.onContextClose)((context)=>{
    context.transport.dispose();
});

},{"../../core/type/Time.js":"9A3Zu","../../core/util/TimelineValue.js":"2Tqlj","../../signal/Pow.js":"9vO86","../context/ContextInitialization.js":"iapnw","../context/Gain.js":"kj68Y","../context/ToneWithContext.js":"gAuzg","../type/Ticks.js":"BGGsE","../type/TransportTime.js":"a6yW0","../util/Debug.js":"2lOIQ","../util/Defaults.js":"a9M5s","../util/Emitter.js":"4ROyf","../util/Interface.js":"hVOjA","../util/IntervalTimeline.js":"4FYQZ","../util/Timeline.js":"36KJ4","../util/TypeCheck.js":"eMH5A","./Clock.js":"52dVv","./TransportEvent.js":"coPXu","./TransportRepeatEvent.js":"7DSUo","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2Tqlj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Represents a single value which is gettable and settable in a timed way
 */ parcelHelpers.export(exports, "TimelineValue", ()=>TimelineValue);
var _timelineJs = require("./Timeline.js");
var _toneJs = require("../Tone.js");
class TimelineValue extends (0, _toneJs.Tone) {
    /**
     * @param initialValue The value to return if there is no scheduled values
     */ constructor(initialValue){
        super();
        this.name = "TimelineValue";
        /**
         * The timeline which stores the values
         */ this._timeline = new (0, _timelineJs.Timeline)({
            memory: 10
        });
        this._initialValue = initialValue;
    }
    /**
     * Set the value at the given time
     */ set(value, time) {
        this._timeline.add({
            value,
            time
        });
        return this;
    }
    /**
     * Get the value at the given time
     */ get(time) {
        const event = this._timeline.get(time);
        if (event) return event.value;
        else return this._initialValue;
    }
}

},{"./Timeline.js":"36KJ4","../Tone.js":"6Gzxl","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9vO86":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Pow applies an exponent to the incoming signal. The incoming signal must be AudioRange [-1, 1]
 *
 * @example
 * const pow = new Tone.Pow(2);
 * const sig = new Tone.Signal(0.5).connect(pow);
 * // output of pow is 0.25.
 * @category Signal
 */ parcelHelpers.export(exports, "Pow", ()=>Pow);
var _waveShaperJs = require("./WaveShaper.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _signalOperatorJs = require("./SignalOperator.js");
class Pow extends (0, _signalOperatorJs.SignalOperator) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Pow.getDefaults(), arguments, [
            "value"
        ]);
        super(options);
        this.name = "Pow";
        this._exponentScaler = this.input = this.output = new (0, _waveShaperJs.WaveShaper)({
            context: this.context,
            mapping: this._expFunc(options.value),
            length: 8192
        });
        this._exponent = options.value;
    }
    static getDefaults() {
        return Object.assign((0, _signalOperatorJs.SignalOperator).getDefaults(), {
            value: 1
        });
    }
    /**
     * the function which maps the waveshaper
     * @param exponent exponent value
     */ _expFunc(exponent) {
        return (val)=>{
            return Math.pow(Math.abs(val), exponent);
        };
    }
    /**
     * The value of the exponent.
     */ get value() {
        return this._exponent;
    }
    set value(exponent) {
        this._exponent = exponent;
        this._exponentScaler.setMap(this._expFunc(this._exponent));
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._exponentScaler.dispose();
        return this;
    }
}

},{"./WaveShaper.js":"k4nzV","../core/util/Defaults.js":"a9M5s","./SignalOperator.js":"4XSes","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k4nzV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wraps the native Web Audio API
 * [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).
 *
 * @example
 * const osc = new Tone.Oscillator().toDestination().start();
 * // multiply the output of the signal by 2 using the waveshaper's function
 * const timesTwo = new Tone.WaveShaper((val) => val * 2, 2048).connect(osc.frequency);
 * const signal = new Tone.Signal(440).connect(timesTwo);
 * @category Signal
 */ parcelHelpers.export(exports, "WaveShaper", ()=>WaveShaper);
var _defaultsJs = require("../core/util/Defaults.js");
var _typeCheckJs = require("../core/util/TypeCheck.js");
var _debugJs = require("../core/util/Debug.js");
var _signalJs = require("./Signal.js");
var _signalOperatorJs = require("./SignalOperator.js");
class WaveShaper extends (0, _signalOperatorJs.SignalOperator) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(WaveShaper.getDefaults(), arguments, [
            "mapping",
            "length"
        ]);
        super(options);
        this.name = "WaveShaper";
        /**
         * the waveshaper node
         */ this._shaper = this.context.createWaveShaper();
        /**
         * The input to the waveshaper node.
         */ this.input = this._shaper;
        /**
         * The output from the waveshaper node
         */ this.output = this._shaper;
        if ((0, _typeCheckJs.isArray)(options.mapping) || options.mapping instanceof Float32Array) this.curve = Float32Array.from(options.mapping);
        else if ((0, _typeCheckJs.isFunction)(options.mapping)) this.setMap(options.mapping, options.length);
    }
    static getDefaults() {
        return Object.assign((0, _signalJs.Signal).getDefaults(), {
            length: 1024
        });
    }
    /**
     * Uses a mapping function to set the value of the curve.
     * @param mapping The function used to define the values.
     *                The mapping function take two arguments:
     *                the first is the value at the current position
     *                which goes from -1 to 1 over the number of elements
     *                in the curve array. The second argument is the array position.
     * @example
     * const shaper = new Tone.WaveShaper();
     * // map the input signal from [-1, 1] to [0, 10]
     * shaper.setMap((val, index) => (val + 1) * 5);
     */ setMap(mapping, length = 1024) {
        const array = new Float32Array(length);
        for(let i = 0, len = length; i < len; i++){
            const normalized = i / (len - 1) * 2 - 1;
            array[i] = mapping(normalized, i);
        }
        this.curve = array;
        return this;
    }
    /**
     * The array to set as the waveshaper curve. For linear curves
     * array length does not make much difference, but for complex curves
     * longer arrays will provide smoother interpolation.
     */ get curve() {
        return this._shaper.curve;
    }
    set curve(mapping) {
        this._shaper.curve = mapping;
    }
    /**
     * Specifies what type of oversampling (if any) should be used when
     * applying the shaping curve. Can either be "none", "2x" or "4x".
     */ get oversample() {
        return this._shaper.oversample;
    }
    set oversample(oversampling) {
        const isOverSampleType = [
            "none",
            "2x",
            "4x"
        ].some((str)=>str.includes(oversampling));
        (0, _debugJs.assert)(isOverSampleType, "oversampling must be either 'none', '2x', or '4x'");
        this._shaper.oversample = oversampling;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._shaper.disconnect();
        return this;
    }
}

},{"../core/util/Defaults.js":"a9M5s","../core/util/TypeCheck.js":"eMH5A","../core/util/Debug.js":"2lOIQ","./Signal.js":"980ri","./SignalOperator.js":"4XSes","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4XSes":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A signal operator has an input and output and modifies the signal.
 */ parcelHelpers.export(exports, "SignalOperator", ()=>SignalOperator);
var _defaultsJs = require("../core/util/Defaults.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _signalJs = require("./Signal.js");
class SignalOperator extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(SignalOperator.getDefaults(), arguments, [
            "context"
        ]));
    }
    connect(destination, outputNum = 0, inputNum = 0) {
        (0, _signalJs.connectSignal)(this, destination, outputNum, inputNum);
        return this;
    }
}

},{"../core/util/Defaults.js":"a9M5s","../core/context/ToneAudioNode.js":"kZ3Kj","./Signal.js":"980ri","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"coPXu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TransportEvent is an internal class used by {@link TransportClass}
 * to schedule events. Do no invoke this class directly, it is
 * handled from within Tone.Transport.
 */ parcelHelpers.export(exports, "TransportEvent", ()=>TransportEvent);
var _interfaceJs = require("../util/Interface.js");
class TransportEvent {
    /**
     * @param transport The transport object which the event belongs to
     */ constructor(transport, opts){
        /**
         * The unique id of the event
         */ this.id = TransportEvent._eventId++;
        /**
         * The remaining value between the passed in time, and Math.floor(time).
         * This value is later added back when scheduling to get sub-tick precision.
         */ this._remainderTime = 0;
        const options = Object.assign(TransportEvent.getDefaults(), opts);
        this.transport = transport;
        this.callback = options.callback;
        this._once = options.once;
        this.time = Math.floor(options.time);
        this._remainderTime = options.time - this.time;
    }
    static getDefaults() {
        return {
            callback: (0, _interfaceJs.noOp),
            once: false,
            time: 0
        };
    }
    /**
     * Get the time and remainder time.
     */ get floatTime() {
        return this.time + this._remainderTime;
    }
    /**
     * Invoke the event callback.
     * @param  time  The AudioContext time in seconds of the event
     */ invoke(time) {
        if (this.callback) {
            const tickDuration = this.transport.bpm.getDurationOfTicks(1, time);
            this.callback(time + this._remainderTime * tickDuration);
            if (this._once) this.transport.clear(this.id);
        }
    }
    /**
     * Clean up
     */ dispose() {
        this.callback = undefined;
        return this;
    }
}
/**
 * Current ID counter
 */ TransportEvent._eventId = 0;

},{"../util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7DSUo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TransportRepeatEvent is an internal class used by Tone.Transport
 * to schedule repeat events. This class should not be instantiated directly.
 */ parcelHelpers.export(exports, "TransportRepeatEvent", ()=>TransportRepeatEvent);
var _ticksJs = require("../type/Ticks.js");
var _transportEventJs = require("./TransportEvent.js");
var _mathJs = require("../util/Math.js");
class TransportRepeatEvent extends (0, _transportEventJs.TransportEvent) {
    /**
     * @param transport The transport object which the event belongs to
     */ constructor(transport, opts){
        super(transport, opts);
        /**
         * The ID of the current timeline event
         */ this._currentId = -1;
        /**
         * The ID of the next timeline event
         */ this._nextId = -1;
        /**
         * The time of the next event
         */ this._nextTick = this.time;
        /**
         * a reference to the bound start method
         */ this._boundRestart = this._restart.bind(this);
        const options = Object.assign(TransportRepeatEvent.getDefaults(), opts);
        this.duration = options.duration;
        this._interval = options.interval;
        this._nextTick = options.time;
        this.transport.on("start", this._boundRestart);
        this.transport.on("loopStart", this._boundRestart);
        this.transport.on("ticks", this._boundRestart);
        this.context = this.transport.context;
        this._restart();
    }
    static getDefaults() {
        return Object.assign({}, (0, _transportEventJs.TransportEvent).getDefaults(), {
            duration: Infinity,
            interval: 1,
            once: false
        });
    }
    /**
     * Invoke the callback. Returns the tick time which
     * the next event should be scheduled at.
     * @param  time  The AudioContext time in seconds of the event
     */ invoke(time) {
        // create more events if necessary
        this._createEvents(time);
        // call the super class
        super.invoke(time);
    }
    /**
     * Create an event on the transport on the nextTick
     */ _createEvent() {
        if ((0, _mathJs.LT)(this._nextTick, this.floatTime + this.duration)) return this.transport.scheduleOnce(this.invoke.bind(this), new (0, _ticksJs.TicksClass)(this.context, this._nextTick).toSeconds());
        return -1;
    }
    /**
     * Push more events onto the timeline to keep up with the position of the timeline
     */ _createEvents(time) {
        // schedule the next event
        // const ticks = this.transport.getTicksAtTime(time);
        // if the next tick is within the bounds set by "duration"
        if ((0, _mathJs.LT)(this._nextTick + this._interval, this.floatTime + this.duration)) {
            this._nextTick += this._interval;
            this._currentId = this._nextId;
            this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new (0, _ticksJs.TicksClass)(this.context, this._nextTick).toSeconds());
        }
    }
    /**
     * Re-compute the events when the transport time has changed from a start/ticks/loopStart event
     */ _restart(time) {
        this.transport.clear(this._currentId);
        this.transport.clear(this._nextId);
        // start at the first event
        this._nextTick = this.floatTime;
        const ticks = this.transport.getTicksAtTime(time);
        if ((0, _mathJs.GT)(ticks, this.time)) // the event is not being scheduled from the beginning and should be offset
        this._nextTick = this.floatTime + Math.ceil((ticks - this.floatTime) / this._interval) * this._interval;
        this._currentId = this._createEvent();
        this._nextTick += this._interval;
        this._nextId = this._createEvent();
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this.transport.clear(this._currentId);
        this.transport.clear(this._nextId);
        this.transport.off("start", this._boundRestart);
        this.transport.off("loopStart", this._boundRestart);
        this.transport.off("ticks", this._boundRestart);
        return this;
    }
}

},{"../type/Ticks.js":"BGGsE","./TransportEvent.js":"coPXu","../util/Math.js":"7mtt2","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9FxEt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the native BufferSourceNode.
 * @category Source
 */ parcelHelpers.export(exports, "ToneBufferSource", ()=>ToneBufferSource);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _paramJs = require("../../core/context/Param.js");
var _toneAudioBufferJs = require("../../core/context/ToneAudioBuffer.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _typeCheckJs = require("../../core/util/TypeCheck.js");
var _debugJs = require("../../core/util/Debug.js");
var _oneShotSourceJs = require("../OneShotSource.js");
var _mathJs = require("../../core/util/Math.js");
class ToneBufferSource extends (0, _oneShotSourceJs.OneShotSource) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(ToneBufferSource.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        super(options);
        this.name = "ToneBufferSource";
        /**
         * The oscillator
         */ this._source = this.context.createBufferSource();
        this._internalChannels = [
            this._source
        ];
        /**
         * indicators if the source has started/stopped
         */ this._sourceStarted = false;
        this._sourceStopped = false;
        (0, _toneAudioNodeJs.connect)(this._source, this._gainNode);
        this._source.onended = ()=>this._stopSource();
        /**
         * The playbackRate of the buffer
         */ this.playbackRate = new (0, _paramJs.Param)({
            context: this.context,
            param: this._source.playbackRate,
            units: "positive",
            value: options.playbackRate
        });
        // set some values initially
        this.loop = options.loop;
        this.loopStart = options.loopStart;
        this.loopEnd = options.loopEnd;
        this._buffer = new (0, _toneAudioBufferJs.ToneAudioBuffer)(options.url, options.onload, options.onerror);
        this._internalChannels.push(this._source);
    }
    static getDefaults() {
        return Object.assign((0, _oneShotSourceJs.OneShotSource).getDefaults(), {
            url: new (0, _toneAudioBufferJs.ToneAudioBuffer)(),
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            onload: (0, _interfaceJs.noOp),
            onerror: (0, _interfaceJs.noOp),
            playbackRate: 1
        });
    }
    /**
     * The fadeIn time of the amplitude envelope.
     */ get fadeIn() {
        return this._fadeIn;
    }
    set fadeIn(t) {
        this._fadeIn = t;
    }
    /**
     * The fadeOut time of the amplitude envelope.
     */ get fadeOut() {
        return this._fadeOut;
    }
    set fadeOut(t) {
        this._fadeOut = t;
    }
    /**
     * The curve applied to the fades, either "linear" or "exponential"
     */ get curve() {
        return this._curve;
    }
    set curve(t) {
        this._curve = t;
    }
    /**
     * Start the buffer
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)
     * @param  gain  The gain to play the buffer back at.
     */ start(time, offset, duration, gain = 1) {
        (0, _debugJs.assert)(this.buffer.loaded, "buffer is either not set or not loaded");
        const computedTime = this.toSeconds(time);
        // apply the gain envelope
        this._startGain(computedTime, gain);
        // if it's a loop the default offset is the loopstart point
        if (this.loop) offset = (0, _defaultsJs.defaultArg)(offset, this.loopStart);
        else // otherwise the default offset is 0
        offset = (0, _defaultsJs.defaultArg)(offset, 0);
        // make sure the offset is not less than 0
        let computedOffset = Math.max(this.toSeconds(offset), 0);
        // start the buffer source
        if (this.loop) {
            // modify the offset if it's greater than the loop time
            const loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;
            const loopStart = this.toSeconds(this.loopStart);
            const loopDuration = loopEnd - loopStart;
            // move the offset back
            if ((0, _mathJs.GTE)(computedOffset, loopEnd)) computedOffset = (computedOffset - loopStart) % loopDuration + loopStart;
            // when the offset is very close to the duration, set it to 0
            if ((0, _mathJs.EQ)(computedOffset, this.buffer.duration)) computedOffset = 0;
        }
        // this.buffer.loaded would have return false if the AudioBuffer was undefined
        this._source.buffer = this.buffer.get();
        this._source.loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;
        if ((0, _mathJs.LT)(computedOffset, this.buffer.duration)) {
            this._sourceStarted = true;
            this._source.start(computedTime, computedOffset);
        }
        // if a duration is given, schedule a stop
        if ((0, _typeCheckJs.isDefined)(duration)) {
            let computedDur = this.toSeconds(duration);
            // make sure it's never negative
            computedDur = Math.max(computedDur, 0);
            this.stop(computedTime + computedDur);
        }
        return this;
    }
    _stopSource(time) {
        if (!this._sourceStopped && this._sourceStarted) {
            this._sourceStopped = true;
            this._source.stop(this.toSeconds(time));
            this._onended();
        }
    }
    /**
     * If loop is true, the loop will start at this position.
     */ get loopStart() {
        return this._source.loopStart;
    }
    set loopStart(loopStart) {
        this._source.loopStart = this.toSeconds(loopStart);
    }
    /**
     * If loop is true, the loop will end at this position.
     */ get loopEnd() {
        return this._source.loopEnd;
    }
    set loopEnd(loopEnd) {
        this._source.loopEnd = this.toSeconds(loopEnd);
    }
    /**
     * The audio buffer belonging to the player.
     */ get buffer() {
        return this._buffer;
    }
    set buffer(buffer) {
        this._buffer.set(buffer);
    }
    /**
     * If the buffer should loop once it's over.
     */ get loop() {
        return this._source.loop;
    }
    set loop(loop) {
        this._source.loop = loop;
        if (this._sourceStarted) this.cancelStop();
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._source.onended = null;
        this._source.disconnect();
        this._buffer.dispose();
        this.playbackRate.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/context/Param.js":"5PVlJ","../../core/context/ToneAudioBuffer.js":"8aSPC","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../core/util/TypeCheck.js":"eMH5A","../../core/util/Debug.js":"2lOIQ","../OneShotSource.js":"iVQxd","../../core/util/Math.js":"7mtt2","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"f1Txo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * UserMedia uses MediaDevices.getUserMedia to open up and external microphone or audio input.
 * Check [MediaDevices API Support](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)
 * to see which browsers are supported. Access to an external input
 * is limited to secure (HTTPS) connections.
 * @example
 * const meter = new Tone.Meter();
 * const mic = new Tone.UserMedia().connect(meter);
 * mic.open().then(() => {
 * 	// promise resolves when input is available
 * 	console.log("mic open");
 * 	// print the incoming mic levels in decibels
 * 	setInterval(() => console.log(meter.getValue()), 100);
 * }).catch(e => {
 * 	// promise is rejected when the user doesn't have or allow mic access
 * 	console.log("mic not open");
 * });
 * @category Source
 */ parcelHelpers.export(exports, "UserMedia", ()=>UserMedia);
var _tslib = require("tslib");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _volumeJs = require("../component/channel/Volume.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _debugJs = require("../core/util/Debug.js");
var _interfaceJs = require("../core/util/Interface.js");
var _typeCheckJs = require("../core/util/TypeCheck.js");
class UserMedia extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(UserMedia.getDefaults(), arguments, [
            "volume"
        ]);
        super(options);
        this.name = "UserMedia";
        this._volume = this.output = new (0, _volumeJs.Volume)({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        (0, _interfaceJs.readOnly)(this, "volume");
        this.mute = options.mute;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            mute: false,
            volume: 0
        });
    }
    /**
     * Open the media stream. If a string is passed in, it is assumed
     * to be the label or id of the stream, if a number is passed in,
     * it is the input number of the stream.
     * @param  labelOrId The label or id of the audio input media device.
     *                   With no argument, the default stream is opened.
     * @return The promise is resolved when the stream is open.
     */ open(labelOrId) {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            (0, _debugJs.assert)(UserMedia.supported, "UserMedia is not supported");
            // close the previous stream
            if (this.state === "started") this.close();
            const devices = yield UserMedia.enumerateDevices();
            if ((0, _typeCheckJs.isNumber)(labelOrId)) this._device = devices[labelOrId];
            else {
                this._device = devices.find((device)=>{
                    return device.label === labelOrId || device.deviceId === labelOrId;
                });
                // didn't find a matching device
                if (!this._device && devices.length > 0) this._device = devices[0];
                (0, _debugJs.assert)((0, _typeCheckJs.isDefined)(this._device), `No matching device ${labelOrId}`);
            }
            // do getUserMedia
            const constraints = {
                audio: {
                    echoCancellation: false,
                    sampleRate: this.context.sampleRate,
                    noiseSuppression: false,
                    mozNoiseSuppression: false
                }
            };
            if (this._device) // @ts-ignore
            constraints.audio.deviceId = this._device.deviceId;
            const stream = yield navigator.mediaDevices.getUserMedia(constraints);
            // start a new source only if the previous one is closed
            if (!this._stream) {
                this._stream = stream;
                // Wrap a MediaStreamSourceNode around the live input stream.
                const mediaStreamNode = this.context.createMediaStreamSource(stream);
                // Connect the MediaStreamSourceNode to a gate gain node
                (0, _toneAudioNodeJs.connect)(mediaStreamNode, this.output);
                this._mediaStream = mediaStreamNode;
            }
            return this;
        });
    }
    /**
     * Close the media stream
     */ close() {
        if (this._stream && this._mediaStream) {
            this._stream.getAudioTracks().forEach((track)=>{
                track.stop();
            });
            this._stream = undefined;
            // remove the old media stream
            this._mediaStream.disconnect();
            this._mediaStream = undefined;
        }
        this._device = undefined;
        return this;
    }
    /**
     * Returns a promise which resolves with the list of audio input devices available.
     * @return The promise that is resolved with the devices
     * @example
     * Tone.UserMedia.enumerateDevices().then((devices) => {
     * 	// print the device labels
     * 	console.log(devices.map(device => device.label));
     * });
     */ static enumerateDevices() {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            const allDevices = yield navigator.mediaDevices.enumerateDevices();
            return allDevices.filter((device)=>{
                return device.kind === "audioinput";
            });
        });
    }
    /**
     * Returns the playback state of the source, "started" when the microphone is open
     * and "stopped" when the mic is closed.
     */ get state() {
        return this._stream && this._stream.active ? "started" : "stopped";
    }
    /**
     * Returns an identifier for the represented device that is
     * persisted across sessions. It is un-guessable by other applications and
     * unique to the origin of the calling application. It is reset when the
     * user clears cookies (for Private Browsing, a different identifier is
     * used that is not persisted across sessions). Returns undefined when the
     * device is not open.
     */ get deviceId() {
        if (this._device) return this._device.deviceId;
        else return undefined;
    }
    /**
     * Returns a group identifier. Two devices have the
     * same group identifier if they belong to the same physical device.
     * Returns null  when the device is not open.
     */ get groupId() {
        if (this._device) return this._device.groupId;
        else return undefined;
    }
    /**
     * Returns a label describing this device (for example "Built-in Microphone").
     * Returns undefined when the device is not open or label is not available
     * because of permissions.
     */ get label() {
        if (this._device) return this._device.label;
        else return undefined;
    }
    /**
     * Mute the output.
     * @example
     * const mic = new Tone.UserMedia();
     * mic.open().then(() => {
     * 	// promise resolves when input is available
     * });
     * // mute the output
     * mic.mute = true;
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    dispose() {
        super.dispose();
        this.close();
        this._volume.dispose();
        this.volume.dispose();
        return this;
    }
    /**
     * If getUserMedia is supported by the browser.
     */ static get supported() {
        return (0, _typeCheckJs.isDefined)(navigator.mediaDevices) && (0, _typeCheckJs.isDefined)(navigator.mediaDevices.getUserMedia);
    }
}

},{"tslib":"lRdW5","../core/context/ToneAudioNode.js":"kZ3Kj","../component/channel/Volume.js":"7Ooeo","../core/util/Defaults.js":"a9M5s","../core/util/Debug.js":"2lOIQ","../core/util/Interface.js":"hVOjA","../core/util/TypeCheck.js":"eMH5A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"204g3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Oscillator supports a number of features including
 * phase rotation, multiple oscillator types (see Oscillator.type),
 * and Transport syncing (see Oscillator.syncFrequency).
 *
 * @example
 * // make and start a 440hz sine tone
 * const osc = new Tone.Oscillator(440, "sine").toDestination().start();
 * @category Source
 */ parcelHelpers.export(exports, "Oscillator", ()=>Oscillator);
var _tslib = require("tslib");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _typeCheckJs = require("../../core/util/TypeCheck.js");
var _signalJs = require("../../signal/Signal.js");
var _sourceJs = require("../Source.js");
var _oscillatorInterfaceJs = require("./OscillatorInterface.js");
var _toneOscillatorNodeJs = require("./ToneOscillatorNode.js");
var _debugJs = require("../../core/util/Debug.js");
var _mathJs = require("../../core/util/Math.js");
class Oscillator extends (0, _sourceJs.Source) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Oscillator.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        super(options);
        this.name = "Oscillator";
        /**
         * the main oscillator
         */ this._oscillator = null;
        this.frequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        (0, _interfaceJs.readOnly)(this, "frequency");
        this.detune = new (0, _signalJs.Signal)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        (0, _interfaceJs.readOnly)(this, "detune");
        this._partials = options.partials;
        this._partialCount = options.partialCount;
        this._type = options.type;
        if (options.partialCount && options.type !== "custom") this._type = this.baseType + options.partialCount.toString();
        this.phase = options.phase;
    }
    static getDefaults() {
        return Object.assign((0, _sourceJs.Source).getDefaults(), {
            detune: 0,
            frequency: 440,
            partialCount: 0,
            partials: [],
            phase: 0,
            type: "sine"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        const computedTime = this.toSeconds(time);
        // new oscillator with previous values
        const oscillator = new (0, _toneOscillatorNodeJs.ToneOscillatorNode)({
            context: this.context,
            onended: ()=>this.onstop(this)
        });
        this._oscillator = oscillator;
        if (this._wave) this._oscillator.setPeriodicWave(this._wave);
        else this._oscillator.type = this._type;
        // connect the control signal to the oscillator frequency & detune
        this._oscillator.connect(this.output);
        this.frequency.connect(this._oscillator.frequency);
        this.detune.connect(this._oscillator.detune);
        // start the oscillator
        this._oscillator.start(computedTime);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        const computedTime = this.toSeconds(time);
        if (this._oscillator) this._oscillator.stop(computedTime);
    }
    /**
     * Restart the oscillator. Does not stop the oscillator, but instead
     * just cancels any scheduled 'stop' from being invoked.
     */ _restart(time) {
        const computedTime = this.toSeconds(time);
        this.log("restart", computedTime);
        if (this._oscillator) this._oscillator.cancelStop();
        this._state.cancel(computedTime);
        return this;
    }
    /**
     * Sync the signal to the Transport's bpm. Any changes to the transports bpm,
     * will also affect the oscillators frequency.
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * osc.frequency.value = 440;
     * // the ratio between the bpm and the frequency will be maintained
     * osc.syncFrequency();
     * // double the tempo
     * Tone.Transport.bpm.value *= 2;
     * // the frequency of the oscillator is doubled to 880
     */ syncFrequency() {
        this.context.transport.syncSignal(this.frequency);
        return this;
    }
    /**
     * Unsync the oscillator's frequency from the Transport.
     * @see {@link syncFrequency}
     */ unsyncFrequency() {
        this.context.transport.unsyncSignal(this.frequency);
        return this;
    }
    /**
     * Get a cached periodic wave. Avoids having to recompute
     * the oscillator values when they have already been computed
     * with the same values.
     */ _getCachedPeriodicWave() {
        if (this._type === "custom") {
            const oscProps = Oscillator._periodicWaveCache.find((description)=>{
                return description.phase === this._phase && (0, _defaultsJs.deepEquals)(description.partials, this._partials);
            });
            return oscProps;
        } else {
            const oscProps = Oscillator._periodicWaveCache.find((description)=>{
                return description.type === this._type && description.phase === this._phase;
            });
            this._partialCount = oscProps ? oscProps.partialCount : this._partialCount;
            return oscProps;
        }
    }
    get type() {
        return this._type;
    }
    set type(type) {
        this._type = type;
        const isBasicType = [
            "sine",
            "square",
            "sawtooth",
            "triangle"
        ].indexOf(type) !== -1;
        if (this._phase === 0 && isBasicType) {
            this._wave = undefined;
            this._partialCount = 0;
            // just go with the basic approach
            if (this._oscillator !== null) // already tested that it's a basic type
            this._oscillator.type = type;
        } else {
            // first check if the value is cached
            const cache = this._getCachedPeriodicWave();
            if ((0, _typeCheckJs.isDefined)(cache)) {
                const { partials, wave } = cache;
                this._wave = wave;
                this._partials = partials;
                if (this._oscillator !== null) this._oscillator.setPeriodicWave(this._wave);
            } else {
                const [real, imag] = this._getRealImaginary(type, this._phase);
                const periodicWave = this.context.createPeriodicWave(real, imag);
                this._wave = periodicWave;
                if (this._oscillator !== null) this._oscillator.setPeriodicWave(this._wave);
                // set the cache
                Oscillator._periodicWaveCache.push({
                    imag,
                    partialCount: this._partialCount,
                    partials: this._partials,
                    phase: this._phase,
                    real,
                    type: this._type,
                    wave: this._wave
                });
                if (Oscillator._periodicWaveCache.length > 100) Oscillator._periodicWaveCache.shift();
            }
        }
    }
    get baseType() {
        return this._type.replace(this.partialCount.toString(), "");
    }
    set baseType(baseType) {
        if (this.partialCount && this._type !== "custom" && baseType !== "custom") this.type = baseType + this.partialCount;
        else this.type = baseType;
    }
    get partialCount() {
        return this._partialCount;
    }
    set partialCount(p) {
        (0, _debugJs.assertRange)(p, 0);
        let type = this._type;
        const partial = /^(sine|triangle|square|sawtooth)(\d+)$/.exec(this._type);
        if (partial) type = partial[1];
        if (this._type !== "custom") {
            if (p === 0) this.type = type;
            else this.type = type + p.toString();
        } else {
            // extend or shorten the partials array
            const fullPartials = new Float32Array(p);
            // copy over the partials array
            this._partials.forEach((v, i)=>fullPartials[i] = v);
            this._partials = Array.from(fullPartials);
            this.type = this._type;
        }
    }
    /**
     * Returns the real and imaginary components based
     * on the oscillator type.
     * @returns [real: Float32Array, imaginary: Float32Array]
     */ _getRealImaginary(type, phase) {
        const fftSize = 4096;
        let periodicWaveSize = fftSize / 2;
        const real = new Float32Array(periodicWaveSize);
        const imag = new Float32Array(periodicWaveSize);
        let partialCount = 1;
        if (type === "custom") {
            partialCount = this._partials.length + 1;
            this._partialCount = this._partials.length;
            periodicWaveSize = partialCount;
            // if the partial count is 0, don't bother doing any computation
            if (this._partials.length === 0) return [
                real,
                imag
            ];
        } else {
            const partial = /^(sine|triangle|square|sawtooth)(\d+)$/.exec(type);
            if (partial) {
                partialCount = parseInt(partial[2], 10) + 1;
                this._partialCount = parseInt(partial[2], 10);
                type = partial[1];
                partialCount = Math.max(partialCount, 2);
                periodicWaveSize = partialCount;
            } else this._partialCount = 0;
            this._partials = [];
        }
        for(let n = 1; n < periodicWaveSize; ++n){
            const piFactor = 2 / (n * Math.PI);
            let b;
            switch(type){
                case "sine":
                    b = n <= partialCount ? 1 : 0;
                    this._partials[n - 1] = b;
                    break;
                case "square":
                    b = n & 1 ? 2 * piFactor : 0;
                    this._partials[n - 1] = b;
                    break;
                case "sawtooth":
                    b = piFactor * (n & 1 ? 1 : -1);
                    this._partials[n - 1] = b;
                    break;
                case "triangle":
                    if (n & 1) b = 2 * (piFactor * piFactor) * (n - 1 >> 1 & 1 ? -1 : 1);
                    else b = 0;
                    this._partials[n - 1] = b;
                    break;
                case "custom":
                    b = this._partials[n - 1];
                    break;
                default:
                    throw new TypeError("Oscillator: invalid type: " + type);
            }
            if (b !== 0) {
                real[n] = -b * Math.sin(phase * n);
                imag[n] = b * Math.cos(phase * n);
            } else {
                real[n] = 0;
                imag[n] = 0;
            }
        }
        return [
            real,
            imag
        ];
    }
    /**
     * Compute the inverse FFT for a given phase.
     */ _inverseFFT(real, imag, phase) {
        let sum = 0;
        const len = real.length;
        for(let i = 0; i < len; i++)sum += real[i] * Math.cos(i * phase) + imag[i] * Math.sin(i * phase);
        return sum;
    }
    /**
     * Returns the initial value of the oscillator when stopped.
     * E.g. a "sine" oscillator with phase = 90 would return an initial value of -1.
     */ getInitialValue() {
        const [real, imag] = this._getRealImaginary(this._type, 0);
        let maxValue = 0;
        const twoPi = Math.PI * 2;
        const testPositions = 32;
        // check for peaks in 16 places
        for(let i = 0; i < testPositions; i++)maxValue = Math.max(this._inverseFFT(real, imag, i / testPositions * twoPi), maxValue);
        return (0, _mathJs.clamp)(-this._inverseFFT(real, imag, this._phase) / maxValue, -1, 1);
    }
    get partials() {
        return this._partials.slice(0, this.partialCount);
    }
    set partials(partials) {
        this._partials = partials;
        this._partialCount = this._partials.length;
        if (partials.length) this.type = "custom";
    }
    get phase() {
        return this._phase * (180 / Math.PI);
    }
    set phase(phase) {
        this._phase = phase * Math.PI / 180;
        // reset the type
        this.type = this._type;
    }
    asArray() {
        return (0, _tslib.__awaiter)(this, arguments, void 0, function*(length = 1024) {
            return (0, _oscillatorInterfaceJs.generateWaveform)(this, length);
        });
    }
    dispose() {
        super.dispose();
        if (this._oscillator !== null) this._oscillator.dispose();
        this._wave = undefined;
        this.frequency.dispose();
        this.detune.dispose();
        return this;
    }
}
/**
 * Cache the periodic waves to avoid having to redo computations
 */ Oscillator._periodicWaveCache = [];

},{"tslib":"lRdW5","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../core/util/TypeCheck.js":"eMH5A","../../signal/Signal.js":"980ri","../Source.js":"eBYFz","./OscillatorInterface.js":"wCQWx","./ToneOscillatorNode.js":"gLw4W","../../core/util/Debug.js":"2lOIQ","../../core/util/Math.js":"7mtt2","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"wCQWx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Render a segment of the oscillator to an offline context and return the results as an array
 */ parcelHelpers.export(exports, "generateWaveform", ()=>generateWaveform);
var _tslib = require("tslib");
var _offlineContextJs = require("../../core/context/OfflineContext.js");
function generateWaveform(instance, length) {
    return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
        const duration = length / instance.context.sampleRate;
        const context = new (0, _offlineContextJs.OfflineContext)(1, duration, instance.context.sampleRate);
        const clone = new instance.constructor(Object.assign(instance.get(), {
            // should do 2 iterations
            frequency: 2 / duration,
            // zero out the detune
            detune: 0,
            context
        })).toDestination();
        clone.start(0);
        const buffer = yield context.render();
        return buffer.getChannelData(0);
    });
}

},{"tslib":"lRdW5","../../core/context/OfflineContext.js":"8VnAL","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gLw4W":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the native fire-and-forget OscillatorNode.
 * Adds the ability to reschedule the stop method.
 * ***{@link Oscillator} is better for most use-cases***
 * @category Source
 */ parcelHelpers.export(exports, "ToneOscillatorNode", ()=>ToneOscillatorNode);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _paramJs = require("../../core/context/Param.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _oneShotSourceJs = require("../OneShotSource.js");
var _interfaceJs = require("../../core/util/Interface.js");
class ToneOscillatorNode extends (0, _oneShotSourceJs.OneShotSource) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(ToneOscillatorNode.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        super(options);
        this.name = "ToneOscillatorNode";
        /**
         * The oscillator
         */ this._oscillator = this.context.createOscillator();
        this._internalChannels = [
            this._oscillator
        ];
        (0, _toneAudioNodeJs.connect)(this._oscillator, this._gainNode);
        this.type = options.type;
        this.frequency = new (0, _paramJs.Param)({
            context: this.context,
            param: this._oscillator.frequency,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new (0, _paramJs.Param)({
            context: this.context,
            param: this._oscillator.detune,
            units: "cents",
            value: options.detune
        });
        (0, _interfaceJs.readOnly)(this, [
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _oneShotSourceJs.OneShotSource).getDefaults(), {
            detune: 0,
            frequency: 440,
            type: "sine"
        });
    }
    /**
     * Start the oscillator node at the given time
     * @param  time When to start the oscillator
     */ start(time) {
        const computedTime = this.toSeconds(time);
        this.log("start", computedTime);
        this._startGain(computedTime);
        this._oscillator.start(computedTime);
        return this;
    }
    _stopSource(time) {
        this._oscillator.stop(time);
    }
    /**
     * Sets an arbitrary custom periodic waveform given a PeriodicWave.
     * @param  periodicWave PeriodicWave should be created with context.createPeriodicWave
     */ setPeriodicWave(periodicWave) {
        this._oscillator.setPeriodicWave(periodicWave);
        return this;
    }
    /**
     * The oscillator type. Either 'sine', 'sawtooth', 'square', or 'triangle'
     */ get type() {
        return this._oscillator.type;
    }
    set type(type) {
        this._oscillator.type = type;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        if (this.state === "started") this.stop();
        this._oscillator.disconnect();
        this.frequency.dispose();
        this.detune.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/context/Param.js":"5PVlJ","../../core/util/Defaults.js":"a9M5s","../OneShotSource.js":"iVQxd","../../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9mU3E":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * An amplitude modulated oscillator node. It is implemented with
 * two oscillators, one which modulators the other's amplitude
 * through a gain node.
 * ```
 *    +-------------+       +----------+
 *    | Carrier Osc +>------> GainNode |
 *    +-------------+       |          +--->Output
 *                      +---> gain     |
 * +---------------+    |   +----------+
 * | Modulator Osc +>---+
 * +---------------+
 * ```
 * @example
 * return Tone.Offline(() => {
 * 	const amOsc = new Tone.AMOscillator(30, "sine", "square").toDestination().start();
 * }, 0.2, 1);
 * @category Source
 */ parcelHelpers.export(exports, "AMOscillator", ()=>AMOscillator);
var _tslib = require("tslib");
var _gainJs = require("../../core/context/Gain.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _audioToGainJs = require("../../signal/AudioToGain.js");
var _multiplyJs = require("../../signal/Multiply.js");
var _sourceJs = require("../Source.js");
var _oscillatorJs = require("./Oscillator.js");
var _oscillatorInterfaceJs = require("./OscillatorInterface.js");
class AMOscillator extends (0, _sourceJs.Source) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(AMOscillator.getDefaults(), arguments, [
            "frequency",
            "type",
            "modulationType"
        ]);
        super(options);
        this.name = "AMOscillator";
        /**
         * convert the -1,1 output to 0,1
         */ this._modulationScale = new (0, _audioToGainJs.AudioToGain)({
            context: this.context
        });
        /**
         * the node where the modulation happens
         */ this._modulationNode = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._carrier = new (0, _oscillatorJs.Oscillator)({
            context: this.context,
            detune: options.detune,
            frequency: options.frequency,
            onstop: ()=>this.onstop(this),
            phase: options.phase,
            type: options.type
        });
        this.frequency = this._carrier.frequency, this.detune = this._carrier.detune;
        this._modulator = new (0, _oscillatorJs.Oscillator)({
            context: this.context,
            phase: options.phase,
            type: options.modulationType
        });
        this.harmonicity = new (0, _multiplyJs.Multiply)({
            context: this.context,
            units: "positive",
            value: options.harmonicity
        });
        // connections
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this._modulator.chain(this._modulationScale, this._modulationNode.gain);
        this._carrier.chain(this._modulationNode, this.output);
        (0, _interfaceJs.readOnly)(this, [
            "frequency",
            "detune",
            "harmonicity"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _oscillatorJs.Oscillator).getDefaults(), {
            harmonicity: 1,
            modulationType: "square"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        this._modulator.start(time);
        this._carrier.start(time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        this._modulator.stop(time);
        this._carrier.stop(time);
    }
    _restart(time) {
        this._modulator.restart(time);
        this._carrier.restart(time);
    }
    /**
     * The type of the carrier oscillator
     */ get type() {
        return this._carrier.type;
    }
    set type(type) {
        this._carrier.type = type;
    }
    get baseType() {
        return this._carrier.baseType;
    }
    set baseType(baseType) {
        this._carrier.baseType = baseType;
    }
    get partialCount() {
        return this._carrier.partialCount;
    }
    set partialCount(partialCount) {
        this._carrier.partialCount = partialCount;
    }
    /**
     * The type of the modulator oscillator
     */ get modulationType() {
        return this._modulator.type;
    }
    set modulationType(type) {
        this._modulator.type = type;
    }
    get phase() {
        return this._carrier.phase;
    }
    set phase(phase) {
        this._carrier.phase = phase;
        this._modulator.phase = phase;
    }
    get partials() {
        return this._carrier.partials;
    }
    set partials(partials) {
        this._carrier.partials = partials;
    }
    asArray() {
        return (0, _tslib.__awaiter)(this, arguments, void 0, function*(length = 1024) {
            return (0, _oscillatorInterfaceJs.generateWaveform)(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this.harmonicity.dispose();
        this._carrier.dispose();
        this._modulator.dispose();
        this._modulationNode.dispose();
        this._modulationScale.dispose();
        return this;
    }
}

},{"tslib":"lRdW5","../../core/context/Gain.js":"kj68Y","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../signal/AudioToGain.js":"kLli1","../../signal/Multiply.js":"4C0VG","../Source.js":"eBYFz","./Oscillator.js":"204g3","./OscillatorInterface.js":"wCQWx","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kLli1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1].
 * @see {@link GainToAudio}.
 * @category Signal
 */ parcelHelpers.export(exports, "AudioToGain", ()=>AudioToGain);
var _signalOperatorJs = require("./SignalOperator.js");
var _waveShaperJs = require("./WaveShaper.js");
class AudioToGain extends (0, _signalOperatorJs.SignalOperator) {
    constructor(){
        super(...arguments);
        this.name = "AudioToGain";
        /**
         * The node which converts the audio ranges
         */ this._norm = new (0, _waveShaperJs.WaveShaper)({
            context: this.context,
            mapping: (x)=>(x + 1) / 2
        });
        /**
         * The AudioRange input [-1, 1]
         */ this.input = this._norm;
        /**
         * The GainRange output [0, 1]
         */ this.output = this._norm;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._norm.dispose();
        return this;
    }
}

},{"./SignalOperator.js":"4XSes","./WaveShaper.js":"k4nzV","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4C0VG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Multiply two incoming signals. Or, if a number is given in the constructor,
 * multiplies the incoming signal by that value.
 *
 * @example
 * // multiply two signals
 * const mult = new Tone.Multiply();
 * const sigA = new Tone.Signal(3);
 * const sigB = new Tone.Signal(4);
 * sigA.connect(mult);
 * sigB.connect(mult.factor);
 * // output of mult is 12.
 * @example
 * // multiply a signal and a number
 * const mult = new Tone.Multiply(10);
 * const sig = new Tone.Signal(2).connect(mult);
 * // the output of mult is 20.
 * @category Signal
 */ parcelHelpers.export(exports, "Multiply", ()=>Multiply);
var _gainJs = require("../core/context/Gain.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _signalJs = require("./Signal.js");
class Multiply extends (0, _signalJs.Signal) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Multiply.getDefaults(), arguments, [
            "value"
        ]);
        super(options);
        this.name = "Multiply";
        /**
         * Indicates if the value should be overridden on connection
         */ this.override = false;
        this._mult = this.input = this.output = new (0, _gainJs.Gain)({
            context: this.context,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
        this.factor = this._param = this._mult.gain;
        this.factor.setValueAtTime(options.value, 0);
    }
    static getDefaults() {
        return Object.assign((0, _signalJs.Signal).getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._mult.dispose();
        return this;
    }
}

},{"../core/context/Gain.js":"kj68Y","../core/util/Defaults.js":"a9M5s","./Signal.js":"980ri","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3UNlG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FMOscillator implements a frequency modulation synthesis
 * ```
 *                                              +-------------+
 * +---------------+        +-------------+     | Carrier Osc |
 * | Modulator Osc +>-------> GainNode    |     |             +--->Output
 * +---------------+        |             +>----> frequency   |
 *                       +--> gain        |     +-------------+
 *                       |  +-------------+
 * +-----------------+   |
 * | modulationIndex +>--+
 * +-----------------+
 * ```
 *
 * @example
 * return Tone.Offline(() => {
 * 	const fmOsc = new Tone.FMOscillator({
 * 		frequency: 200,
 * 		type: "square",
 * 		modulationType: "triangle",
 * 		harmonicity: 0.2,
 * 		modulationIndex: 3
 * 	}).toDestination().start();
 * }, 0.1, 1);
 * @category Source
 */ parcelHelpers.export(exports, "FMOscillator", ()=>FMOscillator);
var _tslib = require("tslib");
var _gainJs = require("../../core/context/Gain.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _multiplyJs = require("../../signal/Multiply.js");
var _signalJs = require("../../signal/Signal.js");
var _sourceJs = require("../Source.js");
var _oscillatorJs = require("./Oscillator.js");
var _oscillatorInterfaceJs = require("./OscillatorInterface.js");
class FMOscillator extends (0, _sourceJs.Source) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(FMOscillator.getDefaults(), arguments, [
            "frequency",
            "type",
            "modulationType"
        ]);
        super(options);
        this.name = "FMOscillator";
        /**
         * the node where the modulation happens
         */ this._modulationNode = new (0, _gainJs.Gain)({
            context: this.context,
            gain: 0
        });
        this._carrier = new (0, _oscillatorJs.Oscillator)({
            context: this.context,
            detune: options.detune,
            frequency: 0,
            onstop: ()=>this.onstop(this),
            phase: options.phase,
            type: options.type
        });
        this.detune = this._carrier.detune;
        this.frequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this._modulator = new (0, _oscillatorJs.Oscillator)({
            context: this.context,
            phase: options.phase,
            type: options.modulationType
        });
        this.harmonicity = new (0, _multiplyJs.Multiply)({
            context: this.context,
            units: "positive",
            value: options.harmonicity
        });
        this.modulationIndex = new (0, _multiplyJs.Multiply)({
            context: this.context,
            units: "positive",
            value: options.modulationIndex
        });
        // connections
        this.frequency.connect(this._carrier.frequency);
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this.frequency.chain(this.modulationIndex, this._modulationNode);
        this._modulator.connect(this._modulationNode.gain);
        this._modulationNode.connect(this._carrier.frequency);
        this._carrier.connect(this.output);
        this.detune.connect(this._modulator.detune);
        (0, _interfaceJs.readOnly)(this, [
            "modulationIndex",
            "frequency",
            "detune",
            "harmonicity"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _oscillatorJs.Oscillator).getDefaults(), {
            harmonicity: 1,
            modulationIndex: 2,
            modulationType: "square"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        this._modulator.start(time);
        this._carrier.start(time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        this._modulator.stop(time);
        this._carrier.stop(time);
    }
    _restart(time) {
        this._modulator.restart(time);
        this._carrier.restart(time);
        return this;
    }
    get type() {
        return this._carrier.type;
    }
    set type(type) {
        this._carrier.type = type;
    }
    get baseType() {
        return this._carrier.baseType;
    }
    set baseType(baseType) {
        this._carrier.baseType = baseType;
    }
    get partialCount() {
        return this._carrier.partialCount;
    }
    set partialCount(partialCount) {
        this._carrier.partialCount = partialCount;
    }
    /**
     * The type of the modulator oscillator
     */ get modulationType() {
        return this._modulator.type;
    }
    set modulationType(type) {
        this._modulator.type = type;
    }
    get phase() {
        return this._carrier.phase;
    }
    set phase(phase) {
        this._carrier.phase = phase;
        this._modulator.phase = phase;
    }
    get partials() {
        return this._carrier.partials;
    }
    set partials(partials) {
        this._carrier.partials = partials;
    }
    asArray() {
        return (0, _tslib.__awaiter)(this, arguments, void 0, function*(length = 1024) {
            return (0, _oscillatorInterfaceJs.generateWaveform)(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.frequency.dispose();
        this.harmonicity.dispose();
        this._carrier.dispose();
        this._modulator.dispose();
        this._modulationNode.dispose();
        this.modulationIndex.dispose();
        return this;
    }
}

},{"tslib":"lRdW5","../../core/context/Gain.js":"kj68Y","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../signal/Multiply.js":"4C0VG","../../signal/Signal.js":"980ri","../Source.js":"eBYFz","./Oscillator.js":"204g3","./OscillatorInterface.js":"wCQWx","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g3ood":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PulseOscillator is an oscillator with control over pulse width,
 * also known as the duty cycle. At 50% duty cycle (width = 0) the wave is
 * a square wave.
 * [Read more](https://wigglewave.wordpress.com/2014/08/16/pulse-waveforms-and-harmonics/).
 * ```
 *    width = -0.25        width = 0.0          width = 0.25
 *
 *   +-----+            +-------+       +    +-------+     +-+
 *   |     |            |       |       |            |     |
 *   |     |            |       |       |            |     |
 * +-+     +-------+    +       +-------+            +-----+
 *
 *
 *    width = -0.5                              width = 0.5
 *
 *     +---+                                 +-------+   +---+
 *     |   |                                         |   |
 *     |   |                                         |   |
 * +---+   +-------+                                 +---+
 *
 *
 *    width = -0.75                             width = 0.75
 *
 *       +-+                                 +-------+ +-----+
 *       | |                                         | |
 *       | |                                         | |
 * +-----+ +-------+                                 +-+
 * ```
 * @example
 * return Tone.Offline(() => {
 * 	const pulse = new Tone.PulseOscillator(50, 0.4).toDestination().start();
 * }, 0.1, 1);
 * @category Source
 */ parcelHelpers.export(exports, "PulseOscillator", ()=>PulseOscillator);
var _tslib = require("tslib");
var _gainJs = require("../../core/context/Gain.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _signalJs = require("../../signal/Signal.js");
var _waveShaperJs = require("../../signal/WaveShaper.js");
var _sourceJs = require("../Source.js");
var _oscillatorJs = require("./Oscillator.js");
var _oscillatorInterfaceJs = require("./OscillatorInterface.js");
class PulseOscillator extends (0, _sourceJs.Source) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(PulseOscillator.getDefaults(), arguments, [
            "frequency",
            "width"
        ]);
        super(options);
        this.name = "PulseOscillator";
        /**
         * gate the width amount
         */ this._widthGate = new (0, _gainJs.Gain)({
            context: this.context,
            gain: 0
        });
        /**
         * Threshold the signal to turn it into a square
         */ this._thresh = new (0, _waveShaperJs.WaveShaper)({
            context: this.context,
            mapping: (val)=>val <= 0 ? -1 : 1
        });
        this.width = new (0, _signalJs.Signal)({
            context: this.context,
            units: "audioRange",
            value: options.width
        });
        this._triangle = new (0, _oscillatorJs.Oscillator)({
            context: this.context,
            detune: options.detune,
            frequency: options.frequency,
            onstop: ()=>this.onstop(this),
            phase: options.phase,
            type: "triangle"
        });
        this.frequency = this._triangle.frequency;
        this.detune = this._triangle.detune;
        // connections
        this._triangle.chain(this._thresh, this.output);
        this.width.chain(this._widthGate, this._thresh);
        (0, _interfaceJs.readOnly)(this, [
            "width",
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _sourceJs.Source).getDefaults(), {
            detune: 0,
            frequency: 440,
            phase: 0,
            type: "pulse",
            width: 0.2
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        time = this.toSeconds(time);
        this._triangle.start(time);
        this._widthGate.gain.setValueAtTime(1, time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        time = this.toSeconds(time);
        this._triangle.stop(time);
        // the width is still connected to the output.
        // that needs to be stopped also
        this._widthGate.gain.cancelScheduledValues(time);
        this._widthGate.gain.setValueAtTime(0, time);
    }
    _restart(time) {
        this._triangle.restart(time);
        this._widthGate.gain.cancelScheduledValues(time);
        this._widthGate.gain.setValueAtTime(1, time);
    }
    /**
     * The phase of the oscillator in degrees.
     */ get phase() {
        return this._triangle.phase;
    }
    set phase(phase) {
        this._triangle.phase = phase;
    }
    /**
     * The type of the oscillator. Always returns "pulse".
     */ get type() {
        return "pulse";
    }
    /**
     * The baseType of the oscillator. Always returns "pulse".
     */ get baseType() {
        return "pulse";
    }
    /**
     * The partials of the waveform. Cannot set partials for this waveform type
     */ get partials() {
        return [];
    }
    /**
     * No partials for this waveform type.
     */ get partialCount() {
        return 0;
    }
    /**
     * *Internal use* The carrier oscillator type is fed through the
     * waveshaper node to create the pulse. Using different carrier oscillators
     * changes oscillator's behavior.
     */ set carrierType(type) {
        this._triangle.type = type;
    }
    asArray() {
        return (0, _tslib.__awaiter)(this, arguments, void 0, function*(length = 1024) {
            return (0, _oscillatorInterfaceJs.generateWaveform)(this, length);
        });
    }
    /**
     * Clean up method.
     */ dispose() {
        super.dispose();
        this._triangle.dispose();
        this.width.dispose();
        this._widthGate.dispose();
        this._thresh.dispose();
        return this;
    }
}

},{"tslib":"lRdW5","../../core/context/Gain.js":"kj68Y","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../signal/Signal.js":"980ri","../../signal/WaveShaper.js":"k4nzV","../Source.js":"eBYFz","./Oscillator.js":"204g3","./OscillatorInterface.js":"wCQWx","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2aUtm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FatOscillator is an array of oscillators with detune spread between the oscillators
 * @example
 * const fatOsc = new Tone.FatOscillator("Ab3", "sawtooth", 40).toDestination().start();
 * @category Source
 */ parcelHelpers.export(exports, "FatOscillator", ()=>FatOscillator);
var _tslib = require("tslib");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _signalJs = require("../../signal/Signal.js");
var _sourceJs = require("../Source.js");
var _oscillatorJs = require("./Oscillator.js");
var _oscillatorInterfaceJs = require("./OscillatorInterface.js");
var _debugJs = require("../../core/util/Debug.js");
class FatOscillator extends (0, _sourceJs.Source) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(FatOscillator.getDefaults(), arguments, [
            "frequency",
            "type",
            "spread"
        ]);
        super(options);
        this.name = "FatOscillator";
        /**
         * The array of oscillators
         */ this._oscillators = [];
        this.frequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new (0, _signalJs.Signal)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        this._spread = options.spread;
        this._type = options.type;
        this._phase = options.phase;
        this._partials = options.partials;
        this._partialCount = options.partialCount;
        // set the count initially
        this.count = options.count;
        (0, _interfaceJs.readOnly)(this, [
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _oscillatorJs.Oscillator).getDefaults(), {
            count: 3,
            spread: 20,
            type: "sawtooth"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        time = this.toSeconds(time);
        this._forEach((osc)=>osc.start(time));
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        time = this.toSeconds(time);
        this._forEach((osc)=>osc.stop(time));
    }
    _restart(time) {
        this._forEach((osc)=>osc.restart(time));
    }
    /**
     * Iterate over all of the oscillators
     */ _forEach(iterator) {
        for(let i = 0; i < this._oscillators.length; i++)iterator(this._oscillators[i], i);
    }
    /**
     * The type of the oscillator
     */ get type() {
        return this._type;
    }
    set type(type) {
        this._type = type;
        this._forEach((osc)=>osc.type = type);
    }
    /**
     * The detune spread between the oscillators. If "count" is
     * set to 3 oscillators and the "spread" is set to 40,
     * the three oscillators would be detuned like this: [-20, 0, 20]
     * for a total detune spread of 40 cents.
     * @example
     * const fatOsc = new Tone.FatOscillator().toDestination().start();
     * fatOsc.spread = 70;
     */ get spread() {
        return this._spread;
    }
    set spread(spread) {
        this._spread = spread;
        if (this._oscillators.length > 1) {
            const start = -spread / 2;
            const step = spread / (this._oscillators.length - 1);
            this._forEach((osc, i)=>osc.detune.value = start + step * i);
        }
    }
    /**
     * The number of detuned oscillators. Must be an integer greater than 1.
     * @example
     * const fatOsc = new Tone.FatOscillator("C#3", "sawtooth").toDestination().start();
     * // use 4 sawtooth oscillators
     * fatOsc.count = 4;
     */ get count() {
        return this._oscillators.length;
    }
    set count(count) {
        (0, _debugJs.assertRange)(count, 1);
        if (this._oscillators.length !== count) {
            // dispose the previous oscillators
            this._forEach((osc)=>osc.dispose());
            this._oscillators = [];
            for(let i = 0; i < count; i++){
                const osc = new (0, _oscillatorJs.Oscillator)({
                    context: this.context,
                    volume: -6 - count * 1.1,
                    type: this._type,
                    phase: this._phase + i / count * 360,
                    partialCount: this._partialCount,
                    onstop: i === 0 ? ()=>this.onstop(this) : (0, _interfaceJs.noOp)
                });
                if (this.type === "custom") osc.partials = this._partials;
                this.frequency.connect(osc.frequency);
                this.detune.connect(osc.detune);
                osc.detune.overridden = false;
                osc.connect(this.output);
                this._oscillators[i] = osc;
            }
            // set the spread
            this.spread = this._spread;
            if (this.state === "started") this._forEach((osc)=>osc.start());
        }
    }
    get phase() {
        return this._phase;
    }
    set phase(phase) {
        this._phase = phase;
        this._forEach((osc, i)=>osc.phase = this._phase + i / this.count * 360);
    }
    get baseType() {
        return this._oscillators[0].baseType;
    }
    set baseType(baseType) {
        this._forEach((osc)=>osc.baseType = baseType);
        this._type = this._oscillators[0].type;
    }
    get partials() {
        return this._oscillators[0].partials;
    }
    set partials(partials) {
        this._partials = partials;
        this._partialCount = this._partials.length;
        if (partials.length) {
            this._type = "custom";
            this._forEach((osc)=>osc.partials = partials);
        }
    }
    get partialCount() {
        return this._oscillators[0].partialCount;
    }
    set partialCount(partialCount) {
        this._partialCount = partialCount;
        this._forEach((osc)=>osc.partialCount = partialCount);
        this._type = this._oscillators[0].type;
    }
    asArray() {
        return (0, _tslib.__awaiter)(this, arguments, void 0, function*(length = 1024) {
            return (0, _oscillatorInterfaceJs.generateWaveform)(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this._forEach((osc)=>osc.dispose());
        return this;
    }
}

},{"tslib":"lRdW5","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../signal/Signal.js":"980ri","../Source.js":"eBYFz","./Oscillator.js":"204g3","./OscillatorInterface.js":"wCQWx","../../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8eNKU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PWMOscillator modulates the width of a Tone.PulseOscillator
 * at the modulationFrequency. This has the effect of continuously
 * changing the timbre of the oscillator by altering the harmonics
 * generated.
 * @example
 * return Tone.Offline(() => {
 * 	const pwm = new Tone.PWMOscillator(60, 0.3).toDestination().start();
 * }, 0.1, 1);
 * @category Source
 */ parcelHelpers.export(exports, "PWMOscillator", ()=>PWMOscillator);
var _tslib = require("tslib");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _multiplyJs = require("../../signal/Multiply.js");
var _sourceJs = require("../Source.js");
var _oscillatorJs = require("./Oscillator.js");
var _oscillatorInterfaceJs = require("./OscillatorInterface.js");
var _pulseOscillatorJs = require("./PulseOscillator.js");
class PWMOscillator extends (0, _sourceJs.Source) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(PWMOscillator.getDefaults(), arguments, [
            "frequency",
            "modulationFrequency"
        ]);
        super(options);
        this.name = "PWMOscillator";
        this.sourceType = "pwm";
        /**
         * Scale the oscillator so it doesn't go silent
         * at the extreme values.
         */ this._scale = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: 2
        });
        this._pulse = new (0, _pulseOscillatorJs.PulseOscillator)({
            context: this.context,
            frequency: options.modulationFrequency
        });
        // change the pulse oscillator type
        this._pulse.carrierType = "sine";
        this.modulationFrequency = this._pulse.frequency;
        this._modulator = new (0, _oscillatorJs.Oscillator)({
            context: this.context,
            detune: options.detune,
            frequency: options.frequency,
            onstop: ()=>this.onstop(this),
            phase: options.phase
        });
        this.frequency = this._modulator.frequency;
        this.detune = this._modulator.detune;
        // connections
        this._modulator.chain(this._scale, this._pulse.width);
        this._pulse.connect(this.output);
        (0, _interfaceJs.readOnly)(this, [
            "modulationFrequency",
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _sourceJs.Source).getDefaults(), {
            detune: 0,
            frequency: 440,
            modulationFrequency: 0.4,
            phase: 0,
            type: "pwm"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        time = this.toSeconds(time);
        this._modulator.start(time);
        this._pulse.start(time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        time = this.toSeconds(time);
        this._modulator.stop(time);
        this._pulse.stop(time);
    }
    /**
     * restart the oscillator
     */ _restart(time) {
        this._modulator.restart(time);
        this._pulse.restart(time);
    }
    /**
     * The type of the oscillator. Always returns "pwm".
     */ get type() {
        return "pwm";
    }
    /**
     * The baseType of the oscillator. Always returns "pwm".
     */ get baseType() {
        return "pwm";
    }
    /**
     * The partials of the waveform. Cannot set partials for this waveform type
     */ get partials() {
        return [];
    }
    /**
     * No partials for this waveform type.
     */ get partialCount() {
        return 0;
    }
    /**
     * The phase of the oscillator in degrees.
     */ get phase() {
        return this._modulator.phase;
    }
    set phase(phase) {
        this._modulator.phase = phase;
    }
    asArray() {
        return (0, _tslib.__awaiter)(this, arguments, void 0, function*(length = 1024) {
            return (0, _oscillatorInterfaceJs.generateWaveform)(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._pulse.dispose();
        this._scale.dispose();
        this._modulator.dispose();
        return this;
    }
}

},{"tslib":"lRdW5","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../signal/Multiply.js":"4C0VG","../Source.js":"eBYFz","./Oscillator.js":"204g3","./OscillatorInterface.js":"wCQWx","./PulseOscillator.js":"g3ood","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7bzEJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * OmniOscillator aggregates all of the oscillator types into one.
 * @example
 * return Tone.Offline(() => {
 * 	const omniOsc = new Tone.OmniOscillator("C#4", "pwm").toDestination().start();
 * }, 0.1, 1);
 * @category Source
 */ parcelHelpers.export(exports, "OmniOscillator", ()=>OmniOscillator);
var _tslib = require("tslib");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _typeCheckJs = require("../../core/util/TypeCheck.js");
var _signalJs = require("../../signal/Signal.js");
var _sourceJs = require("../Source.js");
var _amoscillatorJs = require("./AMOscillator.js");
var _fatOscillatorJs = require("./FatOscillator.js");
var _fmoscillatorJs = require("./FMOscillator.js");
var _oscillatorJs = require("./Oscillator.js");
var _oscillatorInterfaceJs = require("./OscillatorInterface.js");
var _pulseOscillatorJs = require("./PulseOscillator.js");
var _pwmoscillatorJs = require("./PWMOscillator.js");
const OmniOscillatorSourceMap = {
    am: (0, _amoscillatorJs.AMOscillator),
    fat: (0, _fatOscillatorJs.FatOscillator),
    fm: (0, _fmoscillatorJs.FMOscillator),
    oscillator: (0, _oscillatorJs.Oscillator),
    pulse: (0, _pulseOscillatorJs.PulseOscillator),
    pwm: (0, _pwmoscillatorJs.PWMOscillator)
};
class OmniOscillator extends (0, _sourceJs.Source) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(OmniOscillator.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        super(options);
        this.name = "OmniOscillator";
        this.frequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new (0, _signalJs.Signal)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        (0, _interfaceJs.readOnly)(this, [
            "frequency",
            "detune"
        ]);
        // set the options
        this.set(options);
    }
    static getDefaults() {
        return Object.assign((0, _oscillatorJs.Oscillator).getDefaults(), (0, _fmoscillatorJs.FMOscillator).getDefaults(), (0, _amoscillatorJs.AMOscillator).getDefaults(), (0, _fatOscillatorJs.FatOscillator).getDefaults(), (0, _pulseOscillatorJs.PulseOscillator).getDefaults(), (0, _pwmoscillatorJs.PWMOscillator).getDefaults());
    }
    /**
     * start the oscillator
     */ _start(time) {
        this._oscillator.start(time);
    }
    /**
     * start the oscillator
     */ _stop(time) {
        this._oscillator.stop(time);
    }
    _restart(time) {
        this._oscillator.restart(time);
        return this;
    }
    /**
     * The type of the oscillator. Can be any of the basic types: sine, square, triangle, sawtooth. Or
     * prefix the basic types with "fm", "am", or "fat" to use the FMOscillator, AMOscillator or FatOscillator
     * types. The oscillator could also be set to "pwm" or "pulse". All of the parameters of the
     * oscillator's class are accessible when the oscillator is set to that type, but throws an error
     * when it's not.
     * @example
     * const omniOsc = new Tone.OmniOscillator().toDestination().start();
     * omniOsc.type = "pwm";
     * // modulationFrequency is parameter which is available
     * // only when the type is "pwm".
     * omniOsc.modulationFrequency.value = 0.5;
     */ get type() {
        let prefix = "";
        if ([
            "am",
            "fm",
            "fat"
        ].some((p)=>this._sourceType === p)) prefix = this._sourceType;
        return prefix + this._oscillator.type;
    }
    set type(type) {
        if (type.substr(0, 2) === "fm") {
            this._createNewOscillator("fm");
            this._oscillator = this._oscillator;
            this._oscillator.type = type.substr(2);
        } else if (type.substr(0, 2) === "am") {
            this._createNewOscillator("am");
            this._oscillator = this._oscillator;
            this._oscillator.type = type.substr(2);
        } else if (type.substr(0, 3) === "fat") {
            this._createNewOscillator("fat");
            this._oscillator = this._oscillator;
            this._oscillator.type = type.substr(3);
        } else if (type === "pwm") {
            this._createNewOscillator("pwm");
            this._oscillator = this._oscillator;
        } else if (type === "pulse") this._createNewOscillator("pulse");
        else {
            this._createNewOscillator("oscillator");
            this._oscillator = this._oscillator;
            this._oscillator.type = type;
        }
    }
    /**
     * The value is an empty array when the type is not "custom".
     * This is not available on "pwm" and "pulse" oscillator types.
     * @see {@link Oscillator.partials}
     */ get partials() {
        return this._oscillator.partials;
    }
    set partials(partials) {
        if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm")) this._oscillator.partials = partials;
    }
    get partialCount() {
        return this._oscillator.partialCount;
    }
    set partialCount(partialCount) {
        if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm")) this._oscillator.partialCount = partialCount;
    }
    set(props) {
        // make sure the type is set first
        if (Reflect.has(props, "type") && props.type) this.type = props.type;
        // then set the rest
        super.set(props);
        return this;
    }
    /**
     * connect the oscillator to the frequency and detune signals
     */ _createNewOscillator(oscType) {
        if (oscType !== this._sourceType) {
            this._sourceType = oscType;
            const OscConstructor = OmniOscillatorSourceMap[oscType];
            // short delay to avoid clicks on the change
            const now = this.now();
            if (this._oscillator) {
                const oldOsc = this._oscillator;
                oldOsc.stop(now);
                // dispose the old one
                this.context.setTimeout(()=>oldOsc.dispose(), this.blockTime);
            }
            this._oscillator = new OscConstructor({
                context: this.context
            });
            this.frequency.connect(this._oscillator.frequency);
            this.detune.connect(this._oscillator.detune);
            this._oscillator.connect(this.output);
            this._oscillator.onstop = ()=>this.onstop(this);
            if (this.state === "started") this._oscillator.start(now);
        }
    }
    get phase() {
        return this._oscillator.phase;
    }
    set phase(phase) {
        this._oscillator.phase = phase;
    }
    /**
     * The source type of the oscillator.
     * @example
     * const omniOsc = new Tone.OmniOscillator(440, "fmsquare");
     * console.log(omniOsc.sourceType); // 'fm'
     */ get sourceType() {
        return this._sourceType;
    }
    set sourceType(sType) {
        // the basetype defaults to sine
        let baseType = "sine";
        if (this._oscillator.type !== "pwm" && this._oscillator.type !== "pulse") baseType = this._oscillator.type;
        // set the type
        if (sType === "fm") this.type = "fm" + baseType;
        else if (sType === "am") this.type = "am" + baseType;
        else if (sType === "fat") this.type = "fat" + baseType;
        else if (sType === "oscillator") this.type = baseType;
        else if (sType === "pulse") this.type = "pulse";
        else if (sType === "pwm") this.type = "pwm";
    }
    _getOscType(osc, sourceType) {
        return osc instanceof OmniOscillatorSourceMap[sourceType];
    }
    /**
     * The base type of the oscillator.
     * @see {@link Oscillator.baseType}
     * @example
     * const omniOsc = new Tone.OmniOscillator(440, "fmsquare4");
     * console.log(omniOsc.sourceType, omniOsc.baseType, omniOsc.partialCount);
     */ get baseType() {
        return this._oscillator.baseType;
    }
    set baseType(baseType) {
        if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm") && baseType !== "pulse" && baseType !== "pwm") this._oscillator.baseType = baseType;
    }
    /**
     * The width of the oscillator when sourceType === "pulse".
     * @see {@link PWMOscillator}
     */ get width() {
        if (this._getOscType(this._oscillator, "pulse")) return this._oscillator.width;
        else return undefined;
    }
    /**
     * The number of detuned oscillators when sourceType === "fat".
     * @see {@link FatOscillator.count}
     */ get count() {
        if (this._getOscType(this._oscillator, "fat")) return this._oscillator.count;
        else return undefined;
    }
    set count(count) {
        if (this._getOscType(this._oscillator, "fat") && (0, _typeCheckJs.isNumber)(count)) this._oscillator.count = count;
    }
    /**
     * The detune spread between the oscillators when sourceType === "fat".
     * @see {@link FatOscillator.count}
     */ get spread() {
        if (this._getOscType(this._oscillator, "fat")) return this._oscillator.spread;
        else return undefined;
    }
    set spread(spread) {
        if (this._getOscType(this._oscillator, "fat") && (0, _typeCheckJs.isNumber)(spread)) this._oscillator.spread = spread;
    }
    /**
     * The type of the modulator oscillator. Only if the oscillator is set to "am" or "fm" types.
     * @see {@link AMOscillator} or {@link FMOscillator}
     */ get modulationType() {
        if (this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) return this._oscillator.modulationType;
        else return undefined;
    }
    set modulationType(mType) {
        if ((this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) && (0, _typeCheckJs.isString)(mType)) this._oscillator.modulationType = mType;
    }
    /**
     * The modulation index when the sourceType === "fm"
     * @see {@link FMOscillator}.
     */ get modulationIndex() {
        if (this._getOscType(this._oscillator, "fm")) return this._oscillator.modulationIndex;
        else return undefined;
    }
    /**
     * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.
     * @see {@link AMOscillator} or {@link FMOscillator}
     */ get harmonicity() {
        if (this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) return this._oscillator.harmonicity;
        else return undefined;
    }
    /**
     * The modulationFrequency Signal of the oscillator when sourceType === "pwm"
     * see {@link PWMOscillator}
     * @min 0.1
     * @max 5
     */ get modulationFrequency() {
        if (this._getOscType(this._oscillator, "pwm")) return this._oscillator.modulationFrequency;
        else return undefined;
    }
    asArray() {
        return (0, _tslib.__awaiter)(this, arguments, void 0, function*(length = 1024) {
            return (0, _oscillatorInterfaceJs.generateWaveform)(this, length);
        });
    }
    dispose() {
        super.dispose();
        this.detune.dispose();
        this.frequency.dispose();
        this._oscillator.dispose();
        return this;
    }
}

},{"tslib":"lRdW5","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../core/util/TypeCheck.js":"eMH5A","../../signal/Signal.js":"980ri","../Source.js":"eBYFz","./AMOscillator.js":"9mU3E","./FatOscillator.js":"2aUtm","./FMOscillator.js":"3UNlG","./Oscillator.js":"204g3","./OscillatorInterface.js":"wCQWx","./PulseOscillator.js":"g3ood","./PWMOscillator.js":"8eNKU","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jsBJT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * LFO stands for low frequency oscillator. LFO produces an output signal
 * which can be attached to an AudioParam or Tone.Signal
 * in order to modulate that parameter with an oscillator. The LFO can
 * also be synced to the transport to start/stop and change when the tempo changes.
 * @example
 * return Tone.Offline(() => {
 * 	const lfo = new Tone.LFO("4n", 400, 4000).start().toDestination();
 * }, 0.5, 1);
 * @category Source
 */ parcelHelpers.export(exports, "LFO", ()=>LFO);
var _gainJs = require("../../core/context/Gain.js");
var _paramJs = require("../../core/context/Param.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _audioToGainJs = require("../../signal/AudioToGain.js");
var _scaleJs = require("../../signal/Scale.js");
var _signalJs = require("../../signal/Signal.js");
var _zeroJs = require("../../signal/Zero.js");
var _oscillatorJs = require("./Oscillator.js");
class LFO extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(LFO.getDefaults(), arguments, [
            "frequency",
            "min",
            "max"
        ]);
        super(options);
        this.name = "LFO";
        /**
         * The value that the LFO outputs when it's stopped
         */ this._stoppedValue = 0;
        /**
         * A private placeholder for the units
         */ this._units = "number";
        /**
         * If the input value is converted using the {@link units}
         */ this.convert = true;
        /**
         * Private methods borrowed from Param
         */ // @ts-ignore
        this._fromType = (0, _paramJs.Param).prototype._fromType;
        // @ts-ignore
        this._toType = (0, _paramJs.Param).prototype._toType;
        // @ts-ignore
        this._is = (0, _paramJs.Param).prototype._is;
        // @ts-ignore
        this._clampValue = (0, _paramJs.Param).prototype._clampValue;
        this._oscillator = new (0, _oscillatorJs.Oscillator)(options);
        this.frequency = this._oscillator.frequency;
        this._amplitudeGain = new (0, _gainJs.Gain)({
            context: this.context,
            gain: options.amplitude,
            units: "normalRange"
        });
        this.amplitude = this._amplitudeGain.gain;
        this._stoppedSignal = new (0, _signalJs.Signal)({
            context: this.context,
            units: "audioRange",
            value: 0
        });
        this._zeros = new (0, _zeroJs.Zero)({
            context: this.context
        });
        this._a2g = new (0, _audioToGainJs.AudioToGain)({
            context: this.context
        });
        this._scaler = this.output = new (0, _scaleJs.Scale)({
            context: this.context,
            max: options.max,
            min: options.min
        });
        this.units = options.units;
        this.min = options.min;
        this.max = options.max;
        // connect it up
        this._oscillator.chain(this._amplitudeGain, this._a2g, this._scaler);
        this._zeros.connect(this._a2g);
        this._stoppedSignal.connect(this._a2g);
        (0, _interfaceJs.readOnly)(this, [
            "amplitude",
            "frequency"
        ]);
        this.phase = options.phase;
    }
    static getDefaults() {
        return Object.assign((0, _oscillatorJs.Oscillator).getDefaults(), {
            amplitude: 1,
            frequency: "4n",
            max: 1,
            min: 0,
            type: "sine",
            units: "number"
        });
    }
    /**
     * Start the LFO.
     * @param time The time the LFO will start
     */ start(time) {
        time = this.toSeconds(time);
        this._stoppedSignal.setValueAtTime(0, time);
        this._oscillator.start(time);
        return this;
    }
    /**
     * Stop the LFO.
     * @param  time The time the LFO will stop
     */ stop(time) {
        time = this.toSeconds(time);
        this._stoppedSignal.setValueAtTime(this._stoppedValue, time);
        this._oscillator.stop(time);
        return this;
    }
    /**
     * Sync the start/stop/pause to the transport
     * and the frequency to the bpm of the transport
     * @example
     * const lfo = new Tone.LFO("8n");
     * lfo.sync().start(0);
     * // the rate of the LFO will always be an eighth note, even as the tempo changes
     */ sync() {
        this._oscillator.sync();
        this._oscillator.syncFrequency();
        return this;
    }
    /**
     * unsync the LFO from transport control
     */ unsync() {
        this._oscillator.unsync();
        this._oscillator.unsyncFrequency();
        return this;
    }
    /**
     * After the oscillator waveform is updated, reset the `_stoppedSignal` value to match the updated waveform
     */ _setStoppedValue() {
        this._stoppedValue = this._oscillator.getInitialValue();
        this._stoppedSignal.value = this._stoppedValue;
    }
    /**
     * The minimum output of the LFO.
     */ get min() {
        return this._toType(this._scaler.min);
    }
    set min(min) {
        min = this._fromType(min);
        this._scaler.min = min;
    }
    /**
     * The maximum output of the LFO.
     */ get max() {
        return this._toType(this._scaler.max);
    }
    set max(max) {
        max = this._fromType(max);
        this._scaler.max = max;
    }
    /**
     * The type of the oscillator.
     * @see {@link Oscillator.type}
     */ get type() {
        return this._oscillator.type;
    }
    set type(type) {
        this._oscillator.type = type;
        this._setStoppedValue();
    }
    /**
     * The oscillator's partials array.
     * @see {@link Oscillator.partials}
     */ get partials() {
        return this._oscillator.partials;
    }
    set partials(partials) {
        this._oscillator.partials = partials;
        this._setStoppedValue();
    }
    /**
     * The phase of the LFO.
     */ get phase() {
        return this._oscillator.phase;
    }
    set phase(phase) {
        this._oscillator.phase = phase;
        this._setStoppedValue();
    }
    /**
     * The output units of the LFO.
     */ get units() {
        return this._units;
    }
    set units(val) {
        const currentMin = this.min;
        const currentMax = this.max;
        // convert the min and the max
        this._units = val;
        this.min = currentMin;
        this.max = currentMax;
    }
    /**
     * Returns the playback state of the source, either "started" or "stopped".
     */ get state() {
        return this._oscillator.state;
    }
    /**
     * @param node the destination to connect to
     * @param outputNum the optional output number
     * @param inputNum the input number
     */ connect(node, outputNum, inputNum) {
        if (node instanceof (0, _paramJs.Param) || node instanceof (0, _signalJs.Signal)) {
            this.convert = node.convert;
            this.units = node.units;
        }
        (0, _signalJs.connectSignal)(this, node, outputNum, inputNum);
        return this;
    }
    dispose() {
        super.dispose();
        this._oscillator.dispose();
        this._stoppedSignal.dispose();
        this._zeros.dispose();
        this._scaler.dispose();
        this._a2g.dispose();
        this._amplitudeGain.dispose();
        this.amplitude.dispose();
        return this;
    }
}

},{"../../core/context/Gain.js":"kj68Y","../../core/context/Param.js":"5PVlJ","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../signal/AudioToGain.js":"kLli1","../../signal/Scale.js":"3qxrw","../../signal/Signal.js":"980ri","../../signal/Zero.js":"5ROIx","./Oscillator.js":"204g3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3qxrw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Performs a linear scaling on an input signal.
 * Scales a NormalRange input to between
 * outputMin and outputMax.
 *
 * @example
 * const scale = new Tone.Scale(50, 100);
 * const signal = new Tone.Signal(0.5).connect(scale);
 * // the output of scale equals 75
 * @category Signal
 */ parcelHelpers.export(exports, "Scale", ()=>Scale);
var _defaultsJs = require("../core/util/Defaults.js");
var _addJs = require("./Add.js");
var _multiplyJs = require("./Multiply.js");
var _signalOperatorJs = require("./SignalOperator.js");
class Scale extends (0, _signalOperatorJs.SignalOperator) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Scale.getDefaults(), arguments, [
            "min",
            "max"
        ]);
        super(options);
        this.name = "Scale";
        this._mult = this.input = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: options.max - options.min
        });
        this._add = this.output = new (0, _addJs.Add)({
            context: this.context,
            value: options.min
        });
        this._min = options.min;
        this._max = options.max;
        this.input.connect(this.output);
    }
    static getDefaults() {
        return Object.assign((0, _signalOperatorJs.SignalOperator).getDefaults(), {
            max: 1,
            min: 0
        });
    }
    /**
     * The minimum output value. This number is output when the value input value is 0.
     */ get min() {
        return this._min;
    }
    set min(min) {
        this._min = min;
        this._setRange();
    }
    /**
     * The maximum output value. This number is output when the value input value is 1.
     */ get max() {
        return this._max;
    }
    set max(max) {
        this._max = max;
        this._setRange();
    }
    /**
     * set the values
     */ _setRange() {
        this._add.value = this._min;
        this._mult.value = this._max - this._min;
    }
    dispose() {
        super.dispose();
        this._add.dispose();
        this._mult.dispose();
        return this;
    }
}

},{"../core/util/Defaults.js":"a9M5s","./Add.js":"jeoK8","./Multiply.js":"4C0VG","./SignalOperator.js":"4XSes","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jeoK8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Add a signal and a number or two signals. When no value is
 * passed into the constructor, Tone.Add will sum input and `addend`
 * If a value is passed into the constructor, the it will be added to the input.
 *
 * @example
 * return Tone.Offline(() => {
 * 	const add = new Tone.Add(2).toDestination();
 * 	add.addend.setValueAtTime(1, 0.2);
 * 	const signal = new Tone.Signal(2);
 * 	// add a signal and a scalar
 * 	signal.connect(add);
 * 	signal.setValueAtTime(1, 0.1);
 * }, 0.5, 1);
 * @category Signal
 */ parcelHelpers.export(exports, "Add", ()=>Add);
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _gainJs = require("../core/context/Gain.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _signalJs = require("./Signal.js");
class Add extends (0, _signalJs.Signal) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(Add.getDefaults(), arguments, [
            "value"
        ]));
        this.override = false;
        this.name = "Add";
        /**
         * the summing node
         */ this._sum = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.input = this._sum;
        this.output = this._sum;
        /**
         * The value which is added to the input signal
         */ this.addend = this._param;
        (0, _toneAudioNodeJs.connectSeries)(this._constantSource, this._sum);
    }
    static getDefaults() {
        return Object.assign((0, _signalJs.Signal).getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._sum.dispose();
        return this;
    }
}

},{"../core/context/ToneAudioNode.js":"kZ3Kj","../core/context/Gain.js":"kj68Y","../core/util/Defaults.js":"a9M5s","./Signal.js":"980ri","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5ROIx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone.Zero outputs 0's at audio-rate. The reason this has to be
 * it's own class is that many browsers optimize out Tone.Signal
 * with a value of 0 and will not process nodes further down the graph.
 * @category Signal
 */ parcelHelpers.export(exports, "Zero", ()=>Zero);
var _gainJs = require("../core/context/Gain.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _signalOperatorJs = require("./SignalOperator.js");
class Zero extends (0, _signalOperatorJs.SignalOperator) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(Zero.getDefaults(), arguments));
        this.name = "Zero";
        /**
         * The gain node which connects the constant source to the output
         */ this._gain = new (0, _gainJs.Gain)({
            context: this.context
        });
        /**
         * Only outputs 0
         */ this.output = this._gain;
        /**
         * no input node
         */ this.input = undefined;
        (0, _toneAudioNodeJs.connect)(this.context.getConstant(0), this._gain);
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        (0, _toneAudioNodeJs.disconnect)(this.context.getConstant(0), this._gain);
        return this;
    }
}

},{"../core/context/Gain.js":"kj68Y","../core/context/ToneAudioNode.js":"kZ3Kj","../core/util/Defaults.js":"a9M5s","./SignalOperator.js":"4XSes","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4UJCG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Player is an audio file player with start, loop, and stop functions.
 * @example
 * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/gong_1.mp3").toDestination();
 * // play as soon as the buffer is loaded
 * player.autostart = true;
 * @category Source
 */ parcelHelpers.export(exports, "Player", ()=>Player);
var _tslib = require("tslib");
var _toneAudioBufferJs = require("../../core/context/ToneAudioBuffer.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _typeCheckJs = require("../../core/util/TypeCheck.js");
var _sourceJs = require("../Source.js");
var _toneBufferSourceJs = require("./ToneBufferSource.js");
var _debugJs = require("../../core/util/Debug.js");
var _decoratorJs = require("../../core/util/Decorator.js");
class Player extends (0, _sourceJs.Source) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Player.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        super(options);
        this.name = "Player";
        /**
         * All of the active buffer source nodes
         */ this._activeSources = new Set();
        this._buffer = new (0, _toneAudioBufferJs.ToneAudioBuffer)({
            onload: this._onload.bind(this, options.onload),
            onerror: options.onerror,
            reverse: options.reverse,
            url: options.url
        });
        this.autostart = options.autostart;
        this._loop = options.loop;
        this._loopStart = options.loopStart;
        this._loopEnd = options.loopEnd;
        this._playbackRate = options.playbackRate;
        this.fadeIn = options.fadeIn;
        this.fadeOut = options.fadeOut;
    }
    static getDefaults() {
        return Object.assign((0, _sourceJs.Source).getDefaults(), {
            autostart: false,
            fadeIn: 0,
            fadeOut: 0,
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            onload: (0, _interfaceJs.noOp),
            onerror: (0, _interfaceJs.noOp),
            playbackRate: 1,
            reverse: false
        });
    }
    /**
     * Load the audio file as an audio buffer.
     * Decodes the audio asynchronously and invokes
     * the callback once the audio buffer loads.
     * Note: this does not need to be called if a url
     * was passed in to the constructor. Only use this
     * if you want to manually load a new url.
     * @param url The url of the buffer to load. Filetype support depends on the browser.
     */ load(url) {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            yield this._buffer.load(url);
            this._onload();
            return this;
        });
    }
    /**
     * Internal callback when the buffer is loaded.
     */ _onload(callback = (0, _interfaceJs.noOp)) {
        callback();
        if (this.autostart) this.start();
    }
    /**
     * Internal callback when the buffer is done playing.
     */ _onSourceEnd(source) {
        // invoke the onstop function
        this.onstop(this);
        // delete the source from the active sources
        this._activeSources.delete(source);
        if (this._activeSources.size === 0 && !this._synced && this._state.getValueAtTime(this.now()) === "started") {
            // remove the 'implicitEnd' event and replace with an explicit end
            this._state.cancel(this.now());
            this._state.setStateAtTime("stopped", this.now());
        }
    }
    /**
     * Play the buffer at the given startTime. Optionally add an offset
     * and/or duration which will play the buffer from a position
     * within the buffer for the given duration.
     *
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)
     */ start(time, offset, duration) {
        super.start(time, offset, duration);
        return this;
    }
    /**
     * Internal start method
     */ _start(startTime, offset, duration) {
        // if it's a loop the default offset is the loopStart point
        if (this._loop) offset = (0, _defaultsJs.defaultArg)(offset, this._loopStart);
        else // otherwise the default offset is 0
        offset = (0, _defaultsJs.defaultArg)(offset, 0);
        // compute the values in seconds
        const computedOffset = this.toSeconds(offset);
        // compute the duration which is either the passed in duration of the buffer.duration - offset
        const origDuration = duration;
        duration = (0, _defaultsJs.defaultArg)(duration, Math.max(this._buffer.duration - computedOffset, 0));
        let computedDuration = this.toSeconds(duration);
        // scale it by the playback rate
        computedDuration = computedDuration / this._playbackRate;
        // get the start time
        startTime = this.toSeconds(startTime);
        // make the source
        const source = new (0, _toneBufferSourceJs.ToneBufferSource)({
            url: this._buffer,
            context: this.context,
            fadeIn: this.fadeIn,
            fadeOut: this.fadeOut,
            loop: this._loop,
            loopEnd: this._loopEnd,
            loopStart: this._loopStart,
            onended: this._onSourceEnd.bind(this),
            playbackRate: this._playbackRate
        }).connect(this.output);
        // set the looping properties
        if (!this._loop && !this._synced) {
            // cancel the previous stop
            this._state.cancel(startTime + computedDuration);
            // if it's not looping, set the state change at the end of the sample
            this._state.setStateAtTime("stopped", startTime + computedDuration, {
                implicitEnd: true
            });
        }
        // add it to the array of active sources
        this._activeSources.add(source);
        // start it
        if (this._loop && (0, _typeCheckJs.isUndef)(origDuration)) source.start(startTime, computedOffset);
        else // subtract the fade out time
        source.start(startTime, computedOffset, computedDuration - this.toSeconds(this.fadeOut));
    }
    /**
     * Stop playback.
     */ _stop(time) {
        const computedTime = this.toSeconds(time);
        this._activeSources.forEach((source)=>source.stop(computedTime));
    }
    /**
     * Stop and then restart the player from the beginning (or offset)
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given,
     * 					it will default to the full length of the sample (minus any offset)
     */ restart(time, offset, duration) {
        super.restart(time, offset, duration);
        return this;
    }
    _restart(time, offset, duration) {
        var _a;
        (_a = [
            ...this._activeSources
        ].pop()) === null || _a === void 0 || _a.stop(time); // explicitly stop only the most recently created source, to avoid edge case when > 1 source exists and _stop() erroneously sets all stop times past original end offset
        this._start(time, offset, duration);
    }
    /**
     * Seek to a specific time in the player's buffer. If the
     * source is no longer playing at that time, it will stop.
     * @param offset The time to seek to.
     * @param when The time for the seek event to occur.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/gurgling_theremin_1.mp3", () => {
     * 	player.start();
     * 	// seek to the offset in 1 second from now
     * 	player.seek(0.4, "+1");
     * }).toDestination();
     */ seek(offset, when) {
        const computedTime = this.toSeconds(when);
        if (this._state.getValueAtTime(computedTime) === "started") {
            const computedOffset = this.toSeconds(offset);
            // if it's currently playing, stop it
            this._stop(computedTime);
            // restart it at the given time
            this._start(computedTime, computedOffset);
        }
        return this;
    }
    /**
     * Set the loop start and end. Will only loop if loop is set to true.
     * @param loopStart The loop start time
     * @param loopEnd The loop end time
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/malevoices_aa2_F3.mp3").toDestination();
     * // loop between the given points
     * player.setLoopPoints(0.2, 0.3);
     * player.loop = true;
     * player.autostart = true;
     */ setLoopPoints(loopStart, loopEnd) {
        this.loopStart = loopStart;
        this.loopEnd = loopEnd;
        return this;
    }
    /**
     * If loop is true, the loop will start at this position.
     */ get loopStart() {
        return this._loopStart;
    }
    set loopStart(loopStart) {
        this._loopStart = loopStart;
        if (this.buffer.loaded) (0, _debugJs.assertRange)(this.toSeconds(loopStart), 0, this.buffer.duration);
        // get the current source
        this._activeSources.forEach((source)=>{
            source.loopStart = loopStart;
        });
    }
    /**
     * If loop is true, the loop will end at this position.
     */ get loopEnd() {
        return this._loopEnd;
    }
    set loopEnd(loopEnd) {
        this._loopEnd = loopEnd;
        if (this.buffer.loaded) (0, _debugJs.assertRange)(this.toSeconds(loopEnd), 0, this.buffer.duration);
        // get the current source
        this._activeSources.forEach((source)=>{
            source.loopEnd = loopEnd;
        });
    }
    /**
     * The audio buffer belonging to the player.
     */ get buffer() {
        return this._buffer;
    }
    set buffer(buffer) {
        this._buffer.set(buffer);
    }
    /**
     * If the buffer should loop once it's over.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/breakbeat.mp3").toDestination();
     * player.loop = true;
     * player.autostart = true;
     */ get loop() {
        return this._loop;
    }
    set loop(loop) {
        // if no change, do nothing
        if (this._loop === loop) return;
        this._loop = loop;
        // set the loop of all of the sources
        this._activeSources.forEach((source)=>{
            source.loop = loop;
        });
        if (loop) {
            // remove the next stopEvent
            const stopEvent = this._state.getNextState("stopped", this.now());
            if (stopEvent) this._state.cancel(stopEvent.time);
        }
    }
    /**
     * Normal speed is 1. The pitch will change with the playback rate.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/femalevoices_aa2_A5.mp3").toDestination();
     * // play at 1/4 speed
     * player.playbackRate = 0.25;
     * // play as soon as the buffer is loaded
     * player.autostart = true;
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        const now = this.now();
        // cancel the stop event since it's at a different time now
        const stopEvent = this._state.getNextState("stopped", now);
        if (stopEvent && stopEvent.implicitEnd) {
            this._state.cancel(stopEvent.time);
            this._activeSources.forEach((source)=>source.cancelStop());
        }
        // set all the sources
        this._activeSources.forEach((source)=>{
            source.playbackRate.setValueAtTime(rate, now);
        });
    }
    /**
     * If the buffer should be reversed. Note that this sets the underlying {@link ToneAudioBuffer.reverse}, so
     * if multiple players are pointing at the same ToneAudioBuffer, they will all be reversed.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/chime_1.mp3").toDestination();
     * player.autostart = true;
     * player.reverse = true;
     */ get reverse() {
        return this._buffer.reverse;
    }
    set reverse(rev) {
        this._buffer.reverse = rev;
    }
    /**
     * If the buffer is loaded
     */ get loaded() {
        return this._buffer.loaded;
    }
    dispose() {
        super.dispose();
        // disconnect all of the players
        this._activeSources.forEach((source)=>source.dispose());
        this._activeSources.clear();
        this._buffer.dispose();
        return this;
    }
}
(0, _tslib.__decorate)([
    (0, _decoratorJs.timeRange)(0)
], Player.prototype, "fadeIn", void 0);
(0, _tslib.__decorate)([
    (0, _decoratorJs.timeRange)(0)
], Player.prototype, "fadeOut", void 0);

},{"tslib":"lRdW5","../../core/context/ToneAudioBuffer.js":"8aSPC","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../core/util/TypeCheck.js":"eMH5A","../Source.js":"eBYFz","./ToneBufferSource.js":"9FxEt","../../core/util/Debug.js":"2lOIQ","../../core/util/Decorator.js":"fl7ql","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"fl7ql":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Assert that the number is in the given range.
 */ parcelHelpers.export(exports, "range", ()=>range);
/**
 * Convert the time to seconds and assert that the time is in between the two
 * values when being set.
 */ parcelHelpers.export(exports, "timeRange", ()=>timeRange);
var _debugJs = require("./Debug.js");
function range(min, max = Infinity) {
    const valueMap = new WeakMap();
    return function(target, propertyKey) {
        Reflect.defineProperty(target, propertyKey, {
            configurable: true,
            enumerable: true,
            get: function() {
                return valueMap.get(this);
            },
            set: function(newValue) {
                (0, _debugJs.assertRange)(newValue, min, max);
                valueMap.set(this, newValue);
            }
        });
    };
}
function timeRange(min, max = Infinity) {
    const valueMap = new WeakMap();
    return function(target, propertyKey) {
        Reflect.defineProperty(target, propertyKey, {
            configurable: true,
            enumerable: true,
            get: function() {
                return valueMap.get(this);
            },
            set: function(newValue) {
                (0, _debugJs.assertRange)(this.toSeconds(newValue), min, max);
                valueMap.set(this, newValue);
            }
        });
    };
}

},{"./Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"17BMn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Players combines multiple {@link Player} objects.
 * @category Source
 */ parcelHelpers.export(exports, "Players", ()=>Players);
var _volumeJs = require("../../component/channel/Volume.js");
var _toneAudioBuffersJs = require("../../core/context/ToneAudioBuffers.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _debugJs = require("../../core/util/Debug.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _sourceJs = require("../Source.js");
var _playerJs = require("./Player.js");
class Players extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Players.getDefaults(), arguments, [
            "urls",
            "onload"
        ], "urls");
        super(options);
        this.name = "Players";
        /**
         * Players has no input.
         */ this.input = undefined;
        /**
         * The container of all of the players
         */ this._players = new Map();
        /**
         * The output volume node
         */ this._volume = this.output = new (0, _volumeJs.Volume)({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        (0, _interfaceJs.readOnly)(this, "volume");
        this._buffers = new (0, _toneAudioBuffersJs.ToneAudioBuffers)({
            urls: options.urls,
            onload: options.onload,
            baseUrl: options.baseUrl,
            onerror: options.onerror
        });
        // mute initially
        this.mute = options.mute;
        this._fadeIn = options.fadeIn;
        this._fadeOut = options.fadeOut;
    }
    static getDefaults() {
        return Object.assign((0, _sourceJs.Source).getDefaults(), {
            baseUrl: "",
            fadeIn: 0,
            fadeOut: 0,
            mute: false,
            onload: (0, _interfaceJs.noOp),
            onerror: (0, _interfaceJs.noOp),
            urls: {},
            volume: 0
        });
    }
    /**
     * Mute the output.
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    /**
     * The fadeIn time of the envelope applied to the source.
     */ get fadeIn() {
        return this._fadeIn;
    }
    set fadeIn(fadeIn) {
        this._fadeIn = fadeIn;
        this._players.forEach((player)=>{
            player.fadeIn = fadeIn;
        });
    }
    /**
     * The fadeOut time of the each of the sources.
     */ get fadeOut() {
        return this._fadeOut;
    }
    set fadeOut(fadeOut) {
        this._fadeOut = fadeOut;
        this._players.forEach((player)=>{
            player.fadeOut = fadeOut;
        });
    }
    /**
     * The state of the players object. Returns "started" if any of the players are playing.
     */ get state() {
        const playing = Array.from(this._players).some(([_, player])=>player.state === "started");
        return playing ? "started" : "stopped";
    }
    /**
     * True if the buffers object has a buffer by that name.
     * @param name  The key or index of the buffer.
     */ has(name) {
        return this._buffers.has(name);
    }
    /**
     * Get a player by name.
     * @param  name  The players name as defined in the constructor object or `add` method.
     */ player(name) {
        (0, _debugJs.assert)(this.has(name), `No Player with the name ${name} exists on this object`);
        if (!this._players.has(name)) {
            const player = new (0, _playerJs.Player)({
                context: this.context,
                fadeIn: this._fadeIn,
                fadeOut: this._fadeOut,
                url: this._buffers.get(name)
            }).connect(this.output);
            this._players.set(name, player);
        }
        return this._players.get(name);
    }
    /**
     * If all the buffers are loaded or not
     */ get loaded() {
        return this._buffers.loaded;
    }
    /**
     * Add a player by name and url to the Players
     * @param  name A unique name to give the player
     * @param  url  Either the url of the bufer or a buffer which will be added with the given name.
     * @param callback  The callback to invoke when the url is loaded.
     * @example
     * const players = new Tone.Players();
     * players.add("gong", "https://tonejs.github.io/audio/berklee/gong_1.mp3", () => {
     * 	console.log("gong loaded");
     * 	players.player("gong").start();
     * });
     */ add(name, url, callback) {
        (0, _debugJs.assert)(!this._buffers.has(name), "A buffer with that name already exists on this object");
        this._buffers.add(name, url, callback);
        return this;
    }
    /**
     * Stop all of the players at the given time
     * @param time The time to stop all of the players.
     */ stopAll(time) {
        this._players.forEach((player)=>player.stop(time));
        return this;
    }
    dispose() {
        super.dispose();
        this._volume.dispose();
        this.volume.dispose();
        this._players.forEach((player)=>player.dispose());
        this._buffers.dispose();
        return this;
    }
}

},{"../../component/channel/Volume.js":"7Ooeo","../../core/context/ToneAudioBuffers.js":"8zO1I","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/Debug.js":"2lOIQ","../../core/util/Interface.js":"hVOjA","../Source.js":"eBYFz","./Player.js":"4UJCG","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"opCGx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * GrainPlayer implements [granular synthesis](https://en.wikipedia.org/wiki/Granular_synthesis).
 * Granular Synthesis enables you to adjust pitch and playback rate independently. The grainSize is the
 * amount of time each small chunk of audio is played for and the overlap is the
 * amount of crossfading transition time between successive grains.
 * @category Source
 */ parcelHelpers.export(exports, "GrainPlayer", ()=>GrainPlayer);
var _sourceJs = require("../Source.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _toneAudioBufferJs = require("../../core/context/ToneAudioBuffer.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _clockJs = require("../../core/clock/Clock.js");
var _toneBufferSourceJs = require("./ToneBufferSource.js");
var _conversionsJs = require("../../core/type/Conversions.js");
var _debugJs = require("../../core/util/Debug.js");
class GrainPlayer extends (0, _sourceJs.Source) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(GrainPlayer.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        super(options);
        this.name = "GrainPlayer";
        /**
         * Internal loopStart value
         */ this._loopStart = 0;
        /**
         * Internal loopStart value
         */ this._loopEnd = 0;
        /**
         * All of the currently playing BufferSources
         */ this._activeSources = [];
        this.buffer = new (0, _toneAudioBufferJs.ToneAudioBuffer)({
            onload: options.onload,
            onerror: options.onerror,
            reverse: options.reverse,
            url: options.url
        });
        this._clock = new (0, _clockJs.Clock)({
            context: this.context,
            callback: this._tick.bind(this),
            frequency: 1 / options.grainSize
        });
        this._playbackRate = options.playbackRate;
        this._grainSize = options.grainSize;
        this._overlap = options.overlap;
        this.detune = options.detune;
        // setup
        this.overlap = options.overlap;
        this.loop = options.loop;
        this.playbackRate = options.playbackRate;
        this.grainSize = options.grainSize;
        this.loopStart = options.loopStart;
        this.loopEnd = options.loopEnd;
        this.reverse = options.reverse;
        this._clock.on("stop", this._onstop.bind(this));
    }
    static getDefaults() {
        return Object.assign((0, _sourceJs.Source).getDefaults(), {
            onload: (0, _interfaceJs.noOp),
            onerror: (0, _interfaceJs.noOp),
            overlap: 0.1,
            grainSize: 0.2,
            playbackRate: 1,
            detune: 0,
            loop: false,
            loopStart: 0,
            loopEnd: 0,
            reverse: false
        });
    }
    /**
     * Internal start method
     */ _start(time, offset, duration) {
        offset = (0, _defaultsJs.defaultArg)(offset, 0);
        offset = this.toSeconds(offset);
        time = this.toSeconds(time);
        const grainSize = 1 / this._clock.frequency.getValueAtTime(time);
        this._clock.start(time, offset / grainSize);
        if (duration) this.stop(time + this.toSeconds(duration));
    }
    /**
     * Stop and then restart the player from the beginning (or offset)
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given,
     * 					it will default to the full length of the sample (minus any offset)
     */ restart(time, offset, duration) {
        super.restart(time, offset, duration);
        return this;
    }
    _restart(time, offset, duration) {
        this._stop(time);
        this._start(time, offset, duration);
    }
    /**
     * Internal stop method
     */ _stop(time) {
        this._clock.stop(time);
    }
    /**
     * Invoked when the clock is stopped
     */ _onstop(time) {
        // stop the players
        this._activeSources.forEach((source)=>{
            source.fadeOut = 0;
            source.stop(time);
        });
        this.onstop(this);
    }
    /**
     * Invoked on each clock tick. scheduled a new grain at this time.
     */ _tick(time) {
        // check if it should stop looping
        const ticks = this._clock.getTicksAtTime(time);
        const offset = ticks * this._grainSize;
        this.log("offset", offset);
        if (!this.loop && offset > this.buffer.duration) {
            this.stop(time);
            return;
        }
        // at the beginning of the file, the fade in should be 0
        const fadeIn = offset < this._overlap ? 0 : this._overlap;
        // create a buffer source
        const source = new (0, _toneBufferSourceJs.ToneBufferSource)({
            context: this.context,
            url: this.buffer,
            fadeIn: fadeIn,
            fadeOut: this._overlap,
            loop: this.loop,
            loopStart: this._loopStart,
            loopEnd: this._loopEnd,
            // compute the playbackRate based on the detune
            playbackRate: (0, _conversionsJs.intervalToFrequencyRatio)(this.detune / 100)
        }).connect(this.output);
        source.start(time, this._grainSize * ticks);
        source.stop(time + this._grainSize / this.playbackRate);
        // add it to the active sources
        this._activeSources.push(source);
        // remove it when it's done
        source.onended = ()=>{
            const index = this._activeSources.indexOf(source);
            if (index !== -1) this._activeSources.splice(index, 1);
        };
    }
    /**
     * The playback rate of the sample
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        (0, _debugJs.assertRange)(rate, 0.001);
        this._playbackRate = rate;
        this.grainSize = this._grainSize;
    }
    /**
     * The loop start time.
     */ get loopStart() {
        return this._loopStart;
    }
    set loopStart(time) {
        if (this.buffer.loaded) (0, _debugJs.assertRange)(this.toSeconds(time), 0, this.buffer.duration);
        this._loopStart = this.toSeconds(time);
    }
    /**
     * The loop end time.
     */ get loopEnd() {
        return this._loopEnd;
    }
    set loopEnd(time) {
        if (this.buffer.loaded) (0, _debugJs.assertRange)(this.toSeconds(time), 0, this.buffer.duration);
        this._loopEnd = this.toSeconds(time);
    }
    /**
     * The direction the buffer should play in
     */ get reverse() {
        return this.buffer.reverse;
    }
    set reverse(rev) {
        this.buffer.reverse = rev;
    }
    /**
     * The size of each chunk of audio that the
     * buffer is chopped into and played back at.
     */ get grainSize() {
        return this._grainSize;
    }
    set grainSize(size) {
        this._grainSize = this.toSeconds(size);
        this._clock.frequency.setValueAtTime(this._playbackRate / this._grainSize, this.now());
    }
    /**
     * The duration of the cross-fade between successive grains.
     */ get overlap() {
        return this._overlap;
    }
    set overlap(time) {
        const computedTime = this.toSeconds(time);
        (0, _debugJs.assertRange)(computedTime, 0);
        this._overlap = computedTime;
    }
    /**
     * If all the buffer is loaded
     */ get loaded() {
        return this.buffer.loaded;
    }
    dispose() {
        super.dispose();
        this.buffer.dispose();
        this._clock.dispose();
        this._activeSources.forEach((source)=>source.dispose());
        return this;
    }
}

},{"../Source.js":"eBYFz","../../core/util/Interface.js":"hVOjA","../../core/context/ToneAudioBuffer.js":"8aSPC","../../core/util/Defaults.js":"a9M5s","../../core/clock/Clock.js":"52dVv","./ToneBufferSource.js":"9FxEt","../../core/type/Conversions.js":"iww1u","../../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kDXus":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _addJs = require("./Add.js");
parcelHelpers.exportAll(_addJs, exports);
var _absJs = require("./Abs.js");
parcelHelpers.exportAll(_absJs, exports);
var _audioToGainJs = require("./AudioToGain.js");
parcelHelpers.exportAll(_audioToGainJs, exports);
var _gainToAudioJs = require("./GainToAudio.js");
parcelHelpers.exportAll(_gainToAudioJs, exports);
var _greaterThanJs = require("./GreaterThan.js");
parcelHelpers.exportAll(_greaterThanJs, exports);
var _greaterThanZeroJs = require("./GreaterThanZero.js");
parcelHelpers.exportAll(_greaterThanZeroJs, exports);
var _multiplyJs = require("./Multiply.js");
parcelHelpers.exportAll(_multiplyJs, exports);
var _negateJs = require("./Negate.js");
parcelHelpers.exportAll(_negateJs, exports);
var _powJs = require("./Pow.js");
parcelHelpers.exportAll(_powJs, exports);
var _signalJs = require("./Signal.js");
parcelHelpers.exportAll(_signalJs, exports);
var _scaleJs = require("./Scale.js");
parcelHelpers.exportAll(_scaleJs, exports);
var _scaleExpJs = require("./ScaleExp.js");
parcelHelpers.exportAll(_scaleExpJs, exports);
var _subtractJs = require("./Subtract.js");
parcelHelpers.exportAll(_subtractJs, exports);
var _syncedSignalJs = require("./SyncedSignal.js");
parcelHelpers.exportAll(_syncedSignalJs, exports);
var _waveShaperJs = require("./WaveShaper.js");
parcelHelpers.exportAll(_waveShaperJs, exports);
var _zeroJs = require("./Zero.js");
parcelHelpers.exportAll(_zeroJs, exports);

},{"./Add.js":"jeoK8","./Abs.js":"91cHq","./AudioToGain.js":"kLli1","./GainToAudio.js":"g3Bng","./GreaterThan.js":"gPdXT","./GreaterThanZero.js":"hu7tO","./Multiply.js":"4C0VG","./Negate.js":"9nMgn","./Pow.js":"9vO86","./Signal.js":"980ri","./Scale.js":"3qxrw","./ScaleExp.js":"aFAXE","./Subtract.js":"cVmeJ","./SyncedSignal.js":"9n5vu","./WaveShaper.js":"k4nzV","./Zero.js":"5ROIx","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"91cHq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Return the absolute value of an incoming signal.
 *
 * @example
 * return Tone.Offline(() => {
 * 	const abs = new Tone.Abs().toDestination();
 * 	const signal = new Tone.Signal(1);
 * 	signal.rampTo(-1, 0.5);
 * 	signal.connect(abs);
 * }, 0.5, 1);
 * @category Signal
 */ parcelHelpers.export(exports, "Abs", ()=>Abs);
var _signalOperatorJs = require("./SignalOperator.js");
var _waveShaperJs = require("./WaveShaper.js");
class Abs extends (0, _signalOperatorJs.SignalOperator) {
    constructor(){
        super(...arguments);
        this.name = "Abs";
        /**
         * The node which converts the audio ranges
         */ this._abs = new (0, _waveShaperJs.WaveShaper)({
            context: this.context,
            mapping: (val)=>{
                if (Math.abs(val) < 0.001) return 0;
                else return Math.abs(val);
            }
        });
        /**
         * The AudioRange input [-1, 1]
         */ this.input = this._abs;
        /**
         * The output range [0, 1]
         */ this.output = this._abs;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._abs.dispose();
        return this;
    }
}

},{"./SignalOperator.js":"4XSes","./WaveShaper.js":"k4nzV","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g3Bng":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * GainToAudio converts an input in NormalRange [0,1] to AudioRange [-1,1].
 * @see {@link AudioToGain}.
 * @category Signal
 */ parcelHelpers.export(exports, "GainToAudio", ()=>GainToAudio);
var _signalOperatorJs = require("./SignalOperator.js");
var _waveShaperJs = require("./WaveShaper.js");
class GainToAudio extends (0, _signalOperatorJs.SignalOperator) {
    constructor(){
        super(...arguments);
        this.name = "GainToAudio";
        /**
         * The node which converts the audio ranges
         */ this._norm = new (0, _waveShaperJs.WaveShaper)({
            context: this.context,
            mapping: (x)=>Math.abs(x) * 2 - 1
        });
        /**
         * The NormalRange input [0, 1]
         */ this.input = this._norm;
        /**
         * The AudioRange output [-1, 1]
         */ this.output = this._norm;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._norm.dispose();
        return this;
    }
}

},{"./SignalOperator.js":"4XSes","./WaveShaper.js":"k4nzV","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gPdXT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Output 1 if the signal is greater than the value, otherwise outputs 0.
 * can compare two signals or a signal and a number.
 *
 * @example
 * return Tone.Offline(() => {
 * 	const gt = new Tone.GreaterThan(2).toDestination();
 * 	const sig = new Tone.Signal(4).connect(gt);
 * }, 0.1, 1);
 * @category Signal
 */ parcelHelpers.export(exports, "GreaterThan", ()=>GreaterThan);
var _defaultsJs = require("../core/util/Defaults.js");
var _subtractJs = require("./Subtract.js");
var _signalJs = require("./Signal.js");
var _greaterThanZeroJs = require("./GreaterThanZero.js");
var _interfaceJs = require("../core/util/Interface.js");
class GreaterThan extends (0, _signalJs.Signal) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(GreaterThan.getDefaults(), arguments, [
            "value"
        ]);
        super(options);
        this.name = "GreaterThan";
        this.override = false;
        this._subtract = this.input = new (0, _subtractJs.Subtract)({
            context: this.context,
            value: options.value
        });
        this._gtz = this.output = new (0, _greaterThanZeroJs.GreaterThanZero)({
            context: this.context
        });
        this.comparator = this._param = this._subtract.subtrahend;
        (0, _interfaceJs.readOnly)(this, "comparator");
        // connect
        this._subtract.connect(this._gtz);
    }
    static getDefaults() {
        return Object.assign((0, _signalJs.Signal).getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._gtz.dispose();
        this._subtract.dispose();
        this.comparator.dispose();
        return this;
    }
}

},{"../core/util/Defaults.js":"a9M5s","./Subtract.js":"cVmeJ","./Signal.js":"980ri","./GreaterThanZero.js":"hu7tO","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cVmeJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Subtract the signal connected to the input is subtracted from the signal connected
 * The subtrahend.
 *
 * @example
 * // subtract a scalar from a signal
 * const sub = new Tone.Subtract(1);
 * const sig = new Tone.Signal(4).connect(sub);
 * // the output of sub is 3.
 * @example
 * // subtract two signals
 * const sub = new Tone.Subtract();
 * const sigA = new Tone.Signal(10);
 * const sigB = new Tone.Signal(2.5);
 * sigA.connect(sub);
 * sigB.connect(sub.subtrahend);
 * // output of sub is 7.5
 * @category Signal
 */ parcelHelpers.export(exports, "Subtract", ()=>Subtract);
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _gainJs = require("../core/context/Gain.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _negateJs = require("../signal/Negate.js");
var _signalJs = require("../signal/Signal.js");
class Subtract extends (0, _signalJs.Signal) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(Subtract.getDefaults(), arguments, [
            "value"
        ]));
        this.override = false;
        this.name = "Subtract";
        /**
         * the summing node
         */ this._sum = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.input = this._sum;
        this.output = this._sum;
        /**
         * Negate the input of the second input before connecting it to the summing node.
         */ this._neg = new (0, _negateJs.Negate)({
            context: this.context
        });
        /**
         * The value which is subtracted from the main signal
         */ this.subtrahend = this._param;
        (0, _toneAudioNodeJs.connectSeries)(this._constantSource, this._neg, this._sum);
    }
    static getDefaults() {
        return Object.assign((0, _signalJs.Signal).getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._neg.dispose();
        this._sum.dispose();
        return this;
    }
}

},{"../core/context/ToneAudioNode.js":"kZ3Kj","../core/context/Gain.js":"kj68Y","../core/util/Defaults.js":"a9M5s","../signal/Negate.js":"9nMgn","../signal/Signal.js":"980ri","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9nMgn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Negate the incoming signal. i.e. an input signal of 10 will output -10
 *
 * @example
 * const neg = new Tone.Negate();
 * const sig = new Tone.Signal(-2).connect(neg);
 * // output of neg is positive 2.
 * @category Signal
 */ parcelHelpers.export(exports, "Negate", ()=>Negate);
var _multiplyJs = require("./Multiply.js");
var _signalOperatorJs = require("./SignalOperator.js");
class Negate extends (0, _signalOperatorJs.SignalOperator) {
    constructor(){
        super(...arguments);
        this.name = "Negate";
        /**
         * negation is done by multiplying by -1
         */ this._multiply = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: -1
        });
        /**
         * The input and output are equal to the multiply node
         */ this.input = this._multiply;
        this.output = this._multiply;
    }
    /**
     * clean up
     * @returns {Negate} this
     */ dispose() {
        super.dispose();
        this._multiply.dispose();
        return this;
    }
}

},{"./Multiply.js":"4C0VG","./SignalOperator.js":"4XSes","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hu7tO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * GreaterThanZero outputs 1 when the input is strictly greater than zero
 * @example
 * return Tone.Offline(() => {
 * 	const gt0 = new Tone.GreaterThanZero().toDestination();
 * 	const sig = new Tone.Signal(0.5).connect(gt0);
 * 	sig.setValueAtTime(-1, 0.05);
 * }, 0.1, 1);
 * @category Signal
 */ parcelHelpers.export(exports, "GreaterThanZero", ()=>GreaterThanZero);
var _signalOperatorJs = require("./SignalOperator.js");
var _multiplyJs = require("./Multiply.js");
var _waveShaperJs = require("./WaveShaper.js");
var _defaultsJs = require("../core/util/Defaults.js");
class GreaterThanZero extends (0, _signalOperatorJs.SignalOperator) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(GreaterThanZero.getDefaults(), arguments));
        this.name = "GreaterThanZero";
        this._thresh = this.output = new (0, _waveShaperJs.WaveShaper)({
            context: this.context,
            length: 127,
            mapping: (val)=>{
                if (val <= 0) return 0;
                else return 1;
            }
        });
        this._scale = this.input = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: 10000
        });
        // connections
        this._scale.connect(this._thresh);
    }
    dispose() {
        super.dispose();
        this._scale.dispose();
        this._thresh.dispose();
        return this;
    }
}

},{"./SignalOperator.js":"4XSes","./Multiply.js":"4C0VG","./WaveShaper.js":"k4nzV","../core/util/Defaults.js":"a9M5s","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aFAXE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Performs an exponential scaling on an input signal.
 * Scales a NormalRange value [0,1] exponentially
 * to the output range of outputMin to outputMax.
 * @example
 * const scaleExp = new Tone.ScaleExp(0, 100, 2);
 * const signal = new Tone.Signal(0.5).connect(scaleExp);
 * @category Signal
 */ parcelHelpers.export(exports, "ScaleExp", ()=>ScaleExp);
var _scaleJs = require("./Scale.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _powJs = require("./Pow.js");
class ScaleExp extends (0, _scaleJs.Scale) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(ScaleExp.getDefaults(), arguments, [
            "min",
            "max",
            "exponent"
        ]);
        super(options);
        this.name = "ScaleExp";
        this.input = this._exp = new (0, _powJs.Pow)({
            context: this.context,
            value: options.exponent
        });
        this._exp.connect(this._mult);
    }
    static getDefaults() {
        return Object.assign((0, _scaleJs.Scale).getDefaults(), {
            exponent: 1
        });
    }
    /**
     * Instead of interpolating linearly between the {@link min} and
     * {@link max} values, setting the exponent will interpolate between
     * the two values with an exponential curve.
     */ get exponent() {
        return this._exp.value;
    }
    set exponent(exp) {
        this._exp.value = exp;
    }
    dispose() {
        super.dispose();
        this._exp.dispose();
        return this;
    }
}

},{"./Scale.js":"3qxrw","../core/util/Defaults.js":"a9M5s","./Pow.js":"9vO86","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9n5vu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Adds the ability to synchronize the signal to the {@link TransportClass}
 * @category Signal
 */ parcelHelpers.export(exports, "SyncedSignal", ()=>SyncedSignal);
var _signalJs = require("./Signal.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _transportTimeJs = require("../core/type/TransportTime.js");
var _toneConstantSourceJs = require("./ToneConstantSource.js");
class SyncedSignal extends (0, _signalJs.Signal) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)((0, _signalJs.Signal).getDefaults(), arguments, [
            "value",
            "units"
        ]);
        super(options);
        this.name = "SyncedSignal";
        /**
         * Don't override when something is connected to the input
         */ this.override = false;
        this._lastVal = options.value;
        this._synced = this.context.transport.scheduleRepeat(this._onTick.bind(this), "1i");
        this._syncedCallback = this._anchorValue.bind(this);
        this.context.transport.on("start", this._syncedCallback);
        this.context.transport.on("pause", this._syncedCallback);
        this.context.transport.on("stop", this._syncedCallback);
        // disconnect the constant source from the output and replace it with another one
        this._constantSource.disconnect();
        this._constantSource.stop(0);
        // create a new one
        this._constantSource = this.output = new (0, _toneConstantSourceJs.ToneConstantSource)({
            context: this.context,
            offset: options.value,
            units: options.units
        }).start(0);
        this.setValueAtTime(options.value, 0);
    }
    /**
     * Callback which is invoked every tick.
     */ _onTick(time) {
        const val = super.getValueAtTime(this.context.transport.seconds);
        // approximate ramp curves with linear ramps
        if (this._lastVal !== val) {
            this._lastVal = val;
            this._constantSource.offset.setValueAtTime(val, time);
        }
    }
    /**
     * Anchor the value at the start and stop of the Transport
     */ _anchorValue(time) {
        const val = super.getValueAtTime(this.context.transport.seconds);
        this._lastVal = val;
        this._constantSource.offset.cancelAndHoldAtTime(time);
        this._constantSource.offset.setValueAtTime(val, time);
    }
    getValueAtTime(time) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, time).toSeconds();
        return super.getValueAtTime(computedTime);
    }
    setValueAtTime(value, time) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, time).toSeconds();
        super.setValueAtTime(value, computedTime);
        return this;
    }
    linearRampToValueAtTime(value, time) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, time).toSeconds();
        super.linearRampToValueAtTime(value, computedTime);
        return this;
    }
    exponentialRampToValueAtTime(value, time) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, time).toSeconds();
        super.exponentialRampToValueAtTime(value, computedTime);
        return this;
    }
    setTargetAtTime(value, startTime, timeConstant) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, startTime).toSeconds();
        super.setTargetAtTime(value, computedTime, timeConstant);
        return this;
    }
    cancelScheduledValues(startTime) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, startTime).toSeconds();
        super.cancelScheduledValues(computedTime);
        return this;
    }
    setValueCurveAtTime(values, startTime, duration, scaling) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, startTime).toSeconds();
        duration = this.toSeconds(duration);
        super.setValueCurveAtTime(values, computedTime, duration, scaling);
        return this;
    }
    cancelAndHoldAtTime(time) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, time).toSeconds();
        super.cancelAndHoldAtTime(computedTime);
        return this;
    }
    setRampPoint(time) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, time).toSeconds();
        super.setRampPoint(computedTime);
        return this;
    }
    exponentialRampTo(value, rampTime, startTime) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, startTime).toSeconds();
        super.exponentialRampTo(value, rampTime, computedTime);
        return this;
    }
    linearRampTo(value, rampTime, startTime) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, startTime).toSeconds();
        super.linearRampTo(value, rampTime, computedTime);
        return this;
    }
    targetRampTo(value, rampTime, startTime) {
        const computedTime = new (0, _transportTimeJs.TransportTimeClass)(this.context, startTime).toSeconds();
        super.targetRampTo(value, rampTime, computedTime);
        return this;
    }
    dispose() {
        super.dispose();
        this.context.transport.clear(this._synced);
        this.context.transport.off("start", this._syncedCallback);
        this.context.transport.off("pause", this._syncedCallback);
        this.context.transport.off("stop", this._syncedCallback);
        this._constantSource.dispose();
        return this;
    }
}

},{"./Signal.js":"980ri","../core/util/Defaults.js":"a9M5s","../core/type/TransportTime.js":"a6yW0","./ToneConstantSource.js":"aU7Ju","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ed4wq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _amsynthJs = require("./AMSynth.js");
parcelHelpers.exportAll(_amsynthJs, exports);
var _duoSynthJs = require("./DuoSynth.js");
parcelHelpers.exportAll(_duoSynthJs, exports);
var _fmsynthJs = require("./FMSynth.js");
parcelHelpers.exportAll(_fmsynthJs, exports);
var _metalSynthJs = require("./MetalSynth.js");
parcelHelpers.exportAll(_metalSynthJs, exports);
var _membraneSynthJs = require("./MembraneSynth.js");
parcelHelpers.exportAll(_membraneSynthJs, exports);
var _monoSynthJs = require("./MonoSynth.js");
parcelHelpers.exportAll(_monoSynthJs, exports);
var _noiseSynthJs = require("./NoiseSynth.js");
parcelHelpers.exportAll(_noiseSynthJs, exports);
var _pluckSynthJs = require("./PluckSynth.js");
parcelHelpers.exportAll(_pluckSynthJs, exports);
var _polySynthJs = require("./PolySynth.js");
parcelHelpers.exportAll(_polySynthJs, exports);
var _samplerJs = require("./Sampler.js");
parcelHelpers.exportAll(_samplerJs, exports);
var _synthJs = require("./Synth.js");
parcelHelpers.exportAll(_synthJs, exports);

},{"./AMSynth.js":"jPnoh","./DuoSynth.js":"batNh","./FMSynth.js":"9ms3z","./MetalSynth.js":"itJ1n","./MembraneSynth.js":"gVrZJ","./MonoSynth.js":"jT7JE","./NoiseSynth.js":"hhi7P","./PluckSynth.js":"4DPlg","./PolySynth.js":"6hx2H","./Sampler.js":"dBIID","./Synth.js":"kwmGi","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jPnoh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AMSynth uses the output of one Tone.Synth to modulate the
 * amplitude of another Tone.Synth. The harmonicity (the ratio between
 * the two signals) affects the timbre of the output signal greatly.
 * Read more about Amplitude Modulation Synthesis on
 * [SoundOnSound](https://web.archive.org/web/20160404103653/http://www.soundonsound.com:80/sos/mar00/articles/synthsecrets.htm).
 *
 * @example
 * const synth = new Tone.AMSynth().toDestination();
 * synth.triggerAttackRelease("C4", "4n");
 *
 * @category Instrument
 */ parcelHelpers.export(exports, "AMSynth", ()=>AMSynth);
var _audioToGainJs = require("../signal/AudioToGain.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _modulationSynthJs = require("./ModulationSynth.js");
class AMSynth extends (0, _modulationSynthJs.ModulationSynth) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(AMSynth.getDefaults(), arguments));
        this.name = "AMSynth";
        this._modulationScale = new (0, _audioToGainJs.AudioToGain)({
            context: this.context
        });
        // control the two voices frequency
        this.frequency.connect(this._carrier.frequency);
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this.detune.fan(this._carrier.detune, this._modulator.detune);
        this._modulator.chain(this._modulationScale, this._modulationNode.gain);
        this._carrier.chain(this._modulationNode, this.output);
    }
    dispose() {
        super.dispose();
        this._modulationScale.dispose();
        return this;
    }
}

},{"../signal/AudioToGain.js":"kLli1","../core/util/Defaults.js":"a9M5s","./ModulationSynth.js":"3DhsT","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3DhsT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for both AM and FM synths
 */ parcelHelpers.export(exports, "ModulationSynth", ()=>ModulationSynth);
var _signalJs = require("../signal/Signal.js");
var _multiplyJs = require("../signal/Multiply.js");
var _gainJs = require("../core/context/Gain.js");
var _envelopeJs = require("../component/envelope/Envelope.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _monophonicJs = require("./Monophonic.js");
var _omniOscillatorJs = require("../source/oscillator/OmniOscillator.js");
var _sourceJs = require("../source/Source.js");
var _synthJs = require("./Synth.js");
var _interfaceJs = require("../core/util/Interface.js");
var _defaultsJs = require("../core/util/Defaults.js");
class ModulationSynth extends (0, _monophonicJs.Monophonic) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(ModulationSynth.getDefaults(), arguments);
        super(options);
        this.name = "ModulationSynth";
        this._carrier = new (0, _synthJs.Synth)({
            context: this.context,
            oscillator: options.oscillator,
            envelope: options.envelope,
            onsilence: ()=>this.onsilence(this),
            volume: -10
        });
        this._modulator = new (0, _synthJs.Synth)({
            context: this.context,
            oscillator: options.modulation,
            envelope: options.modulationEnvelope,
            volume: -10
        });
        this.oscillator = this._carrier.oscillator;
        this.envelope = this._carrier.envelope;
        this.modulation = this._modulator.oscillator;
        this.modulationEnvelope = this._modulator.envelope;
        this.frequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency"
        });
        this.detune = new (0, _signalJs.Signal)({
            context: this.context,
            value: options.detune,
            units: "cents"
        });
        this.harmonicity = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: options.harmonicity,
            minValue: 0
        });
        this._modulationNode = new (0, _gainJs.Gain)({
            context: this.context,
            gain: 0
        });
        (0, _interfaceJs.readOnly)(this, [
            "frequency",
            "harmonicity",
            "oscillator",
            "envelope",
            "modulation",
            "modulationEnvelope",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _monophonicJs.Monophonic).getDefaults(), {
            harmonicity: 3,
            oscillator: Object.assign((0, _defaultsJs.omitFromObject)((0, _omniOscillatorJs.OmniOscillator).getDefaults(), [
                ...Object.keys((0, _sourceJs.Source).getDefaults()),
                "frequency",
                "detune"
            ]), {
                type: "sine"
            }),
            envelope: Object.assign((0, _defaultsJs.omitFromObject)((0, _envelopeJs.Envelope).getDefaults(), Object.keys((0, _toneAudioNodeJs.ToneAudioNode).getDefaults())), {
                attack: 0.01,
                decay: 0.01,
                sustain: 1,
                release: 0.5
            }),
            modulation: Object.assign((0, _defaultsJs.omitFromObject)((0, _omniOscillatorJs.OmniOscillator).getDefaults(), [
                ...Object.keys((0, _sourceJs.Source).getDefaults()),
                "frequency",
                "detune"
            ]), {
                type: "square"
            }),
            modulationEnvelope: Object.assign((0, _defaultsJs.omitFromObject)((0, _envelopeJs.Envelope).getDefaults(), Object.keys((0, _toneAudioNodeJs.ToneAudioNode).getDefaults())), {
                attack: 0.5,
                decay: 0.0,
                sustain: 1,
                release: 0.5
            })
        });
    }
    /**
     * Trigger the attack portion of the note
     */ _triggerEnvelopeAttack(time, velocity) {
        // @ts-ignore
        this._carrier._triggerEnvelopeAttack(time, velocity);
        // @ts-ignore
        this._modulator._triggerEnvelopeAttack(time, velocity);
    }
    /**
     * Trigger the release portion of the note
     */ _triggerEnvelopeRelease(time) {
        // @ts-ignore
        this._carrier._triggerEnvelopeRelease(time);
        // @ts-ignore
        this._modulator._triggerEnvelopeRelease(time);
        return this;
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    dispose() {
        super.dispose();
        this._carrier.dispose();
        this._modulator.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this.harmonicity.dispose();
        this._modulationNode.dispose();
        return this;
    }
}

},{"../signal/Signal.js":"980ri","../signal/Multiply.js":"4C0VG","../core/context/Gain.js":"kj68Y","../component/envelope/Envelope.js":"cU1tT","../core/context/ToneAudioNode.js":"kZ3Kj","./Monophonic.js":"eKiiZ","../source/oscillator/OmniOscillator.js":"7bzEJ","../source/Source.js":"eBYFz","./Synth.js":"kwmGi","../core/util/Interface.js":"hVOjA","../core/util/Defaults.js":"a9M5s","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cU1tT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Envelope is an [ADSR](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)
 * envelope generator. Envelope outputs a signal which
 * can be connected to an AudioParam or Tone.Signal.
 * ```
 *           /\
 *          /  \
 *         /    \
 *        /      \
 *       /        \___________
 *      /                     \
 *     /                       \
 *    /                         \
 *   /                           \
 * ```
 * @example
 * return Tone.Offline(() => {
 * 	const env = new Tone.Envelope({
 * 		attack: 0.1,
 * 		decay: 0.2,
 * 		sustain: 0.5,
 * 		release: 0.8,
 * 	}).toDestination();
 * 	env.triggerAttackRelease(0.5);
 * }, 1.5, 1);
 * @category Component
 */ parcelHelpers.export(exports, "Envelope", ()=>Envelope);
var _tslib = require("tslib");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _typeCheckJs = require("../../core/util/TypeCheck.js");
var _signalJs = require("../../signal/Signal.js");
var _offlineContextJs = require("../../core/context/OfflineContext.js");
var _debugJs = require("../../core/util/Debug.js");
var _decoratorJs = require("../../core/util/Decorator.js");
class Envelope extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Envelope.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]);
        super(options);
        this.name = "Envelope";
        /**
         * the signal which is output.
         */ this._sig = new (0, _signalJs.Signal)({
            context: this.context,
            value: 0
        });
        /**
         * The output signal of the envelope
         */ this.output = this._sig;
        /**
         * Envelope has no input
         */ this.input = undefined;
        this.attack = options.attack;
        this.decay = options.decay;
        this.sustain = options.sustain;
        this.release = options.release;
        this.attackCurve = options.attackCurve;
        this.releaseCurve = options.releaseCurve;
        this.decayCurve = options.decayCurve;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            attack: 0.01,
            attackCurve: "linear",
            decay: 0.1,
            decayCurve: "exponential",
            release: 1,
            releaseCurve: "exponential",
            sustain: 0.5
        });
    }
    /**
     * Read the current value of the envelope. Useful for
     * synchronizing visual output to the envelope.
     */ get value() {
        return this.getValueAtTime(this.now());
    }
    /**
     * Get the curve
     * @param  curve
     * @param  direction  In/Out
     * @return The curve name
     */ _getCurve(curve, direction) {
        if ((0, _typeCheckJs.isString)(curve)) return curve;
        else {
            // look up the name in the curves array
            let curveName;
            for(curveName in EnvelopeCurves){
                if (EnvelopeCurves[curveName][direction] === curve) return curveName;
            }
            // return the custom curve
            return curve;
        }
    }
    /**
     * Assign a the curve to the given name using the direction
     * @param  name
     * @param  direction In/Out
     * @param  curve
     */ _setCurve(name, direction, curve) {
        // check if it's a valid type
        if ((0, _typeCheckJs.isString)(curve) && Reflect.has(EnvelopeCurves, curve)) {
            const curveDef = EnvelopeCurves[curve];
            if ((0, _typeCheckJs.isObject)(curveDef)) {
                if (name !== "_decayCurve") this[name] = curveDef[direction];
            } else this[name] = curveDef;
        } else if ((0, _typeCheckJs.isArray)(curve) && name !== "_decayCurve") this[name] = curve;
        else throw new Error("Envelope: invalid curve: " + curve);
    }
    /**
     * The shape of the attack.
     * Can be any of these strings:
     * * "linear"
     * * "exponential"
     * * "sine"
     * * "cosine"
     * * "bounce"
     * * "ripple"
     * * "step"
     *
     * Can also be an array which describes the curve. Values
     * in the array are evenly subdivided and linearly
     * interpolated over the duration of the attack.
     * @example
     * return Tone.Offline(() => {
     * 	const env = new Tone.Envelope(0.4).toDestination();
     * 	env.attackCurve = "linear";
     * 	env.triggerAttack();
     * }, 1, 1);
     */ get attackCurve() {
        return this._getCurve(this._attackCurve, "In");
    }
    set attackCurve(curve) {
        this._setCurve("_attackCurve", "In", curve);
    }
    /**
     * The shape of the release. See the attack curve types.
     * @example
     * return Tone.Offline(() => {
     * 	const env = new Tone.Envelope({
     * 		release: 0.8
     * 	}).toDestination();
     * 	env.triggerAttack();
     * 	// release curve could also be defined by an array
     * 	env.releaseCurve = [1, 0.3, 0.4, 0.2, 0.7, 0];
     * 	env.triggerRelease(0.2);
     * }, 1, 1);
     */ get releaseCurve() {
        return this._getCurve(this._releaseCurve, "Out");
    }
    set releaseCurve(curve) {
        this._setCurve("_releaseCurve", "Out", curve);
    }
    /**
     * The shape of the decay either "linear" or "exponential"
     * @example
     * return Tone.Offline(() => {
     * 	const env = new Tone.Envelope({
     * 		sustain: 0.1,
     * 		decay: 0.5
     * 	}).toDestination();
     * 	env.decayCurve = "linear";
     * 	env.triggerAttack();
     * }, 1, 1);
     */ get decayCurve() {
        return this._getCurve(this._decayCurve, "Out");
    }
    set decayCurve(curve) {
        this._setCurve("_decayCurve", "Out", curve);
    }
    /**
     * Trigger the attack/decay portion of the ADSR envelope.
     * @param  time When the attack should start.
     * @param velocity The velocity of the envelope scales the vales.
     *                             number between 0-1
     * @example
     * const env = new Tone.AmplitudeEnvelope().toDestination();
     * const osc = new Tone.Oscillator().connect(env).start();
     * // trigger the attack 0.5 seconds from now with a velocity of 0.2
     * env.triggerAttack("+0.5", 0.2);
     */ triggerAttack(time, velocity = 1) {
        this.log("triggerAttack", time, velocity);
        time = this.toSeconds(time);
        const originalAttack = this.toSeconds(this.attack);
        let attack = originalAttack;
        const decay = this.toSeconds(this.decay);
        // check if it's not a complete attack
        const currentValue = this.getValueAtTime(time);
        if (currentValue > 0) {
            // subtract the current value from the attack time
            const attackRate = 1 / attack;
            const remainingDistance = 1 - currentValue;
            // the attack is now the remaining time
            attack = remainingDistance / attackRate;
        }
        // attack
        if (attack < this.sampleTime) {
            this._sig.cancelScheduledValues(time);
            // case where the attack time is 0 should set instantly
            this._sig.setValueAtTime(velocity, time);
        } else if (this._attackCurve === "linear") this._sig.linearRampTo(velocity, attack, time);
        else if (this._attackCurve === "exponential") this._sig.targetRampTo(velocity, attack, time);
        else {
            this._sig.cancelAndHoldAtTime(time);
            let curve = this._attackCurve;
            // find the starting position in the curve
            for(let i = 1; i < curve.length; i++)// the starting index is between the two values
            if (curve[i - 1] <= currentValue && currentValue <= curve[i]) {
                curve = this._attackCurve.slice(i);
                // the first index is the current value
                curve[0] = currentValue;
                break;
            }
            this._sig.setValueCurveAtTime(curve, time, attack, velocity);
        }
        // decay
        if (decay && this.sustain < 1) {
            const decayValue = velocity * this.sustain;
            const decayStart = time + attack;
            this.log("decay", decayStart);
            if (this._decayCurve === "linear") this._sig.linearRampToValueAtTime(decayValue, decay + decayStart);
            else this._sig.exponentialApproachValueAtTime(decayValue, decayStart, decay);
        }
        return this;
    }
    /**
     * Triggers the release of the envelope.
     * @param  time When the release portion of the envelope should start.
     * @example
     * const env = new Tone.AmplitudeEnvelope().toDestination();
     * const osc = new Tone.Oscillator({
     * 	type: "sawtooth"
     * }).connect(env).start();
     * env.triggerAttack();
     * // trigger the release half a second after the attack
     * env.triggerRelease("+0.5");
     */ triggerRelease(time) {
        this.log("triggerRelease", time);
        time = this.toSeconds(time);
        const currentValue = this.getValueAtTime(time);
        if (currentValue > 0) {
            const release = this.toSeconds(this.release);
            if (release < this.sampleTime) this._sig.setValueAtTime(0, time);
            else if (this._releaseCurve === "linear") this._sig.linearRampTo(0, release, time);
            else if (this._releaseCurve === "exponential") this._sig.targetRampTo(0, release, time);
            else {
                (0, _debugJs.assert)((0, _typeCheckJs.isArray)(this._releaseCurve), "releaseCurve must be either 'linear', 'exponential' or an array");
                this._sig.cancelAndHoldAtTime(time);
                this._sig.setValueCurveAtTime(this._releaseCurve, time, release, currentValue);
            }
        }
        return this;
    }
    /**
     * Get the scheduled value at the given time. This will
     * return the unconverted (raw) value.
     * @example
     * const env = new Tone.Envelope(0.5, 1, 0.4, 2);
     * env.triggerAttackRelease(2);
     * setInterval(() => console.log(env.getValueAtTime(Tone.now())), 100);
     */ getValueAtTime(time) {
        return this._sig.getValueAtTime(time);
    }
    /**
     * triggerAttackRelease is shorthand for triggerAttack, then waiting
     * some duration, then triggerRelease.
     * @param duration The duration of the sustain.
     * @param time When the attack should be triggered.
     * @param velocity The velocity of the envelope.
     * @example
     * const env = new Tone.AmplitudeEnvelope().toDestination();
     * const osc = new Tone.Oscillator().connect(env).start();
     * // trigger the release 0.5 seconds after the attack
     * env.triggerAttackRelease(0.5);
     */ triggerAttackRelease(duration, time, velocity = 1) {
        time = this.toSeconds(time);
        this.triggerAttack(time, velocity);
        this.triggerRelease(time + this.toSeconds(duration));
        return this;
    }
    /**
     * Cancels all scheduled envelope changes after the given time.
     */ cancel(after) {
        this._sig.cancelScheduledValues(this.toSeconds(after));
        return this;
    }
    /**
     * Connect the envelope to a destination node.
     */ connect(destination, outputNumber = 0, inputNumber = 0) {
        (0, _signalJs.connectSignal)(this, destination, outputNumber, inputNumber);
        return this;
    }
    /**
     * Render the envelope curve to an array of the given length.
     * Good for visualizing the envelope curve. Rescales the duration of the
     * envelope to fit the length.
     */ asArray() {
        return (0, _tslib.__awaiter)(this, arguments, void 0, function*(length = 1024) {
            const duration = length / this.context.sampleRate;
            const context = new (0, _offlineContextJs.OfflineContext)(1, duration, this.context.sampleRate);
            // normalize the ADSR for the given duration with 20% sustain time
            const attackPortion = this.toSeconds(this.attack) + this.toSeconds(this.decay);
            const envelopeDuration = attackPortion + this.toSeconds(this.release);
            const sustainTime = envelopeDuration * 0.1;
            const totalDuration = envelopeDuration + sustainTime;
            // @ts-ignore
            const clone = new this.constructor(Object.assign(this.get(), {
                attack: duration * this.toSeconds(this.attack) / totalDuration,
                decay: duration * this.toSeconds(this.decay) / totalDuration,
                release: duration * this.toSeconds(this.release) / totalDuration,
                context
            }));
            clone._sig.toDestination();
            clone.triggerAttackRelease(duration * (attackPortion + sustainTime) / totalDuration, 0);
            const buffer = yield context.render();
            return buffer.getChannelData(0);
        });
    }
    dispose() {
        super.dispose();
        this._sig.dispose();
        return this;
    }
}
(0, _tslib.__decorate)([
    (0, _decoratorJs.timeRange)(0)
], Envelope.prototype, "attack", void 0);
(0, _tslib.__decorate)([
    (0, _decoratorJs.timeRange)(0)
], Envelope.prototype, "decay", void 0);
(0, _tslib.__decorate)([
    (0, _decoratorJs.range)(0, 1)
], Envelope.prototype, "sustain", void 0);
(0, _tslib.__decorate)([
    (0, _decoratorJs.timeRange)(0)
], Envelope.prototype, "release", void 0);
/**
 * Generate some complex envelope curves.
 */ const EnvelopeCurves = (()=>{
    const curveLen = 128;
    let i;
    let k;
    // cosine curve
    const cosineCurve = [];
    for(i = 0; i < curveLen; i++)cosineCurve[i] = Math.sin(i / (curveLen - 1) * (Math.PI / 2));
    // ripple curve
    const rippleCurve = [];
    const rippleCurveFreq = 6.4;
    for(i = 0; i < curveLen - 1; i++){
        k = i / (curveLen - 1);
        const sineWave = Math.sin(k * (Math.PI * 2) * rippleCurveFreq - Math.PI / 2) + 1;
        rippleCurve[i] = sineWave / 10 + k * 0.83;
    }
    rippleCurve[curveLen - 1] = 1;
    // stairs curve
    const stairsCurve = [];
    const steps = 5;
    for(i = 0; i < curveLen; i++)stairsCurve[i] = Math.ceil(i / (curveLen - 1) * steps) / steps;
    // in-out easing curve
    const sineCurve = [];
    for(i = 0; i < curveLen; i++){
        k = i / (curveLen - 1);
        sineCurve[i] = 0.5 * (1 - Math.cos(Math.PI * k));
    }
    // a bounce curve
    const bounceCurve = [];
    for(i = 0; i < curveLen; i++){
        k = i / (curveLen - 1);
        const freq = Math.pow(k, 3) * 4 + 0.2;
        const val = Math.cos(freq * Math.PI * 2 * k);
        bounceCurve[i] = Math.abs(val * (1 - k));
    }
    /**
     * Invert a value curve to make it work for the release
     */ function invertCurve(curve) {
        const out = new Array(curve.length);
        for(let j = 0; j < curve.length; j++)out[j] = 1 - curve[j];
        return out;
    }
    /**
     * reverse the curve
     */ function reverseCurve(curve) {
        return curve.slice(0).reverse();
    }
    /**
     * attack and release curve arrays
     */ return {
        bounce: {
            In: invertCurve(bounceCurve),
            Out: bounceCurve
        },
        cosine: {
            In: cosineCurve,
            Out: reverseCurve(cosineCurve)
        },
        exponential: "exponential",
        linear: "linear",
        ripple: {
            In: rippleCurve,
            Out: invertCurve(rippleCurve)
        },
        sine: {
            In: sineCurve,
            Out: invertCurve(sineCurve)
        },
        step: {
            In: stairsCurve,
            Out: invertCurve(stairsCurve)
        }
    };
})();

},{"tslib":"lRdW5","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/TypeCheck.js":"eMH5A","../../signal/Signal.js":"980ri","../../core/context/OfflineContext.js":"8VnAL","../../core/util/Debug.js":"2lOIQ","../../core/util/Decorator.js":"fl7ql","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eKiiZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Abstract base class for other monophonic instruments to extend.
 */ parcelHelpers.export(exports, "Monophonic", ()=>Monophonic);
var _tslib = require("tslib");
var _frequencyJs = require("../core/type/Frequency.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _instrumentJs = require("../instrument/Instrument.js");
var _decoratorJs = require("../core/util/Decorator.js");
class Monophonic extends (0, _instrumentJs.Instrument) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Monophonic.getDefaults(), arguments);
        super(options);
        this.portamento = options.portamento;
        this.onsilence = options.onsilence;
    }
    static getDefaults() {
        return Object.assign((0, _instrumentJs.Instrument).getDefaults(), {
            detune: 0,
            onsilence: (0, _interfaceJs.noOp),
            portamento: 0
        });
    }
    /**
     * Trigger the attack of the note optionally with a given velocity.
     * @param  note The note to trigger.
     * @param  time When the note should start.
     * @param  velocity The velocity determines how "loud" the note will be.
     * @example
     * const synth = new Tone.Synth().toDestination();
     * // trigger the note a half second from now at half velocity
     * synth.triggerAttack("C4", "+0.5", 0.5);
     */ triggerAttack(note, time, velocity = 1) {
        this.log("triggerAttack", note, time, velocity);
        const seconds = this.toSeconds(time);
        this._triggerEnvelopeAttack(seconds, velocity);
        this.setNote(note, seconds);
        return this;
    }
    /**
     * Trigger the release portion of the envelope.
     * @param  time If no time is given, the release happens immediately.
     * @example
     * const synth = new Tone.Synth().toDestination();
     * synth.triggerAttack("C4");
     * // trigger the release a second from now
     * synth.triggerRelease("+1");
     */ triggerRelease(time) {
        this.log("triggerRelease", time);
        const seconds = this.toSeconds(time);
        this._triggerEnvelopeRelease(seconds);
        return this;
    }
    /**
     * Set the note at the given time. If no time is given, the note
     * will set immediately.
     * @param note The note to change to.
     * @param  time The time when the note should be set.
     * @example
     * const synth = new Tone.Synth().toDestination();
     * synth.triggerAttack("C4");
     * // change to F#6 in one quarter note from now.
     * synth.setNote("F#6", "+4n");
     */ setNote(note, time) {
        const computedTime = this.toSeconds(time);
        const computedFrequency = note instanceof (0, _frequencyJs.FrequencyClass) ? note.toFrequency() : note;
        if (this.portamento > 0 && this.getLevelAtTime(computedTime) > 0.05) {
            const portTime = this.toSeconds(this.portamento);
            this.frequency.exponentialRampTo(computedFrequency, portTime, computedTime);
        } else this.frequency.setValueAtTime(computedFrequency, computedTime);
        return this;
    }
}
(0, _tslib.__decorate)([
    (0, _decoratorJs.timeRange)(0)
], Monophonic.prototype, "portamento", void 0);

},{"tslib":"lRdW5","../core/type/Frequency.js":"bObwr","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","../instrument/Instrument.js":"cFM2P","../core/util/Decorator.js":"fl7ql","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cFM2P":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base-class for all instruments
 */ parcelHelpers.export(exports, "Instrument", ()=>Instrument);
var _volumeJs = require("../component/channel/Volume.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
class Instrument extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Instrument.getDefaults(), arguments);
        super(options);
        /**
         * Keep track of all events scheduled to the transport
         * when the instrument is 'synced'
         */ this._scheduledEvents = [];
        /**
         * If the instrument is currently synced
         */ this._synced = false;
        this._original_triggerAttack = this.triggerAttack;
        this._original_triggerRelease = this.triggerRelease;
        /**
         * The release which is scheduled to the timeline.
         */ this._syncedRelease = (time)=>this._original_triggerRelease(time);
        this._volume = this.output = new (0, _volumeJs.Volume)({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        (0, _interfaceJs.readOnly)(this, "volume");
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            volume: 0
        });
    }
    /**
     * Sync the instrument to the Transport. All subsequent calls of
     * {@link triggerAttack} and {@link triggerRelease} will be scheduled along the transport.
     * @example
     * const fmSynth = new Tone.FMSynth().toDestination();
     * fmSynth.volume.value = -6;
     * fmSynth.sync();
     * // schedule 3 notes when the transport first starts
     * fmSynth.triggerAttackRelease("C4", "8n", 0);
     * fmSynth.triggerAttackRelease("E4", "8n", "8n");
     * fmSynth.triggerAttackRelease("G4", "8n", "4n");
     * // start the transport to hear the notes
     * Tone.Transport.start();
     */ sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 1);
            this._syncMethod("triggerRelease", 0);
            this.context.transport.on("stop", this._syncedRelease);
            this.context.transport.on("pause", this._syncedRelease);
            this.context.transport.on("loopEnd", this._syncedRelease);
        }
        return this;
    }
    /**
     * set _sync
     */ _syncState() {
        let changed = false;
        if (!this._synced) {
            this._synced = true;
            changed = true;
        }
        return changed;
    }
    /**
     * Wrap the given method so that it can be synchronized
     * @param method Which method to wrap and sync
     * @param  timePosition What position the time argument appears in
     */ _syncMethod(method, timePosition) {
        const originalMethod = this["_original_" + method] = this[method];
        this[method] = (...args)=>{
            const time = args[timePosition];
            const id = this.context.transport.schedule((t)=>{
                args[timePosition] = t;
                originalMethod.apply(this, args);
            }, time);
            this._scheduledEvents.push(id);
        };
    }
    /**
     * Unsync the instrument from the Transport
     */ unsync() {
        this._scheduledEvents.forEach((id)=>this.context.transport.clear(id));
        this._scheduledEvents = [];
        if (this._synced) {
            this._synced = false;
            this.triggerAttack = this._original_triggerAttack;
            this.triggerRelease = this._original_triggerRelease;
            this.context.transport.off("stop", this._syncedRelease);
            this.context.transport.off("pause", this._syncedRelease);
            this.context.transport.off("loopEnd", this._syncedRelease);
        }
        return this;
    }
    /**
     * Trigger the attack and then the release after the duration.
     * @param  note     The note to trigger.
     * @param  duration How long the note should be held for before
     *                         triggering the release. This value must be greater than 0.
     * @param time  When the note should be triggered.
     * @param  velocity The velocity the note should be triggered at.
     * @example
     * const synth = new Tone.Synth().toDestination();
     * // trigger "C4" for the duration of an 8th note
     * synth.triggerAttackRelease("C4", "8n");
     */ triggerAttackRelease(note, duration, time, velocity) {
        const computedTime = this.toSeconds(time);
        const computedDuration = this.toSeconds(duration);
        this.triggerAttack(note, computedTime, velocity);
        this.triggerRelease(computedTime + computedDuration);
        return this;
    }
    /**
     * clean up
     * @returns {Instrument} this
     */ dispose() {
        super.dispose();
        this._volume.dispose();
        this.unsync();
        this._scheduledEvents = [];
        return this;
    }
}

},{"../component/channel/Volume.js":"7Ooeo","../core/context/ToneAudioNode.js":"kZ3Kj","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kwmGi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Synth is composed simply of a {@link OmniOscillator} routed through an {@link AmplitudeEnvelope}.
 * ```
 * +----------------+   +-------------------+
 * | OmniOscillator +>--> AmplitudeEnvelope +>--> Output
 * +----------------+   +-------------------+
 * ```
 * @example
 * const synth = new Tone.Synth().toDestination();
 * synth.triggerAttackRelease("C4", "8n");
 * @category Instrument
 */ parcelHelpers.export(exports, "Synth", ()=>Synth);
var _amplitudeEnvelopeJs = require("../component/envelope/AmplitudeEnvelope.js");
var _envelopeJs = require("../component/envelope/Envelope.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _omniOscillatorJs = require("../source/oscillator/OmniOscillator.js");
var _sourceJs = require("../source/Source.js");
var _monophonicJs = require("./Monophonic.js");
class Synth extends (0, _monophonicJs.Monophonic) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Synth.getDefaults(), arguments);
        super(options);
        this.name = "Synth";
        this.oscillator = new (0, _omniOscillatorJs.OmniOscillator)(Object.assign({
            context: this.context,
            detune: options.detune,
            onstop: ()=>this.onsilence(this)
        }, options.oscillator));
        this.frequency = this.oscillator.frequency;
        this.detune = this.oscillator.detune;
        this.envelope = new (0, _amplitudeEnvelopeJs.AmplitudeEnvelope)(Object.assign({
            context: this.context
        }, options.envelope));
        // connect the oscillators to the output
        this.oscillator.chain(this.envelope, this.output);
        (0, _interfaceJs.readOnly)(this, [
            "oscillator",
            "frequency",
            "detune",
            "envelope"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _monophonicJs.Monophonic).getDefaults(), {
            envelope: Object.assign((0, _defaultsJs.omitFromObject)((0, _envelopeJs.Envelope).getDefaults(), Object.keys((0, _toneAudioNodeJs.ToneAudioNode).getDefaults())), {
                attack: 0.005,
                decay: 0.1,
                release: 1,
                sustain: 0.3
            }),
            oscillator: Object.assign((0, _defaultsJs.omitFromObject)((0, _omniOscillatorJs.OmniOscillator).getDefaults(), [
                ...Object.keys((0, _sourceJs.Source).getDefaults()),
                "frequency",
                "detune"
            ]), {
                type: "triangle"
            })
        });
    }
    /**
     * start the attack portion of the envelope
     * @param time the time the attack should start
     * @param velocity the velocity of the note (0-1)
     */ _triggerEnvelopeAttack(time, velocity) {
        // the envelopes
        this.envelope.triggerAttack(time, velocity);
        this.oscillator.start(time);
        // if there is no release portion, stop the oscillator
        if (this.envelope.sustain === 0) {
            const computedAttack = this.toSeconds(this.envelope.attack);
            const computedDecay = this.toSeconds(this.envelope.decay);
            this.oscillator.stop(time + computedAttack + computedDecay);
        }
    }
    /**
     * start the release portion of the envelope
     * @param time the time the release should start
     */ _triggerEnvelopeRelease(time) {
        this.envelope.triggerRelease(time);
        this.oscillator.stop(time + this.toSeconds(this.envelope.release));
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this.oscillator.dispose();
        this.envelope.dispose();
        return this;
    }
}

},{"../component/envelope/AmplitudeEnvelope.js":"l33WV","../component/envelope/Envelope.js":"cU1tT","../core/context/ToneAudioNode.js":"kZ3Kj","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","../source/oscillator/OmniOscillator.js":"7bzEJ","../source/Source.js":"eBYFz","./Monophonic.js":"eKiiZ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"l33WV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AmplitudeEnvelope is a Tone.Envelope connected to a gain node.
 * Unlike Tone.Envelope, which outputs the envelope's value, AmplitudeEnvelope accepts
 * an audio signal as the input and will apply the envelope to the amplitude
 * of the signal.
 * Read more about ADSR Envelopes on [Wikipedia](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope).
 *
 * @example
 * return Tone.Offline(() => {
 * 	const ampEnv = new Tone.AmplitudeEnvelope({
 * 		attack: 0.1,
 * 		decay: 0.2,
 * 		sustain: 1.0,
 * 		release: 0.8
 * 	}).toDestination();
 * 	// create an oscillator and connect it
 * 	const osc = new Tone.Oscillator().connect(ampEnv).start();
 * 	// trigger the envelopes attack and release "8t" apart
 * 	ampEnv.triggerAttackRelease("8t");
 * }, 1.5, 1);
 * @category Component
 */ parcelHelpers.export(exports, "AmplitudeEnvelope", ()=>AmplitudeEnvelope);
var _gainJs = require("../../core/context/Gain.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _envelopeJs = require("./Envelope.js");
class AmplitudeEnvelope extends (0, _envelopeJs.Envelope) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(AmplitudeEnvelope.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]));
        this.name = "AmplitudeEnvelope";
        this._gainNode = new (0, _gainJs.Gain)({
            context: this.context,
            gain: 0
        });
        this.output = this._gainNode;
        this.input = this._gainNode;
        this._sig.connect(this._gainNode.gain);
        this.output = this._gainNode;
        this.input = this._gainNode;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._gainNode.dispose();
        return this;
    }
}

},{"../../core/context/Gain.js":"kj68Y","../../core/util/Defaults.js":"a9M5s","./Envelope.js":"cU1tT","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"batNh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * DuoSynth is a monophonic synth composed of two {@link MonoSynth}s run in parallel with control over the
 * frequency ratio between the two voices and vibrato effect.
 * @example
 * const duoSynth = new Tone.DuoSynth().toDestination();
 * duoSynth.triggerAttackRelease("C4", "2n");
 * @category Instrument
 */ parcelHelpers.export(exports, "DuoSynth", ()=>DuoSynth);
var _monophonicJs = require("./Monophonic.js");
var _monoSynthJs = require("./MonoSynth.js");
var _signalJs = require("../signal/Signal.js");
var _interfaceJs = require("../core/util/Interface.js");
var _lfoJs = require("../source/oscillator/LFO.js");
var _gainJs = require("../core/context/Gain.js");
var _multiplyJs = require("../signal/Multiply.js");
var _defaultsJs = require("../core/util/Defaults.js");
class DuoSynth extends (0, _monophonicJs.Monophonic) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(DuoSynth.getDefaults(), arguments);
        super(options);
        this.name = "DuoSynth";
        this.voice0 = new (0, _monoSynthJs.MonoSynth)(Object.assign(options.voice0, {
            context: this.context,
            onsilence: ()=>this.onsilence(this)
        }));
        this.voice1 = new (0, _monoSynthJs.MonoSynth)(Object.assign(options.voice1, {
            context: this.context
        }));
        this.harmonicity = new (0, _multiplyJs.Multiply)({
            context: this.context,
            units: "positive",
            value: options.harmonicity
        });
        this._vibrato = new (0, _lfoJs.LFO)({
            frequency: options.vibratoRate,
            context: this.context,
            min: -50,
            max: 50
        });
        // start the vibrato immediately
        this._vibrato.start();
        this.vibratoRate = this._vibrato.frequency;
        this._vibratoGain = new (0, _gainJs.Gain)({
            context: this.context,
            units: "normalRange",
            gain: options.vibratoAmount
        });
        this.vibratoAmount = this._vibratoGain.gain;
        this.frequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency",
            value: 440
        });
        this.detune = new (0, _signalJs.Signal)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        // control the two voices frequency
        this.frequency.connect(this.voice0.frequency);
        this.frequency.chain(this.harmonicity, this.voice1.frequency);
        this._vibrato.connect(this._vibratoGain);
        this._vibratoGain.fan(this.voice0.detune, this.voice1.detune);
        this.detune.fan(this.voice0.detune, this.voice1.detune);
        this.voice0.connect(this.output);
        this.voice1.connect(this.output);
        (0, _interfaceJs.readOnly)(this, [
            "voice0",
            "voice1",
            "frequency",
            "vibratoAmount",
            "vibratoRate"
        ]);
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.voice0.envelope.getValueAtTime(time) + this.voice1.envelope.getValueAtTime(time);
    }
    static getDefaults() {
        return (0, _defaultsJs.deepMerge)((0, _monophonicJs.Monophonic).getDefaults(), {
            vibratoAmount: 0.5,
            vibratoRate: 5,
            harmonicity: 1.5,
            voice0: (0, _defaultsJs.deepMerge)((0, _defaultsJs.omitFromObject)((0, _monoSynthJs.MonoSynth).getDefaults(), Object.keys((0, _monophonicJs.Monophonic).getDefaults())), {
                filterEnvelope: {
                    attack: 0.01,
                    decay: 0.0,
                    sustain: 1,
                    release: 0.5
                },
                envelope: {
                    attack: 0.01,
                    decay: 0.0,
                    sustain: 1,
                    release: 0.5
                }
            }),
            voice1: (0, _defaultsJs.deepMerge)((0, _defaultsJs.omitFromObject)((0, _monoSynthJs.MonoSynth).getDefaults(), Object.keys((0, _monophonicJs.Monophonic).getDefaults())), {
                filterEnvelope: {
                    attack: 0.01,
                    decay: 0.0,
                    sustain: 1,
                    release: 0.5
                },
                envelope: {
                    attack: 0.01,
                    decay: 0.0,
                    sustain: 1,
                    release: 0.5
                }
            })
        });
    }
    /**
     * Trigger the attack portion of the note
     */ _triggerEnvelopeAttack(time, velocity) {
        // @ts-ignore
        this.voice0._triggerEnvelopeAttack(time, velocity);
        // @ts-ignore
        this.voice1._triggerEnvelopeAttack(time, velocity);
    }
    /**
     * Trigger the release portion of the note
     */ _triggerEnvelopeRelease(time) {
        // @ts-ignore
        this.voice0._triggerEnvelopeRelease(time);
        // @ts-ignore
        this.voice1._triggerEnvelopeRelease(time);
        return this;
    }
    dispose() {
        super.dispose();
        this.voice0.dispose();
        this.voice1.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this._vibrato.dispose();
        this.vibratoRate.dispose();
        this._vibratoGain.dispose();
        this.harmonicity.dispose();
        return this;
    }
}

},{"./Monophonic.js":"eKiiZ","./MonoSynth.js":"jT7JE","../signal/Signal.js":"980ri","../core/util/Interface.js":"hVOjA","../source/oscillator/LFO.js":"jsBJT","../core/context/Gain.js":"kj68Y","../signal/Multiply.js":"4C0VG","../core/util/Defaults.js":"a9M5s","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jT7JE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * MonoSynth is composed of one `oscillator`, one `filter`, and two `envelopes`.
 * The amplitude of the Oscillator and the cutoff frequency of the
 * Filter are controlled by Envelopes.
 * <img src="https://docs.google.com/drawings/d/1gaY1DF9_Hzkodqf8JI1Cg2VZfwSElpFQfI94IQwad38/pub?w=924&h=240">
 * @example
 * const synth = new Tone.MonoSynth({
 * 	oscillator: {
 * 		type: "square"
 * 	},
 * 	envelope: {
 * 		attack: 0.1
 * 	}
 * }).toDestination();
 * synth.triggerAttackRelease("C4", "8n");
 * @category Instrument
 */ parcelHelpers.export(exports, "MonoSynth", ()=>MonoSynth);
var _amplitudeEnvelopeJs = require("../component/envelope/AmplitudeEnvelope.js");
var _envelopeJs = require("../component/envelope/Envelope.js");
var _filterJs = require("../component/filter/Filter.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _monophonicJs = require("../instrument/Monophonic.js");
var _omniOscillatorJs = require("../source/oscillator/OmniOscillator.js");
var _sourceJs = require("../source/Source.js");
var _frequencyEnvelopeJs = require("../component/envelope/FrequencyEnvelope.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
class MonoSynth extends (0, _monophonicJs.Monophonic) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(MonoSynth.getDefaults(), arguments);
        super(options);
        this.name = "MonoSynth";
        this.oscillator = new (0, _omniOscillatorJs.OmniOscillator)(Object.assign(options.oscillator, {
            context: this.context,
            detune: options.detune,
            onstop: ()=>this.onsilence(this)
        }));
        this.frequency = this.oscillator.frequency;
        this.detune = this.oscillator.detune;
        this.filter = new (0, _filterJs.Filter)(Object.assign(options.filter, {
            context: this.context
        }));
        this.filterEnvelope = new (0, _frequencyEnvelopeJs.FrequencyEnvelope)(Object.assign(options.filterEnvelope, {
            context: this.context
        }));
        this.envelope = new (0, _amplitudeEnvelopeJs.AmplitudeEnvelope)(Object.assign(options.envelope, {
            context: this.context
        }));
        // connect the oscillators to the output
        this.oscillator.chain(this.filter, this.envelope, this.output);
        // connect the filter envelope
        this.filterEnvelope.connect(this.filter.frequency);
        (0, _interfaceJs.readOnly)(this, [
            "oscillator",
            "frequency",
            "detune",
            "filter",
            "filterEnvelope",
            "envelope"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _monophonicJs.Monophonic).getDefaults(), {
            envelope: Object.assign((0, _defaultsJs.omitFromObject)((0, _envelopeJs.Envelope).getDefaults(), Object.keys((0, _toneAudioNodeJs.ToneAudioNode).getDefaults())), {
                attack: 0.005,
                decay: 0.1,
                release: 1,
                sustain: 0.9
            }),
            filter: Object.assign((0, _defaultsJs.omitFromObject)((0, _filterJs.Filter).getDefaults(), Object.keys((0, _toneAudioNodeJs.ToneAudioNode).getDefaults())), {
                Q: 1,
                rolloff: -12,
                type: "lowpass"
            }),
            filterEnvelope: Object.assign((0, _defaultsJs.omitFromObject)((0, _frequencyEnvelopeJs.FrequencyEnvelope).getDefaults(), Object.keys((0, _toneAudioNodeJs.ToneAudioNode).getDefaults())), {
                attack: 0.6,
                baseFrequency: 200,
                decay: 0.2,
                exponent: 2,
                octaves: 3,
                release: 2,
                sustain: 0.5
            }),
            oscillator: Object.assign((0, _defaultsJs.omitFromObject)((0, _omniOscillatorJs.OmniOscillator).getDefaults(), Object.keys((0, _sourceJs.Source).getDefaults())), {
                type: "sawtooth"
            })
        });
    }
    /**
     * start the attack portion of the envelope
     * @param time the time the attack should start
     * @param velocity the velocity of the note (0-1)
     */ _triggerEnvelopeAttack(time, velocity = 1) {
        this.envelope.triggerAttack(time, velocity);
        this.filterEnvelope.triggerAttack(time);
        this.oscillator.start(time);
        if (this.envelope.sustain === 0) {
            const computedAttack = this.toSeconds(this.envelope.attack);
            const computedDecay = this.toSeconds(this.envelope.decay);
            this.oscillator.stop(time + computedAttack + computedDecay);
        }
    }
    /**
     * start the release portion of the envelope
     * @param time the time the release should start
     */ _triggerEnvelopeRelease(time) {
        this.envelope.triggerRelease(time);
        this.filterEnvelope.triggerRelease(time);
        this.oscillator.stop(time + this.toSeconds(this.envelope.release));
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    dispose() {
        super.dispose();
        this.oscillator.dispose();
        this.envelope.dispose();
        this.filterEnvelope.dispose();
        this.filter.dispose();
        return this;
    }
}

},{"../component/envelope/AmplitudeEnvelope.js":"l33WV","../component/envelope/Envelope.js":"cU1tT","../component/filter/Filter.js":"lel48","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","../instrument/Monophonic.js":"eKiiZ","../source/oscillator/OmniOscillator.js":"7bzEJ","../source/Source.js":"eBYFz","../component/envelope/FrequencyEnvelope.js":"beAqg","../core/context/ToneAudioNode.js":"kZ3Kj","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lel48":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone.Filter is a filter which allows for all of the same native methods
 * as the [BiquadFilterNode](http://webaudio.github.io/web-audio-api/#the-biquadfilternode-interface).
 * Tone.Filter has the added ability to set the filter rolloff at -12
 * (default), -24 and -48.
 * @example
 * const filter = new Tone.Filter(1500, "highpass").toDestination();
 * filter.frequency.rampTo(20000, 10);
 * const noise = new Tone.Noise().connect(filter).start();
 * @category Component
 */ parcelHelpers.export(exports, "Filter", ()=>Filter);
var _gainJs = require("../../core/context/Gain.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _typeCheckJs = require("../../core/util/TypeCheck.js");
var _signalJs = require("../../signal/Signal.js");
var _debugJs = require("../../core/util/Debug.js");
var _biquadFilterJs = require("./BiquadFilter.js");
class Filter extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Filter.getDefaults(), arguments, [
            "frequency",
            "type",
            "rolloff"
        ]);
        super(options);
        this.name = "Filter";
        this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._filters = [];
        this._filters = [];
        this.Q = new (0, _signalJs.Signal)({
            context: this.context,
            units: "positive",
            value: options.Q
        });
        this.frequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new (0, _signalJs.Signal)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        this.gain = new (0, _signalJs.Signal)({
            context: this.context,
            units: "decibels",
            convert: false,
            value: options.gain
        });
        this._type = options.type;
        this.rolloff = options.rolloff;
        (0, _interfaceJs.readOnly)(this, [
            "detune",
            "frequency",
            "gain",
            "Q"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            Q: 1,
            detune: 0,
            frequency: 350,
            gain: 0,
            rolloff: -12,
            type: "lowpass"
        });
    }
    /**
     * The type of the filter. Types: "lowpass", "highpass",
     * "bandpass", "lowshelf", "highshelf", "notch", "allpass", or "peaking".
     */ get type() {
        return this._type;
    }
    set type(type) {
        const types = [
            "lowpass",
            "highpass",
            "bandpass",
            "lowshelf",
            "highshelf",
            "notch",
            "allpass",
            "peaking"
        ];
        (0, _debugJs.assert)(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);
        this._type = type;
        this._filters.forEach((filter)=>filter.type = type);
    }
    /**
     * The rolloff of the filter which is the drop in db
     * per octave. Implemented internally by cascading filters.
     * Only accepts the values -12, -24, -48 and -96.
     */ get rolloff() {
        return this._rolloff;
    }
    set rolloff(rolloff) {
        const rolloffNum = (0, _typeCheckJs.isNumber)(rolloff) ? rolloff : parseInt(rolloff, 10);
        const possibilities = [
            -12,
            -24,
            -48,
            -96
        ];
        let cascadingCount = possibilities.indexOf(rolloffNum);
        // check the rolloff is valid
        (0, _debugJs.assert)(cascadingCount !== -1, `rolloff can only be ${possibilities.join(", ")}`);
        cascadingCount += 1;
        this._rolloff = rolloffNum;
        this.input.disconnect();
        this._filters.forEach((filter)=>filter.disconnect());
        this._filters = new Array(cascadingCount);
        for(let count = 0; count < cascadingCount; count++){
            const filter = new (0, _biquadFilterJs.BiquadFilter)({
                context: this.context
            });
            filter.type = this._type;
            this.frequency.connect(filter.frequency);
            this.detune.connect(filter.detune);
            this.Q.connect(filter.Q);
            this.gain.connect(filter.gain);
            this._filters[count] = filter;
        }
        this._internalChannels = this._filters;
        (0, _toneAudioNodeJs.connectSeries)(this.input, ...this._internalChannels, this.output);
    }
    /**
     * Get the frequency response curve. This curve represents how the filter
     * responses to frequencies between 20hz-20khz.
     * @param  len The number of values to return
     * @return The frequency response curve between 20-20kHz
     */ getFrequencyResponse(len = 128) {
        const filterClone = new (0, _biquadFilterJs.BiquadFilter)({
            frequency: this.frequency.value,
            gain: this.gain.value,
            Q: this.Q.value,
            type: this._type,
            detune: this.detune.value
        });
        // start with all 1s
        const totalResponse = new Float32Array(len).map(()=>1);
        this._filters.forEach(()=>{
            const response = filterClone.getFrequencyResponse(len);
            response.forEach((val, i)=>totalResponse[i] *= val);
        });
        filterClone.dispose();
        return totalResponse;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._filters.forEach((filter)=>{
            filter.dispose();
        });
        (0, _interfaceJs.writable)(this, [
            "detune",
            "frequency",
            "gain",
            "Q"
        ]);
        this.frequency.dispose();
        this.Q.dispose();
        this.detune.dispose();
        this.gain.dispose();
        return this;
    }
}

},{"../../core/context/Gain.js":"kj68Y","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../core/util/TypeCheck.js":"eMH5A","../../signal/Signal.js":"980ri","../../core/util/Debug.js":"2lOIQ","./BiquadFilter.js":"bJIpY","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bJIpY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Thin wrapper around the native Web Audio [BiquadFilterNode](https://webaudio.github.io/web-audio-api/#biquadfilternode).
 * BiquadFilter is similar to {@link Filter} but doesn't have the option to set the "rolloff" value.
 * @category Component
 */ parcelHelpers.export(exports, "BiquadFilter", ()=>BiquadFilter);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _paramJs = require("../../core/context/Param.js");
var _debugJs = require("../../core/util/Debug.js");
class BiquadFilter extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(BiquadFilter.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        super(options);
        this.name = "BiquadFilter";
        this._filter = this.context.createBiquadFilter();
        this.input = this.output = this._filter;
        this.Q = new (0, _paramJs.Param)({
            context: this.context,
            units: "number",
            value: options.Q,
            param: this._filter.Q
        });
        this.frequency = new (0, _paramJs.Param)({
            context: this.context,
            units: "frequency",
            value: options.frequency,
            param: this._filter.frequency
        });
        this.detune = new (0, _paramJs.Param)({
            context: this.context,
            units: "cents",
            value: options.detune,
            param: this._filter.detune
        });
        this.gain = new (0, _paramJs.Param)({
            context: this.context,
            units: "decibels",
            convert: false,
            value: options.gain,
            param: this._filter.gain
        });
        this.type = options.type;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            Q: 1,
            type: "lowpass",
            frequency: 350,
            detune: 0,
            gain: 0
        });
    }
    /**
     * The type of this BiquadFilterNode. For a complete list of types and their attributes, see the
     * [Web Audio API](https://webaudio.github.io/web-audio-api/#dom-biquadfiltertype-lowpass)
     */ get type() {
        return this._filter.type;
    }
    set type(type) {
        const types = [
            "lowpass",
            "highpass",
            "bandpass",
            "lowshelf",
            "highshelf",
            "notch",
            "allpass",
            "peaking"
        ];
        (0, _debugJs.assert)(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);
        this._filter.type = type;
    }
    /**
     * Get the frequency response curve. This curve represents how the filter
     * responses to frequencies between 20hz-20khz.
     * @param  len The number of values to return
     * @return The frequency response curve between 20-20kHz
     */ getFrequencyResponse(len = 128) {
        // start with all 1s
        const freqValues = new Float32Array(len);
        for(let i = 0; i < len; i++){
            const norm = Math.pow(i / len, 2);
            const freq = norm * 19980 + 20;
            freqValues[i] = freq;
        }
        const magValues = new Float32Array(len);
        const phaseValues = new Float32Array(len);
        // clone the filter to remove any connections which may be changing the value
        const filterClone = this.context.createBiquadFilter();
        filterClone.type = this.type;
        filterClone.Q.value = this.Q.value;
        filterClone.frequency.value = this.frequency.value;
        filterClone.gain.value = this.gain.value;
        filterClone.getFrequencyResponse(freqValues, magValues, phaseValues);
        return magValues;
    }
    dispose() {
        super.dispose();
        this._filter.disconnect();
        this.Q.dispose();
        this.frequency.dispose();
        this.gain.dispose();
        this.detune.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/context/Param.js":"5PVlJ","../../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"beAqg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FrequencyEnvelope is an {@link Envelope} which ramps between {@link baseFrequency}
 * and {@link octaves}. It can also have an optional {@link exponent} to adjust the curve
 * which it ramps.
 * @example
 * const oscillator = new Tone.Oscillator().toDestination().start();
 * const freqEnv = new Tone.FrequencyEnvelope({
 * 	attack: 0.2,
 * 	baseFrequency: "C2",
 * 	octaves: 4
 * });
 * freqEnv.connect(oscillator.frequency);
 * freqEnv.triggerAttack();
 * @category Component
 */ parcelHelpers.export(exports, "FrequencyEnvelope", ()=>FrequencyEnvelope);
var _defaultsJs = require("../../core/util/Defaults.js");
var _envelopeJs = require("./Envelope.js");
var _scaleJs = require("../../signal/Scale.js");
var _powJs = require("../../signal/Pow.js");
var _debugJs = require("../../core/util/Debug.js");
class FrequencyEnvelope extends (0, _envelopeJs.Envelope) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(FrequencyEnvelope.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]);
        super(options);
        this.name = "FrequencyEnvelope";
        this._octaves = options.octaves;
        this._baseFrequency = this.toFrequency(options.baseFrequency);
        this._exponent = this.input = new (0, _powJs.Pow)({
            context: this.context,
            value: options.exponent
        });
        this._scale = this.output = new (0, _scaleJs.Scale)({
            context: this.context,
            min: this._baseFrequency,
            max: this._baseFrequency * Math.pow(2, this._octaves)
        });
        this._sig.chain(this._exponent, this._scale);
    }
    static getDefaults() {
        return Object.assign((0, _envelopeJs.Envelope).getDefaults(), {
            baseFrequency: 200,
            exponent: 1,
            octaves: 4
        });
    }
    /**
     * The envelope's minimum output value. This is the value which it
     * starts at.
     */ get baseFrequency() {
        return this._baseFrequency;
    }
    set baseFrequency(min) {
        const freq = this.toFrequency(min);
        (0, _debugJs.assertRange)(freq, 0);
        this._baseFrequency = freq;
        this._scale.min = this._baseFrequency;
        // update the max value when the min changes
        this.octaves = this._octaves;
    }
    /**
     * The number of octaves above the baseFrequency that the
     * envelope will scale to.
     */ get octaves() {
        return this._octaves;
    }
    set octaves(octaves) {
        this._octaves = octaves;
        this._scale.max = this._baseFrequency * Math.pow(2, octaves);
    }
    /**
     * The envelope's exponent value.
     */ get exponent() {
        return this._exponent.value;
    }
    set exponent(exponent) {
        this._exponent.value = exponent;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._exponent.dispose();
        this._scale.dispose();
        return this;
    }
}

},{"../../core/util/Defaults.js":"a9M5s","./Envelope.js":"cU1tT","../../signal/Scale.js":"3qxrw","../../signal/Pow.js":"9vO86","../../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9ms3z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FMSynth is composed of two Tone.Synths where one Tone.Synth modulates
 * the frequency of a second Tone.Synth. A lot of spectral content
 * can be explored using the modulationIndex parameter. Read more about
 * frequency modulation synthesis on Sound On Sound: [Part 1](https://web.archive.org/web/20160403123704/http://www.soundonsound.com/sos/apr00/articles/synthsecrets.htm), [Part 2](https://web.archive.org/web/20160403115835/http://www.soundonsound.com/sos/may00/articles/synth.htm).
 *
 * @example
 * const fmSynth = new Tone.FMSynth().toDestination();
 * fmSynth.triggerAttackRelease("C5", "4n");
 *
 * @category Instrument
 */ parcelHelpers.export(exports, "FMSynth", ()=>FMSynth);
var _defaultsJs = require("../core/util/Defaults.js");
var _multiplyJs = require("../signal/Multiply.js");
var _modulationSynthJs = require("./ModulationSynth.js");
class FMSynth extends (0, _modulationSynthJs.ModulationSynth) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(FMSynth.getDefaults(), arguments);
        super(options);
        this.name = "FMSynth";
        this.modulationIndex = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: options.modulationIndex
        });
        // control the two voices frequency
        this.frequency.connect(this._carrier.frequency);
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this.frequency.chain(this.modulationIndex, this._modulationNode);
        this.detune.fan(this._carrier.detune, this._modulator.detune);
        this._modulator.connect(this._modulationNode.gain);
        this._modulationNode.connect(this._carrier.frequency);
        this._carrier.connect(this.output);
    }
    static getDefaults() {
        return Object.assign((0, _modulationSynthJs.ModulationSynth).getDefaults(), {
            modulationIndex: 10
        });
    }
    dispose() {
        super.dispose();
        this.modulationIndex.dispose();
        return this;
    }
}

},{"../core/util/Defaults.js":"a9M5s","../signal/Multiply.js":"4C0VG","./ModulationSynth.js":"3DhsT","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"itJ1n":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A highly inharmonic and spectrally complex source with a highpass filter
 * and amplitude envelope which is good for making metallophone sounds.
 * Based on CymbalSynth by [@polyrhythmatic](https://github.com/polyrhythmatic).
 * @category Instrument
 */ parcelHelpers.export(exports, "MetalSynth", ()=>MetalSynth);
var _envelopeJs = require("../component/envelope/Envelope.js");
var _filterJs = require("../component/filter/Filter.js");
var _gainJs = require("../core/context/Gain.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _multiplyJs = require("../signal/Multiply.js");
var _scaleJs = require("../signal/Scale.js");
var _signalJs = require("../signal/Signal.js");
var _fmoscillatorJs = require("../source/oscillator/FMOscillator.js");
var _monophonicJs = require("./Monophonic.js");
/**
 * Inharmonic ratio of frequencies based on the Roland TR-808
 * Taken from https://ccrma.stanford.edu/papers/tr-808-cymbal-physically-informed-circuit-bendable-digital-model
 */ const inharmRatios = [
    1.0,
    1.483,
    1.932,
    2.546,
    2.63,
    3.897
];
class MetalSynth extends (0, _monophonicJs.Monophonic) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(MetalSynth.getDefaults(), arguments);
        super(options);
        this.name = "MetalSynth";
        /**
         * The array of FMOscillators
         */ this._oscillators = [];
        /**
         * The frequency multipliers
         */ this._freqMultipliers = [];
        this.detune = new (0, _signalJs.Signal)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        this.frequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency"
        });
        this._amplitude = new (0, _gainJs.Gain)({
            context: this.context,
            gain: 0
        }).connect(this.output);
        this._highpass = new (0, _filterJs.Filter)({
            // Q: -3.0102999566398125,
            Q: 0,
            context: this.context,
            type: "highpass"
        }).connect(this._amplitude);
        for(let i = 0; i < inharmRatios.length; i++){
            const osc = new (0, _fmoscillatorJs.FMOscillator)({
                context: this.context,
                harmonicity: options.harmonicity,
                modulationIndex: options.modulationIndex,
                modulationType: "square",
                onstop: i === 0 ? ()=>this.onsilence(this) : (0, _interfaceJs.noOp),
                type: "square"
            });
            osc.connect(this._highpass);
            this._oscillators[i] = osc;
            const mult = new (0, _multiplyJs.Multiply)({
                context: this.context,
                value: inharmRatios[i]
            });
            this._freqMultipliers[i] = mult;
            this.frequency.chain(mult, osc.frequency);
            this.detune.connect(osc.detune);
        }
        this._filterFreqScaler = new (0, _scaleJs.Scale)({
            context: this.context,
            max: 7000,
            min: this.toFrequency(options.resonance)
        });
        this.envelope = new (0, _envelopeJs.Envelope)({
            attack: options.envelope.attack,
            attackCurve: "linear",
            context: this.context,
            decay: options.envelope.decay,
            release: options.envelope.release,
            sustain: 0
        });
        this.envelope.chain(this._filterFreqScaler, this._highpass.frequency);
        this.envelope.connect(this._amplitude.gain);
        // set the octaves
        this._octaves = options.octaves;
        this.octaves = options.octaves;
    }
    static getDefaults() {
        return (0, _defaultsJs.deepMerge)((0, _monophonicJs.Monophonic).getDefaults(), {
            envelope: Object.assign((0, _defaultsJs.omitFromObject)((0, _envelopeJs.Envelope).getDefaults(), Object.keys((0, _toneAudioNodeJs.ToneAudioNode).getDefaults())), {
                attack: 0.001,
                decay: 1.4,
                release: 0.2
            }),
            harmonicity: 5.1,
            modulationIndex: 32,
            octaves: 1.5,
            resonance: 4000
        });
    }
    /**
     * Trigger the attack.
     * @param time When the attack should be triggered.
     * @param velocity The velocity that the envelope should be triggered at.
     */ _triggerEnvelopeAttack(time, velocity = 1) {
        this.envelope.triggerAttack(time, velocity);
        this._oscillators.forEach((osc)=>osc.start(time));
        if (this.envelope.sustain === 0) this._oscillators.forEach((osc)=>{
            osc.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));
        });
        return this;
    }
    /**
     * Trigger the release of the envelope.
     * @param time When the release should be triggered.
     */ _triggerEnvelopeRelease(time) {
        this.envelope.triggerRelease(time);
        this._oscillators.forEach((osc)=>osc.stop(time + this.toSeconds(this.envelope.release)));
        return this;
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    /**
     * The modulationIndex of the oscillators which make up the source.
     * see {@link FMOscillator.modulationIndex}
     * @min 1
     * @max 100
     */ get modulationIndex() {
        return this._oscillators[0].modulationIndex.value;
    }
    set modulationIndex(val) {
        this._oscillators.forEach((osc)=>osc.modulationIndex.value = val);
    }
    /**
     * The harmonicity of the oscillators which make up the source.
     * see Tone.FMOscillator.harmonicity
     * @min 0.1
     * @max 10
     */ get harmonicity() {
        return this._oscillators[0].harmonicity.value;
    }
    set harmonicity(val) {
        this._oscillators.forEach((osc)=>osc.harmonicity.value = val);
    }
    /**
     * The lower level of the highpass filter which is attached to the envelope.
     * This value should be between [0, 7000]
     * @min 0
     * @max 7000
     */ get resonance() {
        return this._filterFreqScaler.min;
    }
    set resonance(val) {
        this._filterFreqScaler.min = this.toFrequency(val);
        this.octaves = this._octaves;
    }
    /**
     * The number of octaves above the "resonance" frequency
     * that the filter ramps during the attack/decay envelope
     * @min 0
     * @max 8
     */ get octaves() {
        return this._octaves;
    }
    set octaves(val) {
        this._octaves = val;
        this._filterFreqScaler.max = this._filterFreqScaler.min * Math.pow(2, val);
    }
    dispose() {
        super.dispose();
        this._oscillators.forEach((osc)=>osc.dispose());
        this._freqMultipliers.forEach((freqMult)=>freqMult.dispose());
        this.frequency.dispose();
        this.detune.dispose();
        this._filterFreqScaler.dispose();
        this._amplitude.dispose();
        this.envelope.dispose();
        this._highpass.dispose();
        return this;
    }
}

},{"../component/envelope/Envelope.js":"cU1tT","../component/filter/Filter.js":"lel48","../core/context/Gain.js":"kj68Y","../core/context/ToneAudioNode.js":"kZ3Kj","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","../signal/Multiply.js":"4C0VG","../signal/Scale.js":"3qxrw","../signal/Signal.js":"980ri","../source/oscillator/FMOscillator.js":"3UNlG","./Monophonic.js":"eKiiZ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gVrZJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * MembraneSynth makes kick and tom sounds using a single oscillator
 * with an amplitude envelope and frequency ramp. A Tone.OmniOscillator
 * is routed through a Tone.AmplitudeEnvelope to the output. The drum
 * quality of the sound comes from the frequency envelope applied
 * during MembraneSynth.triggerAttack(note). The frequency envelope
 * starts at <code>note * .octaves</code> and ramps to <code>note</code>
 * over the duration of <code>.pitchDecay</code>.
 * @example
 * const synth = new Tone.MembraneSynth().toDestination();
 * synth.triggerAttackRelease("C2", "8n");
 * @category Instrument
 */ parcelHelpers.export(exports, "MembraneSynth", ()=>MembraneSynth);
var _tslib = require("tslib");
var _frequencyJs = require("../core/type/Frequency.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _monophonicJs = require("./Monophonic.js");
var _synthJs = require("./Synth.js");
var _decoratorJs = require("../core/util/Decorator.js");
class MembraneSynth extends (0, _synthJs.Synth) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(MembraneSynth.getDefaults(), arguments);
        super(options);
        this.name = "MembraneSynth";
        /**
         * Portamento is ignored in this synth. use pitch decay instead.
         */ this.portamento = 0;
        this.pitchDecay = options.pitchDecay;
        this.octaves = options.octaves;
        (0, _interfaceJs.readOnly)(this, [
            "oscillator",
            "envelope"
        ]);
    }
    static getDefaults() {
        return (0, _defaultsJs.deepMerge)((0, _monophonicJs.Monophonic).getDefaults(), (0, _synthJs.Synth).getDefaults(), {
            envelope: {
                attack: 0.001,
                attackCurve: "exponential",
                decay: 0.4,
                release: 1.4,
                sustain: 0.01
            },
            octaves: 10,
            oscillator: {
                type: "sine"
            },
            pitchDecay: 0.05
        });
    }
    setNote(note, time) {
        const seconds = this.toSeconds(time);
        const hertz = this.toFrequency(note instanceof (0, _frequencyJs.FrequencyClass) ? note.toFrequency() : note);
        const maxNote = hertz * this.octaves;
        this.oscillator.frequency.setValueAtTime(maxNote, seconds);
        this.oscillator.frequency.exponentialRampToValueAtTime(hertz, seconds + this.toSeconds(this.pitchDecay));
        return this;
    }
    dispose() {
        super.dispose();
        return this;
    }
}
(0, _tslib.__decorate)([
    (0, _decoratorJs.range)(0)
], MembraneSynth.prototype, "octaves", void 0);
(0, _tslib.__decorate)([
    (0, _decoratorJs.timeRange)(0)
], MembraneSynth.prototype, "pitchDecay", void 0);

},{"tslib":"lRdW5","../core/type/Frequency.js":"bObwr","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","./Monophonic.js":"eKiiZ","./Synth.js":"kwmGi","../core/util/Decorator.js":"fl7ql","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hhi7P":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone.NoiseSynth is composed of {@link Noise} through an {@link AmplitudeEnvelope}.
 * ```
 * +-------+   +-------------------+
 * | Noise +>--> AmplitudeEnvelope +>--> Output
 * +-------+   +-------------------+
 * ```
 * @example
 * const noiseSynth = new Tone.NoiseSynth().toDestination();
 * noiseSynth.triggerAttackRelease("8n", 0.05);
 * @category Instrument
 */ parcelHelpers.export(exports, "NoiseSynth", ()=>NoiseSynth);
var _amplitudeEnvelopeJs = require("../component/envelope/AmplitudeEnvelope.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _noiseJs = require("../source/Noise.js");
var _instrumentJs = require("./Instrument.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _envelopeJs = require("../component/envelope/Envelope.js");
var _sourceJs = require("../source/Source.js");
class NoiseSynth extends (0, _instrumentJs.Instrument) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(NoiseSynth.getDefaults(), arguments);
        super(options);
        this.name = "NoiseSynth";
        this.noise = new (0, _noiseJs.Noise)(Object.assign({
            context: this.context
        }, options.noise));
        this.envelope = new (0, _amplitudeEnvelopeJs.AmplitudeEnvelope)(Object.assign({
            context: this.context
        }, options.envelope));
        // connect the noise to the output
        this.noise.chain(this.envelope, this.output);
    }
    static getDefaults() {
        return Object.assign((0, _instrumentJs.Instrument).getDefaults(), {
            envelope: Object.assign((0, _defaultsJs.omitFromObject)((0, _envelopeJs.Envelope).getDefaults(), Object.keys((0, _toneAudioNodeJs.ToneAudioNode).getDefaults())), {
                decay: 0.1,
                sustain: 0.0
            }),
            noise: Object.assign((0, _defaultsJs.omitFromObject)((0, _noiseJs.Noise).getDefaults(), Object.keys((0, _sourceJs.Source).getDefaults())), {
                type: "white"
            })
        });
    }
    /**
     * Start the attack portion of the envelopes. Unlike other
     * instruments, Tone.NoiseSynth doesn't have a note.
     * @example
     * const noiseSynth = new Tone.NoiseSynth().toDestination();
     * noiseSynth.triggerAttack();
     */ triggerAttack(time, velocity = 1) {
        time = this.toSeconds(time);
        // the envelopes
        this.envelope.triggerAttack(time, velocity);
        // start the noise
        this.noise.start(time);
        if (this.envelope.sustain === 0) this.noise.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));
        return this;
    }
    /**
     * Start the release portion of the envelopes.
     */ triggerRelease(time) {
        time = this.toSeconds(time);
        this.envelope.triggerRelease(time);
        this.noise.stop(time + this.toSeconds(this.envelope.release));
        return this;
    }
    sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 0);
            this._syncMethod("triggerRelease", 0);
        }
        return this;
    }
    /**
     * Trigger the attack and then the release after the duration.
     * @param duration The amount of time to hold the note for
     * @param time The time the note should start
     * @param velocity The volume of the note (0-1)
     * @example
     * const noiseSynth = new Tone.NoiseSynth().toDestination();
     * // hold the note for 0.5 seconds
     * noiseSynth.triggerAttackRelease(0.5);
     */ triggerAttackRelease(duration, time, velocity = 1) {
        time = this.toSeconds(time);
        duration = this.toSeconds(duration);
        this.triggerAttack(time, velocity);
        this.triggerRelease(time + duration);
        return this;
    }
    dispose() {
        super.dispose();
        this.noise.dispose();
        this.envelope.dispose();
        return this;
    }
}

},{"../component/envelope/AmplitudeEnvelope.js":"l33WV","../core/util/Defaults.js":"a9M5s","../source/Noise.js":"cOpzx","./Instrument.js":"cFM2P","../core/context/ToneAudioNode.js":"kZ3Kj","../component/envelope/Envelope.js":"cU1tT","../source/Source.js":"eBYFz","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"4DPlg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Karplus-Strong string synthesis.
 * @example
 * const plucky = new Tone.PluckSynth().toDestination();
 * plucky.triggerAttack("C4", "+0.5");
 * plucky.triggerAttack("C3", "+1");
 * plucky.triggerAttack("C2", "+1.5");
 * plucky.triggerAttack("C1", "+2");
 * @category Instrument
 */ parcelHelpers.export(exports, "PluckSynth", ()=>PluckSynth);
var _lowpassCombFilterJs = require("../component/filter/LowpassCombFilter.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _noiseJs = require("../source/Noise.js");
var _instrumentJs = require("./Instrument.js");
class PluckSynth extends (0, _instrumentJs.Instrument) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(PluckSynth.getDefaults(), arguments);
        super(options);
        this.name = "PluckSynth";
        this._noise = new (0, _noiseJs.Noise)({
            context: this.context,
            type: "pink"
        });
        this.attackNoise = options.attackNoise;
        this._lfcf = new (0, _lowpassCombFilterJs.LowpassCombFilter)({
            context: this.context,
            dampening: options.dampening,
            resonance: options.resonance
        });
        this.resonance = options.resonance;
        this.release = options.release;
        this._noise.connect(this._lfcf);
        this._lfcf.connect(this.output);
    }
    static getDefaults() {
        return (0, _defaultsJs.deepMerge)((0, _instrumentJs.Instrument).getDefaults(), {
            attackNoise: 1,
            dampening: 4000,
            resonance: 0.7,
            release: 1
        });
    }
    /**
     * The dampening control. i.e. the lowpass filter frequency of the comb filter
     * @min 0
     * @max 7000
     */ get dampening() {
        return this._lfcf.dampening;
    }
    set dampening(fq) {
        this._lfcf.dampening = fq;
    }
    triggerAttack(note, time) {
        const freq = this.toFrequency(note);
        time = this.toSeconds(time);
        const delayAmount = 1 / freq;
        this._lfcf.delayTime.setValueAtTime(delayAmount, time);
        this._noise.start(time);
        this._noise.stop(time + delayAmount * this.attackNoise);
        this._lfcf.resonance.cancelScheduledValues(time);
        this._lfcf.resonance.setValueAtTime(this.resonance, time);
        return this;
    }
    /**
     * Ramp down the {@link resonance} to 0 over the duration of the release time.
     */ triggerRelease(time) {
        this._lfcf.resonance.linearRampTo(0, this.release, time);
        return this;
    }
    dispose() {
        super.dispose();
        this._noise.dispose();
        this._lfcf.dispose();
        return this;
    }
}

},{"../component/filter/LowpassCombFilter.js":"01n6w","../core/util/Defaults.js":"a9M5s","../source/Noise.js":"cOpzx","./Instrument.js":"cFM2P","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"01n6w":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A lowpass feedback comb filter. It is similar to
 * {@link FeedbackCombFilter}, but includes a lowpass filter.
 * @category Component
 */ parcelHelpers.export(exports, "LowpassCombFilter", ()=>LowpassCombFilter);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _feedbackCombFilterJs = require("./FeedbackCombFilter.js");
var _onePoleFilterJs = require("./OnePoleFilter.js");
class LowpassCombFilter extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(LowpassCombFilter.getDefaults(), arguments, [
            "delayTime",
            "resonance",
            "dampening"
        ]);
        super(options);
        this.name = "LowpassCombFilter";
        this._combFilter = this.output = new (0, _feedbackCombFilterJs.FeedbackCombFilter)({
            context: this.context,
            delayTime: options.delayTime,
            resonance: options.resonance
        });
        this.delayTime = this._combFilter.delayTime;
        this.resonance = this._combFilter.resonance;
        this._lowpass = this.input = new (0, _onePoleFilterJs.OnePoleFilter)({
            context: this.context,
            frequency: options.dampening,
            type: "lowpass"
        });
        // connections
        this._lowpass.connect(this._combFilter);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            dampening: 3000,
            delayTime: 0.1,
            resonance: 0.5
        });
    }
    /**
     * The dampening control of the feedback
     */ get dampening() {
        return this._lowpass.frequency;
    }
    set dampening(fq) {
        this._lowpass.frequency = fq;
    }
    dispose() {
        super.dispose();
        this._combFilter.dispose();
        this._lowpass.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","./FeedbackCombFilter.js":"iMAnY","./OnePoleFilter.js":"1CfWn","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iMAnY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Comb filters are basic building blocks for physical modeling. Read more
 * about comb filters on [CCRMA's website](https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html).
 *
 * This comb filter is implemented with the AudioWorkletNode which allows it to have feedback delays less than the
 * Web Audio processing block of 128 samples. There is a polyfill for browsers that don't yet support the
 * AudioWorkletNode, but it will add some latency and have slower performance than the AudioWorkletNode.
 * @category Component
 */ parcelHelpers.export(exports, "FeedbackCombFilter", ()=>FeedbackCombFilter);
var _gainJs = require("../../core/context/Gain.js");
var _paramJs = require("../../core/context/Param.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _toneAudioWorkletJs = require("../../core/worklet/ToneAudioWorklet.js");
var _feedbackCombFilterWorkletJs = require("./FeedbackCombFilter.worklet.js");
class FeedbackCombFilter extends (0, _toneAudioWorkletJs.ToneAudioWorklet) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(FeedbackCombFilter.getDefaults(), arguments, [
            "delayTime",
            "resonance"
        ]);
        super(options);
        this.name = "FeedbackCombFilter";
        this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.delayTime = new (0, _paramJs.Param)({
            context: this.context,
            value: options.delayTime,
            units: "time",
            minValue: 0,
            maxValue: 1,
            param: this._dummyParam,
            swappable: true
        });
        this.resonance = new (0, _paramJs.Param)({
            context: this.context,
            value: options.resonance,
            units: "normalRange",
            param: this._dummyParam,
            swappable: true
        });
        (0, _interfaceJs.readOnly)(this, [
            "resonance",
            "delayTime"
        ]);
    }
    _audioWorkletName() {
        return 0, _feedbackCombFilterWorkletJs.workletName;
    }
    /**
     * The default parameters
     */ static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            delayTime: 0.1,
            resonance: 0.5
        });
    }
    onReady(node) {
        (0, _toneAudioNodeJs.connectSeries)(this.input, node, this.output);
        const delayTime = node.parameters.get("delayTime");
        this.delayTime.setParam(delayTime);
        const feedback = node.parameters.get("feedback");
        this.resonance.setParam(feedback);
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this.delayTime.dispose();
        this.resonance.dispose();
        return this;
    }
}

},{"../../core/context/Gain.js":"kj68Y","../../core/context/Param.js":"5PVlJ","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../core/worklet/ToneAudioWorklet.js":"gJKvW","./FeedbackCombFilter.worklet.js":"gdia3","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gJKvW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ToneAudioWorklet", ()=>ToneAudioWorklet);
var _toneAudioNodeJs = require("../context/ToneAudioNode.js");
var _interfaceJs = require("../util/Interface.js");
var _workletGlobalScopeJs = require("./WorkletGlobalScope.js");
class ToneAudioWorklet extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(options){
        super(options);
        this.name = "ToneAudioWorklet";
        /**
         * The constructor options for the node
         */ this.workletOptions = {};
        /**
         * Callback which is invoked when there is an error in the processing
         */ this.onprocessorerror = (0, _interfaceJs.noOp);
        const blobUrl = URL.createObjectURL(new Blob([
            (0, _workletGlobalScopeJs.getWorkletGlobalScope)()
        ], {
            type: "text/javascript"
        }));
        const name = this._audioWorkletName();
        this._dummyGain = this.context.createGain();
        this._dummyParam = this._dummyGain.gain;
        // Register the processor
        this.context.addAudioWorkletModule(blobUrl).then(()=>{
            // create the worklet when it's read
            if (!this.disposed) {
                this._worklet = this.context.createAudioWorkletNode(name, this.workletOptions);
                this._worklet.onprocessorerror = this.onprocessorerror.bind(this);
                this.onReady(this._worklet);
            }
        });
    }
    dispose() {
        super.dispose();
        this._dummyGain.disconnect();
        if (this._worklet) {
            this._worklet.port.postMessage("dispose");
            this._worklet.disconnect();
        }
        return this;
    }
}

},{"../context/ToneAudioNode.js":"kZ3Kj","../util/Interface.js":"hVOjA","./WorkletGlobalScope.js":"KZYDB","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"KZYDB":[function(require,module,exports) {
/**
 * All of the classes or functions which are loaded into the AudioWorkletGlobalScope
 */ var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Add a class to the AudioWorkletGlobalScope
 */ parcelHelpers.export(exports, "addToWorklet", ()=>addToWorklet);
/**
 * Register a processor in the AudioWorkletGlobalScope with the given name
 */ parcelHelpers.export(exports, "registerProcessor", ()=>registerProcessor);
/**
 * Get all of the modules which have been registered to the AudioWorkletGlobalScope
 */ parcelHelpers.export(exports, "getWorkletGlobalScope", ()=>getWorkletGlobalScope);
const workletContext = new Set();
function addToWorklet(classOrFunction) {
    workletContext.add(classOrFunction);
}
function registerProcessor(name, classDesc) {
    const processor = /* javascript */ `registerProcessor("${name}", ${classDesc})`;
    workletContext.add(processor);
}
function getWorkletGlobalScope() {
    return Array.from(workletContext).join("\n");
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gdia3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "workletName", ()=>workletName);
var _singleIOProcessorWorkletJs = require("../../core/worklet/SingleIOProcessor.worklet.js");
var _delayLineWorkletJs = require("../../core/worklet/DelayLine.worklet.js");
var _workletGlobalScopeJs = require("../../core/worklet/WorkletGlobalScope.js");
const workletName = "feedback-comb-filter";
const feedbackCombFilter = /* javascript */ `
	class FeedbackCombFilterWorklet extends SingleIOProcessor {

		constructor(options) {
			super(options);
			this.delayLine = new DelayLine(this.sampleRate, options.channelCount || 2);
		}

		static get parameterDescriptors() {
			return [{
				name: "delayTime",
				defaultValue: 0.1,
				minValue: 0,
				maxValue: 1,
				automationRate: "k-rate"
			}, {
				name: "feedback",
				defaultValue: 0.5,
				minValue: 0,
				maxValue: 0.9999,
				automationRate: "k-rate"
			}];
		}

		generate(input, channel, parameters) {
			const delayedSample = this.delayLine.get(channel, parameters.delayTime * this.sampleRate);
			this.delayLine.push(channel, input + delayedSample * parameters.feedback);
			return delayedSample;
		}
	}
`;
(0, _workletGlobalScopeJs.registerProcessor)(workletName, feedbackCombFilter);

},{"../../core/worklet/SingleIOProcessor.worklet.js":"c8hmn","../../core/worklet/DelayLine.worklet.js":"7MQGt","../../core/worklet/WorkletGlobalScope.js":"KZYDB","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"c8hmn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "singleIOProcess", ()=>singleIOProcess);
var _toneAudioWorkletProcessorWorkletJs = require("./ToneAudioWorkletProcessor.worklet.js");
var _workletGlobalScopeJs = require("./WorkletGlobalScope.js");
const singleIOProcess = /* javascript */ `
	/**
	 * Abstract class for a single input/output processor. 
	 * has a 'generate' function which processes one sample at a time
	 */
	class SingleIOProcessor extends ToneAudioWorkletProcessor {

		constructor(options) {
			super(Object.assign(options, {
				numberOfInputs: 1,
				numberOfOutputs: 1
			}));
			/**
			 * Holds the name of the parameter and a single value of that
			 * parameter at the current sample
			 * @type { [name: string]: number }
			 */
			this.params = {}
		}

		/**
		 * Generate an output sample from the input sample and parameters
		 * @abstract
		 * @param input number
		 * @param channel number
		 * @param parameters { [name: string]: number }
		 * @returns number
		 */
		generate(){}

		/**
		 * Update the private params object with the 
		 * values of the parameters at the given index
		 * @param parameters { [name: string]: Float32Array },
		 * @param index number
		 */
		updateParams(parameters, index) {
			for (const paramName in parameters) {
				const param = parameters[paramName];
				if (param.length > 1) {
					this.params[paramName] = parameters[paramName][index];
				} else {
					this.params[paramName] = parameters[paramName][0];
				}
			}
		}

		/**
		 * Process a single frame of the audio
		 * @param inputs Float32Array[][]
		 * @param outputs Float32Array[][]
		 */
		process(inputs, outputs, parameters) {
			const input = inputs[0];
			const output = outputs[0];
			// get the parameter values
			const channelCount = Math.max(input && input.length || 0, output.length);
			for (let sample = 0; sample < this.blockSize; sample++) {
				this.updateParams(parameters, sample);
				for (let channel = 0; channel < channelCount; channel++) {
					const inputSample = input && input.length ? input[channel][sample] : 0;
					output[channel][sample] = this.generate(inputSample, channel, this.params);
				}
			}
			return !this.disposed;
		}
	};
`;
(0, _workletGlobalScopeJs.addToWorklet)(singleIOProcess);

},{"./ToneAudioWorkletProcessor.worklet.js":"gKUpY","./WorkletGlobalScope.js":"KZYDB","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gKUpY":[function(require,module,exports) {
var _workletGlobalScopeJs = require("./WorkletGlobalScope.js");
const toneAudioWorkletProcessor = /* javascript */ `
	/**
	 * The base AudioWorkletProcessor for use in Tone.js. Works with the {@link ToneAudioWorklet}. 
	 */
	class ToneAudioWorkletProcessor extends AudioWorkletProcessor {

		constructor(options) {
			
			super(options);
			/**
			 * If the processor was disposed or not. Keep alive until it's disposed.
			 */
			this.disposed = false;
		   	/** 
			 * The number of samples in the processing block
			 */
			this.blockSize = 128;
			/**
			 * the sample rate
			 */
			this.sampleRate = sampleRate;

			this.port.onmessage = (event) => {
				// when it receives a dispose 
				if (event.data === "dispose") {
					this.disposed = true;
				}
			};
		}
	}
`;
(0, _workletGlobalScopeJs.addToWorklet)(toneAudioWorkletProcessor);

},{"./WorkletGlobalScope.js":"KZYDB"}],"7MQGt":[function(require,module,exports) {
var _workletGlobalScopeJs = require("./WorkletGlobalScope.js");
const delayLine = /* javascript */ `
	/**
	 * A multichannel buffer for use within an AudioWorkletProcessor as a delay line
	 */
	class DelayLine {
		
		constructor(size, channels) {
			this.buffer = [];
			this.writeHead = []
			this.size = size;

			// create the empty channels
			for (let i = 0; i < channels; i++) {
				this.buffer[i] = new Float32Array(this.size);
				this.writeHead[i] = 0;
			}
		}

		/**
		 * Push a value onto the end
		 * @param channel number
		 * @param value number
		 */
		push(channel, value) {
			this.writeHead[channel] += 1;
			if (this.writeHead[channel] > this.size) {
				this.writeHead[channel] = 0;
			}
			this.buffer[channel][this.writeHead[channel]] = value;
		}

		/**
		 * Get the recorded value of the channel given the delay
		 * @param channel number
		 * @param delay number delay samples
		 */
		get(channel, delay) {
			let readHead = this.writeHead[channel] - Math.floor(delay);
			if (readHead < 0) {
				readHead += this.size;
			}
			return this.buffer[channel][readHead];
		}
	}
`;
(0, _workletGlobalScopeJs.addToWorklet)(delayLine);

},{"./WorkletGlobalScope.js":"KZYDB"}],"1CfWn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A one pole filter with 6db-per-octave rolloff. Either "highpass" or "lowpass".
 * Note that changing the type or frequency may result in a discontinuity which
 * can sound like a click or pop.
 * References:
 * * http://www.earlevel.com/main/2012/12/15/a-one-pole-filter/
 * * http://www.dspguide.com/ch19/2.htm
 * * https://github.com/vitaliy-bobrov/js-rocks/blob/master/src/app/audio/effects/one-pole-filters.ts
 * @category Component
 */ parcelHelpers.export(exports, "OnePoleFilter", ()=>OnePoleFilter);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _gainJs = require("../../core/context/Gain.js");
class OnePoleFilter extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(OnePoleFilter.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        super(options);
        this.name = "OnePoleFilter";
        this._frequency = options.frequency;
        this._type = options.type;
        this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._createFilter();
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            frequency: 880,
            type: "lowpass"
        });
    }
    /**
     * Create a filter and dispose the old one
     */ _createFilter() {
        const oldFilter = this._filter;
        const freq = this.toFrequency(this._frequency);
        const t = 1 / (2 * Math.PI * freq);
        if (this._type === "lowpass") {
            const a0 = 1 / (t * this.context.sampleRate);
            const b1 = a0 - 1;
            this._filter = this.context.createIIRFilter([
                a0,
                0
            ], [
                1,
                b1
            ]);
        } else {
            const b1 = 1 / (t * this.context.sampleRate) - 1;
            this._filter = this.context.createIIRFilter([
                1,
                -1
            ], [
                1,
                b1
            ]);
        }
        this.input.chain(this._filter, this.output);
        if (oldFilter) // dispose it on the next block
        this.context.setTimeout(()=>{
            if (!this.disposed) {
                this.input.disconnect(oldFilter);
                oldFilter.disconnect();
            }
        }, this.blockTime);
    }
    /**
     * The frequency value.
     */ get frequency() {
        return this._frequency;
    }
    set frequency(fq) {
        this._frequency = fq;
        this._createFilter();
    }
    /**
     * The OnePole Filter type, either "highpass" or "lowpass"
     */ get type() {
        return this._type;
    }
    set type(t) {
        this._type = t;
        this._createFilter();
    }
    /**
     * Get the frequency response curve. This curve represents how the filter
     * responses to frequencies between 20hz-20khz.
     * @param  len The number of values to return
     * @return The frequency response curve between 20-20kHz
     */ getFrequencyResponse(len = 128) {
        const freqValues = new Float32Array(len);
        for(let i = 0; i < len; i++){
            const norm = Math.pow(i / len, 2);
            const freq = norm * 19980 + 20;
            freqValues[i] = freq;
        }
        const magValues = new Float32Array(len);
        const phaseValues = new Float32Array(len);
        this._filter.getFrequencyResponse(freqValues, magValues, phaseValues);
        return magValues;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this._filter.disconnect();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/context/Gain.js":"kj68Y","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6hx2H":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PolySynth handles voice creation and allocation for any
 * instruments passed in as the second parameter. PolySynth is
 * not a synthesizer by itself, it merely manages voices of
 * one of the other types of synths, allowing any of the
 * monophonic synthesizers to be polyphonic.
 *
 * @example
 * const synth = new Tone.PolySynth().toDestination();
 * // set the attributes across all the voices using 'set'
 * synth.set({ detune: -1200 });
 * // play a chord
 * synth.triggerAttackRelease(["C4", "E4", "A4"], 1);
 * @category Instrument
 */ parcelHelpers.export(exports, "PolySynth", ()=>PolySynth);
var _midiJs = require("../core/type/Midi.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _typeCheckJs = require("../core/util/TypeCheck.js");
var _instrumentJs = require("./Instrument.js");
var _monophonicJs = require("./Monophonic.js");
var _synthJs = require("./Synth.js");
var _debugJs = require("../core/util/Debug.js");
class PolySynth extends (0, _instrumentJs.Instrument) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(PolySynth.getDefaults(), arguments, [
            "voice",
            "options"
        ]);
        super(options);
        this.name = "PolySynth";
        /**
         * The voices which are not currently in use
         */ this._availableVoices = [];
        /**
         * The currently active voices
         */ this._activeVoices = [];
        /**
         * All of the allocated voices for this synth.
         */ this._voices = [];
        /**
         * The GC timeout. Held so that it could be cancelled when the node is disposed.
         */ this._gcTimeout = -1;
        /**
         * A moving average of the number of active voices
         */ this._averageActiveVoices = 0;
        /**
         * The release which is scheduled to the timeline.
         */ this._syncedRelease = (time)=>this.releaseAll(time);
        // check against the old API (pre 14.3.0)
        (0, _debugJs.assert)(!(0, _typeCheckJs.isNumber)(options.voice), "DEPRECATED: The polyphony count is no longer the first argument.");
        const defaults = options.voice.getDefaults();
        this.options = Object.assign(defaults, options.options);
        this.voice = options.voice;
        this.maxPolyphony = options.maxPolyphony;
        // create the first voice
        this._dummyVoice = this._getNextAvailableVoice();
        // remove it from the voices list
        const index = this._voices.indexOf(this._dummyVoice);
        this._voices.splice(index, 1);
        // kick off the GC interval
        this._gcTimeout = this.context.setInterval(this._collectGarbage.bind(this), 1);
    }
    static getDefaults() {
        return Object.assign((0, _instrumentJs.Instrument).getDefaults(), {
            maxPolyphony: 32,
            options: {},
            voice: (0, _synthJs.Synth)
        });
    }
    /**
     * The number of active voices.
     */ get activeVoices() {
        return this._activeVoices.length;
    }
    /**
     * Invoked when the source is done making sound, so that it can be
     * readded to the pool of available voices
     */ _makeVoiceAvailable(voice) {
        this._availableVoices.push(voice);
        // remove the midi note from 'active voices'
        const activeVoiceIndex = this._activeVoices.findIndex((e)=>e.voice === voice);
        this._activeVoices.splice(activeVoiceIndex, 1);
    }
    /**
     * Get an available voice from the pool of available voices.
     * If one is not available and the maxPolyphony limit is reached,
     * steal a voice, otherwise return null.
     */ _getNextAvailableVoice() {
        // if there are available voices, return the first one
        if (this._availableVoices.length) return this._availableVoices.shift();
        else if (this._voices.length < this.maxPolyphony) {
            // otherwise if there is still more maxPolyphony, make a new voice
            const voice = new this.voice(Object.assign(this.options, {
                context: this.context,
                onsilence: this._makeVoiceAvailable.bind(this)
            }));
            (0, _debugJs.assert)(voice instanceof (0, _monophonicJs.Monophonic), "Voice must extend Monophonic class");
            voice.connect(this.output);
            this._voices.push(voice);
            return voice;
        } else (0, _debugJs.warn)("Max polyphony exceeded. Note dropped.");
    }
    /**
     * Occasionally check if there are any allocated voices which can be cleaned up.
     */ _collectGarbage() {
        this._averageActiveVoices = Math.max(this._averageActiveVoices * 0.95, this.activeVoices);
        if (this._availableVoices.length && this._voices.length > Math.ceil(this._averageActiveVoices + 1)) {
            // take off an available note
            const firstAvail = this._availableVoices.shift();
            const index = this._voices.indexOf(firstAvail);
            this._voices.splice(index, 1);
            if (!this.context.isOffline) firstAvail.dispose();
        }
    }
    /**
     * Internal method which triggers the attack
     */ _triggerAttack(notes, time, velocity) {
        notes.forEach((note)=>{
            const midiNote = new (0, _midiJs.MidiClass)(this.context, note).toMidi();
            const voice = this._getNextAvailableVoice();
            if (voice) {
                voice.triggerAttack(note, time, velocity);
                this._activeVoices.push({
                    midi: midiNote,
                    voice,
                    released: false
                });
                this.log("triggerAttack", note, time);
            }
        });
    }
    /**
     * Internal method which triggers the release
     */ _triggerRelease(notes, time) {
        notes.forEach((note)=>{
            const midiNote = new (0, _midiJs.MidiClass)(this.context, note).toMidi();
            const event = this._activeVoices.find(({ midi, released })=>midi === midiNote && !released);
            if (event) {
                // trigger release on that note
                event.voice.triggerRelease(time);
                // mark it as released
                event.released = true;
                this.log("triggerRelease", note, time);
            }
        });
    }
    /**
     * Schedule the attack/release events. If the time is in the future, then it should set a timeout
     * to wait for just-in-time scheduling
     */ _scheduleEvent(type, notes, time, velocity) {
        (0, _debugJs.assert)(!this.disposed, "Synth was already disposed");
        // if the notes are greater than this amount of time in the future, they should be scheduled with setTimeout
        if (time <= this.now()) {
            // do it immediately
            if (type === "attack") this._triggerAttack(notes, time, velocity);
            else this._triggerRelease(notes, time);
        } else // schedule it to start in the future
        this.context.setTimeout(()=>{
            if (!this.disposed) this._scheduleEvent(type, notes, time, velocity);
        }, time - this.now());
    }
    /**
     * Trigger the attack portion of the note
     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.
     * @param  time  The start time of the note.
     * @param velocity The velocity of the note.
     * @example
     * const synth = new Tone.PolySynth(Tone.FMSynth).toDestination();
     * // trigger a chord immediately with a velocity of 0.2
     * synth.triggerAttack(["Ab3", "C4", "F5"], Tone.now(), 0.2);
     */ triggerAttack(notes, time, velocity) {
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        const computedTime = this.toSeconds(time);
        this._scheduleEvent("attack", notes, computedTime, velocity);
        return this;
    }
    /**
     * Trigger the release of the note. Unlike monophonic instruments,
     * a note (or array of notes) needs to be passed in as the first argument.
     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.
     * @param  time  When the release will be triggered.
     * @example
     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();
     * poly.triggerAttack(["Ab3", "C4", "F5"]);
     * // trigger the release of the given notes.
     * poly.triggerRelease(["Ab3", "C4"], "+1");
     * poly.triggerRelease("F5", "+3");
     */ triggerRelease(notes, time) {
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        const computedTime = this.toSeconds(time);
        this._scheduleEvent("release", notes, computedTime);
        return this;
    }
    /**
     * Trigger the attack and release after the specified duration
     * @param  notes The notes to play. Accepts a single  Frequency or an array of frequencies.
     * @param  duration the duration of the note
     * @param  time  if no time is given, defaults to now
     * @param  velocity the velocity of the attack (0-1)
     * @example
     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();
     * // can pass in an array of durations as well
     * poly.triggerAttackRelease(["Eb3", "G4", "Bb4", "D5"], [4, 3, 2, 1]);
     */ triggerAttackRelease(notes, duration, time, velocity) {
        const computedTime = this.toSeconds(time);
        this.triggerAttack(notes, computedTime, velocity);
        if ((0, _typeCheckJs.isArray)(duration)) {
            (0, _debugJs.assert)((0, _typeCheckJs.isArray)(notes), "If the duration is an array, the notes must also be an array");
            notes;
            for(let i = 0; i < notes.length; i++){
                const d = duration[Math.min(i, duration.length - 1)];
                const durationSeconds = this.toSeconds(d);
                (0, _debugJs.assert)(durationSeconds > 0, "The duration must be greater than 0");
                this.triggerRelease(notes[i], computedTime + durationSeconds);
            }
        } else {
            const durationSeconds = this.toSeconds(duration);
            (0, _debugJs.assert)(durationSeconds > 0, "The duration must be greater than 0");
            this.triggerRelease(notes, computedTime + durationSeconds);
        }
        return this;
    }
    sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 1);
            this._syncMethod("triggerRelease", 1);
            // make sure that the sound doesn't play after its been stopped
            this.context.transport.on("stop", this._syncedRelease);
            this.context.transport.on("pause", this._syncedRelease);
            this.context.transport.on("loopEnd", this._syncedRelease);
        }
        return this;
    }
    /**
     * Set a member/attribute of the voices
     * @example
     * const poly = new Tone.PolySynth().toDestination();
     * // set all of the voices using an options object for the synth type
     * poly.set({
     * 	envelope: {
     * 		attack: 0.25
     * 	}
     * });
     * poly.triggerAttackRelease("Bb3", 0.2);
     */ set(options) {
        // remove options which are controlled by the PolySynth
        const sanitizedOptions = (0, _defaultsJs.omitFromObject)(options, [
            "onsilence",
            "context"
        ]);
        // store all of the options
        this.options = (0, _defaultsJs.deepMerge)(this.options, sanitizedOptions);
        this._voices.forEach((voice)=>voice.set(sanitizedOptions));
        this._dummyVoice.set(sanitizedOptions);
        return this;
    }
    get() {
        return this._dummyVoice.get();
    }
    /**
     * Trigger the release portion of all the currently active voices immediately.
     * Useful for silencing the synth.
     */ releaseAll(time) {
        const computedTime = this.toSeconds(time);
        this._activeVoices.forEach(({ voice })=>{
            voice.triggerRelease(computedTime);
        });
        return this;
    }
    dispose() {
        super.dispose();
        this._dummyVoice.dispose();
        this._voices.forEach((v)=>v.dispose());
        this._activeVoices = [];
        this._availableVoices = [];
        this.context.clearInterval(this._gcTimeout);
        return this;
    }
}

},{"../core/type/Midi.js":"kST2k","../core/util/Defaults.js":"a9M5s","../core/util/TypeCheck.js":"eMH5A","./Instrument.js":"cFM2P","./Monophonic.js":"eKiiZ","./Synth.js":"kwmGi","../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dBIID":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Pass in an object which maps the note's pitch or midi value to the url,
 * then you can trigger the attack and release of that note like other instruments.
 * By automatically repitching the samples, it is possible to play pitches which
 * were not explicitly included which can save loading time.
 *
 * For sample or buffer playback where repitching is not necessary,
 * use {@link Player}.
 * @example
 * const sampler = new Tone.Sampler({
 * 	urls: {
 * 		A1: "A1.mp3",
 * 		A2: "A2.mp3",
 * 	},
 * 	baseUrl: "https://tonejs.github.io/audio/casio/",
 * 	onload: () => {
 * 		sampler.triggerAttackRelease(["C1", "E1", "G1", "B1"], 0.5);
 * 	}
 * }).toDestination();
 * @category Instrument
 */ parcelHelpers.export(exports, "Sampler", ()=>Sampler);
var _tslib = require("tslib");
var _toneAudioBuffersJs = require("../core/context/ToneAudioBuffers.js");
var _conversionsJs = require("../core/type/Conversions.js");
var _frequencyJs = require("../core/type/Frequency.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _typeCheckJs = require("../core/util/TypeCheck.js");
var _instrumentJs = require("../instrument/Instrument.js");
var _toneBufferSourceJs = require("../source/buffer/ToneBufferSource.js");
var _decoratorJs = require("../core/util/Decorator.js");
var _debugJs = require("../core/util/Debug.js");
class Sampler extends (0, _instrumentJs.Instrument) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Sampler.getDefaults(), arguments, [
            "urls",
            "onload",
            "baseUrl"
        ], "urls");
        super(options);
        this.name = "Sampler";
        /**
         * The object of all currently playing BufferSources
         */ this._activeSources = new Map();
        const urlMap = {};
        Object.keys(options.urls).forEach((note)=>{
            const noteNumber = parseInt(note, 10);
            (0, _debugJs.assert)((0, _typeCheckJs.isNote)(note) || (0, _typeCheckJs.isNumber)(noteNumber) && isFinite(noteNumber), `url key is neither a note or midi pitch: ${note}`);
            if ((0, _typeCheckJs.isNote)(note)) {
                // convert the note name to MIDI
                const mid = new (0, _frequencyJs.FrequencyClass)(this.context, note).toMidi();
                urlMap[mid] = options.urls[note];
            } else if ((0, _typeCheckJs.isNumber)(noteNumber) && isFinite(noteNumber)) // otherwise if it's numbers assume it's midi
            urlMap[noteNumber] = options.urls[noteNumber];
        });
        this._buffers = new (0, _toneAudioBuffersJs.ToneAudioBuffers)({
            urls: urlMap,
            onload: options.onload,
            baseUrl: options.baseUrl,
            onerror: options.onerror
        });
        this.attack = options.attack;
        this.release = options.release;
        this.curve = options.curve;
        // invoke the callback if it's already loaded
        if (this._buffers.loaded) // invoke onload deferred
        Promise.resolve().then(options.onload);
    }
    static getDefaults() {
        return Object.assign((0, _instrumentJs.Instrument).getDefaults(), {
            attack: 0,
            baseUrl: "",
            curve: "exponential",
            onload: (0, _interfaceJs.noOp),
            onerror: (0, _interfaceJs.noOp),
            release: 0.1,
            urls: {}
        });
    }
    /**
     * Returns the difference in steps between the given midi note at the closets sample.
     */ _findClosest(midi) {
        // searches within 8 octaves of the given midi note
        const MAX_INTERVAL = 96;
        let interval = 0;
        while(interval < MAX_INTERVAL){
            // check above and below
            if (this._buffers.has(midi + interval)) return -interval;
            else if (this._buffers.has(midi - interval)) return interval;
            interval++;
        }
        throw new Error(`No available buffers for note: ${midi}`);
    }
    /**
     * @param  notes	The note to play, or an array of notes.
     * @param  time     When to play the note
     * @param  velocity The velocity to play the sample back.
     */ triggerAttack(notes, time, velocity = 1) {
        this.log("triggerAttack", notes, time, velocity);
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        notes.forEach((note)=>{
            const midiFloat = (0, _conversionsJs.ftomf)(new (0, _frequencyJs.FrequencyClass)(this.context, note).toFrequency());
            const midi = Math.round(midiFloat);
            const remainder = midiFloat - midi;
            // find the closest note pitch
            const difference = this._findClosest(midi);
            const closestNote = midi - difference;
            const buffer = this._buffers.get(closestNote);
            const playbackRate = (0, _conversionsJs.intervalToFrequencyRatio)(difference + remainder);
            // play that note
            const source = new (0, _toneBufferSourceJs.ToneBufferSource)({
                url: buffer,
                context: this.context,
                curve: this.curve,
                fadeIn: this.attack,
                fadeOut: this.release,
                playbackRate
            }).connect(this.output);
            source.start(time, 0, buffer.duration / playbackRate, velocity);
            // add it to the active sources
            if (!(0, _typeCheckJs.isArray)(this._activeSources.get(midi))) this._activeSources.set(midi, []);
            this._activeSources.get(midi).push(source);
            // remove it when it's done
            source.onended = ()=>{
                if (this._activeSources && this._activeSources.has(midi)) {
                    const sources = this._activeSources.get(midi);
                    const index = sources.indexOf(source);
                    if (index !== -1) sources.splice(index, 1);
                }
            };
        });
        return this;
    }
    /**
     * @param  notes	The note to release, or an array of notes.
     * @param  time     	When to release the note.
     */ triggerRelease(notes, time) {
        this.log("triggerRelease", notes, time);
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        notes.forEach((note)=>{
            const midi = new (0, _frequencyJs.FrequencyClass)(this.context, note).toMidi();
            // find the note
            if (this._activeSources.has(midi) && this._activeSources.get(midi).length) {
                const sources = this._activeSources.get(midi);
                time = this.toSeconds(time);
                sources.forEach((source)=>{
                    source.stop(time);
                });
                this._activeSources.set(midi, []);
            }
        });
        return this;
    }
    /**
     * Release all currently active notes.
     * @param  time     	When to release the notes.
     */ releaseAll(time) {
        const computedTime = this.toSeconds(time);
        this._activeSources.forEach((sources)=>{
            while(sources.length){
                const source = sources.shift();
                source.stop(computedTime);
            }
        });
        return this;
    }
    sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 1);
            this._syncMethod("triggerRelease", 1);
        }
        return this;
    }
    /**
     * Invoke the attack phase, then after the duration, invoke the release.
     * @param  notes	The note to play and release, or an array of notes.
     * @param  duration The time the note should be held
     * @param  time     When to start the attack
     * @param  velocity The velocity of the attack
     */ triggerAttackRelease(notes, duration, time, velocity = 1) {
        const computedTime = this.toSeconds(time);
        this.triggerAttack(notes, computedTime, velocity);
        if ((0, _typeCheckJs.isArray)(duration)) {
            (0, _debugJs.assert)((0, _typeCheckJs.isArray)(notes), "notes must be an array when duration is array");
            notes.forEach((note, index)=>{
                const d = duration[Math.min(index, duration.length - 1)];
                this.triggerRelease(note, computedTime + this.toSeconds(d));
            });
        } else this.triggerRelease(notes, computedTime + this.toSeconds(duration));
        return this;
    }
    /**
     * Add a note to the sampler.
     * @param  note      The buffer's pitch.
     * @param  url  Either the url of the buffer, or a buffer which will be added with the given name.
     * @param  callback  The callback to invoke when the url is loaded.
     */ add(note, url, callback) {
        (0, _debugJs.assert)((0, _typeCheckJs.isNote)(note) || isFinite(note), `note must be a pitch or midi: ${note}`);
        if ((0, _typeCheckJs.isNote)(note)) {
            // convert the note name to MIDI
            const mid = new (0, _frequencyJs.FrequencyClass)(this.context, note).toMidi();
            this._buffers.add(mid, url, callback);
        } else // otherwise if it's numbers assume it's midi
        this._buffers.add(note, url, callback);
        return this;
    }
    /**
     * If the buffers are loaded or not
     */ get loaded() {
        return this._buffers.loaded;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._buffers.dispose();
        this._activeSources.forEach((sources)=>{
            sources.forEach((source)=>source.dispose());
        });
        this._activeSources.clear();
        return this;
    }
}
(0, _tslib.__decorate)([
    (0, _decoratorJs.timeRange)(0)
], Sampler.prototype, "attack", void 0);
(0, _tslib.__decorate)([
    (0, _decoratorJs.timeRange)(0)
], Sampler.prototype, "release", void 0);

},{"tslib":"lRdW5","../core/context/ToneAudioBuffers.js":"8zO1I","../core/type/Conversions.js":"iww1u","../core/type/Frequency.js":"bObwr","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","../core/util/TypeCheck.js":"eMH5A","../instrument/Instrument.js":"cFM2P","../source/buffer/ToneBufferSource.js":"9FxEt","../core/util/Decorator.js":"fl7ql","../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"eiKIt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _loopJs = require("./Loop.js");
parcelHelpers.exportAll(_loopJs, exports);
var _partJs = require("./Part.js");
parcelHelpers.exportAll(_partJs, exports);
var _patternJs = require("./Pattern.js");
parcelHelpers.exportAll(_patternJs, exports);
var _sequenceJs = require("./Sequence.js");
parcelHelpers.exportAll(_sequenceJs, exports);
var _toneEventJs = require("./ToneEvent.js");
parcelHelpers.exportAll(_toneEventJs, exports);

},{"./Loop.js":"dX4Gv","./Part.js":"5vWpY","./Pattern.js":"6vioO","./Sequence.js":"ekSeO","./ToneEvent.js":"bq5Fc","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dX4Gv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Loop creates a looped callback at the
 * specified interval. The callback can be
 * started, stopped and scheduled along
 * the Transport's timeline.
 * @example
 * const loop = new Tone.Loop((time) => {
 * 	// triggered every eighth note.
 * 	console.log(time);
 * }, "8n").start(0);
 * Tone.Transport.start();
 * @category Event
 */ parcelHelpers.export(exports, "Loop", ()=>Loop);
var _toneEventJs = require("./ToneEvent.js");
var _toneWithContextJs = require("../core/context/ToneWithContext.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
class Loop extends (0, _toneWithContextJs.ToneWithContext) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Loop.getDefaults(), arguments, [
            "callback",
            "interval"
        ]);
        super(options);
        this.name = "Loop";
        this._event = new (0, _toneEventJs.ToneEvent)({
            context: this.context,
            callback: this._tick.bind(this),
            loop: true,
            loopEnd: options.interval,
            playbackRate: options.playbackRate,
            probability: options.probability,
            humanize: options.humanize
        });
        this.callback = options.callback;
        // set the iterations
        this.iterations = options.iterations;
    }
    static getDefaults() {
        return Object.assign((0, _toneWithContextJs.ToneWithContext).getDefaults(), {
            interval: "4n",
            callback: (0, _interfaceJs.noOp),
            playbackRate: 1,
            iterations: Infinity,
            probability: 1,
            mute: false,
            humanize: false
        });
    }
    /**
     * Start the loop at the specified time along the Transport's timeline.
     * @param  time  When to start the Loop.
     */ start(time) {
        this._event.start(time);
        return this;
    }
    /**
     * Stop the loop at the given time.
     * @param  time  When to stop the Loop.
     */ stop(time) {
        this._event.stop(time);
        return this;
    }
    /**
     * Cancel all scheduled events greater than or equal to the given time
     * @param  time  The time after which events will be cancel.
     */ cancel(time) {
        this._event.cancel(time);
        return this;
    }
    /**
     * Internal function called when the notes should be called
     * @param time  The time the event occurs
     */ _tick(time) {
        this.callback(time);
    }
    /**
     * The state of the Loop, either started or stopped.
     */ get state() {
        return this._event.state;
    }
    /**
     * The progress of the loop as a value between 0-1. 0, when the loop is stopped or done iterating.
     */ get progress() {
        return this._event.progress;
    }
    /**
     * The time between successive callbacks.
     * @example
     * const loop = new Tone.Loop();
     * loop.interval = "8n"; // loop every 8n
     */ get interval() {
        return this._event.loopEnd;
    }
    set interval(interval) {
        this._event.loopEnd = interval;
    }
    /**
     * The playback rate of the loop. The normal playback rate is 1 (no change).
     * A `playbackRate` of 2 would be twice as fast.
     */ get playbackRate() {
        return this._event.playbackRate;
    }
    set playbackRate(rate) {
        this._event.playbackRate = rate;
    }
    /**
     * Random variation +/-0.01s to the scheduled time.
     * Or give it a time value which it will randomize by.
     */ get humanize() {
        return this._event.humanize;
    }
    set humanize(variation) {
        this._event.humanize = variation;
    }
    /**
     * The probably of the callback being invoked.
     */ get probability() {
        return this._event.probability;
    }
    set probability(prob) {
        this._event.probability = prob;
    }
    /**
     * Muting the Loop means that no callbacks are invoked.
     */ get mute() {
        return this._event.mute;
    }
    set mute(mute) {
        this._event.mute = mute;
    }
    /**
     * The number of iterations of the loop. The default value is `Infinity` (loop forever).
     */ get iterations() {
        if (this._event.loop === true) return Infinity;
        else return this._event.loop;
    }
    set iterations(iters) {
        if (iters === Infinity) this._event.loop = true;
        else this._event.loop = iters;
    }
    dispose() {
        super.dispose();
        this._event.dispose();
        return this;
    }
}

},{"./ToneEvent.js":"bq5Fc","../core/context/ToneWithContext.js":"gAuzg","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bq5Fc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * ToneEvent abstracts away this.context.transport.schedule and provides a schedulable
 * callback for a single or repeatable events along the timeline.
 *
 * @example
 * const synth = new Tone.PolySynth().toDestination();
 * const chordEvent = new Tone.ToneEvent(((time, chord) => {
 * 	// the chord as well as the exact time of the event
 * 	// are passed in as arguments to the callback function
 * 	synth.triggerAttackRelease(chord, 0.5, time);
 * }), ["D4", "E4", "F4"]);
 * // start the chord at the beginning of the transport timeline
 * chordEvent.start();
 * // loop it every measure for 8 measures
 * chordEvent.loop = 8;
 * chordEvent.loopEnd = "1m";
 * @category Event
 */ parcelHelpers.export(exports, "ToneEvent", ()=>ToneEvent);
var _transportJs = require("../core/clock/Transport.js");
var _toneWithContextJs = require("../core/context/ToneWithContext.js");
var _ticksJs = require("../core/type/Ticks.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _stateTimelineJs = require("../core/util/StateTimeline.js");
var _typeCheckJs = require("../core/util/TypeCheck.js");
class ToneEvent extends (0, _toneWithContextJs.ToneWithContext) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(ToneEvent.getDefaults(), arguments, [
            "callback",
            "value"
        ]);
        super(options);
        this.name = "ToneEvent";
        /**
         * Tracks the scheduled events
         */ this._state = new (0, _stateTimelineJs.StateTimeline)("stopped");
        /**
         * A delay time from when the event is scheduled to start
         */ this._startOffset = 0;
        this._loop = options.loop;
        this.callback = options.callback;
        this.value = options.value;
        this._loopStart = this.toTicks(options.loopStart);
        this._loopEnd = this.toTicks(options.loopEnd);
        this._playbackRate = options.playbackRate;
        this._probability = options.probability;
        this._humanize = options.humanize;
        this.mute = options.mute;
        this._playbackRate = options.playbackRate;
        this._state.increasing = true;
        // schedule the events for the first time
        this._rescheduleEvents();
    }
    static getDefaults() {
        return Object.assign((0, _toneWithContextJs.ToneWithContext).getDefaults(), {
            callback: (0, _interfaceJs.noOp),
            humanize: false,
            loop: false,
            loopEnd: "1m",
            loopStart: 0,
            mute: false,
            playbackRate: 1,
            probability: 1,
            value: null
        });
    }
    /**
     * Reschedule all of the events along the timeline
     * with the updated values.
     * @param after Only reschedules events after the given time.
     */ _rescheduleEvents(after = -1) {
        // if no argument is given, schedules all of the events
        this._state.forEachFrom(after, (event)=>{
            let duration;
            if (event.state === "started") {
                if (event.id !== -1) this.context.transport.clear(event.id);
                const startTick = event.time + Math.round(this.startOffset / this._playbackRate);
                if (this._loop === true || (0, _typeCheckJs.isNumber)(this._loop) && this._loop > 1) {
                    duration = Infinity;
                    if ((0, _typeCheckJs.isNumber)(this._loop)) duration = this._loop * this._getLoopDuration();
                    const nextEvent = this._state.getAfter(startTick);
                    if (nextEvent !== null) duration = Math.min(duration, nextEvent.time - startTick);
                    if (duration !== Infinity) duration = new (0, _ticksJs.TicksClass)(this.context, duration);
                    const interval = new (0, _ticksJs.TicksClass)(this.context, this._getLoopDuration());
                    event.id = this.context.transport.scheduleRepeat(this._tick.bind(this), interval, new (0, _ticksJs.TicksClass)(this.context, startTick), duration);
                } else event.id = this.context.transport.schedule(this._tick.bind(this), new (0, _ticksJs.TicksClass)(this.context, startTick));
            }
        });
    }
    /**
     * Returns the playback state of the note, either "started" or "stopped".
     */ get state() {
        return this._state.getValueAtTime(this.context.transport.ticks);
    }
    /**
     * The start from the scheduled start time.
     */ get startOffset() {
        return this._startOffset;
    }
    set startOffset(offset) {
        this._startOffset = offset;
    }
    /**
     * The probability of the notes being triggered.
     */ get probability() {
        return this._probability;
    }
    set probability(prob) {
        this._probability = prob;
    }
    /**
     * If set to true, will apply small random variation
     * to the callback time. If the value is given as a time, it will randomize
     * by that amount.
     * @example
     * const event = new Tone.ToneEvent();
     * event.humanize = true;
     */ get humanize() {
        return this._humanize;
    }
    set humanize(variation) {
        this._humanize = variation;
    }
    /**
     * Start the note at the given time.
     * @param  time  When the event should start.
     */ start(time) {
        const ticks = this.toTicks(time);
        if (this._state.getValueAtTime(ticks) === "stopped") {
            this._state.add({
                id: -1,
                state: "started",
                time: ticks
            });
            this._rescheduleEvents(ticks);
        }
        return this;
    }
    /**
     * Stop the Event at the given time.
     * @param  time  When the event should stop.
     */ stop(time) {
        this.cancel(time);
        const ticks = this.toTicks(time);
        if (this._state.getValueAtTime(ticks) === "started") {
            this._state.setStateAtTime("stopped", ticks, {
                id: -1
            });
            const previousEvent = this._state.getBefore(ticks);
            let rescheduleTime = ticks;
            if (previousEvent !== null) rescheduleTime = previousEvent.time;
            this._rescheduleEvents(rescheduleTime);
        }
        return this;
    }
    /**
     * Cancel all scheduled events greater than or equal to the given time
     * @param  time  The time after which events will be cancel.
     */ cancel(time) {
        time = (0, _defaultsJs.defaultArg)(time, -Infinity);
        const ticks = this.toTicks(time);
        this._state.forEachFrom(ticks, (event)=>{
            this.context.transport.clear(event.id);
        });
        this._state.cancel(ticks);
        return this;
    }
    /**
     * The callback function invoker. Also
     * checks if the Event is done playing
     * @param  time  The time of the event in seconds
     */ _tick(time) {
        const ticks = this.context.transport.getTicksAtTime(time);
        if (!this.mute && this._state.getValueAtTime(ticks) === "started") {
            if (this.probability < 1 && Math.random() > this.probability) return;
            if (this.humanize) {
                let variation = 0.02;
                if (!(0, _typeCheckJs.isBoolean)(this.humanize)) variation = this.toSeconds(this.humanize);
                time += (Math.random() * 2 - 1) * variation;
            }
            this.callback(time, this.value);
        }
    }
    /**
     * Get the duration of the loop.
     */ _getLoopDuration() {
        return (this._loopEnd - this._loopStart) / this._playbackRate;
    }
    /**
     * If the note should loop or not
     * between ToneEvent.loopStart and
     * ToneEvent.loopEnd. If set to true,
     * the event will loop indefinitely,
     * if set to a number greater than 1
     * it will play a specific number of
     * times, if set to false, 0 or 1, the
     * part will only play once.
     */ get loop() {
        return this._loop;
    }
    set loop(loop) {
        this._loop = loop;
        this._rescheduleEvents();
    }
    /**
     * The playback rate of the event. Defaults to 1.
     * @example
     * const note = new Tone.ToneEvent();
     * note.loop = true;
     * // repeat the note twice as fast
     * note.playbackRate = 2;
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        this._rescheduleEvents();
    }
    /**
     * The loopEnd point is the time the event will loop
     * if ToneEvent.loop is true.
     */ get loopEnd() {
        return new (0, _ticksJs.TicksClass)(this.context, this._loopEnd).toSeconds();
    }
    set loopEnd(loopEnd) {
        this._loopEnd = this.toTicks(loopEnd);
        if (this._loop) this._rescheduleEvents();
    }
    /**
     * The time when the loop should start.
     */ get loopStart() {
        return new (0, _ticksJs.TicksClass)(this.context, this._loopStart).toSeconds();
    }
    set loopStart(loopStart) {
        this._loopStart = this.toTicks(loopStart);
        if (this._loop) this._rescheduleEvents();
    }
    /**
     * The current progress of the loop interval.
     * Returns 0 if the event is not started yet or
     * it is not set to loop.
     */ get progress() {
        if (this._loop) {
            const ticks = this.context.transport.ticks;
            const lastEvent = this._state.get(ticks);
            if (lastEvent !== null && lastEvent.state === "started") {
                const loopDuration = this._getLoopDuration();
                const progress = (ticks - lastEvent.time) % loopDuration;
                return progress / loopDuration;
            } else return 0;
        } else return 0;
    }
    dispose() {
        super.dispose();
        this.cancel();
        this._state.dispose();
        return this;
    }
}

},{"../core/clock/Transport.js":"2kVaU","../core/context/ToneWithContext.js":"gAuzg","../core/type/Ticks.js":"BGGsE","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","../core/util/StateTimeline.js":"hkouL","../core/util/TypeCheck.js":"eMH5A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5vWpY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Part is a collection ToneEvents which can be started/stopped and looped as a single unit.
 *
 * @example
 * const synth = new Tone.Synth().toDestination();
 * const part = new Tone.Part(((time, note) => {
 * 	// the notes given as the second element in the array
 * 	// will be passed in as the second argument
 * 	synth.triggerAttackRelease(note, "8n", time);
 * }), [[0, "C2"], ["0:2", "C3"], ["0:3:2", "G2"]]).start(0);
 * Tone.Transport.start();
 * @example
 * const synth = new Tone.Synth().toDestination();
 * // use an array of objects as long as the object has a "time" attribute
 * const part = new Tone.Part(((time, value) => {
 * 	// the value is an object which contains both the note and the velocity
 * 	synth.triggerAttackRelease(value.note, "8n", time, value.velocity);
 * }), [{ time: 0, note: "C3", velocity: 0.9 },
 * 	{ time: "0:2", note: "C4", velocity: 0.5 }
 * ]).start(0);
 * Tone.Transport.start();
 * @category Event
 */ parcelHelpers.export(exports, "Part", ()=>Part);
var _ticksJs = require("../core/type/Ticks.js");
var _transportTimeJs = require("../core/type/TransportTime.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _stateTimelineJs = require("../core/util/StateTimeline.js");
var _typeCheckJs = require("../core/util/TypeCheck.js");
var _toneEventJs = require("./ToneEvent.js");
class Part extends (0, _toneEventJs.ToneEvent) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Part.getDefaults(), arguments, [
            "callback",
            "events"
        ]);
        super(options);
        this.name = "Part";
        /**
         * Tracks the scheduled events
         */ this._state = new (0, _stateTimelineJs.StateTimeline)("stopped");
        /**
         * The events that belong to this part
         */ this._events = new Set();
        // make sure things are assigned in the right order
        this._state.increasing = true;
        // add the events
        options.events.forEach((event)=>{
            if ((0, _typeCheckJs.isArray)(event)) this.add(event[0], event[1]);
            else this.add(event);
        });
    }
    static getDefaults() {
        return Object.assign((0, _toneEventJs.ToneEvent).getDefaults(), {
            events: []
        });
    }
    /**
     * Start the part at the given time.
     * @param  time    When to start the part.
     * @param  offset  The offset from the start of the part to begin playing at.
     */ start(time, offset) {
        const ticks = this.toTicks(time);
        if (this._state.getValueAtTime(ticks) !== "started") {
            offset = (0, _defaultsJs.defaultArg)(offset, this._loop ? this._loopStart : 0);
            if (this._loop) offset = (0, _defaultsJs.defaultArg)(offset, this._loopStart);
            else offset = (0, _defaultsJs.defaultArg)(offset, 0);
            const computedOffset = this.toTicks(offset);
            this._state.add({
                id: -1,
                offset: computedOffset,
                state: "started",
                time: ticks
            });
            this._forEach((event)=>{
                this._startNote(event, ticks, computedOffset);
            });
        }
        return this;
    }
    /**
     * Start the event in the given event at the correct time given
     * the ticks and offset and looping.
     * @param  event
     * @param  ticks
     * @param  offset
     */ _startNote(event, ticks, offset) {
        ticks -= offset;
        if (this._loop) {
            if (event.startOffset >= this._loopStart && event.startOffset < this._loopEnd) {
                if (event.startOffset < offset) // start it on the next loop
                ticks += this._getLoopDuration();
                event.start(new (0, _ticksJs.TicksClass)(this.context, ticks));
            } else if (event.startOffset < this._loopStart && event.startOffset >= offset) {
                event.loop = false;
                event.start(new (0, _ticksJs.TicksClass)(this.context, ticks));
            }
        } else if (event.startOffset >= offset) event.start(new (0, _ticksJs.TicksClass)(this.context, ticks));
    }
    get startOffset() {
        return this._startOffset;
    }
    set startOffset(offset) {
        this._startOffset = offset;
        this._forEach((event)=>{
            event.startOffset += this._startOffset;
        });
    }
    /**
     * Stop the part at the given time.
     * @param  time  When to stop the part.
     */ stop(time) {
        const ticks = this.toTicks(time);
        this._state.cancel(ticks);
        this._state.setStateAtTime("stopped", ticks);
        this._forEach((event)=>{
            event.stop(time);
        });
        return this;
    }
    /**
     * Get/Set an Event's value at the given time.
     * If a value is passed in and no event exists at
     * the given time, one will be created with that value.
     * If two events are at the same time, the first one will
     * be returned.
     * @example
     * const part = new Tone.Part();
     * part.at("1m"); // returns the part at the first measure
     * part.at("2m", "C2"); // set the value at "2m" to C2.
     * // if an event didn't exist at that time, it will be created.
     * @param time The time of the event to get or set.
     * @param value If a value is passed in, the value of the event at the given time will be set to it.
     */ at(time, value) {
        const timeInTicks = new (0, _transportTimeJs.TransportTimeClass)(this.context, time).toTicks();
        const tickTime = new (0, _ticksJs.TicksClass)(this.context, 1).toSeconds();
        const iterator = this._events.values();
        let result = iterator.next();
        while(!result.done){
            const event = result.value;
            if (Math.abs(timeInTicks - event.startOffset) < tickTime) {
                if ((0, _typeCheckJs.isDefined)(value)) event.value = value;
                return event;
            }
            result = iterator.next();
        }
        // if there was no event at that time, create one
        if ((0, _typeCheckJs.isDefined)(value)) {
            this.add(time, value);
            // return the new event
            return this.at(time);
        } else return null;
    }
    add(time, value) {
        // extract the parameters
        if (time instanceof Object && Reflect.has(time, "time")) {
            value = time;
            time = value.time;
        }
        const ticks = this.toTicks(time);
        let event;
        if (value instanceof (0, _toneEventJs.ToneEvent)) {
            event = value;
            event.callback = this._tick.bind(this);
        } else event = new (0, _toneEventJs.ToneEvent)({
            callback: this._tick.bind(this),
            context: this.context,
            value
        });
        // the start offset
        event.startOffset = ticks;
        // initialize the values
        event.set({
            humanize: this.humanize,
            loop: this.loop,
            loopEnd: this.loopEnd,
            loopStart: this.loopStart,
            playbackRate: this.playbackRate,
            probability: this.probability
        });
        this._events.add(event);
        // start the note if it should be played right now
        this._restartEvent(event);
        return this;
    }
    /**
     * Restart the given event
     */ _restartEvent(event) {
        this._state.forEach((stateEvent)=>{
            if (stateEvent.state === "started") this._startNote(event, stateEvent.time, stateEvent.offset);
            else // stop the note
            event.stop(new (0, _ticksJs.TicksClass)(this.context, stateEvent.time));
        });
    }
    remove(time, value) {
        // extract the parameters
        if ((0, _typeCheckJs.isObject)(time) && time.hasOwnProperty("time")) {
            value = time;
            time = value.time;
        }
        time = this.toTicks(time);
        this._events.forEach((event)=>{
            if (event.startOffset === time) {
                if ((0, _typeCheckJs.isUndef)(value) || (0, _typeCheckJs.isDefined)(value) && event.value === value) {
                    this._events.delete(event);
                    event.dispose();
                }
            }
        });
        return this;
    }
    /**
     * Remove all of the notes from the group.
     */ clear() {
        this._forEach((event)=>event.dispose());
        this._events.clear();
        return this;
    }
    /**
     * Cancel scheduled state change events: i.e. "start" and "stop".
     * @param after The time after which to cancel the scheduled events.
     */ cancel(after) {
        this._forEach((event)=>event.cancel(after));
        this._state.cancel(this.toTicks(after));
        return this;
    }
    /**
     * Iterate over all of the events
     */ _forEach(callback) {
        if (this._events) this._events.forEach((event)=>{
            if (event instanceof Part) event._forEach(callback);
            else callback(event);
        });
        return this;
    }
    /**
     * Set the attribute of all of the events
     * @param  attr  the attribute to set
     * @param  value      The value to set it to
     */ _setAll(attr, value) {
        this._forEach((event)=>{
            event[attr] = value;
        });
    }
    /**
     * Internal tick method
     * @param  time  The time of the event in seconds
     */ _tick(time, value) {
        if (!this.mute) this.callback(time, value);
    }
    /**
     * Determine if the event should be currently looping
     * given the loop boundries of this Part.
     * @param  event  The event to test
     */ _testLoopBoundries(event) {
        if (this._loop && (event.startOffset < this._loopStart || event.startOffset >= this._loopEnd)) event.cancel(0);
        else if (event.state === "stopped") // reschedule it if it's stopped
        this._restartEvent(event);
    }
    get probability() {
        return this._probability;
    }
    set probability(prob) {
        this._probability = prob;
        this._setAll("probability", prob);
    }
    get humanize() {
        return this._humanize;
    }
    set humanize(variation) {
        this._humanize = variation;
        this._setAll("humanize", variation);
    }
    /**
     * If the part should loop or not
     * between Part.loopStart and
     * Part.loopEnd. If set to true,
     * the part will loop indefinitely,
     * if set to a number greater than 1
     * it will play a specific number of
     * times, if set to false, 0 or 1, the
     * part will only play once.
     * @example
     * const part = new Tone.Part();
     * // loop the part 8 times
     * part.loop = 8;
     */ get loop() {
        return this._loop;
    }
    set loop(loop) {
        this._loop = loop;
        this._forEach((event)=>{
            event.loopStart = this.loopStart;
            event.loopEnd = this.loopEnd;
            event.loop = loop;
            this._testLoopBoundries(event);
        });
    }
    /**
     * The loopEnd point determines when it will
     * loop if Part.loop is true.
     */ get loopEnd() {
        return new (0, _ticksJs.TicksClass)(this.context, this._loopEnd).toSeconds();
    }
    set loopEnd(loopEnd) {
        this._loopEnd = this.toTicks(loopEnd);
        if (this._loop) this._forEach((event)=>{
            event.loopEnd = loopEnd;
            this._testLoopBoundries(event);
        });
    }
    /**
     * The loopStart point determines when it will
     * loop if Part.loop is true.
     */ get loopStart() {
        return new (0, _ticksJs.TicksClass)(this.context, this._loopStart).toSeconds();
    }
    set loopStart(loopStart) {
        this._loopStart = this.toTicks(loopStart);
        if (this._loop) this._forEach((event)=>{
            event.loopStart = this.loopStart;
            this._testLoopBoundries(event);
        });
    }
    /**
     * The playback rate of the part
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        this._setAll("playbackRate", rate);
    }
    /**
     * The number of scheduled notes in the part.
     */ get length() {
        return this._events.size;
    }
    dispose() {
        super.dispose();
        this.clear();
        return this;
    }
}

},{"../core/type/Ticks.js":"BGGsE","../core/type/TransportTime.js":"a6yW0","../core/util/Defaults.js":"a9M5s","../core/util/StateTimeline.js":"hkouL","../core/util/TypeCheck.js":"eMH5A","./ToneEvent.js":"bq5Fc","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6vioO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Pattern arpeggiates between the given notes
 * in a number of patterns.
 * @example
 * const pattern = new Tone.Pattern((time, note) => {
 * 	// the order of the notes passed in depends on the pattern
 * }, ["C2", "D4", "E5", "A6"], "upDown");
 * @category Event
 */ parcelHelpers.export(exports, "Pattern", ()=>Pattern);
var _loopJs = require("./Loop.js");
var _patternGeneratorJs = require("./PatternGenerator.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
class Pattern extends (0, _loopJs.Loop) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Pattern.getDefaults(), arguments, [
            "callback",
            "values",
            "pattern"
        ]);
        super(options);
        this.name = "Pattern";
        this.callback = options.callback;
        this._values = options.values;
        this._pattern = (0, _patternGeneratorJs.PatternGenerator)(options.values.length, options.pattern);
        this._type = options.pattern;
    }
    static getDefaults() {
        return Object.assign((0, _loopJs.Loop).getDefaults(), {
            pattern: "up",
            values: [],
            callback: (0, _interfaceJs.noOp)
        });
    }
    /**
     * Internal function called when the notes should be called
     */ _tick(time) {
        const index = this._pattern.next();
        this._index = index.value;
        this._value = this._values[index.value];
        this.callback(time, this._value);
    }
    /**
     * The array of events.
     */ get values() {
        return this._values;
    }
    set values(val) {
        this._values = val;
        // reset the pattern
        this.pattern = this._type;
    }
    /**
     * The current value of the pattern.
     */ get value() {
        return this._value;
    }
    /**
     * The current index of the pattern.
     */ get index() {
        return this._index;
    }
    /**
     * The pattern type.
     */ get pattern() {
        return this._type;
    }
    set pattern(pattern) {
        this._type = pattern;
        this._pattern = (0, _patternGeneratorJs.PatternGenerator)(this._values.length, this._type);
    }
}

},{"./Loop.js":"dX4Gv","./PatternGenerator.js":"37MIC","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"37MIC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PatternGenerator returns a generator which will yield numbers between 0 and numValues
 * according to the passed in pattern that can be used as indexes into an array of size numValues.
 * @param numValues The size of the array to emit indexes for
 * @param pattern The name of the pattern use when iterating over
 * @param index Where to start in the offset of the values array
 */ parcelHelpers.export(exports, "PatternGenerator", ()=>PatternGenerator);
var _debugJs = require("../core/util/Debug.js");
var _mathJs = require("../core/util/Math.js");
/**
 * Start at the first value and go up to the last
 */ function* upPatternGen(numValues) {
    let index = 0;
    while(index < numValues){
        index = (0, _mathJs.clamp)(index, 0, numValues - 1);
        yield index;
        index++;
    }
}
/**
 * Start at the last value and go down to 0
 */ function* downPatternGen(numValues) {
    let index = numValues - 1;
    while(index >= 0){
        index = (0, _mathJs.clamp)(index, 0, numValues - 1);
        yield index;
        index--;
    }
}
/**
 * Infinitely yield the generator
 */ function* infiniteGen(numValues, gen) {
    while(true)yield* gen(numValues);
}
/**
 * Alternate between two generators
 */ function* alternatingGenerator(numValues, directionUp) {
    let index = directionUp ? 0 : numValues - 1;
    while(true){
        index = (0, _mathJs.clamp)(index, 0, numValues - 1);
        yield index;
        if (directionUp) {
            index++;
            if (index >= numValues - 1) directionUp = false;
        } else {
            index--;
            if (index <= 0) directionUp = true;
        }
    }
}
/**
 * Starting from the bottom move up 2, down 1
 */ function* jumpUp(numValues) {
    let index = 0;
    let stepIndex = 0;
    while(index < numValues){
        index = (0, _mathJs.clamp)(index, 0, numValues - 1);
        yield index;
        stepIndex++;
        index += stepIndex % 2 ? 2 : -1;
    }
}
/**
 * Starting from the top move down 2, up 1
 */ function* jumpDown(numValues) {
    let index = numValues - 1;
    let stepIndex = 0;
    while(index >= 0){
        index = (0, _mathJs.clamp)(index, 0, numValues - 1);
        yield index;
        stepIndex++;
        index += stepIndex % 2 ? -2 : 1;
    }
}
/**
 * Choose a random index each time
 */ function* randomGen(numValues) {
    while(true){
        const randomIndex = Math.floor(Math.random() * numValues);
        yield randomIndex;
    }
}
/**
 * Randomly go through all of the values once before choosing a new random order
 */ function* randomOnce(numValues) {
    // create an array of indices
    const copy = [];
    for(let i = 0; i < numValues; i++)copy.push(i);
    while(copy.length > 0){
        // random choose an index, and then remove it so it's not chosen again
        const randVal = copy.splice(Math.floor(copy.length * Math.random()), 1);
        const index = (0, _mathJs.clamp)(randVal[0], 0, numValues - 1);
        yield index;
    }
}
/**
 * Randomly choose to walk up or down 1 index
 */ function* randomWalk(numValues) {
    // randomly choose a starting index
    let index = Math.floor(Math.random() * numValues);
    while(true){
        if (index === 0) index++; // at bottom, so force upward step
        else if (index === numValues - 1) index--; // at top, so force downward step
        else if (Math.random() < 0.5) // else choose random downward or upward step
        index--;
        else index++;
        yield index;
    }
}
function* PatternGenerator(numValues, pattern = "up", index = 0) {
    // safeguards
    (0, _debugJs.assert)(numValues >= 1, "The number of values must be at least one");
    switch(pattern){
        case "up":
            yield* infiniteGen(numValues, upPatternGen);
        case "down":
            yield* infiniteGen(numValues, downPatternGen);
        case "upDown":
            yield* alternatingGenerator(numValues, true);
        case "downUp":
            yield* alternatingGenerator(numValues, false);
        case "alternateUp":
            yield* infiniteGen(numValues, jumpUp);
        case "alternateDown":
            yield* infiniteGen(numValues, jumpDown);
        case "random":
            yield* randomGen(numValues);
        case "randomOnce":
            yield* infiniteGen(numValues, randomOnce);
        case "randomWalk":
            yield* randomWalk(numValues);
    }
}

},{"../core/util/Debug.js":"2lOIQ","../core/util/Math.js":"7mtt2","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ekSeO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A sequence is an alternate notation of a part. Instead
 * of passing in an array of [time, event] pairs, pass
 * in an array of events which will be spaced at the
 * given subdivision. Sub-arrays will subdivide that beat
 * by the number of items are in the array.
 * Sequence notation inspiration from [Tidal Cycles](http://tidalcycles.org/)
 * @example
 * const synth = new Tone.Synth().toDestination();
 * const seq = new Tone.Sequence((time, note) => {
 * 	synth.triggerAttackRelease(note, 0.1, time);
 * 	// subdivisions are given as subarrays
 * }, ["C4", ["E4", "D4", "E4"], "G4", ["A4", "G4"]]).start(0);
 * Tone.Transport.start();
 * @category Event
 */ parcelHelpers.export(exports, "Sequence", ()=>Sequence);
var _ticksJs = require("../core/type/Ticks.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _typeCheckJs = require("../core/util/TypeCheck.js");
var _partJs = require("./Part.js");
var _toneEventJs = require("./ToneEvent.js");
class Sequence extends (0, _toneEventJs.ToneEvent) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Sequence.getDefaults(), arguments, [
            "callback",
            "events",
            "subdivision"
        ]);
        super(options);
        this.name = "Sequence";
        /**
         * The object responsible for scheduling all of the events
         */ this._part = new (0, _partJs.Part)({
            callback: this._seqCallback.bind(this),
            context: this.context
        });
        /**
         * private reference to all of the sequence proxies
         */ this._events = [];
        /**
         * The proxied array
         */ this._eventsArray = [];
        this._subdivision = this.toTicks(options.subdivision);
        this.events = options.events;
        // set all of the values
        this.loop = options.loop;
        this.loopStart = options.loopStart;
        this.loopEnd = options.loopEnd;
        this.playbackRate = options.playbackRate;
        this.probability = options.probability;
        this.humanize = options.humanize;
        this.mute = options.mute;
        this.playbackRate = options.playbackRate;
    }
    static getDefaults() {
        return Object.assign((0, _defaultsJs.omitFromObject)((0, _toneEventJs.ToneEvent).getDefaults(), [
            "value"
        ]), {
            events: [],
            loop: true,
            loopEnd: 0,
            loopStart: 0,
            subdivision: "8n"
        });
    }
    /**
     * The internal callback for when an event is invoked
     */ _seqCallback(time, value) {
        if (value !== null && !this.mute) this.callback(time, value);
    }
    /**
     * The sequence
     */ get events() {
        return this._events;
    }
    set events(s) {
        this.clear();
        this._eventsArray = s;
        this._events = this._createSequence(this._eventsArray);
        this._eventsUpdated();
    }
    /**
     * Start the part at the given time.
     * @param  time    When to start the part.
     * @param  offset  The offset index to start at
     */ start(time, offset) {
        this._part.start(time, offset ? this._indexTime(offset) : offset);
        return this;
    }
    /**
     * Stop the part at the given time.
     * @param  time  When to stop the part.
     */ stop(time) {
        this._part.stop(time);
        return this;
    }
    /**
     * The subdivision of the sequence. This can only be
     * set in the constructor. The subdivision is the
     * interval between successive steps.
     */ get subdivision() {
        return new (0, _ticksJs.TicksClass)(this.context, this._subdivision).toSeconds();
    }
    /**
     * Create a sequence proxy which can be monitored to create subsequences
     */ _createSequence(array) {
        return new Proxy(array, {
            get: (target, property)=>{
                // property is index in this case
                return target[property];
            },
            set: (target, property, value)=>{
                if ((0, _typeCheckJs.isString)(property) && isFinite(parseInt(property, 10))) {
                    if ((0, _typeCheckJs.isArray)(value)) target[property] = this._createSequence(value);
                    else target[property] = value;
                } else target[property] = value;
                this._eventsUpdated();
                // return true to accept the changes
                return true;
            }
        });
    }
    /**
     * When the sequence has changed, all of the events need to be recreated
     */ _eventsUpdated() {
        this._part.clear();
        this._rescheduleSequence(this._eventsArray, this._subdivision, this.startOffset);
        // update the loopEnd
        this.loopEnd = this.loopEnd;
    }
    /**
     * reschedule all of the events that need to be rescheduled
     */ _rescheduleSequence(sequence, subdivision, startOffset) {
        sequence.forEach((value, index)=>{
            const eventOffset = index * subdivision + startOffset;
            if ((0, _typeCheckJs.isArray)(value)) this._rescheduleSequence(value, subdivision / value.length, eventOffset);
            else {
                const startTime = new (0, _ticksJs.TicksClass)(this.context, eventOffset, "i").toSeconds();
                this._part.add(startTime, value);
            }
        });
    }
    /**
     * Get the time of the index given the Sequence's subdivision
     * @param  index
     * @return The time of that index
     */ _indexTime(index) {
        return new (0, _ticksJs.TicksClass)(this.context, index * this._subdivision + this.startOffset).toSeconds();
    }
    /**
     * Clear all of the events
     */ clear() {
        this._part.clear();
        return this;
    }
    dispose() {
        super.dispose();
        this._part.dispose();
        return this;
    }
    //-------------------------------------
    // PROXY CALLS
    //-------------------------------------
    get loop() {
        return this._part.loop;
    }
    set loop(l) {
        this._part.loop = l;
    }
    /**
     * The index at which the sequence should start looping
     */ get loopStart() {
        return this._loopStart;
    }
    set loopStart(index) {
        this._loopStart = index;
        this._part.loopStart = this._indexTime(index);
    }
    /**
     * The index at which the sequence should end looping
     */ get loopEnd() {
        return this._loopEnd;
    }
    set loopEnd(index) {
        this._loopEnd = index;
        if (index === 0) this._part.loopEnd = this._indexTime(this._eventsArray.length);
        else this._part.loopEnd = this._indexTime(index);
    }
    get startOffset() {
        return this._part.startOffset;
    }
    set startOffset(start) {
        this._part.startOffset = start;
    }
    get playbackRate() {
        return this._part.playbackRate;
    }
    set playbackRate(rate) {
        this._part.playbackRate = rate;
    }
    get probability() {
        return this._part.probability;
    }
    set probability(prob) {
        this._part.probability = prob;
    }
    get progress() {
        return this._part.progress;
    }
    get humanize() {
        return this._part.humanize;
    }
    set humanize(variation) {
        this._part.humanize = variation;
    }
    /**
     * The number of scheduled events
     */ get length() {
        return this._part.length;
    }
}

},{"../core/type/Ticks.js":"BGGsE","../core/util/Defaults.js":"a9M5s","../core/util/TypeCheck.js":"eMH5A","./Part.js":"5vWpY","./ToneEvent.js":"bq5Fc","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hRVtA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _autoFilterJs = require("./AutoFilter.js");
parcelHelpers.exportAll(_autoFilterJs, exports);
var _autoPannerJs = require("./AutoPanner.js");
parcelHelpers.exportAll(_autoPannerJs, exports);
var _autoWahJs = require("./AutoWah.js");
parcelHelpers.exportAll(_autoWahJs, exports);
var _bitCrusherJs = require("./BitCrusher.js");
parcelHelpers.exportAll(_bitCrusherJs, exports);
var _chebyshevJs = require("./Chebyshev.js");
parcelHelpers.exportAll(_chebyshevJs, exports);
var _chorusJs = require("./Chorus.js");
parcelHelpers.exportAll(_chorusJs, exports);
var _distortionJs = require("./Distortion.js");
parcelHelpers.exportAll(_distortionJs, exports);
var _feedbackDelayJs = require("./FeedbackDelay.js");
parcelHelpers.exportAll(_feedbackDelayJs, exports);
var _frequencyShifterJs = require("./FrequencyShifter.js");
parcelHelpers.exportAll(_frequencyShifterJs, exports);
var _freeverbJs = require("./Freeverb.js");
parcelHelpers.exportAll(_freeverbJs, exports);
var _jcreverbJs = require("./JCReverb.js");
parcelHelpers.exportAll(_jcreverbJs, exports);
var _pingPongDelayJs = require("./PingPongDelay.js");
parcelHelpers.exportAll(_pingPongDelayJs, exports);
var _pitchShiftJs = require("./PitchShift.js");
parcelHelpers.exportAll(_pitchShiftJs, exports);
var _phaserJs = require("./Phaser.js");
parcelHelpers.exportAll(_phaserJs, exports);
var _reverbJs = require("./Reverb.js");
parcelHelpers.exportAll(_reverbJs, exports);
var _stereoWidenerJs = require("./StereoWidener.js");
parcelHelpers.exportAll(_stereoWidenerJs, exports);
var _tremoloJs = require("./Tremolo.js");
parcelHelpers.exportAll(_tremoloJs, exports);
var _vibratoJs = require("./Vibrato.js");
parcelHelpers.exportAll(_vibratoJs, exports);

},{"./AutoFilter.js":"dGqIv","./AutoPanner.js":"h1nsJ","./AutoWah.js":"dd0sv","./BitCrusher.js":"jplDV","./Chebyshev.js":"cRQFX","./Chorus.js":"5Fgrn","./Distortion.js":"kWHiD","./FeedbackDelay.js":"5n2nf","./FrequencyShifter.js":"bB1gQ","./Freeverb.js":"k7mdD","./JCReverb.js":"gi3q6","./PingPongDelay.js":"avdgi","./PitchShift.js":"8mlNP","./Phaser.js":"8FJ4l","./Reverb.js":"j2JHY","./StereoWidener.js":"5qIOm","./Tremolo.js":"3TUHb","./Vibrato.js":"5uE99","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dGqIv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AutoFilter is a Tone.Filter with a Tone.LFO connected to the filter cutoff frequency.
 * Setting the LFO rate and depth allows for control over the filter modulation rate
 * and depth.
 *
 * @example
 * // create an autofilter and start it's LFO
 * const autoFilter = new Tone.AutoFilter("4n").toDestination().start();
 * // route an oscillator through the filter and start it
 * const oscillator = new Tone.Oscillator().connect(autoFilter).start();
 * @category Effect
 */ parcelHelpers.export(exports, "AutoFilter", ()=>AutoFilter);
var _filterJs = require("../component/filter/Filter.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _lfoeffectJs = require("./LFOEffect.js");
class AutoFilter extends (0, _lfoeffectJs.LFOEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(AutoFilter.getDefaults(), arguments, [
            "frequency",
            "baseFrequency",
            "octaves"
        ]);
        super(options);
        this.name = "AutoFilter";
        this.filter = new (0, _filterJs.Filter)(Object.assign(options.filter, {
            context: this.context
        }));
        // connections
        this.connectEffect(this.filter);
        this._lfo.connect(this.filter.frequency);
        this.octaves = options.octaves;
        this.baseFrequency = options.baseFrequency;
    }
    static getDefaults() {
        return Object.assign((0, _lfoeffectJs.LFOEffect).getDefaults(), {
            baseFrequency: 200,
            octaves: 2.6,
            filter: {
                type: "lowpass",
                rolloff: -12,
                Q: 1
            }
        });
    }
    /**
     * The minimum value of the filter's cutoff frequency.
     */ get baseFrequency() {
        return this._lfo.min;
    }
    set baseFrequency(freq) {
        this._lfo.min = this.toFrequency(freq);
        // and set the max
        this.octaves = this._octaves;
    }
    /**
     * The maximum value of the filter's cutoff frequency.
     */ get octaves() {
        return this._octaves;
    }
    set octaves(oct) {
        this._octaves = oct;
        this._lfo.max = this._lfo.min * Math.pow(2, oct);
    }
    dispose() {
        super.dispose();
        this.filter.dispose();
        return this;
    }
}

},{"../component/filter/Filter.js":"lel48","../core/util/Defaults.js":"a9M5s","./LFOEffect.js":"5THab","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5THab":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for LFO-based effects.
 */ parcelHelpers.export(exports, "LFOEffect", ()=>LFOEffect);
var _effectJs = require("../effect/Effect.js");
var _lfoJs = require("../source/oscillator/LFO.js");
var _interfaceJs = require("../core/util/Interface.js");
class LFOEffect extends (0, _effectJs.Effect) {
    constructor(options){
        super(options);
        this.name = "LFOEffect";
        this._lfo = new (0, _lfoJs.LFO)({
            context: this.context,
            frequency: options.frequency,
            amplitude: options.depth
        });
        this.depth = this._lfo.amplitude;
        this.frequency = this._lfo.frequency;
        this.type = options.type;
        (0, _interfaceJs.readOnly)(this, [
            "frequency",
            "depth"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _effectJs.Effect).getDefaults(), {
            frequency: 1,
            type: "sine",
            depth: 1
        });
    }
    /**
     * Start the effect.
     */ start(time) {
        this._lfo.start(time);
        return this;
    }
    /**
     * Stop the lfo
     */ stop(time) {
        this._lfo.stop(time);
        return this;
    }
    /**
     * Sync the filter to the transport.
     * @see {@link LFO.sync}
     */ sync() {
        this._lfo.sync();
        return this;
    }
    /**
     * Unsync the filter from the transport.
     */ unsync() {
        this._lfo.unsync();
        return this;
    }
    /**
     * The type of the LFO's oscillator.
     * @see {@link Oscillator.type}
     * @example
     * const autoFilter = new Tone.AutoFilter().start().toDestination();
     * const noise = new Tone.Noise().start().connect(autoFilter);
     * autoFilter.type = "square";
     */ get type() {
        return this._lfo.type;
    }
    set type(type) {
        this._lfo.type = type;
    }
    dispose() {
        super.dispose();
        this._lfo.dispose();
        this.frequency.dispose();
        this.depth.dispose();
        return this;
    }
}

},{"../effect/Effect.js":"g3o0i","../source/oscillator/LFO.js":"jsBJT","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"g3o0i":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Effect is the base class for effects. Connect the effect between
 * the effectSend and effectReturn GainNodes, then control the amount of
 * effect which goes to the output using the wet control.
 */ parcelHelpers.export(exports, "Effect", ()=>Effect);
var _crossFadeJs = require("../component/channel/CrossFade.js");
var _gainJs = require("../core/context/Gain.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _interfaceJs = require("../core/util/Interface.js");
class Effect extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(options){
        super(options);
        this.name = "Effect";
        /**
         * the drywet knob to control the amount of effect
         */ this._dryWet = new (0, _crossFadeJs.CrossFade)({
            context: this.context
        });
        /**
         * The wet control is how much of the effected
         * will pass through to the output. 1 = 100% effected
         * signal, 0 = 100% dry signal.
         */ this.wet = this._dryWet.fade;
        /**
         * connect the effectSend to the input of hte effect
         */ this.effectSend = new (0, _gainJs.Gain)({
            context: this.context
        });
        /**
         * connect the output of the effect to the effectReturn
         */ this.effectReturn = new (0, _gainJs.Gain)({
            context: this.context
        });
        /**
         * The effect input node
         */ this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        /**
         * The effect output
         */ this.output = this._dryWet;
        // connections
        this.input.fan(this._dryWet.a, this.effectSend);
        this.effectReturn.connect(this._dryWet.b);
        this.wet.setValueAtTime(options.wet, 0);
        this._internalChannels = [
            this.effectReturn,
            this.effectSend
        ];
        (0, _interfaceJs.readOnly)(this, "wet");
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            wet: 1
        });
    }
    /**
     * chains the effect in between the effectSend and effectReturn
     */ connectEffect(effect) {
        // add it to the internal channels
        this._internalChannels.push(effect);
        this.effectSend.chain(effect, this.effectReturn);
        return this;
    }
    dispose() {
        super.dispose();
        this._dryWet.dispose();
        this.effectSend.dispose();
        this.effectReturn.dispose();
        this.wet.dispose();
        return this;
    }
}

},{"../component/channel/CrossFade.js":"cd1EQ","../core/context/Gain.js":"kj68Y","../core/context/ToneAudioNode.js":"kZ3Kj","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cd1EQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone.Crossfade provides equal power fading between two inputs.
 * More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).
 * ```
 *                                             +---------+
 *                                            +> input a +>--+
 * +-----------+   +---------------------+     |         |   |
 * | 1s signal +>--> stereoPannerNode  L +>----> gain    |   |
 * +-----------+   |                     |     +---------+   |
 *               +-> pan               R +>-+                |   +--------+
 *               | +---------------------+  |                +---> output +>
 *  +------+     |                          |  +---------+   |   +--------+
 *  | fade +>----+                          | +> input b +>--+
 *  +------+                                |  |         |
 *                                          +--> gain    |
 *                                             +---------+
 * ```
 * @example
 * const crossFade = new Tone.CrossFade().toDestination();
 * // connect two inputs Tone.to a/b
 * const inputA = new Tone.Oscillator(440, "square").connect(crossFade.a).start();
 * const inputB = new Tone.Oscillator(440, "sine").connect(crossFade.b).start();
 * // use the fade to control the mix between the two
 * crossFade.fade.value = 0.5;
 * @category Component
 */ parcelHelpers.export(exports, "CrossFade", ()=>CrossFade);
var _gainJs = require("../../core/context/Gain.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _gainToAudioJs = require("../../signal/GainToAudio.js");
var _signalJs = require("../../signal/Signal.js");
class CrossFade extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(CrossFade.getDefaults(), arguments, [
            "fade"
        ]);
        super(options);
        this.name = "CrossFade";
        /**
         * The crossfading is done by a StereoPannerNode
         */ this._panner = this.context.createStereoPanner();
        /**
         * Split the output of the panner node into two values used to control the gains.
         */ this._split = this.context.createChannelSplitter(2);
        /**
         * Convert the fade value into an audio range value so it can be connected
         * to the panner.pan AudioParam
         */ this._g2a = new (0, _gainToAudioJs.GainToAudio)({
            context: this.context
        });
        /**
         * The input which is at full level when fade = 0
         */ this.a = new (0, _gainJs.Gain)({
            context: this.context,
            gain: 0
        });
        /**
         * The input which is at full level when fade = 1
         */ this.b = new (0, _gainJs.Gain)({
            context: this.context,
            gain: 0
        });
        /**
         * The output is a mix between `a` and `b` at the ratio of `fade`
         */ this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._internalChannels = [
            this.a,
            this.b
        ];
        this.fade = new (0, _signalJs.Signal)({
            context: this.context,
            units: "normalRange",
            value: options.fade
        });
        (0, _interfaceJs.readOnly)(this, "fade");
        this.context.getConstant(1).connect(this._panner);
        this._panner.connect(this._split);
        // this is necessary for standardized-audio-context
        // doesn't make any difference for the native AudioContext
        // https://github.com/chrisguttandin/standardized-audio-context/issues/647
        this._panner.channelCount = 1;
        this._panner.channelCountMode = "explicit";
        (0, _toneAudioNodeJs.connect)(this._split, this.a.gain, 0);
        (0, _toneAudioNodeJs.connect)(this._split, this.b.gain, 1);
        this.fade.chain(this._g2a, this._panner.pan);
        this.a.connect(this.output);
        this.b.connect(this.output);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            fade: 0.5
        });
    }
    dispose() {
        super.dispose();
        this.a.dispose();
        this.b.dispose();
        this.output.dispose();
        this.fade.dispose();
        this._g2a.dispose();
        this._panner.disconnect();
        this._split.disconnect();
        return this;
    }
}

},{"../../core/context/Gain.js":"kj68Y","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../signal/GainToAudio.js":"g3Bng","../../signal/Signal.js":"980ri","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h1nsJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AutoPanner is a {@link Panner} with an {@link LFO} connected to the pan amount.
 * [Related Reading](https://www.ableton.com/en/blog/autopan-chopper-effect-and-more-liveschool/).
 *
 * @example
 * // create an autopanner and start it
 * const autoPanner = new Tone.AutoPanner("4n").toDestination().start();
 * // route an oscillator through the panner and start it
 * const oscillator = new Tone.Oscillator().connect(autoPanner).start();
 * @category Effect
 */ parcelHelpers.export(exports, "AutoPanner", ()=>AutoPanner);
var _pannerJs = require("../component/channel/Panner.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _lfoeffectJs = require("./LFOEffect.js");
class AutoPanner extends (0, _lfoeffectJs.LFOEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(AutoPanner.getDefaults(), arguments, [
            "frequency"
        ]);
        super(options);
        this.name = "AutoPanner";
        this._panner = new (0, _pannerJs.Panner)({
            context: this.context,
            channelCount: options.channelCount
        });
        // connections
        this.connectEffect(this._panner);
        this._lfo.connect(this._panner.pan);
        this._lfo.min = -1;
        this._lfo.max = 1;
    }
    static getDefaults() {
        return Object.assign((0, _lfoeffectJs.LFOEffect).getDefaults(), {
            channelCount: 1
        });
    }
    dispose() {
        super.dispose();
        this._panner.dispose();
        return this;
    }
}

},{"../component/channel/Panner.js":"hwo91","../core/util/Defaults.js":"a9M5s","./LFOEffect.js":"5THab","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hwo91":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Panner is an equal power Left/Right Panner. It is a wrapper around the StereoPannerNode.
 * @example
 * return Tone.Offline(() => {
 * // move the input signal from right to left
 * 	const panner = new Tone.Panner(1).toDestination();
 * 	panner.pan.rampTo(-1, 0.5);
 * 	const osc = new Tone.Oscillator(100).connect(panner).start();
 * }, 0.5, 2);
 * @category Component
 */ parcelHelpers.export(exports, "Panner", ()=>Panner);
var _paramJs = require("../../core/context/Param.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
class Panner extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Panner.getDefaults(), arguments, [
            "pan"
        ]);
        super(options);
        this.name = "Panner";
        /**
         * the panner node
         */ this._panner = this.context.createStereoPanner();
        this.input = this._panner;
        this.output = this._panner;
        this.pan = new (0, _paramJs.Param)({
            context: this.context,
            param: this._panner.pan,
            value: options.pan,
            minValue: -1,
            maxValue: 1
        });
        // this is necessary for standardized-audio-context
        // doesn't make any difference for the native AudioContext
        // https://github.com/chrisguttandin/standardized-audio-context/issues/647
        this._panner.channelCount = options.channelCount;
        this._panner.channelCountMode = "explicit";
        // initial value
        (0, _interfaceJs.readOnly)(this, "pan");
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            pan: 0,
            channelCount: 1
        });
    }
    dispose() {
        super.dispose();
        this._panner.disconnect();
        this.pan.dispose();
        return this;
    }
}

},{"../../core/context/Param.js":"5PVlJ","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dd0sv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AutoWah connects a {@link Follower} to a {@link Filter}.
 * The frequency of the filter, follows the input amplitude curve.
 * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna).
 *
 * @example
 * const autoWah = new Tone.AutoWah(50, 6, -30).toDestination();
 * // initialize the synth and connect to autowah
 * const synth = new Tone.Synth().connect(autoWah);
 * // Q value influences the effect of the wah - default is 2
 * autoWah.Q.value = 6;
 * // more audible on higher notes
 * synth.triggerAttackRelease("C4", "8n");
 * @category Effect
 */ parcelHelpers.export(exports, "AutoWah", ()=>AutoWah);
var _effectJs = require("./Effect.js");
var _filterJs = require("../component/filter/Filter.js");
var _followerJs = require("../component/analysis/Follower.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _gainJs = require("../core/context/Gain.js");
var _conversionsJs = require("../core/type/Conversions.js");
var _scaleExpJs = require("../signal/ScaleExp.js");
var _interfaceJs = require("../core/util/Interface.js");
class AutoWah extends (0, _effectJs.Effect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(AutoWah.getDefaults(), arguments, [
            "baseFrequency",
            "octaves",
            "sensitivity"
        ]);
        super(options);
        this.name = "AutoWah";
        this._follower = new (0, _followerJs.Follower)({
            context: this.context,
            smoothing: options.follower
        });
        this._sweepRange = new (0, _scaleExpJs.ScaleExp)({
            context: this.context,
            min: 0,
            max: 1,
            exponent: 0.5
        });
        this._baseFrequency = this.toFrequency(options.baseFrequency);
        this._octaves = options.octaves;
        this._inputBoost = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._bandpass = new (0, _filterJs.Filter)({
            context: this.context,
            rolloff: -48,
            frequency: 0,
            Q: options.Q
        });
        this._peaking = new (0, _filterJs.Filter)({
            context: this.context,
            type: "peaking"
        });
        this._peaking.gain.value = options.gain;
        this.gain = this._peaking.gain;
        this.Q = this._bandpass.Q;
        // the control signal path
        this.effectSend.chain(this._inputBoost, this._follower, this._sweepRange);
        this._sweepRange.connect(this._bandpass.frequency);
        this._sweepRange.connect(this._peaking.frequency);
        // the filtered path
        this.effectSend.chain(this._bandpass, this._peaking, this.effectReturn);
        // set the initial value
        this._setSweepRange();
        this.sensitivity = options.sensitivity;
        (0, _interfaceJs.readOnly)(this, [
            "gain",
            "Q"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _effectJs.Effect).getDefaults(), {
            baseFrequency: 100,
            octaves: 6,
            sensitivity: 0,
            Q: 2,
            gain: 2,
            follower: 0.2
        });
    }
    /**
     * The number of octaves that the filter will sweep above the baseFrequency.
     */ get octaves() {
        return this._octaves;
    }
    set octaves(octaves) {
        this._octaves = octaves;
        this._setSweepRange();
    }
    /**
     * The follower's smoothing time
     */ get follower() {
        return this._follower.smoothing;
    }
    set follower(follower) {
        this._follower.smoothing = follower;
    }
    /**
     * The base frequency from which the sweep will start from.
     */ get baseFrequency() {
        return this._baseFrequency;
    }
    set baseFrequency(baseFreq) {
        this._baseFrequency = this.toFrequency(baseFreq);
        this._setSweepRange();
    }
    /**
     * The sensitivity to control how responsive to the input signal the filter is.
     */ get sensitivity() {
        return (0, _conversionsJs.gainToDb)(1 / this._inputBoost.gain.value);
    }
    set sensitivity(sensitivity) {
        this._inputBoost.gain.value = 1 / (0, _conversionsJs.dbToGain)(sensitivity);
    }
    /**
     * sets the sweep range of the scaler
     */ _setSweepRange() {
        this._sweepRange.min = this._baseFrequency;
        this._sweepRange.max = Math.min(this._baseFrequency * Math.pow(2, this._octaves), this.context.sampleRate / 2);
    }
    dispose() {
        super.dispose();
        this._follower.dispose();
        this._sweepRange.dispose();
        this._bandpass.dispose();
        this._peaking.dispose();
        this._inputBoost.dispose();
        return this;
    }
}

},{"./Effect.js":"g3o0i","../component/filter/Filter.js":"lel48","../component/analysis/Follower.js":"9fpr2","../core/util/Defaults.js":"a9M5s","../core/context/Gain.js":"kj68Y","../core/type/Conversions.js":"iww1u","../signal/ScaleExp.js":"aFAXE","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9fpr2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Follower is a simple envelope follower.
 * It's implemented by applying a lowpass filter to the absolute value of the incoming signal.
 * ```
 *          +-----+    +---------------+
 * Input +--> Abs +----> OnePoleFilter +--> Output
 *          +-----+    +---------------+
 * ```
 * @category Component
 */ parcelHelpers.export(exports, "Follower", ()=>Follower);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _onePoleFilterJs = require("../filter/OnePoleFilter.js");
var _absJs = require("../../signal/Abs.js");
class Follower extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Follower.getDefaults(), arguments, [
            "smoothing"
        ]);
        super(options);
        this.name = "Follower";
        this._abs = this.input = new (0, _absJs.Abs)({
            context: this.context
        });
        this._lowpass = this.output = new (0, _onePoleFilterJs.OnePoleFilter)({
            context: this.context,
            frequency: 1 / this.toSeconds(options.smoothing),
            type: "lowpass"
        });
        this._abs.connect(this._lowpass);
        this._smoothing = options.smoothing;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            smoothing: 0.05
        });
    }
    /**
     * The amount of time it takes a value change to arrive at the updated value.
     */ get smoothing() {
        return this._smoothing;
    }
    set smoothing(smoothing) {
        this._smoothing = smoothing;
        this._lowpass.frequency = 1 / this.toSeconds(this.smoothing);
    }
    dispose() {
        super.dispose();
        this._abs.dispose();
        this._lowpass.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../filter/OnePoleFilter.js":"1CfWn","../../signal/Abs.js":"91cHq","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jplDV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * BitCrusher down-samples the incoming signal to a different bit depth.
 * Lowering the bit depth of the signal creates distortion. Read more about BitCrushing
 * on [Wikipedia](https://en.wikipedia.org/wiki/Bitcrusher).
 * @example
 * // initialize crusher and route a synth through it
 * const crusher = new Tone.BitCrusher(4).toDestination();
 * const synth = new Tone.Synth().connect(crusher);
 * synth.triggerAttackRelease("C2", 2);
 *
 * @category Effect
 */ parcelHelpers.export(exports, "BitCrusher", ()=>BitCrusher);
var _toneAudioWorkletJs = require("../core/worklet/ToneAudioWorklet.js");
var _effectJs = require("./Effect.js");
var _gainJs = require("../core/context/Gain.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _paramJs = require("../core/context/Param.js");
var _bitCrusherWorkletJs = require("./BitCrusher.worklet.js");
class BitCrusher extends (0, _effectJs.Effect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(BitCrusher.getDefaults(), arguments, [
            "bits"
        ]);
        super(options);
        this.name = "BitCrusher";
        this._bitCrusherWorklet = new BitCrusherWorklet({
            context: this.context,
            bits: options.bits
        });
        // connect it up
        this.connectEffect(this._bitCrusherWorklet);
        this.bits = this._bitCrusherWorklet.bits;
    }
    static getDefaults() {
        return Object.assign((0, _effectJs.Effect).getDefaults(), {
            bits: 4
        });
    }
    dispose() {
        super.dispose();
        this._bitCrusherWorklet.dispose();
        return this;
    }
}
/**
 * Internal class which creates an AudioWorklet to do the bit crushing
 */ class BitCrusherWorklet extends (0, _toneAudioWorkletJs.ToneAudioWorklet) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(BitCrusherWorklet.getDefaults(), arguments);
        super(options);
        this.name = "BitCrusherWorklet";
        this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.bits = new (0, _paramJs.Param)({
            context: this.context,
            value: options.bits,
            units: "positive",
            minValue: 1,
            maxValue: 16,
            param: this._dummyParam,
            swappable: true
        });
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioWorkletJs.ToneAudioWorklet).getDefaults(), {
            bits: 12
        });
    }
    _audioWorkletName() {
        return 0, _bitCrusherWorkletJs.workletName;
    }
    onReady(node) {
        (0, _toneAudioNodeJs.connectSeries)(this.input, node, this.output);
        const bits = node.parameters.get("bits");
        this.bits.setParam(bits);
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this.bits.dispose();
        return this;
    }
}

},{"../core/worklet/ToneAudioWorklet.js":"gJKvW","./Effect.js":"g3o0i","../core/context/Gain.js":"kj68Y","../core/util/Defaults.js":"a9M5s","../core/context/ToneAudioNode.js":"kZ3Kj","../core/context/Param.js":"5PVlJ","./BitCrusher.worklet.js":"7dtyC","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7dtyC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "workletName", ()=>workletName);
parcelHelpers.export(exports, "bitCrusherWorklet", ()=>bitCrusherWorklet);
var _singleIOProcessorWorkletJs = require("../core/worklet/SingleIOProcessor.worklet.js");
var _workletGlobalScopeJs = require("../core/worklet/WorkletGlobalScope.js");
const workletName = "bit-crusher";
const bitCrusherWorklet = /* javascript */ `
	class BitCrusherWorklet extends SingleIOProcessor {

		static get parameterDescriptors() {
			return [{
				name: "bits",
				defaultValue: 12,
				minValue: 1,
				maxValue: 16,
				automationRate: 'k-rate'
			}];
		}

		generate(input, _channel, parameters) {
			const step = Math.pow(0.5, parameters.bits - 1);
			const val = step * Math.floor(input / step + 0.5);
			return val;
		}
	}
`;
(0, _workletGlobalScopeJs.registerProcessor)(workletName, bitCrusherWorklet);

},{"../core/worklet/SingleIOProcessor.worklet.js":"c8hmn","../core/worklet/WorkletGlobalScope.js":"KZYDB","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cRQFX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Chebyshev is a waveshaper which is good
 * for making different types of distortion sounds.
 * Note that odd orders sound very different from even ones,
 * and order = 1 is no change.
 * Read more at [music.columbia.edu](http://music.columbia.edu/cmc/musicandcomputers/chapter4/04_06.php).
 * @example
 * // create a new cheby
 * const cheby = new Tone.Chebyshev(50).toDestination();
 * // create a monosynth connected to our cheby
 * const synth = new Tone.MonoSynth().connect(cheby);
 * synth.triggerAttackRelease("C2", 0.4);
 * @category Effect
 */ parcelHelpers.export(exports, "Chebyshev", ()=>Chebyshev);
var _effectJs = require("./Effect.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _waveShaperJs = require("../signal/WaveShaper.js");
var _debugJs = require("../core/util/Debug.js");
class Chebyshev extends (0, _effectJs.Effect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Chebyshev.getDefaults(), arguments, [
            "order"
        ]);
        super(options);
        this.name = "Chebyshev";
        this._shaper = new (0, _waveShaperJs.WaveShaper)({
            context: this.context,
            length: 4096
        });
        this._order = options.order;
        this.connectEffect(this._shaper);
        this.order = options.order;
        this.oversample = options.oversample;
    }
    static getDefaults() {
        return Object.assign((0, _effectJs.Effect).getDefaults(), {
            order: 1,
            oversample: "none"
        });
    }
    /**
     * get the coefficient for that degree
     * @param  x the x value
     * @param  degree
     * @param  memo memoize the computed value. this speeds up computation greatly.
     */ _getCoefficient(x, degree, memo) {
        if (memo.has(degree)) return memo.get(degree);
        else if (degree === 0) memo.set(degree, 0);
        else if (degree === 1) memo.set(degree, x);
        else memo.set(degree, 2 * x * this._getCoefficient(x, degree - 1, memo) - this._getCoefficient(x, degree - 2, memo));
        return memo.get(degree);
    }
    /**
     * The order of the Chebyshev polynomial which creates the equation which is applied to the incoming
     * signal through a Tone.WaveShaper. Must be an integer. The equations are in the form:
     * ```
     * order 2: 2x^2 + 1
     * order 3: 4x^3 + 3x
     * ```
     * @min 1
     * @max 100
     */ get order() {
        return this._order;
    }
    set order(order) {
        (0, _debugJs.assert)(Number.isInteger(order), "'order' must be an integer");
        this._order = order;
        this._shaper.setMap((x)=>{
            return this._getCoefficient(x, order, new Map());
        });
    }
    /**
     * The oversampling of the effect. Can either be "none", "2x" or "4x".
     */ get oversample() {
        return this._shaper.oversample;
    }
    set oversample(oversampling) {
        this._shaper.oversample = oversampling;
    }
    dispose() {
        super.dispose();
        this._shaper.dispose();
        return this;
    }
}

},{"./Effect.js":"g3o0i","../core/util/Defaults.js":"a9M5s","../signal/WaveShaper.js":"k4nzV","../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5Fgrn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Chorus is a stereo chorus effect composed of a left and right delay with an {@link LFO} applied to the delayTime of each channel.
 * When {@link feedback} is set to a value larger than 0, you also get Flanger-type effects.
 * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna/blob/master/tuna.js).
 * Read more on the chorus effect on [Sound On Sound](http://www.soundonsound.com/sos/jun04/articles/synthsecrets.htm).
 *
 * @example
 * const chorus = new Tone.Chorus(4, 2.5, 0.5).toDestination().start();
 * const synth = new Tone.PolySynth().connect(chorus);
 * synth.triggerAttackRelease(["C3", "E3", "G3"], "8n");
 *
 * @category Effect
 */ parcelHelpers.export(exports, "Chorus", ()=>Chorus);
var _stereoFeedbackEffectJs = require("../effect/StereoFeedbackEffect.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _lfoJs = require("../source/oscillator/LFO.js");
var _delayJs = require("../core/context/Delay.js");
var _interfaceJs = require("../core/util/Interface.js");
class Chorus extends (0, _stereoFeedbackEffectJs.StereoFeedbackEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Chorus.getDefaults(), arguments, [
            "frequency",
            "delayTime",
            "depth"
        ]);
        super(options);
        this.name = "Chorus";
        this._depth = options.depth;
        this._delayTime = options.delayTime / 1000;
        this._lfoL = new (0, _lfoJs.LFO)({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1
        });
        this._lfoR = new (0, _lfoJs.LFO)({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1,
            phase: 180
        });
        this._delayNodeL = new (0, _delayJs.Delay)({
            context: this.context
        });
        this._delayNodeR = new (0, _delayJs.Delay)({
            context: this.context
        });
        this.frequency = this._lfoL.frequency;
        (0, _interfaceJs.readOnly)(this, [
            "frequency"
        ]);
        // have one LFO frequency control the other
        this._lfoL.frequency.connect(this._lfoR.frequency);
        // connections
        this.connectEffectLeft(this._delayNodeL);
        this.connectEffectRight(this._delayNodeR);
        // lfo setup
        this._lfoL.connect(this._delayNodeL.delayTime);
        this._lfoR.connect(this._delayNodeR.delayTime);
        // set the initial values
        this.depth = this._depth;
        this.type = options.type;
        this.spread = options.spread;
    }
    static getDefaults() {
        return Object.assign((0, _stereoFeedbackEffectJs.StereoFeedbackEffect).getDefaults(), {
            frequency: 1.5,
            delayTime: 3.5,
            depth: 0.7,
            type: "sine",
            spread: 180,
            feedback: 0,
            wet: 0.5
        });
    }
    /**
     * The depth of the effect. A depth of 1 makes the delayTime
     * modulate between 0 and 2*delayTime (centered around the delayTime).
     */ get depth() {
        return this._depth;
    }
    set depth(depth) {
        this._depth = depth;
        const deviation = this._delayTime * depth;
        this._lfoL.min = Math.max(this._delayTime - deviation, 0);
        this._lfoL.max = this._delayTime + deviation;
        this._lfoR.min = Math.max(this._delayTime - deviation, 0);
        this._lfoR.max = this._delayTime + deviation;
    }
    /**
     * The delayTime in milliseconds of the chorus. A larger delayTime
     * will give a more pronounced effect. Nominal range a delayTime
     * is between 2 and 20ms.
     */ get delayTime() {
        return this._delayTime * 1000;
    }
    set delayTime(delayTime) {
        this._delayTime = delayTime / 1000;
        this.depth = this._depth;
    }
    /**
     * The oscillator type of the LFO.
     */ get type() {
        return this._lfoL.type;
    }
    set type(type) {
        this._lfoL.type = type;
        this._lfoR.type = type;
    }
    /**
     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.
     * When set to 180, LFO's will be panned hard left and right respectively.
     */ get spread() {
        return this._lfoR.phase - this._lfoL.phase;
    }
    set spread(spread) {
        this._lfoL.phase = 90 - spread / 2;
        this._lfoR.phase = spread / 2 + 90;
    }
    /**
     * Start the effect.
     */ start(time) {
        this._lfoL.start(time);
        this._lfoR.start(time);
        return this;
    }
    /**
     * Stop the lfo
     */ stop(time) {
        this._lfoL.stop(time);
        this._lfoR.stop(time);
        return this;
    }
    /**
     * Sync the filter to the transport.
     * @see {@link LFO.sync}
     */ sync() {
        this._lfoL.sync();
        this._lfoR.sync();
        return this;
    }
    /**
     * Unsync the filter from the transport.
     */ unsync() {
        this._lfoL.unsync();
        this._lfoR.unsync();
        return this;
    }
    dispose() {
        super.dispose();
        this._lfoL.dispose();
        this._lfoR.dispose();
        this._delayNodeL.dispose();
        this._delayNodeR.dispose();
        this.frequency.dispose();
        return this;
    }
}

},{"../effect/StereoFeedbackEffect.js":"2txKj","../core/util/Defaults.js":"a9M5s","../source/oscillator/LFO.js":"jsBJT","../core/context/Delay.js":"1qHQA","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2txKj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for stereo feedback effects where the effectReturn is fed back into the same channel.
 */ parcelHelpers.export(exports, "StereoFeedbackEffect", ()=>StereoFeedbackEffect);
var _stereoEffectJs = require("./StereoEffect.js");
var _signalJs = require("../signal/Signal.js");
var _gainJs = require("../core/context/Gain.js");
var _interfaceJs = require("../core/util/Interface.js");
var _splitJs = require("../component/channel/Split.js");
var _mergeJs = require("../component/channel/Merge.js");
class StereoFeedbackEffect extends (0, _stereoEffectJs.StereoEffect) {
    constructor(options){
        super(options);
        this.feedback = new (0, _signalJs.Signal)({
            context: this.context,
            value: options.feedback,
            units: "normalRange"
        });
        this._feedbackL = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._feedbackR = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._feedbackSplit = new (0, _splitJs.Split)({
            context: this.context,
            channels: 2
        });
        this._feedbackMerge = new (0, _mergeJs.Merge)({
            context: this.context,
            channels: 2
        });
        this._merge.connect(this._feedbackSplit);
        this._feedbackMerge.connect(this._split);
        // the left output connected to the left input
        this._feedbackSplit.connect(this._feedbackL, 0, 0);
        this._feedbackL.connect(this._feedbackMerge, 0, 0);
        // the right output connected to the right input
        this._feedbackSplit.connect(this._feedbackR, 1, 0);
        this._feedbackR.connect(this._feedbackMerge, 0, 1);
        // the feedback control
        this.feedback.fan(this._feedbackL.gain, this._feedbackR.gain);
        (0, _interfaceJs.readOnly)(this, [
            "feedback"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _stereoEffectJs.StereoEffect).getDefaults(), {
            feedback: 0.5
        });
    }
    dispose() {
        super.dispose();
        this.feedback.dispose();
        this._feedbackL.dispose();
        this._feedbackR.dispose();
        this._feedbackSplit.dispose();
        this._feedbackMerge.dispose();
        return this;
    }
}

},{"./StereoEffect.js":"3INxk","../signal/Signal.js":"980ri","../core/context/Gain.js":"kj68Y","../core/util/Interface.js":"hVOjA","../component/channel/Split.js":"hPRgj","../component/channel/Merge.js":"xBcDu","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3INxk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for Stereo effects.
 */ parcelHelpers.export(exports, "StereoEffect", ()=>StereoEffect);
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
var _crossFadeJs = require("../component/channel/CrossFade.js");
var _splitJs = require("../component/channel/Split.js");
var _gainJs = require("../core/context/Gain.js");
var _mergeJs = require("../component/channel/Merge.js");
var _interfaceJs = require("../core/util/Interface.js");
class StereoEffect extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(options){
        super(options);
        this.name = "StereoEffect";
        this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        // force mono sources to be stereo
        this.input.channelCount = 2;
        this.input.channelCountMode = "explicit";
        this._dryWet = this.output = new (0, _crossFadeJs.CrossFade)({
            context: this.context,
            fade: options.wet
        });
        this.wet = this._dryWet.fade;
        this._split = new (0, _splitJs.Split)({
            context: this.context,
            channels: 2
        });
        this._merge = new (0, _mergeJs.Merge)({
            context: this.context,
            channels: 2
        });
        // connections
        this.input.connect(this._split);
        // dry wet connections
        this.input.connect(this._dryWet.a);
        this._merge.connect(this._dryWet.b);
        (0, _interfaceJs.readOnly)(this, [
            "wet"
        ]);
    }
    /**
     * Connect the left part of the effect
     */ connectEffectLeft(...nodes) {
        this._split.connect(nodes[0], 0, 0);
        (0, _toneAudioNodeJs.connectSeries)(...nodes);
        (0, _toneAudioNodeJs.connect)(nodes[nodes.length - 1], this._merge, 0, 0);
    }
    /**
     * Connect the right part of the effect
     */ connectEffectRight(...nodes) {
        this._split.connect(nodes[0], 1, 0);
        (0, _toneAudioNodeJs.connectSeries)(...nodes);
        (0, _toneAudioNodeJs.connect)(nodes[nodes.length - 1], this._merge, 0, 1);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            wet: 1
        });
    }
    dispose() {
        super.dispose();
        this._dryWet.dispose();
        this._split.dispose();
        this._merge.dispose();
        return this;
    }
}

},{"../core/context/ToneAudioNode.js":"kZ3Kj","../component/channel/CrossFade.js":"cd1EQ","../component/channel/Split.js":"hPRgj","../core/context/Gain.js":"kj68Y","../component/channel/Merge.js":"xBcDu","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hPRgj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Split splits an incoming signal into the number of given channels.
 *
 * @example
 * const split = new Tone.Split();
 * // stereoSignal.connect(split);
 * @category Component
 */ parcelHelpers.export(exports, "Split", ()=>Split);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
class Split extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Split.getDefaults(), arguments, [
            "channels"
        ]);
        super(options);
        this.name = "Split";
        this._splitter = this.input = this.output = this.context.createChannelSplitter(options.channels);
        this._internalChannels = [
            this._splitter
        ];
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            channels: 2
        });
    }
    dispose() {
        super.dispose();
        this._splitter.disconnect();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"xBcDu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Merge brings multiple mono input channels into a single multichannel output channel.
 *
 * @example
 * const merge = new Tone.Merge().toDestination();
 * // routing a sine tone in the left channel
 * const osc = new Tone.Oscillator().connect(merge, 0, 0).start();
 * // and noise in the right channel
 * const noise = new Tone.Noise().connect(merge, 0, 1).start();;
 * @category Component
 */ parcelHelpers.export(exports, "Merge", ()=>Merge);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
class Merge extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Merge.getDefaults(), arguments, [
            "channels"
        ]);
        super(options);
        this.name = "Merge";
        this._merger = this.output = this.input = this.context.createChannelMerger(options.channels);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            channels: 2
        });
    }
    dispose() {
        super.dispose();
        this._merger.disconnect();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kWHiD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A simple distortion effect using Tone.WaveShaper.
 * Algorithm from [this stackoverflow answer](http://stackoverflow.com/a/22313408).
 * Read more about distortion on [Wikipedia] (https://en.wikipedia.org/wiki/Distortion_(music)).
 * @example
 * const dist = new Tone.Distortion(0.8).toDestination();
 * const fm = new Tone.FMSynth().connect(dist);
 * fm.triggerAttackRelease("A1", "8n");
 * @category Effect
 */ parcelHelpers.export(exports, "Distortion", ()=>Distortion);
var _defaultsJs = require("../core/util/Defaults.js");
var _waveShaperJs = require("../signal/WaveShaper.js");
var _effectJs = require("./Effect.js");
class Distortion extends (0, _effectJs.Effect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Distortion.getDefaults(), arguments, [
            "distortion"
        ]);
        super(options);
        this.name = "Distortion";
        this._shaper = new (0, _waveShaperJs.WaveShaper)({
            context: this.context,
            length: 4096
        });
        this._distortion = options.distortion;
        this.connectEffect(this._shaper);
        this.distortion = options.distortion;
        this.oversample = options.oversample;
    }
    static getDefaults() {
        return Object.assign((0, _effectJs.Effect).getDefaults(), {
            distortion: 0.4,
            oversample: "none"
        });
    }
    /**
     * The amount of distortion. Nominal range is between 0 and 1.
     */ get distortion() {
        return this._distortion;
    }
    set distortion(amount) {
        this._distortion = amount;
        const k = amount * 100;
        const deg = Math.PI / 180;
        this._shaper.setMap((x)=>{
            if (Math.abs(x) < 0.001) // should output 0 when input is 0
            return 0;
            else return (3 + k) * x * 20 * deg / (Math.PI + k * Math.abs(x));
        });
    }
    /**
     * The oversampling of the effect. Can either be "none", "2x" or "4x".
     */ get oversample() {
        return this._shaper.oversample;
    }
    set oversample(oversampling) {
        this._shaper.oversample = oversampling;
    }
    dispose() {
        super.dispose();
        this._shaper.dispose();
        return this;
    }
}

},{"../core/util/Defaults.js":"a9M5s","../signal/WaveShaper.js":"k4nzV","./Effect.js":"g3o0i","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5n2nf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FeedbackDelay is a DelayNode in which part of output signal is fed back into the delay.
 *
 * @param delayTime The delay applied to the incoming signal.
 * @param feedback The amount of the effected signal which is fed back through the delay.
 * @example
 * const feedbackDelay = new Tone.FeedbackDelay("8n", 0.5).toDestination();
 * const tom = new Tone.MembraneSynth({
 * 	octaves: 4,
 * 	pitchDecay: 0.1
 * }).connect(feedbackDelay);
 * tom.triggerAttackRelease("A2", "32n");
 * @category Effect
 */ parcelHelpers.export(exports, "FeedbackDelay", ()=>FeedbackDelay);
var _delayJs = require("../core/context/Delay.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _feedbackEffectJs = require("./FeedbackEffect.js");
class FeedbackDelay extends (0, _feedbackEffectJs.FeedbackEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(FeedbackDelay.getDefaults(), arguments, [
            "delayTime",
            "feedback"
        ]);
        super(options);
        this.name = "FeedbackDelay";
        this._delayNode = new (0, _delayJs.Delay)({
            context: this.context,
            delayTime: options.delayTime,
            maxDelay: options.maxDelay
        });
        this.delayTime = this._delayNode.delayTime;
        // connect it up
        this.connectEffect(this._delayNode);
        (0, _interfaceJs.readOnly)(this, "delayTime");
    }
    static getDefaults() {
        return Object.assign((0, _feedbackEffectJs.FeedbackEffect).getDefaults(), {
            delayTime: 0.25,
            maxDelay: 1
        });
    }
    dispose() {
        super.dispose();
        this._delayNode.dispose();
        this.delayTime.dispose();
        return this;
    }
}

},{"../core/context/Delay.js":"1qHQA","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","./FeedbackEffect.js":"kSZ9b","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"kSZ9b":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FeedbackEffect provides a loop between an audio source and its own output.
 * This is a base-class for feedback effects.
 */ parcelHelpers.export(exports, "FeedbackEffect", ()=>FeedbackEffect);
var _gainJs = require("../core/context/Gain.js");
var _interfaceJs = require("../core/util/Interface.js");
var _effectJs = require("./Effect.js");
class FeedbackEffect extends (0, _effectJs.Effect) {
    constructor(options){
        super(options);
        this.name = "FeedbackEffect";
        this._feedbackGain = new (0, _gainJs.Gain)({
            context: this.context,
            gain: options.feedback,
            units: "normalRange"
        });
        this.feedback = this._feedbackGain.gain;
        (0, _interfaceJs.readOnly)(this, "feedback");
        // the feedback loop
        this.effectReturn.chain(this._feedbackGain, this.effectSend);
    }
    static getDefaults() {
        return Object.assign((0, _effectJs.Effect).getDefaults(), {
            feedback: 0.125
        });
    }
    dispose() {
        super.dispose();
        this._feedbackGain.dispose();
        this.feedback.dispose();
        return this;
    }
}

},{"../core/context/Gain.js":"kj68Y","../core/util/Interface.js":"hVOjA","./Effect.js":"g3o0i","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"bB1gQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FrequencyShifter can be used to shift all frequencies of a signal by a fixed amount.
 * The amount can be changed at audio rate and the effect is applied in real time.
 * The frequency shifting is implemented with a technique called single side band modulation using a ring modulator.
 * Note: Contrary to pitch shifting, all frequencies are shifted by the same amount,
 * destroying the harmonic relationship between them. This leads to the classic ring modulator timbre distortion.
 * The algorithm will produces some aliasing towards the high end, especially if your source material
 * contains a lot of high frequencies. Unfortunatelly the webaudio API does not support resampling
 * buffers in real time, so it is not possible to fix it properly. Depending on the use case it might
 * be an option to low pass filter your input before frequency shifting it to get ride of the aliasing.
 * You can find a very detailed description of the algorithm here: https://larzeitlin.github.io/RMFS/
 *
 * @example
 * const input = new Tone.Oscillator(230, "sawtooth").start();
 * const shift = new Tone.FrequencyShifter(42).toDestination();
 * input.connect(shift);
 * @category Effect
 */ parcelHelpers.export(exports, "FrequencyShifter", ()=>FrequencyShifter);
var _phaseShiftAllpassJs = require("../component/filter/PhaseShiftAllpass.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _effectJs = require("../effect/Effect.js");
var _addJs = require("../signal/Add.js");
var _multiplyJs = require("../signal/Multiply.js");
var _negateJs = require("../signal/Negate.js");
var _signalJs = require("../signal/Signal.js");
var _oscillatorJs = require("../source/oscillator/Oscillator.js");
var _toneOscillatorNodeJs = require("../source/oscillator/ToneOscillatorNode.js");
class FrequencyShifter extends (0, _effectJs.Effect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(FrequencyShifter.getDefaults(), arguments, [
            "frequency"
        ]);
        super(options);
        this.name = "FrequencyShifter";
        this.frequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency",
            value: options.frequency,
            minValue: -this.context.sampleRate / 2,
            maxValue: this.context.sampleRate / 2
        });
        this._sine = new (0, _toneOscillatorNodeJs.ToneOscillatorNode)({
            context: this.context,
            type: "sine"
        });
        this._cosine = new (0, _oscillatorJs.Oscillator)({
            context: this.context,
            phase: -90,
            type: "sine"
        });
        this._sineMultiply = new (0, _multiplyJs.Multiply)({
            context: this.context
        });
        this._cosineMultiply = new (0, _multiplyJs.Multiply)({
            context: this.context
        });
        this._negate = new (0, _negateJs.Negate)({
            context: this.context
        });
        this._add = new (0, _addJs.Add)({
            context: this.context
        });
        this._phaseShifter = new (0, _phaseShiftAllpassJs.PhaseShiftAllpass)({
            context: this.context
        });
        this.effectSend.connect(this._phaseShifter);
        // connect the carrier frequency signal to the two oscillators
        this.frequency.fan(this._sine.frequency, this._cosine.frequency);
        this._phaseShifter.offset90.connect(this._cosineMultiply);
        this._cosine.connect(this._cosineMultiply.factor);
        this._phaseShifter.connect(this._sineMultiply);
        this._sine.connect(this._sineMultiply.factor);
        this._sineMultiply.connect(this._negate);
        this._cosineMultiply.connect(this._add);
        this._negate.connect(this._add.addend);
        this._add.connect(this.effectReturn);
        // start the oscillators at the same time
        const now = this.immediate();
        this._sine.start(now);
        this._cosine.start(now);
    }
    static getDefaults() {
        return Object.assign((0, _effectJs.Effect).getDefaults(), {
            frequency: 0
        });
    }
    dispose() {
        super.dispose();
        this.frequency.dispose();
        this._add.dispose();
        this._cosine.dispose();
        this._cosineMultiply.dispose();
        this._negate.dispose();
        this._phaseShifter.dispose();
        this._sine.dispose();
        this._sineMultiply.dispose();
        return this;
    }
}

},{"../component/filter/PhaseShiftAllpass.js":"8SNb7","../core/util/Defaults.js":"a9M5s","../effect/Effect.js":"g3o0i","../signal/Add.js":"jeoK8","../signal/Multiply.js":"4C0VG","../signal/Negate.js":"9nMgn","../signal/Signal.js":"980ri","../source/oscillator/Oscillator.js":"204g3","../source/oscillator/ToneOscillatorNode.js":"gLw4W","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8SNb7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PhaseShiftAllpass is an very efficient implementation of a Hilbert Transform
 * using two Allpass filter banks whose outputs have a phase difference of 90.
 * Here the `offset90` phase is offset by +90 in relation to `output`.
 * Coefficients and structure was developed by Olli Niemitalo.
 * For more details see: http://yehar.com/blog/?p=368
 * @category Component
 */ parcelHelpers.export(exports, "PhaseShiftAllpass", ()=>PhaseShiftAllpass);
var _gainJs = require("../../core/context/Gain.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
class PhaseShiftAllpass extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(options){
        super(options);
        this.name = "PhaseShiftAllpass";
        this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        /**
         * The phase shifted output
         */ this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        /**
         * The PhaseShifted allpass output
         */ this.offset90 = new (0, _gainJs.Gain)({
            context: this.context
        });
        const allpassBank1Values = [
            0.6923878,
            0.9360654322959,
            0.988229522686,
            0.9987488452737
        ];
        const allpassBank2Values = [
            0.4021921162426,
            0.856171088242,
            0.9722909545651,
            0.9952884791278
        ];
        this._bank0 = this._createAllPassFilterBank(allpassBank1Values);
        this._bank1 = this._createAllPassFilterBank(allpassBank2Values);
        this._oneSampleDelay = this.context.createIIRFilter([
            0.0,
            1.0
        ], [
            1.0,
            0.0
        ]);
        // connect Allpass filter banks
        (0, _toneAudioNodeJs.connectSeries)(this.input, ...this._bank0, this._oneSampleDelay, this.output);
        (0, _toneAudioNodeJs.connectSeries)(this.input, ...this._bank1, this.offset90);
    }
    /**
     * Create all of the IIR filters from an array of values using the coefficient calculation.
     */ _createAllPassFilterBank(bankValues) {
        const nodes = bankValues.map((value)=>{
            const coefficients = [
                [
                    value * value,
                    0,
                    -1
                ],
                [
                    1,
                    0,
                    -(value * value)
                ]
            ];
            return this.context.createIIRFilter(coefficients[0], coefficients[1]);
        });
        return nodes;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this.offset90.dispose();
        this._bank0.forEach((f)=>f.disconnect());
        this._bank1.forEach((f)=>f.disconnect());
        this._oneSampleDelay.disconnect();
        return this;
    }
}

},{"../../core/context/Gain.js":"kj68Y","../../core/context/ToneAudioNode.js":"kZ3Kj","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"k7mdD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Freeverb is a reverb based on [Freeverb](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html).
 * Read more on reverb on [Sound On Sound](https://web.archive.org/web/20160404083902/http://www.soundonsound.com:80/sos/feb01/articles/synthsecrets.asp).
 * Freeverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using {@link Reverb}.
 * @example
 * const freeverb = new Tone.Freeverb().toDestination();
 * freeverb.dampening = 1000;
 * // routing synth through the reverb
 * const synth = new Tone.NoiseSynth().connect(freeverb);
 * synth.triggerAttackRelease(0.05);
 * @category Effect
 */ parcelHelpers.export(exports, "Freeverb", ()=>Freeverb);
var _stereoEffectJs = require("./StereoEffect.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _signalJs = require("../signal/Signal.js");
var _lowpassCombFilterJs = require("../component/filter/LowpassCombFilter.js");
/**
 * An array of comb filter delay values from Freeverb implementation
 */ const combFilterTunings = [
    1557 / 44100,
    1617 / 44100,
    1491 / 44100,
    1422 / 44100,
    1277 / 44100,
    1356 / 44100,
    1188 / 44100,
    1116 / 44100
];
/**
 * An array of allpass filter frequency values from Freeverb implementation
 */ const allpassFilterFrequencies = [
    225,
    556,
    441,
    341
];
class Freeverb extends (0, _stereoEffectJs.StereoEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Freeverb.getDefaults(), arguments, [
            "roomSize",
            "dampening"
        ]);
        super(options);
        this.name = "Freeverb";
        /**
         * the comb filters
         */ this._combFilters = [];
        /**
         * the allpass filters on the left
         */ this._allpassFiltersL = [];
        /**
         * the allpass filters on the right
         */ this._allpassFiltersR = [];
        this.roomSize = new (0, _signalJs.Signal)({
            context: this.context,
            value: options.roomSize,
            units: "normalRange"
        });
        // make the allpass filters on the right
        this._allpassFiltersL = allpassFilterFrequencies.map((freq)=>{
            const allpassL = this.context.createBiquadFilter();
            allpassL.type = "allpass";
            allpassL.frequency.value = freq;
            return allpassL;
        });
        // make the allpass filters on the left
        this._allpassFiltersR = allpassFilterFrequencies.map((freq)=>{
            const allpassR = this.context.createBiquadFilter();
            allpassR.type = "allpass";
            allpassR.frequency.value = freq;
            return allpassR;
        });
        // make the comb filters
        this._combFilters = combFilterTunings.map((delayTime, index)=>{
            const lfpf = new (0, _lowpassCombFilterJs.LowpassCombFilter)({
                context: this.context,
                dampening: options.dampening,
                delayTime
            });
            if (index < combFilterTunings.length / 2) this.connectEffectLeft(lfpf, ...this._allpassFiltersL);
            else this.connectEffectRight(lfpf, ...this._allpassFiltersR);
            this.roomSize.connect(lfpf.resonance);
            return lfpf;
        });
        (0, _interfaceJs.readOnly)(this, [
            "roomSize"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _stereoEffectJs.StereoEffect).getDefaults(), {
            roomSize: 0.7,
            dampening: 3000
        });
    }
    /**
     * The amount of dampening of the reverberant signal.
     */ get dampening() {
        return this._combFilters[0].dampening;
    }
    set dampening(d) {
        this._combFilters.forEach((c)=>c.dampening = d);
    }
    dispose() {
        super.dispose();
        this._allpassFiltersL.forEach((al)=>al.disconnect());
        this._allpassFiltersR.forEach((ar)=>ar.disconnect());
        this._combFilters.forEach((cf)=>cf.dispose());
        this.roomSize.dispose();
        return this;
    }
}

},{"./StereoEffect.js":"3INxk","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","../signal/Signal.js":"980ri","../component/filter/LowpassCombFilter.js":"01n6w","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gi3q6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * JCReverb is a simple [Schroeder Reverberator](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Reverberators.html)
 * tuned by John Chowning in 1970.
 * It is made up of three allpass filters and four {@link FeedbackCombFilter}.
 * JCReverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using {@link Reverb}.
 * @example
 * const reverb = new Tone.JCReverb(0.4).toDestination();
 * const delay = new Tone.FeedbackDelay(0.5);
 * // connecting the synth to reverb through delay
 * const synth = new Tone.DuoSynth().chain(delay, reverb);
 * synth.triggerAttackRelease("A4", "8n");
 *
 * @category Effect
 */ parcelHelpers.export(exports, "JCReverb", ()=>JCReverb);
var _stereoEffectJs = require("./StereoEffect.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _scaleJs = require("../signal/Scale.js");
var _signalJs = require("../signal/Signal.js");
var _feedbackCombFilterJs = require("../component/filter/FeedbackCombFilter.js");
var _interfaceJs = require("../core/util/Interface.js");
/**
 * an array of the comb filter delay time values
 */ const combFilterDelayTimes = [
    0.06748,
    0.06404,
    0.08212,
    0.09004
];
/**
 * the resonances of each of the comb filters
 */ const combFilterResonances = [
    0.773,
    0.802,
    0.753,
    0.733
];
/**
 * the allpass filter frequencies
 */ const allpassFilterFreqs = [
    347,
    113,
    37
];
class JCReverb extends (0, _stereoEffectJs.StereoEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(JCReverb.getDefaults(), arguments, [
            "roomSize"
        ]);
        super(options);
        this.name = "JCReverb";
        /**
         * a series of allpass filters
         */ this._allpassFilters = [];
        /**
         * parallel feedback comb filters
         */ this._feedbackCombFilters = [];
        this.roomSize = new (0, _signalJs.Signal)({
            context: this.context,
            value: options.roomSize,
            units: "normalRange"
        });
        this._scaleRoomSize = new (0, _scaleJs.Scale)({
            context: this.context,
            min: -0.733,
            max: 0.197
        });
        // make the allpass filters
        this._allpassFilters = allpassFilterFreqs.map((freq)=>{
            const allpass = this.context.createBiquadFilter();
            allpass.type = "allpass";
            allpass.frequency.value = freq;
            return allpass;
        });
        // and the comb filters
        this._feedbackCombFilters = combFilterDelayTimes.map((delayTime, index)=>{
            const fbcf = new (0, _feedbackCombFilterJs.FeedbackCombFilter)({
                context: this.context,
                delayTime
            });
            this._scaleRoomSize.connect(fbcf.resonance);
            fbcf.resonance.value = combFilterResonances[index];
            if (index < combFilterDelayTimes.length / 2) this.connectEffectLeft(...this._allpassFilters, fbcf);
            else this.connectEffectRight(...this._allpassFilters, fbcf);
            return fbcf;
        });
        // chain the allpass filters together
        this.roomSize.connect(this._scaleRoomSize);
        (0, _interfaceJs.readOnly)(this, [
            "roomSize"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _stereoEffectJs.StereoEffect).getDefaults(), {
            roomSize: 0.5
        });
    }
    dispose() {
        super.dispose();
        this._allpassFilters.forEach((apf)=>apf.disconnect());
        this._feedbackCombFilters.forEach((fbcf)=>fbcf.dispose());
        this.roomSize.dispose();
        this._scaleRoomSize.dispose();
        return this;
    }
}

},{"./StereoEffect.js":"3INxk","../core/util/Defaults.js":"a9M5s","../signal/Scale.js":"3qxrw","../signal/Signal.js":"980ri","../component/filter/FeedbackCombFilter.js":"iMAnY","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"avdgi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PingPongDelay is a feedback delay effect where the echo is heard
 * first in one channel and next in the opposite channel. In a stereo
 * system these are the right and left channels.
 * PingPongDelay in more simplified terms is two Tone.FeedbackDelays
 * with independent delay values. Each delay is routed to one channel
 * (left or right), and the channel triggered second will always
 * trigger at the same interval after the first.
 * @example
 * const pingPong = new Tone.PingPongDelay("4n", 0.2).toDestination();
 * const drum = new Tone.MembraneSynth().connect(pingPong);
 * drum.triggerAttackRelease("C4", "32n");
 * @category Effect
 */ parcelHelpers.export(exports, "PingPongDelay", ()=>PingPongDelay);
var _stereoXFeedbackEffectJs = require("./StereoXFeedbackEffect.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _delayJs = require("../core/context/Delay.js");
var _signalJs = require("../signal/Signal.js");
var _interfaceJs = require("../core/util/Interface.js");
class PingPongDelay extends (0, _stereoXFeedbackEffectJs.StereoXFeedbackEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(PingPongDelay.getDefaults(), arguments, [
            "delayTime",
            "feedback"
        ]);
        super(options);
        this.name = "PingPongDelay";
        this._leftDelay = new (0, _delayJs.Delay)({
            context: this.context,
            maxDelay: options.maxDelay
        });
        this._rightDelay = new (0, _delayJs.Delay)({
            context: this.context,
            maxDelay: options.maxDelay
        });
        this._rightPreDelay = new (0, _delayJs.Delay)({
            context: this.context,
            maxDelay: options.maxDelay
        });
        this.delayTime = new (0, _signalJs.Signal)({
            context: this.context,
            units: "time",
            value: options.delayTime
        });
        // connect it up
        this.connectEffectLeft(this._leftDelay);
        this.connectEffectRight(this._rightPreDelay, this._rightDelay);
        this.delayTime.fan(this._leftDelay.delayTime, this._rightDelay.delayTime, this._rightPreDelay.delayTime);
        // rearranged the feedback to be after the rightPreDelay
        this._feedbackL.disconnect();
        this._feedbackL.connect(this._rightDelay);
        (0, _interfaceJs.readOnly)(this, [
            "delayTime"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _stereoXFeedbackEffectJs.StereoXFeedbackEffect).getDefaults(), {
            delayTime: 0.25,
            maxDelay: 1
        });
    }
    dispose() {
        super.dispose();
        this._leftDelay.dispose();
        this._rightDelay.dispose();
        this._rightPreDelay.dispose();
        this.delayTime.dispose();
        return this;
    }
}

},{"./StereoXFeedbackEffect.js":"h6Kio","../core/util/Defaults.js":"a9M5s","../core/context/Delay.js":"1qHQA","../signal/Signal.js":"980ri","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"h6Kio":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Just like a {@link StereoFeedbackEffect}, but the feedback is routed from left to right
 * and right to left instead of on the same channel.
 * ```
 * +--------------------------------+ feedbackL <-----------------------------------+
 * |                                                                                |
 * +-->                          +----->        +---->                          +-----+
 *      feedbackMerge +--> split        (EFFECT)       merge +--> feedbackSplit     | |
 * +-->                          +----->        +---->                          +---+ |
 * |                                                                                  |
 * +--------------------------------+ feedbackR <-------------------------------------+
 * ```
 */ parcelHelpers.export(exports, "StereoXFeedbackEffect", ()=>StereoXFeedbackEffect);
var _stereoFeedbackEffectJs = require("./StereoFeedbackEffect.js");
var _interfaceJs = require("../core/util/Interface.js");
class StereoXFeedbackEffect extends (0, _stereoFeedbackEffectJs.StereoFeedbackEffect) {
    constructor(options){
        super(options);
        // the left output connected to the right input
        this._feedbackL.disconnect();
        this._feedbackL.connect(this._feedbackMerge, 0, 1);
        // the left output connected to the right input
        this._feedbackR.disconnect();
        this._feedbackR.connect(this._feedbackMerge, 0, 0);
        (0, _interfaceJs.readOnly)(this, [
            "feedback"
        ]);
    }
}

},{"./StereoFeedbackEffect.js":"2txKj","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8mlNP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PitchShift does near-realtime pitch shifting to the incoming signal.
 * The effect is achieved by speeding up or slowing down the delayTime
 * of a DelayNode using a sawtooth wave.
 * Algorithm found in [this pdf](http://dsp-book.narod.ru/soundproc.pdf).
 * Additional reference by [Miller Pucket](http://msp.ucsd.edu/techniques/v0.11/book-html/node115.html).
 * @category Effect
 */ parcelHelpers.export(exports, "PitchShift", ()=>PitchShift);
var _feedbackEffectJs = require("./FeedbackEffect.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _lfoJs = require("../source/oscillator/LFO.js");
var _delayJs = require("../core/context/Delay.js");
var _crossFadeJs = require("../component/channel/CrossFade.js");
var _signalJs = require("../signal/Signal.js");
var _interfaceJs = require("../core/util/Interface.js");
var _conversionsJs = require("../core/type/Conversions.js");
class PitchShift extends (0, _feedbackEffectJs.FeedbackEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(PitchShift.getDefaults(), arguments, [
            "pitch"
        ]);
        super(options);
        this.name = "PitchShift";
        this._frequency = new (0, _signalJs.Signal)({
            context: this.context
        });
        this._delayA = new (0, _delayJs.Delay)({
            maxDelay: 1,
            context: this.context
        });
        this._lfoA = new (0, _lfoJs.LFO)({
            context: this.context,
            min: 0,
            max: 0.1,
            type: "sawtooth"
        }).connect(this._delayA.delayTime);
        this._delayB = new (0, _delayJs.Delay)({
            maxDelay: 1,
            context: this.context
        });
        this._lfoB = new (0, _lfoJs.LFO)({
            context: this.context,
            min: 0,
            max: 0.1,
            type: "sawtooth",
            phase: 180
        }).connect(this._delayB.delayTime);
        this._crossFade = new (0, _crossFadeJs.CrossFade)({
            context: this.context
        });
        this._crossFadeLFO = new (0, _lfoJs.LFO)({
            context: this.context,
            min: 0,
            max: 1,
            type: "triangle",
            phase: 90
        }).connect(this._crossFade.fade);
        this._feedbackDelay = new (0, _delayJs.Delay)({
            delayTime: options.delayTime,
            context: this.context
        });
        this.delayTime = this._feedbackDelay.delayTime;
        (0, _interfaceJs.readOnly)(this, "delayTime");
        this._pitch = options.pitch;
        this._windowSize = options.windowSize;
        // connect the two delay lines up
        this._delayA.connect(this._crossFade.a);
        this._delayB.connect(this._crossFade.b);
        // connect the frequency
        this._frequency.fan(this._lfoA.frequency, this._lfoB.frequency, this._crossFadeLFO.frequency);
        // route the input
        this.effectSend.fan(this._delayA, this._delayB);
        this._crossFade.chain(this._feedbackDelay, this.effectReturn);
        // start the LFOs at the same time
        const now = this.now();
        this._lfoA.start(now);
        this._lfoB.start(now);
        this._crossFadeLFO.start(now);
        // set the initial value
        this.windowSize = this._windowSize;
    }
    static getDefaults() {
        return Object.assign((0, _feedbackEffectJs.FeedbackEffect).getDefaults(), {
            pitch: 0,
            windowSize: 0.1,
            delayTime: 0,
            feedback: 0
        });
    }
    /**
     * Repitch the incoming signal by some interval (measured in semi-tones).
     * @example
     * const pitchShift = new Tone.PitchShift().toDestination();
     * const osc = new Tone.Oscillator().connect(pitchShift).start().toDestination();
     * pitchShift.pitch = -12; // down one octave
     * pitchShift.pitch = 7; // up a fifth
     */ get pitch() {
        return this._pitch;
    }
    set pitch(interval) {
        this._pitch = interval;
        let factor = 0;
        if (interval < 0) {
            this._lfoA.min = 0;
            this._lfoA.max = this._windowSize;
            this._lfoB.min = 0;
            this._lfoB.max = this._windowSize;
            factor = (0, _conversionsJs.intervalToFrequencyRatio)(interval - 1) + 1;
        } else {
            this._lfoA.min = this._windowSize;
            this._lfoA.max = 0;
            this._lfoB.min = this._windowSize;
            this._lfoB.max = 0;
            factor = (0, _conversionsJs.intervalToFrequencyRatio)(interval) - 1;
        }
        this._frequency.value = factor * (1.2 / this._windowSize);
    }
    /**
     * The window size corresponds roughly to the sample length in a looping sampler.
     * Smaller values are desirable for a less noticeable delay time of the pitch shifted
     * signal, but larger values will result in smoother pitch shifting for larger intervals.
     * A nominal range of 0.03 to 0.1 is recommended.
     */ get windowSize() {
        return this._windowSize;
    }
    set windowSize(size) {
        this._windowSize = this.toSeconds(size);
        this.pitch = this._pitch;
    }
    dispose() {
        super.dispose();
        this._frequency.dispose();
        this._delayA.dispose();
        this._delayB.dispose();
        this._lfoA.dispose();
        this._lfoB.dispose();
        this._crossFade.dispose();
        this._crossFadeLFO.dispose();
        this._feedbackDelay.dispose();
        return this;
    }
}

},{"./FeedbackEffect.js":"kSZ9b","../core/util/Defaults.js":"a9M5s","../source/oscillator/LFO.js":"jsBJT","../core/context/Delay.js":"1qHQA","../component/channel/CrossFade.js":"cd1EQ","../signal/Signal.js":"980ri","../core/util/Interface.js":"hVOjA","../core/type/Conversions.js":"iww1u","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8FJ4l":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Phaser is a phaser effect. Phasers work by changing the phase
 * of different frequency components of an incoming signal. Read more on
 * [Wikipedia](https://en.wikipedia.org/wiki/Phaser_(effect)).
 * Inspiration for this phaser comes from [Tuna.js](https://github.com/Dinahmoe/tuna/).
 * @example
 * const phaser = new Tone.Phaser({
 * 	frequency: 15,
 * 	octaves: 5,
 * 	baseFrequency: 1000
 * }).toDestination();
 * const synth = new Tone.FMSynth().connect(phaser);
 * synth.triggerAttackRelease("E3", "2n");
 * @category Effect
 */ parcelHelpers.export(exports, "Phaser", ()=>Phaser);
var _stereoEffectJs = require("./StereoEffect.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _lfoJs = require("../source/oscillator/LFO.js");
var _signalJs = require("../signal/Signal.js");
var _interfaceJs = require("../core/util/Interface.js");
class Phaser extends (0, _stereoEffectJs.StereoEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Phaser.getDefaults(), arguments, [
            "frequency",
            "octaves",
            "baseFrequency"
        ]);
        super(options);
        this.name = "Phaser";
        this._lfoL = new (0, _lfoJs.LFO)({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1
        });
        this._lfoR = new (0, _lfoJs.LFO)({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1,
            phase: 180
        });
        this._baseFrequency = this.toFrequency(options.baseFrequency);
        this._octaves = options.octaves;
        this.Q = new (0, _signalJs.Signal)({
            context: this.context,
            value: options.Q,
            units: "positive"
        });
        this._filtersL = this._makeFilters(options.stages, this._lfoL);
        this._filtersR = this._makeFilters(options.stages, this._lfoR);
        this.frequency = this._lfoL.frequency;
        this.frequency.value = options.frequency;
        // connect them up
        this.connectEffectLeft(...this._filtersL);
        this.connectEffectRight(...this._filtersR);
        // control the frequency with one LFO
        this._lfoL.frequency.connect(this._lfoR.frequency);
        // set the options
        this.baseFrequency = options.baseFrequency;
        this.octaves = options.octaves;
        // start the lfo
        this._lfoL.start();
        this._lfoR.start();
        (0, _interfaceJs.readOnly)(this, [
            "frequency",
            "Q"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _stereoEffectJs.StereoEffect).getDefaults(), {
            frequency: 0.5,
            octaves: 3,
            stages: 10,
            Q: 10,
            baseFrequency: 350
        });
    }
    _makeFilters(stages, connectToFreq) {
        const filters = [];
        // make all the filters
        for(let i = 0; i < stages; i++){
            const filter = this.context.createBiquadFilter();
            filter.type = "allpass";
            this.Q.connect(filter.Q);
            connectToFreq.connect(filter.frequency);
            filters.push(filter);
        }
        return filters;
    }
    /**
     * The number of octaves the phase goes above the baseFrequency
     */ get octaves() {
        return this._octaves;
    }
    set octaves(octaves) {
        this._octaves = octaves;
        const max = this._baseFrequency * Math.pow(2, octaves);
        this._lfoL.max = max;
        this._lfoR.max = max;
    }
    /**
     * The the base frequency of the filters.
     */ get baseFrequency() {
        return this._baseFrequency;
    }
    set baseFrequency(freq) {
        this._baseFrequency = this.toFrequency(freq);
        this._lfoL.min = this._baseFrequency;
        this._lfoR.min = this._baseFrequency;
        this.octaves = this._octaves;
    }
    dispose() {
        super.dispose();
        this.Q.dispose();
        this._lfoL.dispose();
        this._lfoR.dispose();
        this._filtersL.forEach((f)=>f.disconnect());
        this._filtersR.forEach((f)=>f.disconnect());
        this.frequency.dispose();
        return this;
    }
}

},{"./StereoEffect.js":"3INxk","../core/util/Defaults.js":"a9M5s","../source/oscillator/LFO.js":"jsBJT","../signal/Signal.js":"980ri","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"j2JHY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Simple convolution created with decaying noise.
 * Generates an Impulse Response Buffer
 * with Tone.Offline then feeds the IR into ConvolverNode.
 * The impulse response generation is async, so you have
 * to wait until {@link ready} resolves before it will make a sound.
 *
 * Inspiration from [ReverbGen](https://github.com/adelespinasse/reverbGen).
 * Copyright (c) 2014 Alan deLespinasse Apache 2.0 License.
 *
 * @category Effect
 */ parcelHelpers.export(exports, "Reverb", ()=>Reverb);
var _tslib = require("tslib");
var _mergeJs = require("../component/channel/Merge.js");
var _gainJs = require("../core/context/Gain.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _noiseJs = require("../source/Noise.js");
var _effectJs = require("./Effect.js");
var _offlineContextJs = require("../core/context/OfflineContext.js");
var _interfaceJs = require("../core/util/Interface.js");
var _debugJs = require("../core/util/Debug.js");
class Reverb extends (0, _effectJs.Effect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Reverb.getDefaults(), arguments, [
            "decay"
        ]);
        super(options);
        this.name = "Reverb";
        /**
         * Convolver node
         */ this._convolver = this.context.createConvolver();
        /**
         * Resolves when the reverb buffer is generated. Whenever either {@link decay}
         * or {@link preDelay} are set, you have to wait until {@link ready} resolves
         * before the IR is generated with the latest values.
         */ this.ready = Promise.resolve();
        this._decay = options.decay;
        this._preDelay = options.preDelay;
        this.generate();
        this.connectEffect(this._convolver);
    }
    static getDefaults() {
        return Object.assign((0, _effectJs.Effect).getDefaults(), {
            decay: 1.5,
            preDelay: 0.01
        });
    }
    /**
     * The duration of the reverb.
     */ get decay() {
        return this._decay;
    }
    set decay(time) {
        time = this.toSeconds(time);
        (0, _debugJs.assertRange)(time, 0.001);
        this._decay = time;
        this.generate();
    }
    /**
     * The amount of time before the reverb is fully ramped in.
     */ get preDelay() {
        return this._preDelay;
    }
    set preDelay(time) {
        time = this.toSeconds(time);
        (0, _debugJs.assertRange)(time, 0);
        this._preDelay = time;
        this.generate();
    }
    /**
     * Generate the Impulse Response. Returns a promise while the IR is being generated.
     * @return Promise which returns this object.
     */ generate() {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            const previousReady = this.ready;
            // create a noise burst which decays over the duration in each channel
            const context = new (0, _offlineContextJs.OfflineContext)(2, this._decay + this._preDelay, this.context.sampleRate);
            const noiseL = new (0, _noiseJs.Noise)({
                context
            });
            const noiseR = new (0, _noiseJs.Noise)({
                context
            });
            const merge = new (0, _mergeJs.Merge)({
                context
            });
            noiseL.connect(merge, 0, 0);
            noiseR.connect(merge, 0, 1);
            const gainNode = new (0, _gainJs.Gain)({
                context
            }).toDestination();
            merge.connect(gainNode);
            noiseL.start(0);
            noiseR.start(0);
            // predelay
            gainNode.gain.setValueAtTime(0, 0);
            gainNode.gain.setValueAtTime(1, this._preDelay);
            // decay
            gainNode.gain.exponentialApproachValueAtTime(0, this._preDelay, this.decay);
            // render the buffer
            const renderPromise = context.render();
            this.ready = renderPromise.then((0, _interfaceJs.noOp));
            // wait for the previous `ready` to resolve
            yield previousReady;
            // set the buffer
            this._convolver.buffer = (yield renderPromise).get();
            return this;
        });
    }
    dispose() {
        super.dispose();
        this._convolver.disconnect();
        return this;
    }
}

},{"tslib":"lRdW5","../component/channel/Merge.js":"xBcDu","../core/context/Gain.js":"kj68Y","../core/util/Defaults.js":"a9M5s","../source/Noise.js":"cOpzx","./Effect.js":"g3o0i","../core/context/OfflineContext.js":"8VnAL","../core/util/Interface.js":"hVOjA","../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5qIOm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Applies a width factor to the mid/side seperation.
 * 0 is all mid and 1 is all side.
 * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).
 * ```
 * Mid *= 2*(1-width)<br>
 * Side *= 2*width
 * ```
 * @category Effect
 */ parcelHelpers.export(exports, "StereoWidener", ()=>StereoWidener);
var _midSideEffectJs = require("../effect/MidSideEffect.js");
var _signalJs = require("../signal/Signal.js");
var _multiplyJs = require("../signal/Multiply.js");
var _subtractJs = require("../signal/Subtract.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
var _toneAudioNodeJs = require("../core/context/ToneAudioNode.js");
class StereoWidener extends (0, _midSideEffectJs.MidSideEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(StereoWidener.getDefaults(), arguments, [
            "width"
        ]);
        super(options);
        this.name = "StereoWidener";
        this.width = new (0, _signalJs.Signal)({
            context: this.context,
            value: options.width,
            units: "normalRange"
        });
        (0, _interfaceJs.readOnly)(this, [
            "width"
        ]);
        this._twoTimesWidthMid = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: 2
        });
        this._twoTimesWidthSide = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: 2
        });
        this._midMult = new (0, _multiplyJs.Multiply)({
            context: this.context
        });
        this._twoTimesWidthMid.connect(this._midMult.factor);
        this.connectEffectMid(this._midMult);
        this._oneMinusWidth = new (0, _subtractJs.Subtract)({
            context: this.context
        });
        this._oneMinusWidth.connect(this._twoTimesWidthMid);
        (0, _toneAudioNodeJs.connect)(this.context.getConstant(1), this._oneMinusWidth);
        this.width.connect(this._oneMinusWidth.subtrahend);
        this._sideMult = new (0, _multiplyJs.Multiply)({
            context: this.context
        });
        this.width.connect(this._twoTimesWidthSide);
        this._twoTimesWidthSide.connect(this._sideMult.factor);
        this.connectEffectSide(this._sideMult);
    }
    static getDefaults() {
        return Object.assign((0, _midSideEffectJs.MidSideEffect).getDefaults(), {
            width: 0.5
        });
    }
    dispose() {
        super.dispose();
        this.width.dispose();
        this._midMult.dispose();
        this._sideMult.dispose();
        this._twoTimesWidthMid.dispose();
        this._twoTimesWidthSide.dispose();
        this._oneMinusWidth.dispose();
        return this;
    }
}

},{"../effect/MidSideEffect.js":"gOGAT","../signal/Signal.js":"980ri","../signal/Multiply.js":"4C0VG","../signal/Subtract.js":"cVmeJ","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","../core/context/ToneAudioNode.js":"kZ3Kj","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gOGAT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Mid/Side processing separates the the 'mid' signal
 * (which comes out of both the left and the right channel)
 * and the 'side' (which only comes out of the the side channels)
 * and effects them separately before being recombined.
 * Applies a Mid/Side seperation and recombination.
 * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).
 * This is a base-class for Mid/Side Effects.
 * @category Effect
 */ parcelHelpers.export(exports, "MidSideEffect", ()=>MidSideEffect);
var _effectJs = require("./Effect.js");
var _midSideSplitJs = require("../component/channel/MidSideSplit.js");
var _midSideMergeJs = require("../component/channel/MidSideMerge.js");
class MidSideEffect extends (0, _effectJs.Effect) {
    constructor(options){
        super(options);
        this.name = "MidSideEffect";
        this._midSideMerge = new (0, _midSideMergeJs.MidSideMerge)({
            context: this.context
        });
        this._midSideSplit = new (0, _midSideSplitJs.MidSideSplit)({
            context: this.context
        });
        this._midSend = this._midSideSplit.mid;
        this._sideSend = this._midSideSplit.side;
        this._midReturn = this._midSideMerge.mid;
        this._sideReturn = this._midSideMerge.side;
        // the connections
        this.effectSend.connect(this._midSideSplit);
        this._midSideMerge.connect(this.effectReturn);
    }
    /**
     * Connect the mid chain of the effect
     */ connectEffectMid(...nodes) {
        this._midSend.chain(...nodes, this._midReturn);
    }
    /**
     * Connect the side chain of the effect
     */ connectEffectSide(...nodes) {
        this._sideSend.chain(...nodes, this._sideReturn);
    }
    dispose() {
        super.dispose();
        this._midSideSplit.dispose();
        this._midSideMerge.dispose();
        this._midSend.dispose();
        this._sideSend.dispose();
        this._midReturn.dispose();
        this._sideReturn.dispose();
        return this;
    }
}

},{"./Effect.js":"g3o0i","../component/channel/MidSideSplit.js":"3oEnx","../component/channel/MidSideMerge.js":"8osXs","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3oEnx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Mid/Side processing separates the the 'mid' signal (which comes out of both the left and the right channel)
 * and the 'side' (which only comes out of the the side channels).
 * ```
 * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right
 * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right
 * ```
 * @category Component
 */ parcelHelpers.export(exports, "MidSideSplit", ()=>MidSideSplit);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _splitJs = require("./Split.js");
var _addJs = require("../../signal/Add.js");
var _multiplyJs = require("../../signal/Multiply.js");
var _subtractJs = require("../../signal/Subtract.js");
var _defaultsJs = require("../../core/util/Defaults.js");
class MidSideSplit extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(MidSideSplit.getDefaults(), arguments));
        this.name = "MidSideSplit";
        this._split = this.input = new (0, _splitJs.Split)({
            channels: 2,
            context: this.context
        });
        this._midAdd = new (0, _addJs.Add)({
            context: this.context
        });
        this.mid = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._sideSubtract = new (0, _subtractJs.Subtract)({
            context: this.context
        });
        this.side = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._split.connect(this._midAdd, 0);
        this._split.connect(this._midAdd.addend, 1);
        this._split.connect(this._sideSubtract, 0);
        this._split.connect(this._sideSubtract.subtrahend, 1);
        this._midAdd.connect(this.mid);
        this._sideSubtract.connect(this.side);
    }
    dispose() {
        super.dispose();
        this.mid.dispose();
        this.side.dispose();
        this._midAdd.dispose();
        this._sideSubtract.dispose();
        this._split.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","./Split.js":"hPRgj","../../signal/Add.js":"jeoK8","../../signal/Multiply.js":"4C0VG","../../signal/Subtract.js":"cVmeJ","../../core/util/Defaults.js":"a9M5s","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8osXs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * MidSideMerge merges the mid and side signal after they've been separated by {@link MidSideSplit}
 * ```
 * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right
 * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right
 * ```
 * @category Component
 */ parcelHelpers.export(exports, "MidSideMerge", ()=>MidSideMerge);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _mergeJs = require("./Merge.js");
var _addJs = require("../../signal/Add.js");
var _multiplyJs = require("../../signal/Multiply.js");
var _subtractJs = require("../../signal/Subtract.js");
var _gainJs = require("../../core/context/Gain.js");
var _defaultsJs = require("../../core/util/Defaults.js");
class MidSideMerge extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(MidSideMerge.getDefaults(), arguments));
        this.name = "MidSideMerge";
        this.mid = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.side = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._left = new (0, _addJs.Add)({
            context: this.context
        });
        this._leftMult = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._right = new (0, _subtractJs.Subtract)({
            context: this.context
        });
        this._rightMult = new (0, _multiplyJs.Multiply)({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._merge = this.output = new (0, _mergeJs.Merge)({
            context: this.context
        });
        this.mid.fan(this._left);
        this.side.connect(this._left.addend);
        this.mid.connect(this._right);
        this.side.connect(this._right.subtrahend);
        this._left.connect(this._leftMult);
        this._right.connect(this._rightMult);
        this._leftMult.connect(this._merge, 0, 0);
        this._rightMult.connect(this._merge, 0, 1);
    }
    dispose() {
        super.dispose();
        this.mid.dispose();
        this.side.dispose();
        this._leftMult.dispose();
        this._rightMult.dispose();
        this._left.dispose();
        this._right.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","./Merge.js":"xBcDu","../../signal/Add.js":"jeoK8","../../signal/Multiply.js":"4C0VG","../../signal/Subtract.js":"cVmeJ","../../core/context/Gain.js":"kj68Y","../../core/util/Defaults.js":"a9M5s","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3TUHb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tremolo modulates the amplitude of an incoming signal using an {@link LFO}.
 * The effect is a stereo effect where the modulation phase is inverted in each channel.
 *
 * @example
 * // create a tremolo and start it's LFO
 * const tremolo = new Tone.Tremolo(9, 0.75).toDestination().start();
 * // route an oscillator through the tremolo and start it
 * const oscillator = new Tone.Oscillator().connect(tremolo).start();
 *
 * @category Effect
 */ parcelHelpers.export(exports, "Tremolo", ()=>Tremolo);
var _stereoEffectJs = require("./StereoEffect.js");
var _lfoJs = require("../source/oscillator/LFO.js");
var _gainJs = require("../core/context/Gain.js");
var _signalJs = require("../signal/Signal.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _interfaceJs = require("../core/util/Interface.js");
class Tremolo extends (0, _stereoEffectJs.StereoEffect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Tremolo.getDefaults(), arguments, [
            "frequency",
            "depth"
        ]);
        super(options);
        this.name = "Tremolo";
        this._lfoL = new (0, _lfoJs.LFO)({
            context: this.context,
            type: options.type,
            min: 1,
            max: 0
        });
        this._lfoR = new (0, _lfoJs.LFO)({
            context: this.context,
            type: options.type,
            min: 1,
            max: 0
        });
        this._amplitudeL = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._amplitudeR = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.frequency = new (0, _signalJs.Signal)({
            context: this.context,
            value: options.frequency,
            units: "frequency"
        });
        this.depth = new (0, _signalJs.Signal)({
            context: this.context,
            value: options.depth,
            units: "normalRange"
        });
        (0, _interfaceJs.readOnly)(this, [
            "frequency",
            "depth"
        ]);
        this.connectEffectLeft(this._amplitudeL);
        this.connectEffectRight(this._amplitudeR);
        this._lfoL.connect(this._amplitudeL.gain);
        this._lfoR.connect(this._amplitudeR.gain);
        this.frequency.fan(this._lfoL.frequency, this._lfoR.frequency);
        this.depth.fan(this._lfoR.amplitude, this._lfoL.amplitude);
        this.spread = options.spread;
    }
    static getDefaults() {
        return Object.assign((0, _stereoEffectJs.StereoEffect).getDefaults(), {
            frequency: 10,
            type: "sine",
            depth: 0.5,
            spread: 180
        });
    }
    /**
     * Start the tremolo.
     */ start(time) {
        this._lfoL.start(time);
        this._lfoR.start(time);
        return this;
    }
    /**
     * Stop the tremolo.
     */ stop(time) {
        this._lfoL.stop(time);
        this._lfoR.stop(time);
        return this;
    }
    /**
     * Sync the effect to the transport.
     */ sync() {
        this._lfoL.sync();
        this._lfoR.sync();
        this.context.transport.syncSignal(this.frequency);
        return this;
    }
    /**
     * Unsync the filter from the transport
     */ unsync() {
        this._lfoL.unsync();
        this._lfoR.unsync();
        this.context.transport.unsyncSignal(this.frequency);
        return this;
    }
    /**
     * The oscillator type.
     */ get type() {
        return this._lfoL.type;
    }
    set type(type) {
        this._lfoL.type = type;
        this._lfoR.type = type;
    }
    /**
     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.
     * When set to 180, LFO's will be panned hard left and right respectively.
     */ get spread() {
        return this._lfoR.phase - this._lfoL.phase; // 180
    }
    set spread(spread) {
        this._lfoL.phase = 90 - spread / 2;
        this._lfoR.phase = spread / 2 + 90;
    }
    dispose() {
        super.dispose();
        this._lfoL.dispose();
        this._lfoR.dispose();
        this._amplitudeL.dispose();
        this._amplitudeR.dispose();
        this.frequency.dispose();
        this.depth.dispose();
        return this;
    }
}

},{"./StereoEffect.js":"3INxk","../source/oscillator/LFO.js":"jsBJT","../core/context/Gain.js":"kj68Y","../signal/Signal.js":"980ri","../core/util/Defaults.js":"a9M5s","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"5uE99":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A Vibrato effect composed of a Tone.Delay and a Tone.LFO. The LFO
 * modulates the delayTime of the delay, causing the pitch to rise and fall.
 * @category Effect
 */ parcelHelpers.export(exports, "Vibrato", ()=>Vibrato);
var _effectJs = require("./Effect.js");
var _defaultsJs = require("../core/util/Defaults.js");
var _lfoJs = require("../source/oscillator/LFO.js");
var _delayJs = require("../core/context/Delay.js");
var _interfaceJs = require("../core/util/Interface.js");
class Vibrato extends (0, _effectJs.Effect) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Vibrato.getDefaults(), arguments, [
            "frequency",
            "depth"
        ]);
        super(options);
        this.name = "Vibrato";
        this._delayNode = new (0, _delayJs.Delay)({
            context: this.context,
            delayTime: 0,
            maxDelay: options.maxDelay
        });
        this._lfo = new (0, _lfoJs.LFO)({
            context: this.context,
            type: options.type,
            min: 0,
            max: options.maxDelay,
            frequency: options.frequency,
            phase: -90
        }).start().connect(this._delayNode.delayTime);
        this.frequency = this._lfo.frequency;
        this.depth = this._lfo.amplitude;
        this.depth.value = options.depth;
        (0, _interfaceJs.readOnly)(this, [
            "frequency",
            "depth"
        ]);
        this.effectSend.chain(this._delayNode, this.effectReturn);
    }
    static getDefaults() {
        return Object.assign((0, _effectJs.Effect).getDefaults(), {
            maxDelay: 0.005,
            frequency: 5,
            depth: 0.1,
            type: "sine"
        });
    }
    /**
     * Type of oscillator attached to the Vibrato.
     */ get type() {
        return this._lfo.type;
    }
    set type(type) {
        this._lfo.type = type;
    }
    dispose() {
        super.dispose();
        this._delayNode.dispose();
        this._lfo.dispose();
        this.frequency.dispose();
        this.depth.dispose();
        return this;
    }
}

},{"./Effect.js":"g3o0i","../core/util/Defaults.js":"a9M5s","../source/oscillator/LFO.js":"jsBJT","../core/context/Delay.js":"1qHQA","../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"ab9jt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _analyserJs = require("./analysis/Analyser.js");
parcelHelpers.exportAll(_analyserJs, exports);
var _meterJs = require("./analysis/Meter.js");
parcelHelpers.exportAll(_meterJs, exports);
var _fftJs = require("./analysis/FFT.js");
parcelHelpers.exportAll(_fftJs, exports);
var _dcmeterJs = require("./analysis/DCMeter.js");
parcelHelpers.exportAll(_dcmeterJs, exports);
var _waveformJs = require("./analysis/Waveform.js");
parcelHelpers.exportAll(_waveformJs, exports);
var _followerJs = require("./analysis/Follower.js");
parcelHelpers.exportAll(_followerJs, exports);
var _channelJs = require("./channel/Channel.js");
parcelHelpers.exportAll(_channelJs, exports);
var _crossFadeJs = require("./channel/CrossFade.js");
parcelHelpers.exportAll(_crossFadeJs, exports);
var _mergeJs = require("./channel/Merge.js");
parcelHelpers.exportAll(_mergeJs, exports);
var _midSideMergeJs = require("./channel/MidSideMerge.js");
parcelHelpers.exportAll(_midSideMergeJs, exports);
var _midSideSplitJs = require("./channel/MidSideSplit.js");
parcelHelpers.exportAll(_midSideSplitJs, exports);
var _monoJs = require("./channel/Mono.js");
parcelHelpers.exportAll(_monoJs, exports);
var _multibandSplitJs = require("./channel/MultibandSplit.js");
parcelHelpers.exportAll(_multibandSplitJs, exports);
var _pannerJs = require("./channel/Panner.js");
parcelHelpers.exportAll(_pannerJs, exports);
var _panner3DJs = require("./channel/Panner3D.js");
parcelHelpers.exportAll(_panner3DJs, exports);
var _panVolJs = require("./channel/PanVol.js");
parcelHelpers.exportAll(_panVolJs, exports);
var _recorderJs = require("./channel/Recorder.js");
parcelHelpers.exportAll(_recorderJs, exports);
var _soloJs = require("./channel/Solo.js");
parcelHelpers.exportAll(_soloJs, exports);
var _splitJs = require("./channel/Split.js");
parcelHelpers.exportAll(_splitJs, exports);
var _volumeJs = require("./channel/Volume.js");
parcelHelpers.exportAll(_volumeJs, exports);
var _compressorJs = require("./dynamics/Compressor.js");
parcelHelpers.exportAll(_compressorJs, exports);
var _gateJs = require("./dynamics/Gate.js");
parcelHelpers.exportAll(_gateJs, exports);
var _limiterJs = require("./dynamics/Limiter.js");
parcelHelpers.exportAll(_limiterJs, exports);
var _midSideCompressorJs = require("./dynamics/MidSideCompressor.js");
parcelHelpers.exportAll(_midSideCompressorJs, exports);
var _multibandCompressorJs = require("./dynamics/MultibandCompressor.js");
parcelHelpers.exportAll(_multibandCompressorJs, exports);
var _amplitudeEnvelopeJs = require("./envelope/AmplitudeEnvelope.js");
parcelHelpers.exportAll(_amplitudeEnvelopeJs, exports);
var _envelopeJs = require("./envelope/Envelope.js");
parcelHelpers.exportAll(_envelopeJs, exports);
var _frequencyEnvelopeJs = require("./envelope/FrequencyEnvelope.js");
parcelHelpers.exportAll(_frequencyEnvelopeJs, exports);
var _eq3Js = require("./filter/EQ3.js");
parcelHelpers.exportAll(_eq3Js, exports);
var _filterJs = require("./filter/Filter.js");
parcelHelpers.exportAll(_filterJs, exports);
var _onePoleFilterJs = require("./filter/OnePoleFilter.js");
parcelHelpers.exportAll(_onePoleFilterJs, exports);
var _feedbackCombFilterJs = require("./filter/FeedbackCombFilter.js");
parcelHelpers.exportAll(_feedbackCombFilterJs, exports);
var _lowpassCombFilterJs = require("./filter/LowpassCombFilter.js");
parcelHelpers.exportAll(_lowpassCombFilterJs, exports);
var _convolverJs = require("./filter/Convolver.js");
parcelHelpers.exportAll(_convolverJs, exports);
var _biquadFilterJs = require("./filter/BiquadFilter.js");
parcelHelpers.exportAll(_biquadFilterJs, exports);

},{"./analysis/Analyser.js":"8jdrD","./analysis/Meter.js":"cFFyu","./analysis/FFT.js":"gm2kK","./analysis/DCMeter.js":"iBePn","./analysis/Waveform.js":"9W1xG","./analysis/Follower.js":"9fpr2","./channel/Channel.js":"3fbfr","./channel/CrossFade.js":"cd1EQ","./channel/Merge.js":"xBcDu","./channel/MidSideMerge.js":"8osXs","./channel/MidSideSplit.js":"3oEnx","./channel/Mono.js":"8ZFOa","./channel/MultibandSplit.js":"6mTh7","./channel/Panner.js":"hwo91","./channel/Panner3D.js":"lKwbo","./channel/PanVol.js":"3rZ7o","./channel/Recorder.js":"8gzkS","./channel/Solo.js":"2cwbL","./channel/Split.js":"hPRgj","./channel/Volume.js":"7Ooeo","./dynamics/Compressor.js":"cHP1S","./dynamics/Gate.js":"hJSU2","./dynamics/Limiter.js":"jZwRO","./dynamics/MidSideCompressor.js":"aTPvB","./dynamics/MultibandCompressor.js":"dRDVG","./envelope/AmplitudeEnvelope.js":"l33WV","./envelope/Envelope.js":"cU1tT","./envelope/FrequencyEnvelope.js":"beAqg","./filter/EQ3.js":"gkvWP","./filter/Filter.js":"lel48","./filter/OnePoleFilter.js":"1CfWn","./filter/FeedbackCombFilter.js":"iMAnY","./filter/LowpassCombFilter.js":"01n6w","./filter/Convolver.js":"d2Ucy","./filter/BiquadFilter.js":"bJIpY","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8jdrD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the native Web Audio's [AnalyserNode](http://webaudio.github.io/web-audio-api/#idl-def-AnalyserNode).
 * Extracts FFT or Waveform data from the incoming signal.
 * @category Component
 */ parcelHelpers.export(exports, "Analyser", ()=>Analyser);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _splitJs = require("../channel/Split.js");
var _gainJs = require("../../core/context/Gain.js");
var _debugJs = require("../../core/util/Debug.js");
class Analyser extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Analyser.getDefaults(), arguments, [
            "type",
            "size"
        ]);
        super(options);
        this.name = "Analyser";
        /**
         * The analyser node.
         */ this._analysers = [];
        /**
         * The buffer that the FFT data is written to
         */ this._buffers = [];
        this.input = this.output = this._gain = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._split = new (0, _splitJs.Split)({
            context: this.context,
            channels: options.channels
        });
        this.input.connect(this._split);
        (0, _debugJs.assertRange)(options.channels, 1);
        // create the analysers
        for(let channel = 0; channel < options.channels; channel++){
            this._analysers[channel] = this.context.createAnalyser();
            this._split.connect(this._analysers[channel], channel, 0);
        }
        // set the values initially
        this.size = options.size;
        this.type = options.type;
        this.smoothing = options.smoothing;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            size: 1024,
            smoothing: 0.8,
            type: "fft",
            channels: 1
        });
    }
    /**
     * Run the analysis given the current settings. If {@link channels} = 1,
     * it will return a Float32Array. If {@link channels} > 1, it will
     * return an array of Float32Arrays where each index in the array
     * represents the analysis done on a channel.
     */ getValue() {
        this._analysers.forEach((analyser, index)=>{
            const buffer = this._buffers[index];
            if (this._type === "fft") analyser.getFloatFrequencyData(buffer);
            else if (this._type === "waveform") analyser.getFloatTimeDomainData(buffer);
        });
        if (this.channels === 1) return this._buffers[0];
        else return this._buffers;
    }
    /**
     * The size of analysis. This must be a power of two in the range 16 to 16384.
     */ get size() {
        return this._analysers[0].frequencyBinCount;
    }
    set size(size) {
        this._analysers.forEach((analyser, index)=>{
            analyser.fftSize = size * 2;
            this._buffers[index] = new Float32Array(size);
        });
    }
    /**
     * The number of channels the analyser does the analysis on. Channel
     * separation is done using {@link Split}
     */ get channels() {
        return this._analysers.length;
    }
    /**
     * The analysis function returned by analyser.getValue(), either "fft" or "waveform".
     */ get type() {
        return this._type;
    }
    set type(type) {
        (0, _debugJs.assert)(type === "waveform" || type === "fft", `Analyser: invalid type: ${type}`);
        this._type = type;
    }
    /**
     * 0 represents no time averaging with the last analysis frame.
     */ get smoothing() {
        return this._analysers[0].smoothingTimeConstant;
    }
    set smoothing(val) {
        this._analysers.forEach((a)=>a.smoothingTimeConstant = val);
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._analysers.forEach((a)=>a.disconnect());
        this._split.dispose();
        this._gain.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../channel/Split.js":"hPRgj","../../core/context/Gain.js":"kj68Y","../../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cFFyu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Meter gets the [RMS](https://en.wikipedia.org/wiki/Root_mean_square)
 * of an input signal. It can also get the raw value of the input signal.
 * Setting `normalRange` to `true` will covert the output to a range of
 * 0-1. See an example using a graphical display
 * [here](https://tonejs.github.io/examples/meter).
 * @see {@link DCMeter}.
 *
 * @example
 * const meter = new Tone.Meter();
 * const mic = new Tone.UserMedia();
 * mic.open();
 * // connect mic to the meter
 * mic.connect(meter);
 * // the current level of the mic
 * setInterval(() => console.log(meter.getValue()), 100);
 * @category Component
 */ parcelHelpers.export(exports, "Meter", ()=>Meter);
var _conversionsJs = require("../../core/type/Conversions.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _meterBaseJs = require("./MeterBase.js");
var _debugJs = require("../../core/util/Debug.js");
var _analyserJs = require("./Analyser.js");
class Meter extends (0, _meterBaseJs.MeterBase) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Meter.getDefaults(), arguments, [
            "smoothing"
        ]);
        super(options);
        this.name = "Meter";
        this.input = this.output = this._analyser = new (0, _analyserJs.Analyser)({
            context: this.context,
            size: 256,
            type: "waveform",
            channels: options.channelCount
        });
        this.smoothing = options.smoothing, this.normalRange = options.normalRange;
        this._rms = new Array(options.channelCount);
        this._rms.fill(0);
    }
    static getDefaults() {
        return Object.assign((0, _meterBaseJs.MeterBase).getDefaults(), {
            smoothing: 0.8,
            normalRange: false,
            channelCount: 1
        });
    }
    /**
     * Use {@link getValue} instead. For the previous getValue behavior, use DCMeter.
     * @deprecated
     */ getLevel() {
        (0, _debugJs.warn)("'getLevel' has been changed to 'getValue'");
        return this.getValue();
    }
    /**
     * Get the current value of the incoming signal.
     * Output is in decibels when {@link normalRange} is `false`.
     * If {@link channels} = 1, then the output is a single number
     * representing the value of the input signal. When {@link channels} > 1,
     * then each channel is returned as a value in a number array.
     */ getValue() {
        const aValues = this._analyser.getValue();
        const channelValues = this.channels === 1 ? [
            aValues
        ] : aValues;
        const vals = channelValues.map((values, index)=>{
            const totalSquared = values.reduce((total, current)=>total + current * current, 0);
            const rms = Math.sqrt(totalSquared / values.length);
            // the rms can only fall at the rate of the smoothing
            // but can jump up instantly
            this._rms[index] = Math.max(rms, this._rms[index] * this.smoothing);
            return this.normalRange ? this._rms[index] : (0, _conversionsJs.gainToDb)(this._rms[index]);
        });
        if (this.channels === 1) return vals[0];
        else return vals;
    }
    /**
     * The number of channels of analysis.
     */ get channels() {
        return this._analyser.channels;
    }
    dispose() {
        super.dispose();
        this._analyser.dispose();
        return this;
    }
}

},{"../../core/type/Conversions.js":"iww1u","../../core/util/Defaults.js":"a9M5s","./MeterBase.js":"9bM4A","../../core/util/Debug.js":"2lOIQ","./Analyser.js":"8jdrD","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9bM4A":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * The base class for Metering classes.
 */ parcelHelpers.export(exports, "MeterBase", ()=>MeterBase);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _analyserJs = require("./Analyser.js");
class MeterBase extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(MeterBase.getDefaults(), arguments));
        this.name = "MeterBase";
        this.input = this.output = this._analyser = new (0, _analyserJs.Analyser)({
            context: this.context,
            size: 256,
            type: "waveform"
        });
    }
    dispose() {
        super.dispose();
        this._analyser.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","./Analyser.js":"8jdrD","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gm2kK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Get the current frequency data of the connected audio source using a fast Fourier transform.
 * Read more about FFT algorithms on [Wikipedia] (https://en.wikipedia.org/wiki/Fast_Fourier_transform).
 * @category Component
 */ parcelHelpers.export(exports, "FFT", ()=>FFT);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _conversionsJs = require("../../core/type/Conversions.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _meterBaseJs = require("./MeterBase.js");
var _debugJs = require("../../core/util/Debug.js");
class FFT extends (0, _meterBaseJs.MeterBase) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(FFT.getDefaults(), arguments, [
            "size"
        ]);
        super(options);
        this.name = "FFT";
        this.normalRange = options.normalRange;
        this._analyser.type = "fft";
        this.size = options.size;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            normalRange: false,
            size: 1024,
            smoothing: 0.8
        });
    }
    /**
     * Gets the current frequency data from the connected audio source.
     * Returns the frequency data of length {@link size} as a Float32Array of decibel values.
     */ getValue() {
        const values = this._analyser.getValue();
        return values.map((v)=>this.normalRange ? (0, _conversionsJs.dbToGain)(v) : v);
    }
    /**
     * The size of analysis. This must be a power of two in the range 16 to 16384.
     * Determines the size of the array returned by {@link getValue} (i.e. the number of
     * frequency bins). Large FFT sizes may be costly to compute.
     */ get size() {
        return this._analyser.size;
    }
    set size(size) {
        this._analyser.size = size;
    }
    /**
     * 0 represents no time averaging with the last analysis frame.
     */ get smoothing() {
        return this._analyser.smoothing;
    }
    set smoothing(val) {
        this._analyser.smoothing = val;
    }
    /**
     * Returns the frequency value in hertz of each of the indices of the FFT's {@link getValue} response.
     * @example
     * const fft = new Tone.FFT(32);
     * console.log([0, 1, 2, 3, 4].map(index => fft.getFrequencyOfIndex(index)));
     */ getFrequencyOfIndex(index) {
        (0, _debugJs.assert)(0 <= index && index < this.size, `index must be greater than or equal to 0 and less than ${this.size}`);
        return index * this.context.sampleRate / (this.size * 2);
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/type/Conversions.js":"iww1u","../../core/util/Defaults.js":"a9M5s","./MeterBase.js":"9bM4A","../../core/util/Debug.js":"2lOIQ","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"iBePn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * DCMeter gets the raw value of the input signal at the current time.
 * @see {@link Meter}.
 *
 * @example
 * const meter = new Tone.DCMeter();
 * const mic = new Tone.UserMedia();
 * mic.open();
 * // connect mic to the meter
 * mic.connect(meter);
 * // the current level of the mic
 * const level = meter.getValue();
 * @category Component
 */ parcelHelpers.export(exports, "DCMeter", ()=>DCMeter);
var _defaultsJs = require("../../core/util/Defaults.js");
var _meterBaseJs = require("./MeterBase.js");
class DCMeter extends (0, _meterBaseJs.MeterBase) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(DCMeter.getDefaults(), arguments));
        this.name = "DCMeter";
        this._analyser.type = "waveform";
        this._analyser.size = 256;
    }
    /**
     * Get the signal value of the incoming signal
     */ getValue() {
        const value = this._analyser.getValue();
        return value[0];
    }
}

},{"../../core/util/Defaults.js":"a9M5s","./MeterBase.js":"9bM4A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"9W1xG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Get the current waveform data of the connected audio source.
 * @category Component
 */ parcelHelpers.export(exports, "Waveform", ()=>Waveform);
var _defaultsJs = require("../../core/util/Defaults.js");
var _meterBaseJs = require("./MeterBase.js");
class Waveform extends (0, _meterBaseJs.MeterBase) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Waveform.getDefaults(), arguments, [
            "size"
        ]);
        super(options);
        this.name = "Waveform";
        this._analyser.type = "waveform";
        this.size = options.size;
    }
    static getDefaults() {
        return Object.assign((0, _meterBaseJs.MeterBase).getDefaults(), {
            size: 1024
        });
    }
    /**
     * Return the waveform for the current time as a Float32Array where each value in the array
     * represents a sample in the waveform.
     */ getValue() {
        return this._analyser.getValue();
    }
    /**
     * The size of analysis. This must be a power of two in the range 16 to 16384.
     * Determines the size of the array returned by {@link getValue}.
     */ get size() {
        return this._analyser.size;
    }
    set size(size) {
        this._analyser.size = size;
    }
}

},{"../../core/util/Defaults.js":"a9M5s","./MeterBase.js":"9bM4A","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3fbfr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Channel provides a channel strip interface with volume, pan, solo and mute controls.
 * @see {@link PanVol} and {@link Solo}
 * @example
 * // pan the incoming signal left and drop the volume 12db
 * const channel = new Tone.Channel(-0.25, -12);
 * @category Component
 */ parcelHelpers.export(exports, "Channel", ()=>Channel);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _soloJs = require("./Solo.js");
var _panVolJs = require("./PanVol.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _gainJs = require("../../core/context/Gain.js");
class Channel extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Channel.getDefaults(), arguments, [
            "volume",
            "pan"
        ]);
        super(options);
        this.name = "Channel";
        this._solo = this.input = new (0, _soloJs.Solo)({
            solo: options.solo,
            context: this.context
        });
        this._panVol = this.output = new (0, _panVolJs.PanVol)({
            context: this.context,
            pan: options.pan,
            volume: options.volume,
            mute: options.mute,
            channelCount: options.channelCount
        });
        this.pan = this._panVol.pan;
        this.volume = this._panVol.volume;
        this._solo.connect(this._panVol);
        (0, _interfaceJs.readOnly)(this, [
            "pan",
            "volume"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            pan: 0,
            volume: 0,
            mute: false,
            solo: false,
            channelCount: 1
        });
    }
    /**
     * Solo/unsolo the channel. Soloing is only relative to other {@link Channel}s and {@link Solo} instances
     */ get solo() {
        return this._solo.solo;
    }
    set solo(solo) {
        this._solo.solo = solo;
    }
    /**
     * If the current instance is muted, i.e. another instance is soloed,
     * or the channel is muted
     */ get muted() {
        return this._solo.muted || this.mute;
    }
    /**
     * Mute/unmute the volume
     */ get mute() {
        return this._panVol.mute;
    }
    set mute(mute) {
        this._panVol.mute = mute;
    }
    /**
     * Get the gain node belonging to the bus name. Create it if
     * it doesn't exist
     * @param name The bus name
     */ _getBus(name) {
        if (!Channel.buses.has(name)) Channel.buses.set(name, new (0, _gainJs.Gain)({
            context: this.context
        }));
        return Channel.buses.get(name);
    }
    /**
     * Send audio to another channel using a string. `send` is a lot like
     * {@link connect}, except it uses a string instead of an object. This can
     * be useful in large applications to decouple sections since {@link send}
     * and {@link receive} can be invoked separately in order to connect an object
     * @param name The channel name to send the audio
     * @param volume The amount of the signal to send.
     * 	Defaults to 0db, i.e. send the entire signal
     * @returns Returns the gain node of this connection.
     */ send(name, volume = 0) {
        const bus = this._getBus(name);
        const sendKnob = new (0, _gainJs.Gain)({
            context: this.context,
            units: "decibels",
            gain: volume
        });
        this.connect(sendKnob);
        sendKnob.connect(bus);
        return sendKnob;
    }
    /**
     * Receive audio from a channel which was connected with {@link send}.
     * @param name The channel name to receive audio from.
     */ receive(name) {
        const bus = this._getBus(name);
        bus.connect(this);
        return this;
    }
    dispose() {
        super.dispose();
        this._panVol.dispose();
        this.pan.dispose();
        this.volume.dispose();
        this._solo.dispose();
        return this;
    }
}
/**
 * Store the send/receive channels by name.
 */ Channel.buses = new Map();

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","./Solo.js":"2cwbL","./PanVol.js":"3rZ7o","../../core/util/Interface.js":"hVOjA","../../core/context/Gain.js":"kj68Y","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"2cwbL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Solo lets you isolate a specific audio stream. When an instance is set to `solo=true`,
 * it will mute all other instances of Solo.
 * @example
 * const soloA = new Tone.Solo().toDestination();
 * const oscA = new Tone.Oscillator("C4", "sawtooth").connect(soloA);
 * const soloB = new Tone.Solo().toDestination();
 * const oscB = new Tone.Oscillator("E4", "square").connect(soloB);
 * soloA.solo = true;
 * // no audio will pass through soloB
 * @category Component
 */ parcelHelpers.export(exports, "Solo", ()=>Solo);
var _gainJs = require("../../core/context/Gain.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
class Solo extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Solo.getDefaults(), arguments, [
            "solo"
        ]);
        super(options);
        this.name = "Solo";
        this.input = this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        if (!Solo._allSolos.has(this.context)) Solo._allSolos.set(this.context, new Set());
        Solo._allSolos.get(this.context).add(this);
        // set initially
        this.solo = options.solo;
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            solo: false
        });
    }
    /**
     * Isolates this instance and mutes all other instances of Solo.
     * Only one instance can be soloed at a time. A soloed
     * instance will report `solo=false` when another instance is soloed.
     */ get solo() {
        return this._isSoloed();
    }
    set solo(solo) {
        if (solo) this._addSolo();
        else this._removeSolo();
        Solo._allSolos.get(this.context).forEach((instance)=>instance._updateSolo());
    }
    /**
     * If the current instance is muted, i.e. another instance is soloed
     */ get muted() {
        return this.input.gain.value === 0;
    }
    /**
     * Add this to the soloed array
     */ _addSolo() {
        if (!Solo._soloed.has(this.context)) Solo._soloed.set(this.context, new Set());
        Solo._soloed.get(this.context).add(this);
    }
    /**
     * Remove this from the soloed array
     */ _removeSolo() {
        if (Solo._soloed.has(this.context)) Solo._soloed.get(this.context).delete(this);
    }
    /**
     * Is this on the soloed array
     */ _isSoloed() {
        return Solo._soloed.has(this.context) && Solo._soloed.get(this.context).has(this);
    }
    /**
     * Returns true if no one is soloed
     */ _noSolos() {
        // either does not have any soloed added
        return !Solo._soloed.has(this.context) || // or has a solo set but doesn't include any items
        Solo._soloed.has(this.context) && Solo._soloed.get(this.context).size === 0;
    }
    /**
     * Solo the current instance and unsolo all other instances.
     */ _updateSolo() {
        if (this._isSoloed()) this.input.gain.value = 1;
        else if (this._noSolos()) // no one is soloed
        this.input.gain.value = 1;
        else this.input.gain.value = 0;
    }
    dispose() {
        super.dispose();
        Solo._allSolos.get(this.context).delete(this);
        this._removeSolo();
        return this;
    }
}
/**
 * Hold all of the solo'ed tracks belonging to a specific context
 */ Solo._allSolos = new Map();
/**
 * Hold the currently solo'ed instance(s)
 */ Solo._soloed = new Map();

},{"../../core/context/Gain.js":"kj68Y","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"3rZ7o":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PanVol is a Tone.Panner and Tone.Volume in one.
 * @example
 * // pan the incoming signal left and drop the volume
 * const panVol = new Tone.PanVol(-0.25, -12).toDestination();
 * const osc = new Tone.Oscillator().connect(panVol).start();
 * @category Component
 */ parcelHelpers.export(exports, "PanVol", ()=>PanVol);
var _interfaceJs = require("../../core/util/Interface.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _pannerJs = require("./Panner.js");
var _volumeJs = require("./Volume.js");
class PanVol extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(PanVol.getDefaults(), arguments, [
            "pan",
            "volume"
        ]);
        super(options);
        this.name = "PanVol";
        this._panner = this.input = new (0, _pannerJs.Panner)({
            context: this.context,
            pan: options.pan,
            channelCount: options.channelCount
        });
        this.pan = this._panner.pan;
        this._volume = this.output = new (0, _volumeJs.Volume)({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        // connections
        this._panner.connect(this._volume);
        this.mute = options.mute;
        (0, _interfaceJs.readOnly)(this, [
            "pan",
            "volume"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            mute: false,
            pan: 0,
            volume: 0,
            channelCount: 1
        });
    }
    /**
     * Mute/unmute the volume
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    dispose() {
        super.dispose();
        this._panner.dispose();
        this.pan.dispose();
        this._volume.dispose();
        this.volume.dispose();
        return this;
    }
}

},{"../../core/util/Interface.js":"hVOjA","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","./Panner.js":"hwo91","./Volume.js":"7Ooeo","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8ZFOa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Mono coerces the incoming mono or stereo signal into a mono signal
 * where both left and right channels have the same value. This can be useful
 * for [stereo imaging](https://en.wikipedia.org/wiki/Stereo_imaging).
 * @category Component
 */ parcelHelpers.export(exports, "Mono", ()=>Mono);
var _gainJs = require("../../core/context/Gain.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _mergeJs = require("./Merge.js");
class Mono extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        super((0, _defaultsJs.optionsFromArguments)(Mono.getDefaults(), arguments));
        this.name = "Mono";
        this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._merge = this.output = new (0, _mergeJs.Merge)({
            channels: 2,
            context: this.context
        });
        this.input.connect(this._merge, 0, 0);
        this.input.connect(this._merge, 0, 1);
    }
    dispose() {
        super.dispose();
        this._merge.dispose();
        this.input.dispose();
        return this;
    }
}

},{"../../core/context/Gain.js":"kj68Y","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","./Merge.js":"xBcDu","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"6mTh7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Split the incoming signal into three bands (low, mid, high)
 * with two crossover frequency controls.
 * ```
 *            +----------------------+
 *          +-> input < lowFrequency +------------------> low
 *          | +----------------------+
 *          |
 *          | +--------------------------------------+
 * input ---+-> lowFrequency < input < highFrequency +--> mid
 *          | +--------------------------------------+
 *          |
 *          | +-----------------------+
 *          +-> highFrequency < input +-----------------> high
 *            +-----------------------+
 * ```
 * @category Component
 */ parcelHelpers.export(exports, "MultibandSplit", ()=>MultibandSplit);
var _gainJs = require("../../core/context/Gain.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _signalJs = require("../../signal/Signal.js");
var _filterJs = require("../filter/Filter.js");
class MultibandSplit extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(MultibandSplit.getDefaults(), arguments, [
            "lowFrequency",
            "highFrequency"
        ]);
        super(options);
        this.name = "MultibandSplit";
        /**
         * the input
         */ this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        /**
         * no output node, use either low, mid or high outputs
         */ this.output = undefined;
        /**
         * The low band.
         */ this.low = new (0, _filterJs.Filter)({
            context: this.context,
            frequency: 0,
            type: "lowpass"
        });
        /**
         * the lower filter of the mid band
         */ this._lowMidFilter = new (0, _filterJs.Filter)({
            context: this.context,
            frequency: 0,
            type: "highpass"
        });
        /**
         * The mid band output.
         */ this.mid = new (0, _filterJs.Filter)({
            context: this.context,
            frequency: 0,
            type: "lowpass"
        });
        /**
         * The high band output.
         */ this.high = new (0, _filterJs.Filter)({
            context: this.context,
            frequency: 0,
            type: "highpass"
        });
        this._internalChannels = [
            this.low,
            this.mid,
            this.high
        ];
        this.lowFrequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency",
            value: options.lowFrequency
        });
        this.highFrequency = new (0, _signalJs.Signal)({
            context: this.context,
            units: "frequency",
            value: options.highFrequency
        });
        this.Q = new (0, _signalJs.Signal)({
            context: this.context,
            units: "positive",
            value: options.Q
        });
        this.input.fan(this.low, this.high);
        this.input.chain(this._lowMidFilter, this.mid);
        // the frequency control signal
        this.lowFrequency.fan(this.low.frequency, this._lowMidFilter.frequency);
        this.highFrequency.fan(this.mid.frequency, this.high.frequency);
        // the Q value
        this.Q.connect(this.low.Q);
        this.Q.connect(this._lowMidFilter.Q);
        this.Q.connect(this.mid.Q);
        this.Q.connect(this.high.Q);
        (0, _interfaceJs.readOnly)(this, [
            "high",
            "mid",
            "low",
            "highFrequency",
            "lowFrequency"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            Q: 1,
            highFrequency: 2500,
            lowFrequency: 400
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        (0, _interfaceJs.writable)(this, [
            "high",
            "mid",
            "low",
            "highFrequency",
            "lowFrequency"
        ]);
        this.low.dispose();
        this._lowMidFilter.dispose();
        this.mid.dispose();
        this.high.dispose();
        this.lowFrequency.dispose();
        this.highFrequency.dispose();
        this.Q.dispose();
        return this;
    }
}

},{"../../core/context/Gain.js":"kj68Y","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../../signal/Signal.js":"980ri","../filter/Filter.js":"lel48","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"lKwbo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A spatialized panner node which supports equalpower or HRTF panning.
 * @category Component
 */ parcelHelpers.export(exports, "Panner3D", ()=>Panner3D);
var _paramJs = require("../../core/context/Param.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _listenerJs = require("../../core/context/Listener.js");
class Panner3D extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Panner3D.getDefaults(), arguments, [
            "positionX",
            "positionY",
            "positionZ"
        ]);
        super(options);
        this.name = "Panner3D";
        this._panner = this.input = this.output = this.context.createPanner();
        // set some values
        this.panningModel = options.panningModel;
        this.maxDistance = options.maxDistance;
        this.distanceModel = options.distanceModel;
        this.coneOuterGain = options.coneOuterGain;
        this.coneOuterAngle = options.coneOuterAngle;
        this.coneInnerAngle = options.coneInnerAngle;
        this.refDistance = options.refDistance;
        this.rolloffFactor = options.rolloffFactor;
        this.positionX = new (0, _paramJs.Param)({
            context: this.context,
            param: this._panner.positionX,
            value: options.positionX
        });
        this.positionY = new (0, _paramJs.Param)({
            context: this.context,
            param: this._panner.positionY,
            value: options.positionY
        });
        this.positionZ = new (0, _paramJs.Param)({
            context: this.context,
            param: this._panner.positionZ,
            value: options.positionZ
        });
        this.orientationX = new (0, _paramJs.Param)({
            context: this.context,
            param: this._panner.orientationX,
            value: options.orientationX
        });
        this.orientationY = new (0, _paramJs.Param)({
            context: this.context,
            param: this._panner.orientationY,
            value: options.orientationY
        });
        this.orientationZ = new (0, _paramJs.Param)({
            context: this.context,
            param: this._panner.orientationZ,
            value: options.orientationZ
        });
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            coneInnerAngle: 360,
            coneOuterAngle: 360,
            coneOuterGain: 0,
            distanceModel: "inverse",
            maxDistance: 10000,
            orientationX: 0,
            orientationY: 0,
            orientationZ: 0,
            panningModel: "equalpower",
            positionX: 0,
            positionY: 0,
            positionZ: 0,
            refDistance: 1,
            rolloffFactor: 1
        });
    }
    /**
     * Sets the position of the source in 3d space.
     */ setPosition(x, y, z) {
        this.positionX.value = x;
        this.positionY.value = y;
        this.positionZ.value = z;
        return this;
    }
    /**
     * Sets the orientation of the source in 3d space.
     */ setOrientation(x, y, z) {
        this.orientationX.value = x;
        this.orientationY.value = y;
        this.orientationZ.value = z;
        return this;
    }
    /**
     * The panning model. Either "equalpower" or "HRTF".
     */ get panningModel() {
        return this._panner.panningModel;
    }
    set panningModel(val) {
        this._panner.panningModel = val;
    }
    /**
     * A reference distance for reducing volume as source move further from the listener
     */ get refDistance() {
        return this._panner.refDistance;
    }
    set refDistance(val) {
        this._panner.refDistance = val;
    }
    /**
     * Describes how quickly the volume is reduced as source moves away from listener.
     */ get rolloffFactor() {
        return this._panner.rolloffFactor;
    }
    set rolloffFactor(val) {
        this._panner.rolloffFactor = val;
    }
    /**
     * The distance model used by,  "linear", "inverse", or "exponential".
     */ get distanceModel() {
        return this._panner.distanceModel;
    }
    set distanceModel(val) {
        this._panner.distanceModel = val;
    }
    /**
     * The angle, in degrees, inside of which there will be no volume reduction
     */ get coneInnerAngle() {
        return this._panner.coneInnerAngle;
    }
    set coneInnerAngle(val) {
        this._panner.coneInnerAngle = val;
    }
    /**
     * The angle, in degrees, outside of which the volume will be reduced
     * to a constant value of coneOuterGain
     */ get coneOuterAngle() {
        return this._panner.coneOuterAngle;
    }
    set coneOuterAngle(val) {
        this._panner.coneOuterAngle = val;
    }
    /**
     * The gain outside of the coneOuterAngle
     */ get coneOuterGain() {
        return this._panner.coneOuterGain;
    }
    set coneOuterGain(val) {
        this._panner.coneOuterGain = val;
    }
    /**
     * The maximum distance between source and listener,
     * after which the volume will not be reduced any further.
     */ get maxDistance() {
        return this._panner.maxDistance;
    }
    set maxDistance(val) {
        this._panner.maxDistance = val;
    }
    dispose() {
        super.dispose();
        this._panner.disconnect();
        this.orientationX.dispose();
        this.orientationY.dispose();
        this.orientationZ.dispose();
        this.positionX.dispose();
        this.positionY.dispose();
        this.positionZ.dispose();
        return this;
    }
}

},{"../../core/context/Param.js":"5PVlJ","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/context/Listener.js":"beTyX","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"8gzkS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A wrapper around the MediaRecorder API. Unlike the rest of Tone.js, this module does not offer
 * any sample-accurate scheduling because it is not a feature of the MediaRecorder API.
 * This is only natively supported in Chrome and Firefox.
 * For a cross-browser shim, install (audio-recorder-polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].
 * @example
 * const recorder = new Tone.Recorder();
 * const synth = new Tone.Synth().connect(recorder);
 * // start recording
 * recorder.start();
 * // generate a few notes
 * synth.triggerAttackRelease("C3", 0.5);
 * synth.triggerAttackRelease("C4", 0.5, "+1");
 * synth.triggerAttackRelease("C5", 0.5, "+2");
 * // wait for the notes to end and stop the recording
 * setTimeout(async () => {
 * 	// the recorded audio is returned as a blob
 * 	const recording = await recorder.stop();
 * 	// download the recording by creating an anchor element and blob url
 * 	const url = URL.createObjectURL(recording);
 * 	const anchor = document.createElement("a");
 * 	anchor.download = "recording.webm";
 * 	anchor.href = url;
 * 	anchor.click();
 * }, 4000);
 * @category Component
 */ parcelHelpers.export(exports, "Recorder", ()=>Recorder);
var _tslib = require("tslib");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _gainJs = require("../../core/context/Gain.js");
var _debugJs = require("../../core/util/Debug.js");
var _audioContextJs = require("../../core/context/AudioContext.js");
var _defaultsJs = require("../../core/util/Defaults.js");
class Recorder extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Recorder.getDefaults(), arguments);
        super(options);
        this.name = "Recorder";
        this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        (0, _debugJs.assert)(Recorder.supported, "Media Recorder API is not available");
        this._stream = this.context.createMediaStreamDestination();
        this.input.connect(this._stream);
        this._recorder = new MediaRecorder(this._stream.stream, {
            mimeType: options.mimeType
        });
    }
    static getDefaults() {
        return (0, _toneAudioNodeJs.ToneAudioNode).getDefaults();
    }
    /**
     * The mime type is the format that the audio is encoded in. For Chrome
     * that is typically webm encoded as "vorbis".
     */ get mimeType() {
        return this._recorder.mimeType;
    }
    /**
     * Test if your platform supports the Media Recorder API. If it's not available,
     * try installing this (polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].
     */ static get supported() {
        return (0, _audioContextJs.theWindow) !== null && Reflect.has((0, _audioContextJs.theWindow), "MediaRecorder");
    }
    /**
     * Get the playback state of the Recorder, either "started", "stopped" or "paused"
     */ get state() {
        if (this._recorder.state === "inactive") return "stopped";
        else if (this._recorder.state === "paused") return "paused";
        else return "started";
    }
    /**
     * Start the Recorder. Returns a promise which resolves
     * when the recorder has started.
     */ start() {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            (0, _debugJs.assert)(this.state !== "started", "Recorder is already started");
            const startPromise = new Promise((done)=>{
                const handleStart = ()=>{
                    this._recorder.removeEventListener("start", handleStart, false);
                    done();
                };
                this._recorder.addEventListener("start", handleStart, false);
            });
            this._recorder.start();
            return yield startPromise;
        });
    }
    /**
     * Stop the recorder. Returns a promise with the recorded content until this point
     * encoded as {@link mimeType}
     */ stop() {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            (0, _debugJs.assert)(this.state !== "stopped", "Recorder is not started");
            const dataPromise = new Promise((done)=>{
                const handleData = (e)=>{
                    this._recorder.removeEventListener("dataavailable", handleData, false);
                    done(e.data);
                };
                this._recorder.addEventListener("dataavailable", handleData, false);
            });
            this._recorder.stop();
            return yield dataPromise;
        });
    }
    /**
     * Pause the recorder
     */ pause() {
        (0, _debugJs.assert)(this.state === "started", "Recorder must be started");
        this._recorder.pause();
        return this;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this._stream.disconnect();
        return this;
    }
}

},{"tslib":"lRdW5","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/context/Gain.js":"kj68Y","../../core/util/Debug.js":"2lOIQ","../../core/context/AudioContext.js":"1NjF0","../../core/util/Defaults.js":"a9M5s","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"cHP1S":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Compressor is a thin wrapper around the Web Audio
 * [DynamicsCompressorNode](http://webaudio.github.io/web-audio-api/#the-dynamicscompressornode-interface).
 * Compression reduces the volume of loud sounds or amplifies quiet sounds
 * by narrowing or "compressing" an audio signal's dynamic range.
 * Read more on [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_range_compression).
 * @example
 * const comp = new Tone.Compressor(-30, 3);
 * @category Component
 */ parcelHelpers.export(exports, "Compressor", ()=>Compressor);
var _paramJs = require("../../core/context/Param.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
class Compressor extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Compressor.getDefaults(), arguments, [
            "threshold",
            "ratio"
        ]);
        super(options);
        this.name = "Compressor";
        /**
         * the compressor node
         */ this._compressor = this.context.createDynamicsCompressor();
        this.input = this._compressor;
        this.output = this._compressor;
        this.threshold = new (0, _paramJs.Param)({
            minValue: this._compressor.threshold.minValue,
            maxValue: this._compressor.threshold.maxValue,
            context: this.context,
            convert: false,
            param: this._compressor.threshold,
            units: "decibels",
            value: options.threshold
        });
        this.attack = new (0, _paramJs.Param)({
            minValue: this._compressor.attack.minValue,
            maxValue: this._compressor.attack.maxValue,
            context: this.context,
            param: this._compressor.attack,
            units: "time",
            value: options.attack
        });
        this.release = new (0, _paramJs.Param)({
            minValue: this._compressor.release.minValue,
            maxValue: this._compressor.release.maxValue,
            context: this.context,
            param: this._compressor.release,
            units: "time",
            value: options.release
        });
        this.knee = new (0, _paramJs.Param)({
            minValue: this._compressor.knee.minValue,
            maxValue: this._compressor.knee.maxValue,
            context: this.context,
            convert: false,
            param: this._compressor.knee,
            units: "decibels",
            value: options.knee
        });
        this.ratio = new (0, _paramJs.Param)({
            minValue: this._compressor.ratio.minValue,
            maxValue: this._compressor.ratio.maxValue,
            context: this.context,
            convert: false,
            param: this._compressor.ratio,
            units: "positive",
            value: options.ratio
        });
        // set the defaults
        (0, _interfaceJs.readOnly)(this, [
            "knee",
            "release",
            "attack",
            "ratio",
            "threshold"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            attack: 0.003,
            knee: 30,
            ratio: 12,
            release: 0.25,
            threshold: -24
        });
    }
    /**
     * A read-only decibel value for metering purposes, representing the current amount of gain
     * reduction that the compressor is applying to the signal. If fed no signal the value will be 0 (no gain reduction).
     */ get reduction() {
        return this._compressor.reduction;
    }
    dispose() {
        super.dispose();
        this._compressor.disconnect();
        this.attack.dispose();
        this.release.dispose();
        this.threshold.dispose();
        this.ratio.dispose();
        this.knee.dispose();
        return this;
    }
}

},{"../../core/context/Param.js":"5PVlJ","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"hJSU2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Gate only passes a signal through when the incoming
 * signal exceeds a specified threshold. It uses {@link Follower} to follow the ampltiude
 * of the incoming signal and compares it to the {@link threshold} value using {@link GreaterThan}.
 *
 * @example
 * const gate = new Tone.Gate(-30, 0.2).toDestination();
 * const mic = new Tone.UserMedia().connect(gate);
 * // the gate will only pass through the incoming
 * // signal when it's louder than -30db
 * @category Component
 */ parcelHelpers.export(exports, "Gate", ()=>Gate);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _greaterThanJs = require("../../signal/GreaterThan.js");
var _gainJs = require("../../core/context/Gain.js");
var _followerJs = require("../analysis/Follower.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _conversionsJs = require("../../core/type/Conversions.js");
class Gate extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Gate.getDefaults(), arguments, [
            "threshold",
            "smoothing"
        ]);
        super(options);
        this.name = "Gate";
        this._follower = new (0, _followerJs.Follower)({
            context: this.context,
            smoothing: options.smoothing
        });
        this._gt = new (0, _greaterThanJs.GreaterThan)({
            context: this.context,
            value: (0, _conversionsJs.dbToGain)(options.threshold)
        });
        this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._gate = this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        // connections
        this.input.connect(this._gate);
        // the control signal
        this.input.chain(this._follower, this._gt, this._gate.gain);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            smoothing: 0.1,
            threshold: -40
        });
    }
    /**
     * The threshold of the gate in decibels
     */ get threshold() {
        return (0, _conversionsJs.gainToDb)(this._gt.value);
    }
    set threshold(thresh) {
        this._gt.value = (0, _conversionsJs.dbToGain)(thresh);
    }
    /**
     * The attack/decay speed of the gate.
     * @see {@link Follower.smoothing}
     */ get smoothing() {
        return this._follower.smoothing;
    }
    set smoothing(smoothingTime) {
        this._follower.smoothing = smoothingTime;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this._follower.dispose();
        this._gt.dispose();
        this._gate.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../signal/GreaterThan.js":"gPdXT","../../core/context/Gain.js":"kj68Y","../analysis/Follower.js":"9fpr2","../../core/util/Defaults.js":"a9M5s","../../core/type/Conversions.js":"iww1u","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"jZwRO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Limiter will limit the loudness of an incoming signal.
 * Under the hood it's composed of a {@link Compressor} with a fast attack
 * and release and max compression ratio.
 *
 * @example
 * const limiter = new Tone.Limiter(-20).toDestination();
 * const oscillator = new Tone.Oscillator().connect(limiter);
 * oscillator.start();
 * @category Component
 */ parcelHelpers.export(exports, "Limiter", ()=>Limiter);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _compressorJs = require("./Compressor.js");
var _interfaceJs = require("../../core/util/Interface.js");
class Limiter extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Limiter.getDefaults(), arguments, [
            "threshold"
        ]);
        super(options);
        this.name = "Limiter";
        this._compressor = this.input = this.output = new (0, _compressorJs.Compressor)({
            context: this.context,
            ratio: 20,
            attack: 0.003,
            release: 0.01,
            threshold: options.threshold
        });
        this.threshold = this._compressor.threshold;
        (0, _interfaceJs.readOnly)(this, "threshold");
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            threshold: -12
        });
    }
    /**
     * A read-only decibel value for metering purposes, representing the current amount of gain
     * reduction that the compressor is applying to the signal.
     */ get reduction() {
        return this._compressor.reduction;
    }
    dispose() {
        super.dispose();
        this._compressor.dispose();
        this.threshold.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","./Compressor.js":"cHP1S","../../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"aTPvB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * MidSideCompressor applies two different compressors to the {@link mid}
 * and {@link side} signal components of the input.
 * @see {@link MidSideSplit} and {@link MidSideMerge}.
 * @category Component
 */ parcelHelpers.export(exports, "MidSideCompressor", ()=>MidSideCompressor);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _compressorJs = require("./Compressor.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _midSideSplitJs = require("../channel/MidSideSplit.js");
var _midSideMergeJs = require("../channel/MidSideMerge.js");
var _interfaceJs = require("../../core/util/Interface.js");
class MidSideCompressor extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(MidSideCompressor.getDefaults(), arguments);
        super(options);
        this.name = "MidSideCompressor";
        this._midSideSplit = this.input = new (0, _midSideSplitJs.MidSideSplit)({
            context: this.context
        });
        this._midSideMerge = this.output = new (0, _midSideMergeJs.MidSideMerge)({
            context: this.context
        });
        this.mid = new (0, _compressorJs.Compressor)(Object.assign(options.mid, {
            context: this.context
        }));
        this.side = new (0, _compressorJs.Compressor)(Object.assign(options.side, {
            context: this.context
        }));
        this._midSideSplit.mid.chain(this.mid, this._midSideMerge.mid);
        this._midSideSplit.side.chain(this.side, this._midSideMerge.side);
        (0, _interfaceJs.readOnly)(this, [
            "mid",
            "side"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            mid: {
                ratio: 3,
                threshold: -24,
                release: 0.03,
                attack: 0.02,
                knee: 16
            },
            side: {
                ratio: 6,
                threshold: -30,
                release: 0.25,
                attack: 0.03,
                knee: 10
            }
        });
    }
    dispose() {
        super.dispose();
        this.mid.dispose();
        this.side.dispose();
        this._midSideSplit.dispose();
        this._midSideMerge.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","./Compressor.js":"cHP1S","../../core/util/Defaults.js":"a9M5s","../channel/MidSideSplit.js":"3oEnx","../channel/MidSideMerge.js":"8osXs","../../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"dRDVG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A compressor with separate controls over low/mid/high dynamics.
 * @see {@link Compressor} and {@link MultibandSplit}
 *
 * @example
 * const multiband = new Tone.MultibandCompressor({
 * 	lowFrequency: 200,
 * 	highFrequency: 1300,
 * 	low: {
 * 		threshold: -12
 * 	}
 * });
 * @category Component
 */ parcelHelpers.export(exports, "MultibandCompressor", ()=>MultibandCompressor);
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _compressorJs = require("./Compressor.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _multibandSplitJs = require("../channel/MultibandSplit.js");
var _gainJs = require("../../core/context/Gain.js");
class MultibandCompressor extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(MultibandCompressor.getDefaults(), arguments);
        super(options);
        this.name = "MultibandCompressor";
        this._splitter = this.input = new (0, _multibandSplitJs.MultibandSplit)({
            context: this.context,
            lowFrequency: options.lowFrequency,
            highFrequency: options.highFrequency
        });
        this.lowFrequency = this._splitter.lowFrequency;
        this.highFrequency = this._splitter.highFrequency;
        this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.low = new (0, _compressorJs.Compressor)(Object.assign(options.low, {
            context: this.context
        }));
        this.mid = new (0, _compressorJs.Compressor)(Object.assign(options.mid, {
            context: this.context
        }));
        this.high = new (0, _compressorJs.Compressor)(Object.assign(options.high, {
            context: this.context
        }));
        // connect the compressor
        this._splitter.low.chain(this.low, this.output);
        this._splitter.mid.chain(this.mid, this.output);
        this._splitter.high.chain(this.high, this.output);
        (0, _interfaceJs.readOnly)(this, [
            "high",
            "mid",
            "low",
            "highFrequency",
            "lowFrequency"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            lowFrequency: 250,
            highFrequency: 2000,
            low: {
                ratio: 6,
                threshold: -30,
                release: 0.25,
                attack: 0.03,
                knee: 10
            },
            mid: {
                ratio: 3,
                threshold: -24,
                release: 0.03,
                attack: 0.02,
                knee: 16
            },
            high: {
                ratio: 3,
                threshold: -24,
                release: 0.03,
                attack: 0.02,
                knee: 16
            }
        });
    }
    dispose() {
        super.dispose();
        this._splitter.dispose();
        this.low.dispose();
        this.mid.dispose();
        this.high.dispose();
        this.output.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode.js":"kZ3Kj","./Compressor.js":"cHP1S","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../channel/MultibandSplit.js":"6mTh7","../../core/context/Gain.js":"kj68Y","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"gkvWP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * EQ3 provides 3 equalizer bins: Low/Mid/High.
 * @category Component
 */ parcelHelpers.export(exports, "EQ3", ()=>EQ3);
var _gainJs = require("../../core/context/Gain.js");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _interfaceJs = require("../../core/util/Interface.js");
var _multibandSplitJs = require("../channel/MultibandSplit.js");
class EQ3 extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(EQ3.getDefaults(), arguments, [
            "low",
            "mid",
            "high"
        ]);
        super(options);
        this.name = "EQ3";
        /**
         * the output
         */ this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        this._internalChannels = [];
        this.input = this._multibandSplit = new (0, _multibandSplitJs.MultibandSplit)({
            context: this.context,
            highFrequency: options.highFrequency,
            lowFrequency: options.lowFrequency
        });
        this._lowGain = new (0, _gainJs.Gain)({
            context: this.context,
            gain: options.low,
            units: "decibels"
        });
        this._midGain = new (0, _gainJs.Gain)({
            context: this.context,
            gain: options.mid,
            units: "decibels"
        });
        this._highGain = new (0, _gainJs.Gain)({
            context: this.context,
            gain: options.high,
            units: "decibels"
        });
        this.low = this._lowGain.gain;
        this.mid = this._midGain.gain;
        this.high = this._highGain.gain;
        this.Q = this._multibandSplit.Q;
        this.lowFrequency = this._multibandSplit.lowFrequency;
        this.highFrequency = this._multibandSplit.highFrequency;
        // the frequency bands
        this._multibandSplit.low.chain(this._lowGain, this.output);
        this._multibandSplit.mid.chain(this._midGain, this.output);
        this._multibandSplit.high.chain(this._highGain, this.output);
        (0, _interfaceJs.readOnly)(this, [
            "low",
            "mid",
            "high",
            "lowFrequency",
            "highFrequency"
        ]);
        this._internalChannels = [
            this._multibandSplit
        ];
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            high: 0,
            highFrequency: 2500,
            low: 0,
            lowFrequency: 400,
            mid: 0
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        (0, _interfaceJs.writable)(this, [
            "low",
            "mid",
            "high",
            "lowFrequency",
            "highFrequency"
        ]);
        this._multibandSplit.dispose();
        this.lowFrequency.dispose();
        this.highFrequency.dispose();
        this._lowGain.dispose();
        this._midGain.dispose();
        this._highGain.dispose();
        this.low.dispose();
        this.mid.dispose();
        this.high.dispose();
        this.Q.dispose();
        return this;
    }
}

},{"../../core/context/Gain.js":"kj68Y","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/util/Defaults.js":"a9M5s","../../core/util/Interface.js":"hVOjA","../channel/MultibandSplit.js":"6mTh7","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"d2Ucy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Convolver is a wrapper around the Native Web Audio
 * [ConvolverNode](http://webaudio.github.io/web-audio-api/#the-convolvernode-interface).
 * Convolution is useful for reverb and filter emulation. Read more about convolution reverb on
 * [Wikipedia](https://en.wikipedia.org/wiki/Convolution_reverb).
 *
 * @example
 * // initializing the convolver with an impulse response
 * const convolver = new Tone.Convolver("./path/to/ir.wav").toDestination();
 * @category Component
 */ parcelHelpers.export(exports, "Convolver", ()=>Convolver);
var _tslib = require("tslib");
var _toneAudioNodeJs = require("../../core/context/ToneAudioNode.js");
var _toneAudioBufferJs = require("../../core/context/ToneAudioBuffer.js");
var _defaultsJs = require("../../core/util/Defaults.js");
var _gainJs = require("../../core/context/Gain.js");
var _interfaceJs = require("../../core/util/Interface.js");
class Convolver extends (0, _toneAudioNodeJs.ToneAudioNode) {
    constructor(){
        const options = (0, _defaultsJs.optionsFromArguments)(Convolver.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        super(options);
        this.name = "Convolver";
        /**
         * The native ConvolverNode
         */ this._convolver = this.context.createConvolver();
        this._buffer = new (0, _toneAudioBufferJs.ToneAudioBuffer)(options.url, (buffer)=>{
            this.buffer = buffer;
            options.onload();
        });
        this.input = new (0, _gainJs.Gain)({
            context: this.context
        });
        this.output = new (0, _gainJs.Gain)({
            context: this.context
        });
        // set if it's already loaded, set it immediately
        if (this._buffer.loaded) this.buffer = this._buffer;
        // initially set normalization
        this.normalize = options.normalize;
        // connect it up
        this.input.chain(this._convolver, this.output);
    }
    static getDefaults() {
        return Object.assign((0, _toneAudioNodeJs.ToneAudioNode).getDefaults(), {
            normalize: true,
            onload: (0, _interfaceJs.noOp)
        });
    }
    /**
     * Load an impulse response url as an audio buffer.
     * Decodes the audio asynchronously and invokes
     * the callback once the audio buffer loads.
     * @param url The url of the buffer to load. filetype support depends on the browser.
     */ load(url) {
        return (0, _tslib.__awaiter)(this, void 0, void 0, function*() {
            this.buffer = yield this._buffer.load(url);
        });
    }
    /**
     * The convolver's buffer
     */ get buffer() {
        if (this._buffer.length) return this._buffer;
        else return null;
    }
    set buffer(buffer) {
        if (buffer) this._buffer.set(buffer);
        // if it's already got a buffer, create a new one
        if (this._convolver.buffer) {
            // disconnect the old one
            this.input.disconnect();
            this._convolver.disconnect();
            // create and connect a new one
            this._convolver = this.context.createConvolver();
            this.input.chain(this._convolver, this.output);
        }
        const buff = this._buffer.get();
        this._convolver.buffer = buff ? buff : null;
    }
    /**
     * The normalize property of the ConvolverNode interface is a boolean that
     * controls whether the impulse response from the buffer will be scaled by
     * an equal-power normalization when the buffer attribute is set, or not.
     */ get normalize() {
        return this._convolver.normalize;
    }
    set normalize(norm) {
        this._convolver.normalize = norm;
    }
    dispose() {
        super.dispose();
        this._buffer.dispose();
        this._convolver.disconnect();
        return this;
    }
}

},{"tslib":"lRdW5","../../core/context/ToneAudioNode.js":"kZ3Kj","../../core/context/ToneAudioBuffer.js":"8aSPC","../../core/util/Defaults.js":"a9M5s","../../core/context/Gain.js":"kj68Y","../../core/util/Interface.js":"hVOjA","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}],"7mqRv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "OrbitControls", ()=>OrbitControls);
var _three = require("three");
// OrbitControls performs orbiting, dollying (zooming), and panning.
// Unlike TrackballControls, it maintains the "up" direction object.up (+Y by default).
//
//    Orbit - left mouse / touch: one-finger move
//    Zoom - middle mouse, or mousewheel / touch: two-finger spread or squish
//    Pan - right mouse, or left mouse + ctrl/meta/shiftKey, or arrow keys / touch: two-finger move
const _changeEvent = {
    type: "change"
};
const _startEvent = {
    type: "start"
};
const _endEvent = {
    type: "end"
};
const _ray = new (0, _three.Ray)();
const _plane = new (0, _three.Plane)();
const TILT_LIMIT = Math.cos(70 * (0, _three.MathUtils).DEG2RAD);
class OrbitControls extends (0, _three.EventDispatcher) {
    constructor(object, domElement){
        super();
        this.object = object;
        this.domElement = domElement;
        this.domElement.style.touchAction = "none"; // disable touch scroll
        // Set to false to disable this control
        this.enabled = true;
        // "target" sets the location of focus, where the object orbits around
        this.target = new (0, _three.Vector3)();
        // Sets the 3D cursor (similar to Blender), from which the maxTargetRadius takes effect
        this.cursor = new (0, _three.Vector3)();
        // How far you can dolly in and out ( PerspectiveCamera only )
        this.minDistance = 0;
        this.maxDistance = Infinity;
        // How far you can zoom in and out ( OrthographicCamera only )
        this.minZoom = 0;
        this.maxZoom = Infinity;
        // Limit camera target within a spherical area around the cursor
        this.minTargetRadius = 0;
        this.maxTargetRadius = Infinity;
        // How far you can orbit vertically, upper and lower limits.
        // Range is 0 to Math.PI radians.
        this.minPolarAngle = 0; // radians
        this.maxPolarAngle = Math.PI; // radians
        // How far you can orbit horizontally, upper and lower limits.
        // If set, the interval [ min, max ] must be a sub-interval of [ - 2 PI, 2 PI ], with ( max - min < 2 PI )
        this.minAzimuthAngle = -Infinity; // radians
        this.maxAzimuthAngle = Infinity; // radians
        // Set to true to enable damping (inertia)
        // If damping is enabled, you must call controls.update() in your animation loop
        this.enableDamping = false;
        this.dampingFactor = 0.05;
        // This option actually enables dollying in and out; left as "zoom" for backwards compatibility.
        // Set to false to disable zooming
        this.enableZoom = true;
        this.zoomSpeed = 1.0;
        // Set to false to disable rotating
        this.enableRotate = true;
        this.rotateSpeed = 1.0;
        // Set to false to disable panning
        this.enablePan = true;
        this.panSpeed = 1.0;
        this.screenSpacePanning = true; // if false, pan orthogonal to world-space direction camera.up
        this.keyPanSpeed = 7.0; // pixels moved per arrow key push
        this.zoomToCursor = false;
        // Set to true to automatically rotate around the target
        // If auto-rotate is enabled, you must call controls.update() in your animation loop
        this.autoRotate = false;
        this.autoRotateSpeed = 2.0; // 30 seconds per orbit when fps is 60
        // The four arrow keys
        this.keys = {
            LEFT: "ArrowLeft",
            UP: "ArrowUp",
            RIGHT: "ArrowRight",
            BOTTOM: "ArrowDown"
        };
        // Mouse buttons
        this.mouseButtons = {
            LEFT: (0, _three.MOUSE).ROTATE,
            MIDDLE: (0, _three.MOUSE).DOLLY,
            RIGHT: (0, _three.MOUSE).PAN
        };
        // Touch fingers
        this.touches = {
            ONE: (0, _three.TOUCH).ROTATE,
            TWO: (0, _three.TOUCH).DOLLY_PAN
        };
        // for reset
        this.target0 = this.target.clone();
        this.position0 = this.object.position.clone();
        this.zoom0 = this.object.zoom;
        // the target DOM element for key events
        this._domElementKeyEvents = null;
        //
        // public methods
        //
        this.getPolarAngle = function() {
            return spherical.phi;
        };
        this.getAzimuthalAngle = function() {
            return spherical.theta;
        };
        this.getDistance = function() {
            return this.object.position.distanceTo(this.target);
        };
        this.listenToKeyEvents = function(domElement) {
            domElement.addEventListener("keydown", onKeyDown);
            this._domElementKeyEvents = domElement;
        };
        this.stopListenToKeyEvents = function() {
            this._domElementKeyEvents.removeEventListener("keydown", onKeyDown);
            this._domElementKeyEvents = null;
        };
        this.saveState = function() {
            scope.target0.copy(scope.target);
            scope.position0.copy(scope.object.position);
            scope.zoom0 = scope.object.zoom;
        };
        this.reset = function() {
            scope.target.copy(scope.target0);
            scope.object.position.copy(scope.position0);
            scope.object.zoom = scope.zoom0;
            scope.object.updateProjectionMatrix();
            scope.dispatchEvent(_changeEvent);
            scope.update();
            state = STATE.NONE;
        };
        // this method is exposed, but perhaps it would be better if we can make it private...
        this.update = function() {
            const offset = new (0, _three.Vector3)();
            // so camera.up is the orbit axis
            const quat = new (0, _three.Quaternion)().setFromUnitVectors(object.up, new (0, _three.Vector3)(0, 1, 0));
            const quatInverse = quat.clone().invert();
            const lastPosition = new (0, _three.Vector3)();
            const lastQuaternion = new (0, _three.Quaternion)();
            const lastTargetPosition = new (0, _three.Vector3)();
            const twoPI = 2 * Math.PI;
            return function update(deltaTime = null) {
                const position = scope.object.position;
                offset.copy(position).sub(scope.target);
                // rotate offset to "y-axis-is-up" space
                offset.applyQuaternion(quat);
                // angle from z-axis around y-axis
                spherical.setFromVector3(offset);
                if (scope.autoRotate && state === STATE.NONE) rotateLeft(getAutoRotationAngle(deltaTime));
                if (scope.enableDamping) {
                    spherical.theta += sphericalDelta.theta * scope.dampingFactor;
                    spherical.phi += sphericalDelta.phi * scope.dampingFactor;
                } else {
                    spherical.theta += sphericalDelta.theta;
                    spherical.phi += sphericalDelta.phi;
                }
                // restrict theta to be between desired limits
                let min = scope.minAzimuthAngle;
                let max = scope.maxAzimuthAngle;
                if (isFinite(min) && isFinite(max)) {
                    if (min < -Math.PI) min += twoPI;
                    else if (min > Math.PI) min -= twoPI;
                    if (max < -Math.PI) max += twoPI;
                    else if (max > Math.PI) max -= twoPI;
                    if (min <= max) spherical.theta = Math.max(min, Math.min(max, spherical.theta));
                    else spherical.theta = spherical.theta > (min + max) / 2 ? Math.max(min, spherical.theta) : Math.min(max, spherical.theta);
                }
                // restrict phi to be between desired limits
                spherical.phi = Math.max(scope.minPolarAngle, Math.min(scope.maxPolarAngle, spherical.phi));
                spherical.makeSafe();
                // move target to panned location
                if (scope.enableDamping === true) scope.target.addScaledVector(panOffset, scope.dampingFactor);
                else scope.target.add(panOffset);
                // Limit the target distance from the cursor to create a sphere around the center of interest
                scope.target.sub(scope.cursor);
                scope.target.clampLength(scope.minTargetRadius, scope.maxTargetRadius);
                scope.target.add(scope.cursor);
                let zoomChanged = false;
                // adjust the camera position based on zoom only if we're not zooming to the cursor or if it's an ortho camera
                // we adjust zoom later in these cases
                if (scope.zoomToCursor && performCursorZoom || scope.object.isOrthographicCamera) spherical.radius = clampDistance(spherical.radius);
                else {
                    const prevRadius = spherical.radius;
                    spherical.radius = clampDistance(spherical.radius * scale);
                    zoomChanged = prevRadius != spherical.radius;
                }
                offset.setFromSpherical(spherical);
                // rotate offset back to "camera-up-vector-is-up" space
                offset.applyQuaternion(quatInverse);
                position.copy(scope.target).add(offset);
                scope.object.lookAt(scope.target);
                if (scope.enableDamping === true) {
                    sphericalDelta.theta *= 1 - scope.dampingFactor;
                    sphericalDelta.phi *= 1 - scope.dampingFactor;
                    panOffset.multiplyScalar(1 - scope.dampingFactor);
                } else {
                    sphericalDelta.set(0, 0, 0);
                    panOffset.set(0, 0, 0);
                }
                // adjust camera position
                if (scope.zoomToCursor && performCursorZoom) {
                    let newRadius = null;
                    if (scope.object.isPerspectiveCamera) {
                        // move the camera down the pointer ray
                        // this method avoids floating point error
                        const prevRadius = offset.length();
                        newRadius = clampDistance(prevRadius * scale);
                        const radiusDelta = prevRadius - newRadius;
                        scope.object.position.addScaledVector(dollyDirection, radiusDelta);
                        scope.object.updateMatrixWorld();
                        zoomChanged = !!radiusDelta;
                    } else if (scope.object.isOrthographicCamera) {
                        // adjust the ortho camera position based on zoom changes
                        const mouseBefore = new (0, _three.Vector3)(mouse.x, mouse.y, 0);
                        mouseBefore.unproject(scope.object);
                        const prevZoom = scope.object.zoom;
                        scope.object.zoom = Math.max(scope.minZoom, Math.min(scope.maxZoom, scope.object.zoom / scale));
                        scope.object.updateProjectionMatrix();
                        zoomChanged = prevZoom !== scope.object.zoom;
                        const mouseAfter = new (0, _three.Vector3)(mouse.x, mouse.y, 0);
                        mouseAfter.unproject(scope.object);
                        scope.object.position.sub(mouseAfter).add(mouseBefore);
                        scope.object.updateMatrixWorld();
                        newRadius = offset.length();
                    } else {
                        console.warn("WARNING: OrbitControls.js encountered an unknown camera type - zoom to cursor disabled.");
                        scope.zoomToCursor = false;
                    }
                    // handle the placement of the target
                    if (newRadius !== null) {
                        if (this.screenSpacePanning) // position the orbit target in front of the new camera position
                        scope.target.set(0, 0, -1).transformDirection(scope.object.matrix).multiplyScalar(newRadius).add(scope.object.position);
                        else {
                            // get the ray and translation plane to compute target
                            _ray.origin.copy(scope.object.position);
                            _ray.direction.set(0, 0, -1).transformDirection(scope.object.matrix);
                            // if the camera is 20 degrees above the horizon then don't adjust the focus target to avoid
                            // extremely large values
                            if (Math.abs(scope.object.up.dot(_ray.direction)) < TILT_LIMIT) object.lookAt(scope.target);
                            else {
                                _plane.setFromNormalAndCoplanarPoint(scope.object.up, scope.target);
                                _ray.intersectPlane(_plane, scope.target);
                            }
                        }
                    }
                } else if (scope.object.isOrthographicCamera) {
                    const prevZoom = scope.object.zoom;
                    scope.object.zoom = Math.max(scope.minZoom, Math.min(scope.maxZoom, scope.object.zoom / scale));
                    if (prevZoom !== scope.object.zoom) {
                        scope.object.updateProjectionMatrix();
                        zoomChanged = true;
                    }
                }
                scale = 1;
                performCursorZoom = false;
                // update condition is:
                // min(camera displacement, camera rotation in radians)^2 > EPS
                // using small-angle approximation cos(x/2) = 1 - x^2 / 8
                if (zoomChanged || lastPosition.distanceToSquared(scope.object.position) > EPS || 8 * (1 - lastQuaternion.dot(scope.object.quaternion)) > EPS || lastTargetPosition.distanceToSquared(scope.target) > EPS) {
                    scope.dispatchEvent(_changeEvent);
                    lastPosition.copy(scope.object.position);
                    lastQuaternion.copy(scope.object.quaternion);
                    lastTargetPosition.copy(scope.target);
                    return true;
                }
                return false;
            };
        }();
        this.dispose = function() {
            scope.domElement.removeEventListener("contextmenu", onContextMenu);
            scope.domElement.removeEventListener("pointerdown", onPointerDown);
            scope.domElement.removeEventListener("pointercancel", onPointerUp);
            scope.domElement.removeEventListener("wheel", onMouseWheel);
            scope.domElement.removeEventListener("pointermove", onPointerMove);
            scope.domElement.removeEventListener("pointerup", onPointerUp);
            const document = scope.domElement.getRootNode(); // offscreen canvas compatibility
            document.removeEventListener("keydown", interceptControlDown, {
                capture: true
            });
            if (scope._domElementKeyEvents !== null) {
                scope._domElementKeyEvents.removeEventListener("keydown", onKeyDown);
                scope._domElementKeyEvents = null;
            }
        //scope.dispatchEvent( { type: 'dispose' } ); // should this be added here?
        };
        //
        // internals
        //
        const scope = this;
        const STATE = {
            NONE: -1,
            ROTATE: 0,
            DOLLY: 1,
            PAN: 2,
            TOUCH_ROTATE: 3,
            TOUCH_PAN: 4,
            TOUCH_DOLLY_PAN: 5,
            TOUCH_DOLLY_ROTATE: 6
        };
        let state = STATE.NONE;
        const EPS = 0.000001;
        // current position in spherical coordinates
        const spherical = new (0, _three.Spherical)();
        const sphericalDelta = new (0, _three.Spherical)();
        let scale = 1;
        const panOffset = new (0, _three.Vector3)();
        const rotateStart = new (0, _three.Vector2)();
        const rotateEnd = new (0, _three.Vector2)();
        const rotateDelta = new (0, _three.Vector2)();
        const panStart = new (0, _three.Vector2)();
        const panEnd = new (0, _three.Vector2)();
        const panDelta = new (0, _three.Vector2)();
        const dollyStart = new (0, _three.Vector2)();
        const dollyEnd = new (0, _three.Vector2)();
        const dollyDelta = new (0, _three.Vector2)();
        const dollyDirection = new (0, _three.Vector3)();
        const mouse = new (0, _three.Vector2)();
        let performCursorZoom = false;
        const pointers = [];
        const pointerPositions = {};
        let controlActive = false;
        function getAutoRotationAngle(deltaTime) {
            if (deltaTime !== null) return 2 * Math.PI / 60 * scope.autoRotateSpeed * deltaTime;
            else return 2 * Math.PI / 60 / 60 * scope.autoRotateSpeed;
        }
        function getZoomScale(delta) {
            const normalizedDelta = Math.abs(delta * 0.01);
            return Math.pow(0.95, scope.zoomSpeed * normalizedDelta);
        }
        function rotateLeft(angle) {
            sphericalDelta.theta -= angle;
        }
        function rotateUp(angle) {
            sphericalDelta.phi -= angle;
        }
        const panLeft = function() {
            const v = new (0, _three.Vector3)();
            return function panLeft(distance, objectMatrix) {
                v.setFromMatrixColumn(objectMatrix, 0); // get X column of objectMatrix
                v.multiplyScalar(-distance);
                panOffset.add(v);
            };
        }();
        const panUp = function() {
            const v = new (0, _three.Vector3)();
            return function panUp(distance, objectMatrix) {
                if (scope.screenSpacePanning === true) v.setFromMatrixColumn(objectMatrix, 1);
                else {
                    v.setFromMatrixColumn(objectMatrix, 0);
                    v.crossVectors(scope.object.up, v);
                }
                v.multiplyScalar(distance);
                panOffset.add(v);
            };
        }();
        // deltaX and deltaY are in pixels; right and down are positive
        const pan = function() {
            const offset = new (0, _three.Vector3)();
            return function pan(deltaX, deltaY) {
                const element = scope.domElement;
                if (scope.object.isPerspectiveCamera) {
                    // perspective
                    const position = scope.object.position;
                    offset.copy(position).sub(scope.target);
                    let targetDistance = offset.length();
                    // half of the fov is center to top of screen
                    targetDistance *= Math.tan(scope.object.fov / 2 * Math.PI / 180.0);
                    // we use only clientHeight here so aspect ratio does not distort speed
                    panLeft(2 * deltaX * targetDistance / element.clientHeight, scope.object.matrix);
                    panUp(2 * deltaY * targetDistance / element.clientHeight, scope.object.matrix);
                } else if (scope.object.isOrthographicCamera) {
                    // orthographic
                    panLeft(deltaX * (scope.object.right - scope.object.left) / scope.object.zoom / element.clientWidth, scope.object.matrix);
                    panUp(deltaY * (scope.object.top - scope.object.bottom) / scope.object.zoom / element.clientHeight, scope.object.matrix);
                } else {
                    // camera neither orthographic nor perspective
                    console.warn("WARNING: OrbitControls.js encountered an unknown camera type - pan disabled.");
                    scope.enablePan = false;
                }
            };
        }();
        function dollyOut(dollyScale) {
            if (scope.object.isPerspectiveCamera || scope.object.isOrthographicCamera) scale /= dollyScale;
            else {
                console.warn("WARNING: OrbitControls.js encountered an unknown camera type - dolly/zoom disabled.");
                scope.enableZoom = false;
            }
        }
        function dollyIn(dollyScale) {
            if (scope.object.isPerspectiveCamera || scope.object.isOrthographicCamera) scale *= dollyScale;
            else {
                console.warn("WARNING: OrbitControls.js encountered an unknown camera type - dolly/zoom disabled.");
                scope.enableZoom = false;
            }
        }
        function updateZoomParameters(x, y) {
            if (!scope.zoomToCursor) return;
            performCursorZoom = true;
            const rect = scope.domElement.getBoundingClientRect();
            const dx = x - rect.left;
            const dy = y - rect.top;
            const w = rect.width;
            const h = rect.height;
            mouse.x = dx / w * 2 - 1;
            mouse.y = -(dy / h) * 2 + 1;
            dollyDirection.set(mouse.x, mouse.y, 1).unproject(scope.object).sub(scope.object.position).normalize();
        }
        function clampDistance(dist) {
            return Math.max(scope.minDistance, Math.min(scope.maxDistance, dist));
        }
        //
        // event callbacks - update the object state
        //
        function handleMouseDownRotate(event) {
            rotateStart.set(event.clientX, event.clientY);
        }
        function handleMouseDownDolly(event) {
            updateZoomParameters(event.clientX, event.clientX);
            dollyStart.set(event.clientX, event.clientY);
        }
        function handleMouseDownPan(event) {
            panStart.set(event.clientX, event.clientY);
        }
        function handleMouseMoveRotate(event) {
            rotateEnd.set(event.clientX, event.clientY);
            rotateDelta.subVectors(rotateEnd, rotateStart).multiplyScalar(scope.rotateSpeed);
            const element = scope.domElement;
            rotateLeft(2 * Math.PI * rotateDelta.x / element.clientHeight); // yes, height
            rotateUp(2 * Math.PI * rotateDelta.y / element.clientHeight);
            rotateStart.copy(rotateEnd);
            scope.update();
        }
        function handleMouseMoveDolly(event) {
            dollyEnd.set(event.clientX, event.clientY);
            dollyDelta.subVectors(dollyEnd, dollyStart);
            if (dollyDelta.y > 0) dollyOut(getZoomScale(dollyDelta.y));
            else if (dollyDelta.y < 0) dollyIn(getZoomScale(dollyDelta.y));
            dollyStart.copy(dollyEnd);
            scope.update();
        }
        function handleMouseMovePan(event) {
            panEnd.set(event.clientX, event.clientY);
            panDelta.subVectors(panEnd, panStart).multiplyScalar(scope.panSpeed);
            pan(panDelta.x, panDelta.y);
            panStart.copy(panEnd);
            scope.update();
        }
        function handleMouseWheel(event) {
            updateZoomParameters(event.clientX, event.clientY);
            if (event.deltaY < 0) dollyIn(getZoomScale(event.deltaY));
            else if (event.deltaY > 0) dollyOut(getZoomScale(event.deltaY));
            scope.update();
        }
        function handleKeyDown(event) {
            let needsUpdate = false;
            switch(event.code){
                case scope.keys.UP:
                    if (event.ctrlKey || event.metaKey || event.shiftKey) rotateUp(2 * Math.PI * scope.rotateSpeed / scope.domElement.clientHeight);
                    else pan(0, scope.keyPanSpeed);
                    needsUpdate = true;
                    break;
                case scope.keys.BOTTOM:
                    if (event.ctrlKey || event.metaKey || event.shiftKey) rotateUp(-2 * Math.PI * scope.rotateSpeed / scope.domElement.clientHeight);
                    else pan(0, -scope.keyPanSpeed);
                    needsUpdate = true;
                    break;
                case scope.keys.LEFT:
                    if (event.ctrlKey || event.metaKey || event.shiftKey) rotateLeft(2 * Math.PI * scope.rotateSpeed / scope.domElement.clientHeight);
                    else pan(scope.keyPanSpeed, 0);
                    needsUpdate = true;
                    break;
                case scope.keys.RIGHT:
                    if (event.ctrlKey || event.metaKey || event.shiftKey) rotateLeft(-2 * Math.PI * scope.rotateSpeed / scope.domElement.clientHeight);
                    else pan(-scope.keyPanSpeed, 0);
                    needsUpdate = true;
                    break;
            }
            if (needsUpdate) {
                // prevent the browser from scrolling on cursor keys
                event.preventDefault();
                scope.update();
            }
        }
        function handleTouchStartRotate(event) {
            if (pointers.length === 1) rotateStart.set(event.pageX, event.pageY);
            else {
                const position = getSecondPointerPosition(event);
                const x = 0.5 * (event.pageX + position.x);
                const y = 0.5 * (event.pageY + position.y);
                rotateStart.set(x, y);
            }
        }
        function handleTouchStartPan(event) {
            if (pointers.length === 1) panStart.set(event.pageX, event.pageY);
            else {
                const position = getSecondPointerPosition(event);
                const x = 0.5 * (event.pageX + position.x);
                const y = 0.5 * (event.pageY + position.y);
                panStart.set(x, y);
            }
        }
        function handleTouchStartDolly(event) {
            const position = getSecondPointerPosition(event);
            const dx = event.pageX - position.x;
            const dy = event.pageY - position.y;
            const distance = Math.sqrt(dx * dx + dy * dy);
            dollyStart.set(0, distance);
        }
        function handleTouchStartDollyPan(event) {
            if (scope.enableZoom) handleTouchStartDolly(event);
            if (scope.enablePan) handleTouchStartPan(event);
        }
        function handleTouchStartDollyRotate(event) {
            if (scope.enableZoom) handleTouchStartDolly(event);
            if (scope.enableRotate) handleTouchStartRotate(event);
        }
        function handleTouchMoveRotate(event) {
            if (pointers.length == 1) rotateEnd.set(event.pageX, event.pageY);
            else {
                const position = getSecondPointerPosition(event);
                const x = 0.5 * (event.pageX + position.x);
                const y = 0.5 * (event.pageY + position.y);
                rotateEnd.set(x, y);
            }
            rotateDelta.subVectors(rotateEnd, rotateStart).multiplyScalar(scope.rotateSpeed);
            const element = scope.domElement;
            rotateLeft(2 * Math.PI * rotateDelta.x / element.clientHeight); // yes, height
            rotateUp(2 * Math.PI * rotateDelta.y / element.clientHeight);
            rotateStart.copy(rotateEnd);
        }
        function handleTouchMovePan(event) {
            if (pointers.length === 1) panEnd.set(event.pageX, event.pageY);
            else {
                const position = getSecondPointerPosition(event);
                const x = 0.5 * (event.pageX + position.x);
                const y = 0.5 * (event.pageY + position.y);
                panEnd.set(x, y);
            }
            panDelta.subVectors(panEnd, panStart).multiplyScalar(scope.panSpeed);
            pan(panDelta.x, panDelta.y);
            panStart.copy(panEnd);
        }
        function handleTouchMoveDolly(event) {
            const position = getSecondPointerPosition(event);
            const dx = event.pageX - position.x;
            const dy = event.pageY - position.y;
            const distance = Math.sqrt(dx * dx + dy * dy);
            dollyEnd.set(0, distance);
            dollyDelta.set(0, Math.pow(dollyEnd.y / dollyStart.y, scope.zoomSpeed));
            dollyOut(dollyDelta.y);
            dollyStart.copy(dollyEnd);
            const centerX = (event.pageX + position.x) * 0.5;
            const centerY = (event.pageY + position.y) * 0.5;
            updateZoomParameters(centerX, centerY);
        }
        function handleTouchMoveDollyPan(event) {
            if (scope.enableZoom) handleTouchMoveDolly(event);
            if (scope.enablePan) handleTouchMovePan(event);
        }
        function handleTouchMoveDollyRotate(event) {
            if (scope.enableZoom) handleTouchMoveDolly(event);
            if (scope.enableRotate) handleTouchMoveRotate(event);
        }
        //
        // event handlers - FSM: listen for events and reset state
        //
        function onPointerDown(event) {
            if (scope.enabled === false) return;
            if (pointers.length === 0) {
                scope.domElement.setPointerCapture(event.pointerId);
                scope.domElement.addEventListener("pointermove", onPointerMove);
                scope.domElement.addEventListener("pointerup", onPointerUp);
            }
            //
            if (isTrackingPointer(event)) return;
            //
            addPointer(event);
            if (event.pointerType === "touch") onTouchStart(event);
            else onMouseDown(event);
        }
        function onPointerMove(event) {
            if (scope.enabled === false) return;
            if (event.pointerType === "touch") onTouchMove(event);
            else onMouseMove(event);
        }
        function onPointerUp(event) {
            removePointer(event);
            switch(pointers.length){
                case 0:
                    scope.domElement.releasePointerCapture(event.pointerId);
                    scope.domElement.removeEventListener("pointermove", onPointerMove);
                    scope.domElement.removeEventListener("pointerup", onPointerUp);
                    scope.dispatchEvent(_endEvent);
                    state = STATE.NONE;
                    break;
                case 1:
                    const pointerId = pointers[0];
                    const position = pointerPositions[pointerId];
                    // minimal placeholder event - allows state correction on pointer-up
                    onTouchStart({
                        pointerId: pointerId,
                        pageX: position.x,
                        pageY: position.y
                    });
                    break;
            }
        }
        function onMouseDown(event) {
            let mouseAction;
            switch(event.button){
                case 0:
                    mouseAction = scope.mouseButtons.LEFT;
                    break;
                case 1:
                    mouseAction = scope.mouseButtons.MIDDLE;
                    break;
                case 2:
                    mouseAction = scope.mouseButtons.RIGHT;
                    break;
                default:
                    mouseAction = -1;
            }
            switch(mouseAction){
                case (0, _three.MOUSE).DOLLY:
                    if (scope.enableZoom === false) return;
                    handleMouseDownDolly(event);
                    state = STATE.DOLLY;
                    break;
                case (0, _three.MOUSE).ROTATE:
                    if (event.ctrlKey || event.metaKey || event.shiftKey) {
                        if (scope.enablePan === false) return;
                        handleMouseDownPan(event);
                        state = STATE.PAN;
                    } else {
                        if (scope.enableRotate === false) return;
                        handleMouseDownRotate(event);
                        state = STATE.ROTATE;
                    }
                    break;
                case (0, _three.MOUSE).PAN:
                    if (event.ctrlKey || event.metaKey || event.shiftKey) {
                        if (scope.enableRotate === false) return;
                        handleMouseDownRotate(event);
                        state = STATE.ROTATE;
                    } else {
                        if (scope.enablePan === false) return;
                        handleMouseDownPan(event);
                        state = STATE.PAN;
                    }
                    break;
                default:
                    state = STATE.NONE;
            }
            if (state !== STATE.NONE) scope.dispatchEvent(_startEvent);
        }
        function onMouseMove(event) {
            switch(state){
                case STATE.ROTATE:
                    if (scope.enableRotate === false) return;
                    handleMouseMoveRotate(event);
                    break;
                case STATE.DOLLY:
                    if (scope.enableZoom === false) return;
                    handleMouseMoveDolly(event);
                    break;
                case STATE.PAN:
                    if (scope.enablePan === false) return;
                    handleMouseMovePan(event);
                    break;
            }
        }
        function onMouseWheel(event) {
            if (scope.enabled === false || scope.enableZoom === false || state !== STATE.NONE) return;
            event.preventDefault();
            scope.dispatchEvent(_startEvent);
            handleMouseWheel(customWheelEvent(event));
            scope.dispatchEvent(_endEvent);
        }
        function customWheelEvent(event) {
            const mode = event.deltaMode;
            // minimal wheel event altered to meet delta-zoom demand
            const newEvent = {
                clientX: event.clientX,
                clientY: event.clientY,
                deltaY: event.deltaY
            };
            switch(mode){
                case 1:
                    newEvent.deltaY *= 16;
                    break;
                case 2:
                    newEvent.deltaY *= 100;
                    break;
            }
            // detect if event was triggered by pinching
            if (event.ctrlKey && !controlActive) newEvent.deltaY *= 10;
            return newEvent;
        }
        function interceptControlDown(event) {
            if (event.key === "Control") {
                controlActive = true;
                const document = scope.domElement.getRootNode(); // offscreen canvas compatibility
                document.addEventListener("keyup", interceptControlUp, {
                    passive: true,
                    capture: true
                });
            }
        }
        function interceptControlUp(event) {
            if (event.key === "Control") {
                controlActive = false;
                const document = scope.domElement.getRootNode(); // offscreen canvas compatibility
                document.removeEventListener("keyup", interceptControlUp, {
                    passive: true,
                    capture: true
                });
            }
        }
        function onKeyDown(event) {
            if (scope.enabled === false || scope.enablePan === false) return;
            handleKeyDown(event);
        }
        function onTouchStart(event) {
            trackPointer(event);
            switch(pointers.length){
                case 1:
                    switch(scope.touches.ONE){
                        case (0, _three.TOUCH).ROTATE:
                            if (scope.enableRotate === false) return;
                            handleTouchStartRotate(event);
                            state = STATE.TOUCH_ROTATE;
                            break;
                        case (0, _three.TOUCH).PAN:
                            if (scope.enablePan === false) return;
                            handleTouchStartPan(event);
                            state = STATE.TOUCH_PAN;
                            break;
                        default:
                            state = STATE.NONE;
                    }
                    break;
                case 2:
                    switch(scope.touches.TWO){
                        case (0, _three.TOUCH).DOLLY_PAN:
                            if (scope.enableZoom === false && scope.enablePan === false) return;
                            handleTouchStartDollyPan(event);
                            state = STATE.TOUCH_DOLLY_PAN;
                            break;
                        case (0, _three.TOUCH).DOLLY_ROTATE:
                            if (scope.enableZoom === false && scope.enableRotate === false) return;
                            handleTouchStartDollyRotate(event);
                            state = STATE.TOUCH_DOLLY_ROTATE;
                            break;
                        default:
                            state = STATE.NONE;
                    }
                    break;
                default:
                    state = STATE.NONE;
            }
            if (state !== STATE.NONE) scope.dispatchEvent(_startEvent);
        }
        function onTouchMove(event) {
            trackPointer(event);
            switch(state){
                case STATE.TOUCH_ROTATE:
                    if (scope.enableRotate === false) return;
                    handleTouchMoveRotate(event);
                    scope.update();
                    break;
                case STATE.TOUCH_PAN:
                    if (scope.enablePan === false) return;
                    handleTouchMovePan(event);
                    scope.update();
                    break;
                case STATE.TOUCH_DOLLY_PAN:
                    if (scope.enableZoom === false && scope.enablePan === false) return;
                    handleTouchMoveDollyPan(event);
                    scope.update();
                    break;
                case STATE.TOUCH_DOLLY_ROTATE:
                    if (scope.enableZoom === false && scope.enableRotate === false) return;
                    handleTouchMoveDollyRotate(event);
                    scope.update();
                    break;
                default:
                    state = STATE.NONE;
            }
        }
        function onContextMenu(event) {
            if (scope.enabled === false) return;
            event.preventDefault();
        }
        function addPointer(event) {
            pointers.push(event.pointerId);
        }
        function removePointer(event) {
            delete pointerPositions[event.pointerId];
            for(let i = 0; i < pointers.length; i++)if (pointers[i] == event.pointerId) {
                pointers.splice(i, 1);
                return;
            }
        }
        function isTrackingPointer(event) {
            for(let i = 0; i < pointers.length; i++){
                if (pointers[i] == event.pointerId) return true;
            }
            return false;
        }
        function trackPointer(event) {
            let position = pointerPositions[event.pointerId];
            if (position === undefined) {
                position = new (0, _three.Vector2)();
                pointerPositions[event.pointerId] = position;
            }
            position.set(event.pageX, event.pageY);
        }
        function getSecondPointerPosition(event) {
            const pointerId = event.pointerId === pointers[0] ? pointers[1] : pointers[0];
            return pointerPositions[pointerId];
        }
        //
        scope.domElement.addEventListener("contextmenu", onContextMenu);
        scope.domElement.addEventListener("pointerdown", onPointerDown);
        scope.domElement.addEventListener("pointercancel", onPointerUp);
        scope.domElement.addEventListener("wheel", onMouseWheel, {
            passive: false
        });
        const document = scope.domElement.getRootNode(); // offscreen canvas compatibility
        document.addEventListener("keydown", interceptControlDown, {
            passive: true,
            capture: true
        });
        // force an update at start
        this.update();
    }
}

},{"three":"ktPTu","@parcel/transformer-js/src/esmodule-helpers.js":"gkKU3"}]},["aP7aF","8lRBv"], "8lRBv", "parcelRequireba6b")

//# sourceMappingURL=index.59a40e7a.js.map
